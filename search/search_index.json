{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 Welcome to the EKS Best Practices Guides. The primary goal of this project is to offer a set of best practices for day 2 operations for Amazon EKS. We elected to publish this guidance to GitHub so we could iterate quickly, provide timely and effective recommendations for variety of concerns, and easily incorporate suggestions from the broader community. We currently have published guides for the following topics: Best Practices for Security Best Practices for Reliability Best Practices for Cluster Autoscaling: karpenter , cluster-autoscaler Best Practices for Running Windows Containers Best Practices for Networking In the future we will be publishing best practices guidance for performance, cost optimization, and operational excellence. Contributing \u00b6 We encourage you to contribute to these guides. If you have implemented a practice that has proven to be effective, please share it with us by opening an issue or a pull request. Similarly, if you discover an error or flaw in the guidance we've already published, please submit a PR to correct it.","title":"Introduction"},{"location":"#introduction","text":"Welcome to the EKS Best Practices Guides. The primary goal of this project is to offer a set of best practices for day 2 operations for Amazon EKS. We elected to publish this guidance to GitHub so we could iterate quickly, provide timely and effective recommendations for variety of concerns, and easily incorporate suggestions from the broader community. We currently have published guides for the following topics: Best Practices for Security Best Practices for Reliability Best Practices for Cluster Autoscaling: karpenter , cluster-autoscaler Best Practices for Running Windows Containers Best Practices for Networking In the future we will be publishing best practices guidance for performance, cost optimization, and operational excellence.","title":"Introduction"},{"location":"#contributing","text":"We encourage you to contribute to these guides. If you have implemented a practice that has proven to be effective, please share it with us by opening an issue or a pull request. Similarly, if you discover an error or flaw in the guidance we've already published, please submit a PR to correct it.","title":"Contributing"},{"location":"cluster-autoscaling/","text":"Kubernetes Cluster Autoscaler \u00b6 Overview \u00b6 The Kubernetes Cluster Autoscaler is a popular Cluster Autoscaling solution maintained by SIG Autoscaling . It is responsible for ensuring that your cluster has enough nodes to schedule your pods without wasting resources. It watches for pods that fail to schedule and for nodes that are underutilized. It then simulates the addition or removal of nodes before applying the change to your cluster. The AWS Cloud Provider implementation within Cluster Autoscaler controls the .DesiredReplicas field of your EC2 Auto Scaling Groups. This guide will provide a mental model for configuring the Cluster Autoscaler and choosing the best set of tradeoffs to meet your organization\u2019s requirements. While there is no single best configuration, there are a set of configuration options that enable you to trade off performance, scalability, cost, and availability. Additionally, this guide will provide tips and best practices for optimizing your configuration for AWS. Glossary \u00b6 The following terminology will be used frequently throughout this document. These terms can have broad meaning, but are limited to the definitions below for the purposes of this document. Scalability refers to how well the Cluster Autoscaler performs as your Kubernetes Cluster increases in number of pods and nodes. As scalability limits are reached, the Cluster Autoscaler\u2019s performance and functionality degrades. As the Cluster Autoscaler exceeds its scalability limits, it may no longer add or remove nodes in your cluster. Performance refers to how quickly the Cluster Autoscaler is able to make and execute scaling decisions. A perfectly performing Cluster Autoscaler would instantly make a decision and trigger a scaling action in response to stimuli, such as a pod becoming unschedulable. Availability means that pods can be scheduled quickly and without disruption. This includes when newly created pods need to be scheduled and when a scaled down node terminates any remaining pods scheduled to it. Cost is determined by the decision behind scale out and scale in events. Resources are wasted if an existing node is underutilized or a new node is added that is too large for incoming pods. Depending on the use case, there can be costs associated with prematurely terminating pods due to an aggressive scale down decision. Node Groups are an abstract Kubernetes concept for a group of nodes within a cluster. It is not a true Kubernetes resource, but exists as an abstraction in the Cluster Autoscaler, Cluster API, and other components. Nodes within a Node Group share properties like labels and taints, but may consist of multiple Availability Zones or Instance Types. EC2 Auto Scaling Groups can be used as an implementation of Node Groups on EC2. EC2 Auto Scaling Groups are configured to launch instances that automatically join their Kubernetes Clusters and apply labels and taints to their corresponding Node resource in the Kubernetes API. EC2 Managed Node Groups are another implementation of Node Groups on EC2. They abstract away the complexity manually configuring EC2 Autoscaling Scaling Groups and provide additional management features like node version upgrade and graceful node termination. Operating the Cluster Autoscaler \u00b6 The Cluster Autoscaler is typically installed as a Deployment in your cluster. It uses leader election to ensure high availability, but work is done by a single replica at a time. It is not horizontally scalable. For basic setups, the default it should work out of the box using the provided installation instructions , but there are a few things to keep in mind. Ensure that: The Cluster Autoscaler\u2019s version matches the Cluster\u2019s Version. Cross version compatibility is not tested or supported . Auto Discovery is enabled, unless you have specific advanced use cases that prevent use of this mode. Employ least privileged access to the IAM role \u00b6 When the Auto Discovery is used, we strongly recommend that you employ least privelege access by limiting Actions autoscaling:SetDesiredCapacity and autoscaling:TerminateInstanceInAutoScalingGroup to the Auto Scaling groups that are scoped to the current cluster. This will prevents a Cluster Autoscaler running in one cluster from modifying nodegroups in a different cluster even if the --node-group-auto-discovery argument wasnt scoped down to the nodegroups of the cluster using tags (for example k8s.io/cluster-autoscaler/<cluster-name> ). { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"autoscaling:SetDesiredCapacity\" , \"autoscaling:TerminateInstanceInAutoScalingGroup\" ], \"Resource\" : \"*\" , \"Condition\" : { \"StringEquals\" : { \"autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled\" : \"true\" , \"aws:ResourceTag/k8s.io/cluster-autoscaler/<my-cluster>\" : \"owned\" } } }, { \"Effect\" : \"Allow\" , \"Action\" : [ \"autoscaling:DescribeAutoScalingInstances\" , \"autoscaling:DescribeAutoScalingGroups\" , \"ec2:DescribeLaunchTemplateVersions\" , \"autoscaling:DescribeTags\" , \"autoscaling:DescribeLaunchConfigurations\" ], \"Resource\" : \"*\" } ] } Configuring your Node Groups \u00b6 Effective autoscaling starts with correctly configuring a set of Node Groups for your cluster. Selecting the right set of Node Groups is key to maximizing availability and reducing cost across your workloads. AWS implements Node Groups using EC2 Auto Scaling Groups, which are flexible to a large number of use cases. However, the Cluster Autoscaler makes some assumptions about your Node Groups. Keeping your EC2 Auto Scaling Group configurations consistent with these assumptions will minimize undesired behavior. Ensure that: Each Node in a Node Group has identical scheduling properties, such as Labels, Taints, and Resources. For MixedInstancePolicies, the Instance Types must be of the same shape for CPU, Memory, and GPU The first Instance Type specified in the policy will be used to simulate scheduling. If your policy has additional Instance Types with more resources, resources may be wasted after scale out. If your policy has additional Instance Types with less resources, pods may fail to schedule on the instances. Node Groups with many nodes are preferred over many Node Groups with fewer nodes. This will have the biggest impact on scalability. Wherever possible, prefer EC2 features when both systems provide support (e.g. Regions, MixedInstancePolicy) Note: We recommend using EKS Managed Node Groups . Managed Node Groups come with powerful management features, including features for Cluster Autoscaler like automatic EC2 Auto Scaling Group discovery and graceful node termination. Optimizing for Performance and Scalability \u00b6 Understanding the autoscaling algorithm\u2019s runtime complexity will help you tune the Cluster Autoscaler to continue operating smoothly in large clusters with greater than 1,000 nodes . The primary knobs for tuning scalability of the Cluster Autoscaler are the resources provided to the process, the scan interval of the algorithm, and the number of Node Groups in the cluster. There are other factors involved in the true runtime complexity of this algorithm, such as scheduling plugin complexity and number of pods. These are considered to be unconfigurable parameters as they are natural to the cluster\u2019s workload and cannot easily be tuned. The Cluster Autoscaler loads the entire cluster\u2019s state into memory, including Pods, Nodes, and Node Groups. On each scan interval, the algorithm identifies unschedulable pods and simulates scheduling for each Node Group. Tuning these factors come with different tradeoffs which should be carefully considered for your use case. Vertically Autoscaling the Cluster Autoscaler \u00b6 The simplest way to scale the Cluster Autoscaler to larger clusters is to increase the resource requests for its deployment. Both memory and CPU should be increased for large clusters, though this varies significantly with cluster size. The autoscaling algorithm stores all pods and nodes in memory, which can result in a memory footprint larger than a gigabyte in some cases. Increasing resources is typically done manually. If you find that constant resource tuning is creating an operational burden, consider using the Addon Resizer or Vertical Pod Autoscaler . Reducing the number of Node Groups \u00b6 Minimizing the number of node groups is one way to ensure that the Cluster Autoscaler will continue to perform well on large clusters. This may be challenging for some organizations who structure their node groups per team or per application. While this is fully supported by the Kubernetes API, this is considered to be a Cluster Autoscaler anti-pattern with repercussions for scalability. There are many reasons to use multiple node groups (e.g. Spot or GPUs), but in many cases there are alternative designs that achieve the same effect while using a small number of groups. Ensure that: Pod isolation is done using Namespaces rather than Node Groups. This may not be possible in low-trust multi-tenant clusters. Pod ResourceRequests and ResourceLimits are properly set to avoid resource contention. Larger instance types will result in more optimal bin packing and reduced system pod overhead. NodeTaints or NodeSelectors are used to schedule pods as the exception, not as the rule. Regional resources are defined as a single EC2 Auto Scaling Group with multiple Availability Zones. Reducing the Scan Interval \u00b6 A low scan interval (e.g. 10 seconds) will ensure that the Cluster Autoscaler responds as quickly as possible when pods become unschedulable. However, each scan results in many API calls to the Kubernetes API and EC2 Auto Scaling Group or EKS Managed Node Group APIs. These API calls can result in rate limiting or even service unavailability for your Kubernetes Control Plane. The default scan interval is 10 seconds, but on AWS, launching a node takes significantly longer to launch a new instance. This means that it\u2019s possible to increase the interval without significantly increasing overall scale up time. For example, if it takes 2 minutes to launch a node, changing the interval to 1 minute will result a tradeoff of 6x reduced API calls for 38% slower scale ups. Sharding Across Node Groups \u00b6 The Cluster Autoscaler can be configured to operate on a specific set of Node Groups. Using this functionality, it\u2019s possible to deploy multiple instances of the Cluster Autoscaler, each configured to operate on a different set of Node Groups. This strategy enables you use arbitrarily large numbers of Node Groups, trading cost for scalability. We only recommend using this as a last resort for improving performance. The Cluster Autoscaler was not originally designed for this configuration, so there are some side effects. Since the shards do not communicate, it\u2019s possible for multiple autoscalers to attempt to schedule an unschedulable pod. This can result in unnecessary scale out of multiple Node Groups. These extra nodes will scale back in after the scale-down-delay . metadata : name : cluster - autoscaler namespace : cluster - autoscaler - 1 ... -- nodes = 1 : 10 : k8s - worker - asg - 1 -- nodes = 1 : 10 : k8s - worker - asg - 2 --- metadata : name : cluster - autoscaler namespace : cluster - autoscaler - 2 ... -- nodes = 1 : 10 : k8s - worker - asg - 3 -- nodes = 1 : 10 : k8s - worker - asg - 4 Ensure that: Each shard is configured to point to a unique set of EC2 Auto Scaling Groups Each shard is deployed to a separate namespace to avoid leader election conflicts Optimizing for Cost and Availability \u00b6 Spot Instances \u00b6 You can use Spot Instances in your node groups and save up to 90% off the on-demand price, with the trade-off the Spot Instances can be interrupted at any time when EC2 needs the capacity back. Insufficient Capacity Errors will occur when your EC2 Auto Scaling group cannot scale up due to lack of available capacity. Maximizing diversity by selecting many instance families can increase your chance of achieving your desired scale by tapping into many Spot capacity pools, and decrease the impact of Spot Instance interruptions on your cluster availability. Mixed Instance Policies with Spot Instances are a great way to increase diversity without increasing the number of node groups. Keep in mind, if you need guaranteed resources, use On-Demand Instances instead of Spot Instances. It\u2019s critical that all Instance Types have similar resource capacity when configuring Mixed Instance Policies. The autoscaler\u2019s scheduling simulator uses the first InstanceType in the MixedInstancePolicy. If subsequent Instance Types are larger, resources may be wasted after a scale up. If smaller, your pods may fail to schedule on the new instances due to insufficient capacity. For example, M4, M5, M5a, and M5n instances all have similar amounts of CPU and Memory and are great candidates for a MixedInstancePolicy. The EC2 Instance Selector tool can help you identify similar instance types. It's recommended to isolate On-Demand and Spot capacity into separate EC2 Auto Scaling groups. This is preferred over using a base capacity strategy because the scheduling properties are fundamentally different. Since Spot Instances be interrupted at any time (when EC2 needs the capacity back), users will often taint their preemptable nodes, requiring an explicit pod toleration to the preemption behavior. These taints result in different scheduling properties for the nodes, so they should be separated into multiple EC2 Auto Scaling Groups. The Cluster Autoscaler has a concept of Expanders , which provide different strategies for selecting which Node Group to scale. The strategy --expander=least-waste is a good general purpose default, and if you're going to use multiple node groups for Spot Instance diversification (as described in the image above), it could help further cost-optimize the node groups by scaling the group which would be best utilized after the scaling activity. Prioritizing a node group / ASG \u00b6 You may also configure priority based autoscaling by using the Priority expander. --expander=priority enables your cluster to prioritize a node group / ASG, and if it is unable to scale for any reason, it will choose the next node group in the prioritized list. This is useful in situations where, for example, you want to use P3 instance types because their GPU provides optimal performance for your workload, but as a second option you can also use P2 instance types. apiVersion : v1 kind : ConfigMap metadata : name : cluster - autoscaler - priority - expander namespace : kube - system data : priorities : |- 10 : - .* p2 - node - group .* 50 : - .* p3 - node - group .* Cluster Autoscaler will try to scale up the EC2 Auto Scaling group matching the name p2-node-group . If this operation does not succeed within --max-node-provision-time , it will attempt to scale an EC2 Auto Scaling group matching the name p3-node-group . This value defaults to 15 minutes and can be reduced for more responsive node group selection, though if the value is too low, it can cause unnecessary scale outs. Overprovisioning \u00b6 The Cluster Autoscaler minimizes costs by ensuring that nodes are only added to the cluster when needed and are removed when unused. This significantly impacts deployment latency because many pods will be forced to wait for a node scale up before they can be scheduled. Nodes can take multiple minutes to become available, which can increase pod scheduling latency by an order of magnitude. This can be mitigated using overprovisioning , which trades cost for scheduling latency. Overprovisioning is implemented using temporary pods with negative priority, which occupy space in the cluster. When newly created pods are unschedulable and have higher priority, the temporary pods will be preempted to make room. The temporary pods then become unschedulable, triggering the Cluster Autoscaler to scale out new overprovisioned nodes. There are other less obvious benefits to overprovisioning. Without overprovisioning, one of the side effects of a highly utilized cluster is that pods will make less optimal scheduling decisions using the preferredDuringSchedulingIgnoredDuringExecution rule of Pod or Node Affinity. A common use case for this is to separate pods for a highly available application across availability zones using AntiAffinity. Overprovisioning can significantly increase the chance that a node of the correct zone is available. The amount of overprovisioned capacity is a careful business decision for your organization. At its core, it\u2019s a tradeoff between performance and cost. One way to make this decision is to determine your average scale up frequency and divide it by the amount of time it takes to scale up a new node. For example, if on average you require a new node every 30 seconds and EC2 takes 30 seconds to provision a new node, a single node of overprovisioning will ensure that there\u2019s always an extra node available, reducing scheduling latency by 30 seconds at the cost of a single additional EC2 Instance. To improve zonal scheduling decisions, overprovision a number of nodes equal to the number of availability zones in your EC2 Auto Scaling Group to ensure that the scheduler can select the best zone for incoming pods. Prevent Scale Down Eviction \u00b6 Some workloads are expensive to evict. Big data analysis, machine learning tasks, and test runners will eventually complete, but must be restarted if interrupted. The Cluster Autoscaler will attempt to scale down any node under the scale-down-utilization-threshold, which will interrupt any remaining pods on the node. This can be prevented by ensuring that pods that are expensive to evict are protected by a label recognized by the Cluster Autoscaler. Ensure that: Expensive to evict pods have the annotation cluster-autoscaler.kubernetes.io/safe-to-evict=false Advanced Use Cases \u00b6 EBS Volumes \u00b6 Persistent storage is critical for building stateful applications, such as database or distributed caches. EBS Volumes enable this use case on Kubernetes, but are limited to a specific zone. These applications can be highly available if sharded across multiple AZs using a separate EBS Volume for each AZ. The Cluster Autoscaler can then balance the scaling of the EC2 Autoscaling Groups. Ensure that: Node group balancing is enabled by setting balance-similar-node-groups=true . Node Groups are configured with identical settings except for different availability zones and EBS Volumes. Co-Scheduling \u00b6 Machine learning distributed training jobs benefit significantly from the minimized latency of same-zone node configurations. These workloads deploy multiple pods to a specific zone. This can be achieved by setting Pod Affinity for all co-scheduled pods or Node Affinity using topologyKey: failure-domain.beta.kubernetes.io/zone . The Cluster Autoscaler will then scale out a specific zone to match demands. You may wish to allocate multiple EC2 Auto Scaling Groups, one per availability zone to enable failover for the entire co-scheduled workload. Ensure that: Node group balancing is enabled by setting balance-similar-node-groups=false Node Affinity and/or Pod Preemption is used when clusters include both Regional and Zonal Node Groups. Use Node Affinity to force or encourage regional pods to avoid zonal Node Groups, and vice versa. If zonal pods schedule onto regional node groups, this will result in imbalanced capacity for your regional pods. If your zonal workloads can tolerate disruption and relocation, configure Pod Preemption to enable regionally scaled pods to force preemption and rescheduling on a less contested zone. Accelerators \u00b6 Some clusters take advantage of specialized hardware accelerators such as GPU. When scaling out, the accelerator device plugin can take several minutes to advertise the resource to the cluster. The Cluster Autoscaler has simulated that this node will have the accelerator, but until the accelerator becomes ready and updates the node\u2019s available resources, pending pods can not be scheduled on the node. This can result in repeated unnecessary scale out . Additionally, nodes with accelerators and high CPU or Memory utilization will not be considered for scale down, even if the accelerator is unused. This behavior can be expensive due to the relative cost of accelerators. Instead, the Cluster Autoscaler can apply special rules to consider nodes for scale down if they have unoccupied accelerators. To ensure the correct behavior for these cases, you can configure the kubelet on your accelerator nodes to label the node before it joins the cluster. The Cluster Autoscaler will use this label selector to trigger the accelerator optimized behavior. Ensure that: The Kubelet for GPU nodes is configured with --node-labels k8s.amazonaws.com/accelerator=$ACCELERATOR_TYPE Nodes with Accelerators adhere to the identical scheduling properties rule noted above. Scaling from 0 \u00b6 Cluster Autoscaler is capable of scaling Node Groups to and from zero, which can yield significant cost savings. It detects the CPU, memory, and GPU resources of an Auto Scaling Group by inspecting the InstanceType specified in its LaunchConfiguration or LaunchTemplate. Some pods require additional resources like WindowsENI or PrivateIPv4Address or specific NodeSelectors or Taints which cannot be discovered from the LaunchConfiguration. The Cluster Autoscaler can account for these factors by discovering them from tags on the EC2 Auto Scaling Group. For example: Key : k8s . io /cluster-autoscaler/node-template/resources/ $RESOURCE_NAME Value : 5 Key : k8s . io /cluster-autoscaler/node-template/label/ $LABEL_KEY Value : $LABEL_VALUE Key : k8s . io /cluster-autoscaler/node-template/taint/ $TAINT_KEY Value : NoSchedule Note: Keep in mind, when scaling to zero your capacity is returned to EC2 and may be unavailable in the future. Additional Parameters \u00b6 There are many configuration options that can be used to tune the behavior and performance of the Cluster Autoscaler. A complete list of parameters is available on Github . Parameter Description Default scan-interval How often cluster is reevaluated for scale up or down 10 seconds max-empty-bulk-delete Maximum number of empty nodes that can be deleted at the same time. 10 scale-down-delay-after-add How long after scale up that scale down evaluation resumes 10 minutes scale-down-delay-after-delete How long after node deletion that scale down evaluation resumes, defaults to scan-interval scan-interval scale-down-delay-after-failure How long after scale down failure that scale down evaluation resumes 3 minutes scale-down-unneeded-time How long a node should be unneeded before it is eligible for scale down 10 minutes scale-down-unready-time How long an unready node should be unneeded before it is eligible for scale down 20 minutes scale-down-utilization-threshold Node utilization level, defined as sum of requested resources divided by capacity, below which a node can be considered for scale down 0.5 scale-down-non-empty-candidates-count Maximum number of non empty nodes considered in one iteration as candidates for scale down with drain. Lower value means better CA responsiveness but possible slower scale down latency. Higher value can affect CA performance with big clusters (hundreds of nodes). Set to non positive value to turn this heuristic off - CA will not limit the number of nodes it considers.\u201c 30 scale-down-candidates-pool-ratio A ratio of nodes that are considered as additional non empty candidates for scale down when some candidates from previous iteration are no longer valid. Lower value means better CA responsiveness but possible slower scale down latency. Higher value can affect CA performance with big clusters (hundreds of nodes). Set to 1.0 to turn this heuristics off - CA will take all nodes as additional candidates. 0.1 scale-down-candidates-pool-min-count Minimum number of nodes that are considered as additional non empty candidates for scale down when some candidates from previous iteration are no longer valid. When calculating the pool size for additional candidates we take max(#nodes * scale-down-candidates-pool-ratio, scale-down-candidates-pool-min-count) 50 Additional Resources \u00b6 This page contains a list of Cluster Autoscaler presentations and demos. If you'd like to add a presentation or demo here, please send a pull request. Presentation/Demo Presenters Autoscaling and Cost Optimization on Kubernetes: From 0 to 100 Guy Templeton, Skyscanner & Jiaxin Shan, Amazon SIG-Autoscaling Deep Dive Maciek Pytel & Marcin Wielgus References \u00b6 https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md https://github.com/aws/amazon-ec2-instance-selector https://github.com/aws/aws-node-termination-handler","title":"Cluster-Autoscaler"},{"location":"cluster-autoscaling/#kubernetes-cluster-autoscaler","text":"","title":"Kubernetes Cluster Autoscaler"},{"location":"cluster-autoscaling/#overview","text":"The Kubernetes Cluster Autoscaler is a popular Cluster Autoscaling solution maintained by SIG Autoscaling . It is responsible for ensuring that your cluster has enough nodes to schedule your pods without wasting resources. It watches for pods that fail to schedule and for nodes that are underutilized. It then simulates the addition or removal of nodes before applying the change to your cluster. The AWS Cloud Provider implementation within Cluster Autoscaler controls the .DesiredReplicas field of your EC2 Auto Scaling Groups. This guide will provide a mental model for configuring the Cluster Autoscaler and choosing the best set of tradeoffs to meet your organization\u2019s requirements. While there is no single best configuration, there are a set of configuration options that enable you to trade off performance, scalability, cost, and availability. Additionally, this guide will provide tips and best practices for optimizing your configuration for AWS.","title":"Overview"},{"location":"cluster-autoscaling/#glossary","text":"The following terminology will be used frequently throughout this document. These terms can have broad meaning, but are limited to the definitions below for the purposes of this document. Scalability refers to how well the Cluster Autoscaler performs as your Kubernetes Cluster increases in number of pods and nodes. As scalability limits are reached, the Cluster Autoscaler\u2019s performance and functionality degrades. As the Cluster Autoscaler exceeds its scalability limits, it may no longer add or remove nodes in your cluster. Performance refers to how quickly the Cluster Autoscaler is able to make and execute scaling decisions. A perfectly performing Cluster Autoscaler would instantly make a decision and trigger a scaling action in response to stimuli, such as a pod becoming unschedulable. Availability means that pods can be scheduled quickly and without disruption. This includes when newly created pods need to be scheduled and when a scaled down node terminates any remaining pods scheduled to it. Cost is determined by the decision behind scale out and scale in events. Resources are wasted if an existing node is underutilized or a new node is added that is too large for incoming pods. Depending on the use case, there can be costs associated with prematurely terminating pods due to an aggressive scale down decision. Node Groups are an abstract Kubernetes concept for a group of nodes within a cluster. It is not a true Kubernetes resource, but exists as an abstraction in the Cluster Autoscaler, Cluster API, and other components. Nodes within a Node Group share properties like labels and taints, but may consist of multiple Availability Zones or Instance Types. EC2 Auto Scaling Groups can be used as an implementation of Node Groups on EC2. EC2 Auto Scaling Groups are configured to launch instances that automatically join their Kubernetes Clusters and apply labels and taints to their corresponding Node resource in the Kubernetes API. EC2 Managed Node Groups are another implementation of Node Groups on EC2. They abstract away the complexity manually configuring EC2 Autoscaling Scaling Groups and provide additional management features like node version upgrade and graceful node termination.","title":"Glossary"},{"location":"cluster-autoscaling/#operating-the-cluster-autoscaler","text":"The Cluster Autoscaler is typically installed as a Deployment in your cluster. It uses leader election to ensure high availability, but work is done by a single replica at a time. It is not horizontally scalable. For basic setups, the default it should work out of the box using the provided installation instructions , but there are a few things to keep in mind. Ensure that: The Cluster Autoscaler\u2019s version matches the Cluster\u2019s Version. Cross version compatibility is not tested or supported . Auto Discovery is enabled, unless you have specific advanced use cases that prevent use of this mode.","title":"Operating the Cluster Autoscaler"},{"location":"cluster-autoscaling/#employ-least-privileged-access-to-the-iam-role","text":"When the Auto Discovery is used, we strongly recommend that you employ least privelege access by limiting Actions autoscaling:SetDesiredCapacity and autoscaling:TerminateInstanceInAutoScalingGroup to the Auto Scaling groups that are scoped to the current cluster. This will prevents a Cluster Autoscaler running in one cluster from modifying nodegroups in a different cluster even if the --node-group-auto-discovery argument wasnt scoped down to the nodegroups of the cluster using tags (for example k8s.io/cluster-autoscaler/<cluster-name> ). { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"autoscaling:SetDesiredCapacity\" , \"autoscaling:TerminateInstanceInAutoScalingGroup\" ], \"Resource\" : \"*\" , \"Condition\" : { \"StringEquals\" : { \"autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled\" : \"true\" , \"aws:ResourceTag/k8s.io/cluster-autoscaler/<my-cluster>\" : \"owned\" } } }, { \"Effect\" : \"Allow\" , \"Action\" : [ \"autoscaling:DescribeAutoScalingInstances\" , \"autoscaling:DescribeAutoScalingGroups\" , \"ec2:DescribeLaunchTemplateVersions\" , \"autoscaling:DescribeTags\" , \"autoscaling:DescribeLaunchConfigurations\" ], \"Resource\" : \"*\" } ] }","title":"Employ least privileged access to the IAM role"},{"location":"cluster-autoscaling/#configuring-your-node-groups","text":"Effective autoscaling starts with correctly configuring a set of Node Groups for your cluster. Selecting the right set of Node Groups is key to maximizing availability and reducing cost across your workloads. AWS implements Node Groups using EC2 Auto Scaling Groups, which are flexible to a large number of use cases. However, the Cluster Autoscaler makes some assumptions about your Node Groups. Keeping your EC2 Auto Scaling Group configurations consistent with these assumptions will minimize undesired behavior. Ensure that: Each Node in a Node Group has identical scheduling properties, such as Labels, Taints, and Resources. For MixedInstancePolicies, the Instance Types must be of the same shape for CPU, Memory, and GPU The first Instance Type specified in the policy will be used to simulate scheduling. If your policy has additional Instance Types with more resources, resources may be wasted after scale out. If your policy has additional Instance Types with less resources, pods may fail to schedule on the instances. Node Groups with many nodes are preferred over many Node Groups with fewer nodes. This will have the biggest impact on scalability. Wherever possible, prefer EC2 features when both systems provide support (e.g. Regions, MixedInstancePolicy) Note: We recommend using EKS Managed Node Groups . Managed Node Groups come with powerful management features, including features for Cluster Autoscaler like automatic EC2 Auto Scaling Group discovery and graceful node termination.","title":"Configuring your Node Groups"},{"location":"cluster-autoscaling/#optimizing-for-performance-and-scalability","text":"Understanding the autoscaling algorithm\u2019s runtime complexity will help you tune the Cluster Autoscaler to continue operating smoothly in large clusters with greater than 1,000 nodes . The primary knobs for tuning scalability of the Cluster Autoscaler are the resources provided to the process, the scan interval of the algorithm, and the number of Node Groups in the cluster. There are other factors involved in the true runtime complexity of this algorithm, such as scheduling plugin complexity and number of pods. These are considered to be unconfigurable parameters as they are natural to the cluster\u2019s workload and cannot easily be tuned. The Cluster Autoscaler loads the entire cluster\u2019s state into memory, including Pods, Nodes, and Node Groups. On each scan interval, the algorithm identifies unschedulable pods and simulates scheduling for each Node Group. Tuning these factors come with different tradeoffs which should be carefully considered for your use case.","title":"Optimizing for Performance and Scalability"},{"location":"cluster-autoscaling/#vertically-autoscaling-the-cluster-autoscaler","text":"The simplest way to scale the Cluster Autoscaler to larger clusters is to increase the resource requests for its deployment. Both memory and CPU should be increased for large clusters, though this varies significantly with cluster size. The autoscaling algorithm stores all pods and nodes in memory, which can result in a memory footprint larger than a gigabyte in some cases. Increasing resources is typically done manually. If you find that constant resource tuning is creating an operational burden, consider using the Addon Resizer or Vertical Pod Autoscaler .","title":"Vertically Autoscaling the Cluster Autoscaler"},{"location":"cluster-autoscaling/#reducing-the-number-of-node-groups","text":"Minimizing the number of node groups is one way to ensure that the Cluster Autoscaler will continue to perform well on large clusters. This may be challenging for some organizations who structure their node groups per team or per application. While this is fully supported by the Kubernetes API, this is considered to be a Cluster Autoscaler anti-pattern with repercussions for scalability. There are many reasons to use multiple node groups (e.g. Spot or GPUs), but in many cases there are alternative designs that achieve the same effect while using a small number of groups. Ensure that: Pod isolation is done using Namespaces rather than Node Groups. This may not be possible in low-trust multi-tenant clusters. Pod ResourceRequests and ResourceLimits are properly set to avoid resource contention. Larger instance types will result in more optimal bin packing and reduced system pod overhead. NodeTaints or NodeSelectors are used to schedule pods as the exception, not as the rule. Regional resources are defined as a single EC2 Auto Scaling Group with multiple Availability Zones.","title":"Reducing the number of Node Groups"},{"location":"cluster-autoscaling/#reducing-the-scan-interval","text":"A low scan interval (e.g. 10 seconds) will ensure that the Cluster Autoscaler responds as quickly as possible when pods become unschedulable. However, each scan results in many API calls to the Kubernetes API and EC2 Auto Scaling Group or EKS Managed Node Group APIs. These API calls can result in rate limiting or even service unavailability for your Kubernetes Control Plane. The default scan interval is 10 seconds, but on AWS, launching a node takes significantly longer to launch a new instance. This means that it\u2019s possible to increase the interval without significantly increasing overall scale up time. For example, if it takes 2 minutes to launch a node, changing the interval to 1 minute will result a tradeoff of 6x reduced API calls for 38% slower scale ups.","title":"Reducing the Scan Interval"},{"location":"cluster-autoscaling/#sharding-across-node-groups","text":"The Cluster Autoscaler can be configured to operate on a specific set of Node Groups. Using this functionality, it\u2019s possible to deploy multiple instances of the Cluster Autoscaler, each configured to operate on a different set of Node Groups. This strategy enables you use arbitrarily large numbers of Node Groups, trading cost for scalability. We only recommend using this as a last resort for improving performance. The Cluster Autoscaler was not originally designed for this configuration, so there are some side effects. Since the shards do not communicate, it\u2019s possible for multiple autoscalers to attempt to schedule an unschedulable pod. This can result in unnecessary scale out of multiple Node Groups. These extra nodes will scale back in after the scale-down-delay . metadata : name : cluster - autoscaler namespace : cluster - autoscaler - 1 ... -- nodes = 1 : 10 : k8s - worker - asg - 1 -- nodes = 1 : 10 : k8s - worker - asg - 2 --- metadata : name : cluster - autoscaler namespace : cluster - autoscaler - 2 ... -- nodes = 1 : 10 : k8s - worker - asg - 3 -- nodes = 1 : 10 : k8s - worker - asg - 4 Ensure that: Each shard is configured to point to a unique set of EC2 Auto Scaling Groups Each shard is deployed to a separate namespace to avoid leader election conflicts","title":"Sharding Across Node Groups"},{"location":"cluster-autoscaling/#optimizing-for-cost-and-availability","text":"","title":"Optimizing for Cost and Availability"},{"location":"cluster-autoscaling/#spot-instances","text":"You can use Spot Instances in your node groups and save up to 90% off the on-demand price, with the trade-off the Spot Instances can be interrupted at any time when EC2 needs the capacity back. Insufficient Capacity Errors will occur when your EC2 Auto Scaling group cannot scale up due to lack of available capacity. Maximizing diversity by selecting many instance families can increase your chance of achieving your desired scale by tapping into many Spot capacity pools, and decrease the impact of Spot Instance interruptions on your cluster availability. Mixed Instance Policies with Spot Instances are a great way to increase diversity without increasing the number of node groups. Keep in mind, if you need guaranteed resources, use On-Demand Instances instead of Spot Instances. It\u2019s critical that all Instance Types have similar resource capacity when configuring Mixed Instance Policies. The autoscaler\u2019s scheduling simulator uses the first InstanceType in the MixedInstancePolicy. If subsequent Instance Types are larger, resources may be wasted after a scale up. If smaller, your pods may fail to schedule on the new instances due to insufficient capacity. For example, M4, M5, M5a, and M5n instances all have similar amounts of CPU and Memory and are great candidates for a MixedInstancePolicy. The EC2 Instance Selector tool can help you identify similar instance types. It's recommended to isolate On-Demand and Spot capacity into separate EC2 Auto Scaling groups. This is preferred over using a base capacity strategy because the scheduling properties are fundamentally different. Since Spot Instances be interrupted at any time (when EC2 needs the capacity back), users will often taint their preemptable nodes, requiring an explicit pod toleration to the preemption behavior. These taints result in different scheduling properties for the nodes, so they should be separated into multiple EC2 Auto Scaling Groups. The Cluster Autoscaler has a concept of Expanders , which provide different strategies for selecting which Node Group to scale. The strategy --expander=least-waste is a good general purpose default, and if you're going to use multiple node groups for Spot Instance diversification (as described in the image above), it could help further cost-optimize the node groups by scaling the group which would be best utilized after the scaling activity.","title":"Spot Instances"},{"location":"cluster-autoscaling/#prioritizing-a-node-group-asg","text":"You may also configure priority based autoscaling by using the Priority expander. --expander=priority enables your cluster to prioritize a node group / ASG, and if it is unable to scale for any reason, it will choose the next node group in the prioritized list. This is useful in situations where, for example, you want to use P3 instance types because their GPU provides optimal performance for your workload, but as a second option you can also use P2 instance types. apiVersion : v1 kind : ConfigMap metadata : name : cluster - autoscaler - priority - expander namespace : kube - system data : priorities : |- 10 : - .* p2 - node - group .* 50 : - .* p3 - node - group .* Cluster Autoscaler will try to scale up the EC2 Auto Scaling group matching the name p2-node-group . If this operation does not succeed within --max-node-provision-time , it will attempt to scale an EC2 Auto Scaling group matching the name p3-node-group . This value defaults to 15 minutes and can be reduced for more responsive node group selection, though if the value is too low, it can cause unnecessary scale outs.","title":"Prioritizing a node group / ASG"},{"location":"cluster-autoscaling/#overprovisioning","text":"The Cluster Autoscaler minimizes costs by ensuring that nodes are only added to the cluster when needed and are removed when unused. This significantly impacts deployment latency because many pods will be forced to wait for a node scale up before they can be scheduled. Nodes can take multiple minutes to become available, which can increase pod scheduling latency by an order of magnitude. This can be mitigated using overprovisioning , which trades cost for scheduling latency. Overprovisioning is implemented using temporary pods with negative priority, which occupy space in the cluster. When newly created pods are unschedulable and have higher priority, the temporary pods will be preempted to make room. The temporary pods then become unschedulable, triggering the Cluster Autoscaler to scale out new overprovisioned nodes. There are other less obvious benefits to overprovisioning. Without overprovisioning, one of the side effects of a highly utilized cluster is that pods will make less optimal scheduling decisions using the preferredDuringSchedulingIgnoredDuringExecution rule of Pod or Node Affinity. A common use case for this is to separate pods for a highly available application across availability zones using AntiAffinity. Overprovisioning can significantly increase the chance that a node of the correct zone is available. The amount of overprovisioned capacity is a careful business decision for your organization. At its core, it\u2019s a tradeoff between performance and cost. One way to make this decision is to determine your average scale up frequency and divide it by the amount of time it takes to scale up a new node. For example, if on average you require a new node every 30 seconds and EC2 takes 30 seconds to provision a new node, a single node of overprovisioning will ensure that there\u2019s always an extra node available, reducing scheduling latency by 30 seconds at the cost of a single additional EC2 Instance. To improve zonal scheduling decisions, overprovision a number of nodes equal to the number of availability zones in your EC2 Auto Scaling Group to ensure that the scheduler can select the best zone for incoming pods.","title":"Overprovisioning"},{"location":"cluster-autoscaling/#prevent-scale-down-eviction","text":"Some workloads are expensive to evict. Big data analysis, machine learning tasks, and test runners will eventually complete, but must be restarted if interrupted. The Cluster Autoscaler will attempt to scale down any node under the scale-down-utilization-threshold, which will interrupt any remaining pods on the node. This can be prevented by ensuring that pods that are expensive to evict are protected by a label recognized by the Cluster Autoscaler. Ensure that: Expensive to evict pods have the annotation cluster-autoscaler.kubernetes.io/safe-to-evict=false","title":"Prevent Scale Down Eviction"},{"location":"cluster-autoscaling/#advanced-use-cases","text":"","title":"Advanced Use Cases"},{"location":"cluster-autoscaling/#ebs-volumes","text":"Persistent storage is critical for building stateful applications, such as database or distributed caches. EBS Volumes enable this use case on Kubernetes, but are limited to a specific zone. These applications can be highly available if sharded across multiple AZs using a separate EBS Volume for each AZ. The Cluster Autoscaler can then balance the scaling of the EC2 Autoscaling Groups. Ensure that: Node group balancing is enabled by setting balance-similar-node-groups=true . Node Groups are configured with identical settings except for different availability zones and EBS Volumes.","title":"EBS Volumes"},{"location":"cluster-autoscaling/#co-scheduling","text":"Machine learning distributed training jobs benefit significantly from the minimized latency of same-zone node configurations. These workloads deploy multiple pods to a specific zone. This can be achieved by setting Pod Affinity for all co-scheduled pods or Node Affinity using topologyKey: failure-domain.beta.kubernetes.io/zone . The Cluster Autoscaler will then scale out a specific zone to match demands. You may wish to allocate multiple EC2 Auto Scaling Groups, one per availability zone to enable failover for the entire co-scheduled workload. Ensure that: Node group balancing is enabled by setting balance-similar-node-groups=false Node Affinity and/or Pod Preemption is used when clusters include both Regional and Zonal Node Groups. Use Node Affinity to force or encourage regional pods to avoid zonal Node Groups, and vice versa. If zonal pods schedule onto regional node groups, this will result in imbalanced capacity for your regional pods. If your zonal workloads can tolerate disruption and relocation, configure Pod Preemption to enable regionally scaled pods to force preemption and rescheduling on a less contested zone.","title":"Co-Scheduling"},{"location":"cluster-autoscaling/#accelerators","text":"Some clusters take advantage of specialized hardware accelerators such as GPU. When scaling out, the accelerator device plugin can take several minutes to advertise the resource to the cluster. The Cluster Autoscaler has simulated that this node will have the accelerator, but until the accelerator becomes ready and updates the node\u2019s available resources, pending pods can not be scheduled on the node. This can result in repeated unnecessary scale out . Additionally, nodes with accelerators and high CPU or Memory utilization will not be considered for scale down, even if the accelerator is unused. This behavior can be expensive due to the relative cost of accelerators. Instead, the Cluster Autoscaler can apply special rules to consider nodes for scale down if they have unoccupied accelerators. To ensure the correct behavior for these cases, you can configure the kubelet on your accelerator nodes to label the node before it joins the cluster. The Cluster Autoscaler will use this label selector to trigger the accelerator optimized behavior. Ensure that: The Kubelet for GPU nodes is configured with --node-labels k8s.amazonaws.com/accelerator=$ACCELERATOR_TYPE Nodes with Accelerators adhere to the identical scheduling properties rule noted above.","title":"Accelerators"},{"location":"cluster-autoscaling/#scaling-from-0","text":"Cluster Autoscaler is capable of scaling Node Groups to and from zero, which can yield significant cost savings. It detects the CPU, memory, and GPU resources of an Auto Scaling Group by inspecting the InstanceType specified in its LaunchConfiguration or LaunchTemplate. Some pods require additional resources like WindowsENI or PrivateIPv4Address or specific NodeSelectors or Taints which cannot be discovered from the LaunchConfiguration. The Cluster Autoscaler can account for these factors by discovering them from tags on the EC2 Auto Scaling Group. For example: Key : k8s . io /cluster-autoscaler/node-template/resources/ $RESOURCE_NAME Value : 5 Key : k8s . io /cluster-autoscaler/node-template/label/ $LABEL_KEY Value : $LABEL_VALUE Key : k8s . io /cluster-autoscaler/node-template/taint/ $TAINT_KEY Value : NoSchedule Note: Keep in mind, when scaling to zero your capacity is returned to EC2 and may be unavailable in the future.","title":"Scaling from 0"},{"location":"cluster-autoscaling/#additional-parameters","text":"There are many configuration options that can be used to tune the behavior and performance of the Cluster Autoscaler. A complete list of parameters is available on Github . Parameter Description Default scan-interval How often cluster is reevaluated for scale up or down 10 seconds max-empty-bulk-delete Maximum number of empty nodes that can be deleted at the same time. 10 scale-down-delay-after-add How long after scale up that scale down evaluation resumes 10 minutes scale-down-delay-after-delete How long after node deletion that scale down evaluation resumes, defaults to scan-interval scan-interval scale-down-delay-after-failure How long after scale down failure that scale down evaluation resumes 3 minutes scale-down-unneeded-time How long a node should be unneeded before it is eligible for scale down 10 minutes scale-down-unready-time How long an unready node should be unneeded before it is eligible for scale down 20 minutes scale-down-utilization-threshold Node utilization level, defined as sum of requested resources divided by capacity, below which a node can be considered for scale down 0.5 scale-down-non-empty-candidates-count Maximum number of non empty nodes considered in one iteration as candidates for scale down with drain. Lower value means better CA responsiveness but possible slower scale down latency. Higher value can affect CA performance with big clusters (hundreds of nodes). Set to non positive value to turn this heuristic off - CA will not limit the number of nodes it considers.\u201c 30 scale-down-candidates-pool-ratio A ratio of nodes that are considered as additional non empty candidates for scale down when some candidates from previous iteration are no longer valid. Lower value means better CA responsiveness but possible slower scale down latency. Higher value can affect CA performance with big clusters (hundreds of nodes). Set to 1.0 to turn this heuristics off - CA will take all nodes as additional candidates. 0.1 scale-down-candidates-pool-min-count Minimum number of nodes that are considered as additional non empty candidates for scale down when some candidates from previous iteration are no longer valid. When calculating the pool size for additional candidates we take max(#nodes * scale-down-candidates-pool-ratio, scale-down-candidates-pool-min-count) 50","title":"Additional Parameters"},{"location":"cluster-autoscaling/#additional-resources","text":"This page contains a list of Cluster Autoscaler presentations and demos. If you'd like to add a presentation or demo here, please send a pull request. Presentation/Demo Presenters Autoscaling and Cost Optimization on Kubernetes: From 0 to 100 Guy Templeton, Skyscanner & Jiaxin Shan, Amazon SIG-Autoscaling Deep Dive Maciek Pytel & Marcin Wielgus","title":"Additional Resources"},{"location":"cluster-autoscaling/#references","text":"https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md https://github.com/aws/amazon-ec2-instance-selector https://github.com/aws/aws-node-termination-handler","title":"References"},{"location":"cost_optimization/awareness/","text":"Expenditure awareness \u00b6 Expenditure awareness is understanding who, where and what is causing expenditures in your EKS cluster. Getting an accurate picture of this data will help raise awareness of your spend and highlight areas to remediate. Recommendations \u00b6 Use Cost Explorer \u00b6 AWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time. You can analyze cost and usage data, at various levels using the filters available in Cost Explorer. EKS Control Plane and EKS Fargate costs \u00b6 Using the filters, we can query the costs incurred for the EKS costs at the Control Plane and Fargate Pod as shown in the diagram below: Using the filters, we can query the aggregate costs incurred for the Fargate Pods across regions in EKS - which includes both vCPU-Hours per CPU and GB Hrs as shown in the diagram below: Tagging of Resources \u00b6 Amazon EKS supports adding AWS tags to your Amazon EKS clusters. This makes it easy to control access to the EKS API for managing your clusters. Tags added to an EKS cluster are specific to the AWS EKS cluster resource, they do not propagate to other AWS resources used by the cluster such as EC2 instances or load balancers. Today, cluster tagging is supported for all new and existing EKS clusters via the AWS API, Console, and SDKs. AWS Fargate is a technology that provides on-demand, right-sized compute capacity for containers. Before you can schedule pods on Fargate in your cluster, you must define at least one Fargate profile that specifies which pods should use Fargate when they are launched. Adding and Listing tags to an EKS cluster: $ aws eks tag-resource --resource-arn arn:aws:eks:us-west-2:xxx:cluster/ekscluster1 --tags team = devops,env = staging,bu = cio,costcenter = 1234 $ aws eks list-tags-for-resource --resource-arn arn:aws:eks:us-west-2:xxx:cluster/ekscluster1 { \"tags\" : { \"bu\" : \"cio\" , \"env\" : \"staging\" , \"costcenter\" : \"1234\" , \"team\" : \"devops\" } } After you activate cost allocation tags in the AWS Cost Explorer , AWS uses the cost allocation tags to organize your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs. Tags don't have any semantic meaning to Amazon EKS and are interpreted strictly as a string of characters. For example, you can define a set of tags for your Amazon EKS clusters to help you track each cluster's owner and stack level. Use AWS Trusted Advisor \u00b6 AWS Trusted Advisor offers a rich set of best practice checks and recommendations across five categories: cost optimization; security; fault tolerance; performance; and service limits. For Cost Optimization, Trusted Advisor helps eliminate unused and idle resources and recommends making commitments to reserved capacity. The key action items that will help Amazon EKS will be around low utilsed EC2 instances, unassociated Elastic IP addresses, Idle Load Balancers, underutilized EBS volumes among other things. The complete list of checks are provided at https://aws.amazon.com/premiumsupport/technology/trusted-advisor/best-practice-checklist/. The Trusted Advisor also provides Savings Plans and Reserved Instances recommendations for EC2 instances and Fargate which allows you to commit to a consistent usage amount in exchange for discounted rates. Note that the recommendations from Trusted Advisor are generic recommendations and not specific to EKS. Use the Kubernetes dashboard \u00b6 Kubernetes dashboard Kubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters, which provides information about the Kubernetes cluster including the resource usage at a cluster, node and pod level. The deployment of the Kubernetes dashboard on an Amazon EKS cluster is described in the Amazon EKS documentation . Dashboard provides resource usage breakdowns for each node and pod, as well as detailed metadata about pods, services, Deployments, and other Kubernetes objects. This consolidated information provides visibility into your Kubernetes environment. kubectl top and describe commands Viewing resource usage metrics with kubectl top and kubectl describe commands. kubectl top will show current CPU and memory usage for the pods or nodes across your cluster, or for a specific pod or node. The kubectl describe command will give more detailed information about a specific node or a pod. $ kubectl top pods $ kubectl top nodes $ kubectl top pod pod-name --namespace mynamespace --containers Using the top command, the output will displays the total amount of CPU (in cores) and memory (in MiB) that the node is using, and the percentages of the node\u2019s allocatable capacity those numbers represent. You can then drill-down to the next level, container level within pods by adding a --containers flag. $ kubectl describe node <node> $ kubectl describe pod <pod> kubectl describe returns the percent of total available capacity that each resource request or limit represents. kubectl top and describe, track the utilization and availability of critical resources such as CPU, memory, and storage across kubernetes pods, nodes and containers. This awareness will help in understanding resource usage and help in controlling costs. Use CloudWatch Container Insights \u00b6 Use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices. Container Insights is available for Amazon Elastic Kubernetes Service on EC2, and Kubernetes platforms on Amazon EC2. The metrics include utilization for resources such as CPU, memory, disk, and network. The installation of insights is given in the documentation . CloudWatch creates aggregated metrics at the cluster, node, pod, task, and service level as CloudWatch metrics. The following query shows a list of nodes, sorted by average node CPU utilization STATS avg(node_cpu_utilization) as avg_node_cpu_utilization by NodeName | SORT avg_node_cpu_utilization DESC CPU usage by Container name stats pct(container_cpu_usage_total, 50) as CPUPercMedian by kubernetes.container_name | filter Type=\"Container\" Disk usage by Container name stats floor(avg(container_filesystem_usage/1024)) as container_filesystem_usage_avg_kb by InstanceId, kubernetes.container_name, device | filter Type=\"ContainerFS\" | sort container_filesystem_usage_avg_kb desc More sample queries are given in the Container Insights documention This awareness will help in understanding resource usage and help in controlling costs. Using KubeCost for expenditure awareness and guidance \u00b6 Third party tools like kubecost can also be deployed on Amazon EKS to get visibility into cost of running your Kubernetes cluster. Please refer to this AWS blog for tracking costs using Kubecost Deploying kubecost using Helm 3: $ curl - sSL https: // raw . githubusercontent . com / helm / helm / master / scripts / get-helm-3 | bash $ helm version -- short v3 .2.1 + gfe51cd1 $ helm repo add stable https: // kubernetes-charts . storage . googleapis . com / $ helm repo add stable https: // kubernetes-charts . storage . googleapis . com / c ^ C $ kubectl create namespace kubecost namespace / kubecost created $ helm repo add kubecost https: // kubecost . github . io / cost-analyzer / \"kubecost\" has been added to your repositories $ helm install kubecost kubecost / cost-analyzer -- namespace kubecost -- set kubecostToken = \"aGRoZEBqc2pzLmNvbQ==xm343yadf98\" NAME: kubecost LAST DEPLOYED: Mon May 18 08 : 49 : 05 2020 NAMESPACE: kubecost STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: -------------------------------------------------- Kubecost has been successfully installed . When pods are Ready , you can enable port-forwarding with the following command: kubectl port-forward -- namespace kubecost deployment / kubecost-cost-analyzer 9090 Next , navigate to http: // localhost:9090 in a web browser . $ kubectl port-forward -- namespace kubecost deployment / kubecost-cost-analyzer 9090 Note: If you are using Cloud 9 or have a need to forward it to a different port like 8080 , issue the following command $ kubectl port-forward -- namespace kubecost deployment / kubecost-cost-analyzer 8080 : 9090 Kube Cost Dashboard - Use Kubernetes Cost Allocation and Capacity Planning Analytics Tool \u00b6 Kubernetes Opex Analytics is a tool to help organizations track the resources being consumed by their Kubernetes clusters to prevent overpaying. To do so it generates, short- (7 days), mid- (14 days) and long-term (12 months) usage reports showing relevant insights on what amount of resources each project is spending over time. Magalix Kubeadvisor \u00b6 KubeAdvisor continuously scans your Kubernetes clusters and reports how you can fix issues, apply best practices, and optimize your cluster (with recommendations of resources like CPU/Memory around cost-efficiency). Spot.io, previously called Spotinst \u00b6 Spotinst Ocean is an application scaling service. Similar to Amazon Elastic Compute Cloud (Amazon EC2) Auto Scaling groups, Spotinst Ocean is designed to optimize performance and costs by leveraging Spot Instances combined with On-Demand and Reserved Instances. Using a combination of automated Spot Instance management and the variety of instance sizes, the Ocean cluster autoscaler scales according to the pod resource requirements. Spotinst Ocean also includes a prediction algorithm to predict Spot Instance interruption 15 minutes ahead of time and spin up a new node in a different Spot capacity pool. This is available as an AWS Quickstart developed by Spotinst, Inc. in collaboration with AWS. The EKS workshop also has a module on Optimized Worker Node on Amazon EKS Management with Ocean by Spot.io which includes sections on cost allocation, right sizing and scaling strategies. Yotascale \u00b6 Yotascale helps with accurately allocating Kubernetes costs. Yotascale Kubernetes Cost Allocation feature utilizes actual cost data, which is inclusive of Reserved Instance discounts and spot instance pricing instead of generic market-rate estimations, to inform the total Kubernetes cost footprint More details can be found at their website . Alcide Advisor \u00b6 Alcide is an AWS Partner Network (APN) Advanced Technology Partner. Alcide Advisor helps ensure your Amazon EKS cluster, nodes, and pods configuration are tuned to run according to security best practices and internal guidelines. Alcide Advisor is an agentless service for Kubernetes audit and compliance that\u2019s built to ensure a frictionless and secured DevSecOps flow by hardening the development stage before moving to production. More details can be found in this blog post . Other tools \u00b6 Kubernetes Garbage Collection \u00b6 The role of the Kubernetes garbage collector is to delete certain objects that once had an owner, but no longer have an owner. Fargate count \u00b6 Fargatecount is an useful tool, which allows AWS customers to track, with a custom CloudWatch metric, the total number of EKS pods that have been deployed on Fargate in a specific region of a specific account. This helps in keeping track of all the Fargate pods running across an EKS cluster. Kubernetes Ops View \u00b6 Kube Ops View is an useful tool, which provides a common operational picture visually for multiple Kubernetes clusters. git clone https://github.com/hjacobs/kube-ops-view cd kube-ops-view kubectl apply -k deploy/ Popeye - A Kubernetes Cluster Sanitizer \u00b6 Popeye - A Kubernetes Cluster Sanitizer is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations. It sanitizes your cluster based on what's deployed and not what's sitting on disk. By scanning your cluster, it detects misconfigurations and helps you to ensure that best practices are in place Resources \u00b6 Refer to the following resources to learn more about best practices for cost optimization. Documentation and Blogs + Amazon EKS supports tagging Tools + What is AWS Billing and Cost Management? + Amazon CloudWatch Container Insights + How to track costs in multi-tenant Amazon EKS clusters using Kubecost + Kube Cost + Kube Opsview + Kube Janitor + Kubernetes Opex Analytics","title":"Expenditure awareness"},{"location":"cost_optimization/awareness/#expenditure-awareness","text":"Expenditure awareness is understanding who, where and what is causing expenditures in your EKS cluster. Getting an accurate picture of this data will help raise awareness of your spend and highlight areas to remediate.","title":"Expenditure awareness"},{"location":"cost_optimization/awareness/#recommendations","text":"","title":"Recommendations"},{"location":"cost_optimization/awareness/#use-cost-explorer","text":"AWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time. You can analyze cost and usage data, at various levels using the filters available in Cost Explorer.","title":"Use Cost Explorer"},{"location":"cost_optimization/awareness/#eks-control-plane-and-eks-fargate-costs","text":"Using the filters, we can query the costs incurred for the EKS costs at the Control Plane and Fargate Pod as shown in the diagram below: Using the filters, we can query the aggregate costs incurred for the Fargate Pods across regions in EKS - which includes both vCPU-Hours per CPU and GB Hrs as shown in the diagram below:","title":"EKS Control Plane and EKS Fargate costs"},{"location":"cost_optimization/awareness/#tagging-of-resources","text":"Amazon EKS supports adding AWS tags to your Amazon EKS clusters. This makes it easy to control access to the EKS API for managing your clusters. Tags added to an EKS cluster are specific to the AWS EKS cluster resource, they do not propagate to other AWS resources used by the cluster such as EC2 instances or load balancers. Today, cluster tagging is supported for all new and existing EKS clusters via the AWS API, Console, and SDKs. AWS Fargate is a technology that provides on-demand, right-sized compute capacity for containers. Before you can schedule pods on Fargate in your cluster, you must define at least one Fargate profile that specifies which pods should use Fargate when they are launched. Adding and Listing tags to an EKS cluster: $ aws eks tag-resource --resource-arn arn:aws:eks:us-west-2:xxx:cluster/ekscluster1 --tags team = devops,env = staging,bu = cio,costcenter = 1234 $ aws eks list-tags-for-resource --resource-arn arn:aws:eks:us-west-2:xxx:cluster/ekscluster1 { \"tags\" : { \"bu\" : \"cio\" , \"env\" : \"staging\" , \"costcenter\" : \"1234\" , \"team\" : \"devops\" } } After you activate cost allocation tags in the AWS Cost Explorer , AWS uses the cost allocation tags to organize your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs. Tags don't have any semantic meaning to Amazon EKS and are interpreted strictly as a string of characters. For example, you can define a set of tags for your Amazon EKS clusters to help you track each cluster's owner and stack level.","title":"Tagging of Resources"},{"location":"cost_optimization/awareness/#use-aws-trusted-advisor","text":"AWS Trusted Advisor offers a rich set of best practice checks and recommendations across five categories: cost optimization; security; fault tolerance; performance; and service limits. For Cost Optimization, Trusted Advisor helps eliminate unused and idle resources and recommends making commitments to reserved capacity. The key action items that will help Amazon EKS will be around low utilsed EC2 instances, unassociated Elastic IP addresses, Idle Load Balancers, underutilized EBS volumes among other things. The complete list of checks are provided at https://aws.amazon.com/premiumsupport/technology/trusted-advisor/best-practice-checklist/. The Trusted Advisor also provides Savings Plans and Reserved Instances recommendations for EC2 instances and Fargate which allows you to commit to a consistent usage amount in exchange for discounted rates. Note that the recommendations from Trusted Advisor are generic recommendations and not specific to EKS.","title":"Use AWS Trusted Advisor"},{"location":"cost_optimization/awareness/#use-the-kubernetes-dashboard","text":"Kubernetes dashboard Kubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters, which provides information about the Kubernetes cluster including the resource usage at a cluster, node and pod level. The deployment of the Kubernetes dashboard on an Amazon EKS cluster is described in the Amazon EKS documentation . Dashboard provides resource usage breakdowns for each node and pod, as well as detailed metadata about pods, services, Deployments, and other Kubernetes objects. This consolidated information provides visibility into your Kubernetes environment. kubectl top and describe commands Viewing resource usage metrics with kubectl top and kubectl describe commands. kubectl top will show current CPU and memory usage for the pods or nodes across your cluster, or for a specific pod or node. The kubectl describe command will give more detailed information about a specific node or a pod. $ kubectl top pods $ kubectl top nodes $ kubectl top pod pod-name --namespace mynamespace --containers Using the top command, the output will displays the total amount of CPU (in cores) and memory (in MiB) that the node is using, and the percentages of the node\u2019s allocatable capacity those numbers represent. You can then drill-down to the next level, container level within pods by adding a --containers flag. $ kubectl describe node <node> $ kubectl describe pod <pod> kubectl describe returns the percent of total available capacity that each resource request or limit represents. kubectl top and describe, track the utilization and availability of critical resources such as CPU, memory, and storage across kubernetes pods, nodes and containers. This awareness will help in understanding resource usage and help in controlling costs.","title":"Use the Kubernetes dashboard"},{"location":"cost_optimization/awareness/#use-cloudwatch-container-insights","text":"Use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices. Container Insights is available for Amazon Elastic Kubernetes Service on EC2, and Kubernetes platforms on Amazon EC2. The metrics include utilization for resources such as CPU, memory, disk, and network. The installation of insights is given in the documentation . CloudWatch creates aggregated metrics at the cluster, node, pod, task, and service level as CloudWatch metrics. The following query shows a list of nodes, sorted by average node CPU utilization STATS avg(node_cpu_utilization) as avg_node_cpu_utilization by NodeName | SORT avg_node_cpu_utilization DESC CPU usage by Container name stats pct(container_cpu_usage_total, 50) as CPUPercMedian by kubernetes.container_name | filter Type=\"Container\" Disk usage by Container name stats floor(avg(container_filesystem_usage/1024)) as container_filesystem_usage_avg_kb by InstanceId, kubernetes.container_name, device | filter Type=\"ContainerFS\" | sort container_filesystem_usage_avg_kb desc More sample queries are given in the Container Insights documention This awareness will help in understanding resource usage and help in controlling costs.","title":"Use CloudWatch Container Insights"},{"location":"cost_optimization/awareness/#using-kubecost-for-expenditure-awareness-and-guidance","text":"Third party tools like kubecost can also be deployed on Amazon EKS to get visibility into cost of running your Kubernetes cluster. Please refer to this AWS blog for tracking costs using Kubecost Deploying kubecost using Helm 3: $ curl - sSL https: // raw . githubusercontent . com / helm / helm / master / scripts / get-helm-3 | bash $ helm version -- short v3 .2.1 + gfe51cd1 $ helm repo add stable https: // kubernetes-charts . storage . googleapis . com / $ helm repo add stable https: // kubernetes-charts . storage . googleapis . com / c ^ C $ kubectl create namespace kubecost namespace / kubecost created $ helm repo add kubecost https: // kubecost . github . io / cost-analyzer / \"kubecost\" has been added to your repositories $ helm install kubecost kubecost / cost-analyzer -- namespace kubecost -- set kubecostToken = \"aGRoZEBqc2pzLmNvbQ==xm343yadf98\" NAME: kubecost LAST DEPLOYED: Mon May 18 08 : 49 : 05 2020 NAMESPACE: kubecost STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: -------------------------------------------------- Kubecost has been successfully installed . When pods are Ready , you can enable port-forwarding with the following command: kubectl port-forward -- namespace kubecost deployment / kubecost-cost-analyzer 9090 Next , navigate to http: // localhost:9090 in a web browser . $ kubectl port-forward -- namespace kubecost deployment / kubecost-cost-analyzer 9090 Note: If you are using Cloud 9 or have a need to forward it to a different port like 8080 , issue the following command $ kubectl port-forward -- namespace kubecost deployment / kubecost-cost-analyzer 8080 : 9090 Kube Cost Dashboard -","title":"Using KubeCost for expenditure awareness and guidance"},{"location":"cost_optimization/awareness/#use-kubernetes-cost-allocation-and-capacity-planning-analytics-tool","text":"Kubernetes Opex Analytics is a tool to help organizations track the resources being consumed by their Kubernetes clusters to prevent overpaying. To do so it generates, short- (7 days), mid- (14 days) and long-term (12 months) usage reports showing relevant insights on what amount of resources each project is spending over time.","title":"Use Kubernetes Cost Allocation and Capacity Planning Analytics Tool"},{"location":"cost_optimization/awareness/#magalix-kubeadvisor","text":"KubeAdvisor continuously scans your Kubernetes clusters and reports how you can fix issues, apply best practices, and optimize your cluster (with recommendations of resources like CPU/Memory around cost-efficiency).","title":"Magalix Kubeadvisor"},{"location":"cost_optimization/awareness/#spotio-previously-called-spotinst","text":"Spotinst Ocean is an application scaling service. Similar to Amazon Elastic Compute Cloud (Amazon EC2) Auto Scaling groups, Spotinst Ocean is designed to optimize performance and costs by leveraging Spot Instances combined with On-Demand and Reserved Instances. Using a combination of automated Spot Instance management and the variety of instance sizes, the Ocean cluster autoscaler scales according to the pod resource requirements. Spotinst Ocean also includes a prediction algorithm to predict Spot Instance interruption 15 minutes ahead of time and spin up a new node in a different Spot capacity pool. This is available as an AWS Quickstart developed by Spotinst, Inc. in collaboration with AWS. The EKS workshop also has a module on Optimized Worker Node on Amazon EKS Management with Ocean by Spot.io which includes sections on cost allocation, right sizing and scaling strategies.","title":"Spot.io, previously called Spotinst"},{"location":"cost_optimization/awareness/#yotascale","text":"Yotascale helps with accurately allocating Kubernetes costs. Yotascale Kubernetes Cost Allocation feature utilizes actual cost data, which is inclusive of Reserved Instance discounts and spot instance pricing instead of generic market-rate estimations, to inform the total Kubernetes cost footprint More details can be found at their website .","title":"Yotascale"},{"location":"cost_optimization/awareness/#alcide-advisor","text":"Alcide is an AWS Partner Network (APN) Advanced Technology Partner. Alcide Advisor helps ensure your Amazon EKS cluster, nodes, and pods configuration are tuned to run according to security best practices and internal guidelines. Alcide Advisor is an agentless service for Kubernetes audit and compliance that\u2019s built to ensure a frictionless and secured DevSecOps flow by hardening the development stage before moving to production. More details can be found in this blog post .","title":"Alcide Advisor"},{"location":"cost_optimization/awareness/#other-tools","text":"","title":"Other tools"},{"location":"cost_optimization/awareness/#kubernetes-garbage-collection","text":"The role of the Kubernetes garbage collector is to delete certain objects that once had an owner, but no longer have an owner.","title":"Kubernetes Garbage Collection"},{"location":"cost_optimization/awareness/#fargate-count","text":"Fargatecount is an useful tool, which allows AWS customers to track, with a custom CloudWatch metric, the total number of EKS pods that have been deployed on Fargate in a specific region of a specific account. This helps in keeping track of all the Fargate pods running across an EKS cluster.","title":"Fargate count"},{"location":"cost_optimization/awareness/#kubernetes-ops-view","text":"Kube Ops View is an useful tool, which provides a common operational picture visually for multiple Kubernetes clusters. git clone https://github.com/hjacobs/kube-ops-view cd kube-ops-view kubectl apply -k deploy/","title":"Kubernetes Ops View"},{"location":"cost_optimization/awareness/#popeye-a-kubernetes-cluster-sanitizer","text":"Popeye - A Kubernetes Cluster Sanitizer is a utility that scans live Kubernetes cluster and reports potential issues with deployed resources and configurations. It sanitizes your cluster based on what's deployed and not what's sitting on disk. By scanning your cluster, it detects misconfigurations and helps you to ensure that best practices are in place","title":"Popeye - A Kubernetes Cluster Sanitizer"},{"location":"cost_optimization/awareness/#resources","text":"Refer to the following resources to learn more about best practices for cost optimization. Documentation and Blogs + Amazon EKS supports tagging Tools + What is AWS Billing and Cost Management? + Amazon CloudWatch Container Insights + How to track costs in multi-tenant Amazon EKS clusters using Kubecost + Kube Cost + Kube Opsview + Kube Janitor + Kubernetes Opex Analytics","title":"Resources"},{"location":"cost_optimization/cost-effective/","text":"Cost-effective resources \u00b6 Cost Effective resources means using the appropriate services, resources, and configurations for your workloads running on a Kubernetes cluster, which will result in cost savings. Recommendations \u00b6 Ensure that the infrastructure used to deploy the containerized service matches the application profile and scaling needs \u00b6 There are several types of Kubernetes autoscaling supported in Amazon EKS - Cluster Autoscaler , Horizontal Pod Autoscaler and Vertical Pod Autoscaler . This section covers two of them, Cluster Auto Scaler and Horizontal Pod Autoscaler. Use Cluster Autoscaler to adjust the size of a Kubernetes cluster to meet the current needs \u00b6 The Kubernetes Cluster Autoscaler automatically adjusts the number of nodes in the EKS cluster when pods fail to launch due to lack of resources or when nodes in the cluster are underutilized and their pods can be rescheduled onto other nodes in the cluster. The Cluster Autoscaler scales worker nodes within any specified Auto Scaling group and runs as a deployment in your EKS cluster. Amazon EKS with EC2 managed node groups automate the provisioning and lifecycle management of nodes (Amazon EC2 instances) for Amazon EKS Kubernetes clusters. All managed nodes are provisioned as part of an Amazon EC2 Auto Scaling group that is managed for you by Amazon EKS and all resources including Amazon EC2 instances and Auto Scaling groups run within your AWS account. Amazon EKS tags managed node group resources so that they can be discovered the Kubernetes Cluster Autoscaler. The documentation at https://docs.aws.amazon.com/eks/latest/userguide/cluster-autoscaler.html provides detailed guidance on setting up a Managed Node Group and then deploying Kubernetes Cluster Auto Scaler. If you are running a stateful application across multiple Availability Zones that is backed by Amazon EBS volumes and using the Kubernetes Cluster Autoscaler, you should configure multiple node groups, each scoped to a single Availability Zone. Cluster Autoscaler logs for EC2 based Worker Nodes - When a pod cannot be scheduled due to lack of available resources, Cluster Autoscaler determines that the cluster must scale out and increases the size of the node group. When multiple node groups are used, Cluster Autoscaler chooses one based on the Expander configuration. Currently, the following strategies are supported in EKS: + random - default expander, selects the instance group randomly + most-pods - selects the instance group that schedules the most amount of pods. + least-waste - selects the node group that will have the least idle CPU (if tied, unused memory) after scale-up. This is useful when you have different classes of nodes, for example, high CPU or high memory nodes, and only want to expand those when there are pending pods that need a lot of those resources. + priority - selects the node group that has the highest priority assigned by the user You can use the random placement strategy for the Expander in Cluster Autoscaler, if EC2 Spot instances are being used as worker nodes. This is the default expander, and arbitrarily chooses a node-group when the cluster must scale out. The random expander maximizes your ability to leverage multiple Spot capacity pools. Priority based expander selects an expansion option based on priorities assigned by a user to scaling groups. Sample priorities can be to let Autoscaler first try to scale out a spot instance node group and then, if it cannot, falls back to scaling out an on-demand node group. most-pods based expander is useful when you are using nodeSelector to make sure certain pods land on certain nodes. From the documentation to specify least-waste as the expander type for the Cluster Autoscaling configuration: spec: containers: - command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=aws - --skip-nodes-with-local-storage=false - --expander=least-waste - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/<YOUR CLUSTER NAME> - --balance-similar-node-groups - --skip-nodes-with-system-pods=false Deploy Horizontal Pod Autoscaling to automatically scales the number of pods in a deployment, replication controller, or replica set based on that resource's CPU utilization or other application related metrics \u00b6 The Kubernetes Horizontal Pod Autoscaler automatically scales the number of pods in a deployment, replication controller, or replica set based on resource metrics like CPU utilization or with custom metrics support, on some other application-provided metrics. This can help your applications scale out to meet increased demand or scale in when resources are not needed, thus freeing up your worker nodes for other applications. When you set a target metric utilization percentage, the Horizontal Pod Autoscaler scales your application in or out to try to meet that target. The k8s-cloudwatch-adapter is an implementation of the Kubernetes Custom Metrics API and External Metrics API with integration for CloudWatch metrics. It allows you to scale your Kubernetes deployment using the Horizontal Pod Autoscaler (HPA) with CloudWatch metrics. For an example of scaling using a resource metric like CPU, follow https://eksworkshop.com/beginner/080_scaling/test_hpa/ to deploy a sample app, perform a simple load test to test the autoscaling of pod and simulate pod autoscaling. Refer to this blog for an example of a custom metric for an application to scale according to the number of messages in the Amazon SQS (Simple Queue Service) queue. An example of an external metric from Amazon SQS from the blog: apiVersion : metrics.aws/v1alpha1 kind : ExternalMetric : metadata : name : hello-queue-length spec : name : hello-queue-length resource : resource : \"deployment\" queries : - id : sqs_helloworld metricStat : metric : namespace : \"AWS/SQS\" metricName : \"ApproximateNumberOfMessagesVisible\" dimensions : - name : QueueName value : \"helloworld\" period : 300 stat : Average unit : Count returnData : true An example of an HPA utilizing this external metric: kind : HorizontalPodAutoscaler apiVersion : autoscaling/v2beta1 metadata : name : sqs-consumer-scaler spec : scaleTargetRef : apiVersion : apps/v1beta1 kind : Deployment name : sqs-consumer minReplicas : 1 maxReplicas : 10 metrics : - type : External external : metricName : hello-queue-length targetAverageValue : 30 The combination of Cluster Auto Scaler for the Kubernetes worker nodes and Horizontal Pod Autoscaler for the pods, will ensure that the provisioned resources will be as close to the actual utilization as possible. (Image source: https://aws.amazon.com/blogs/containers/cost-optimization-for-kubernetes-on-aws/) Amazon EKS with Fargate *Horizontal Pod Autoscaling of Pods * Autoscaling EKS on Fargate can be done using the following mechanisms: Using the Kubernetes metrics server and configure auto-scaling based on CPU and/or memory usage. Configure autoscaling based on custom metrics like HTTP traffic using Prometheus and Prometheus metrics adapter Configure autoscaling based on App Mesh traffic The above scenarios are explained in a hands-on blog on \"Autoscaling EKS on Fargate with custom metrics *Vertical Pod Autoscaling * Use the Vertical Pod Autoscaler with pods running on Fargate to optimize the CPU and memory used for your applications. However, because changing the resource allocation for a pod requires the pod to be restarted, you must set the pod update policy to either Auto or Recreate to ensure correct functionality. Recommendations \u00b6 Use Down Scaling to scale down Kubernetes Deployments, StatefulSets, and/or HorizontalPodAutoscalers during non-work hours. \u00b6 As part of controlling costs Down-Scaling resources that are not in-use can also have an huge impact on the overall costs. There are tools like kube-downscaler and Descheduler for Kubernetes . Kube-descaler , can be used to Scale down Kubernetes deployments after work hours or during set periods of time. Descheduler for Kubernetes , based on its policy, can find pods that can be moved and evicts them. In its current implementation, the kubernetes descheduler does not reschedule evicted pods but relies on the default scheduler for that Kube-descaler Installation of kube-downscaler : git clone https://github.com/hjacobs/kube-downscaler cd kube-downscaler kubectl apply -k deploy/ The example configuration uses the --dry-run as a safety flag to prevent downscaling --- remove it to enable the downscaler, e.g. by editing the deployment: $ kubectl edit deploy kube-downscaler Deploy an nginx pod and schedule it to be run in the time zone - Mon-Fri 09:00-17:00 Asia/Kolkata: $ kubectl run nginx1 --image = nginx $ kubectl annotate deploy nginx1 'downscaler/uptime=Mon-Fri 09:00-17:00 Asia/Kolkata' Note The default grace period of 15 minutes applies to the new nginx deployment, i.e. if the current time is not within Mon-Fri 9-17 (Asia/Kolkata timezone), it will downscale not immediately, but after 15 minutes. More advanced downscaling deployment scenarios are available at the kube-down-scaler github project . Kubernetes descheduler The descheduler can be run as a Job or CronJob inside of a k8s cluster. Descheduler's policy is configurable and includes strategies that can be enabled or disabled. Seven strategies RemoveDuplicates , LowNodeUtilization , RemovePodsViolatingInterPodAntiAffinity , RemovePodsViolatingNodeAffinity , RemovePodsViolatingNodeTaints , RemovePodsHavingTooManyRestarts , and PodLifeTime are currently implemented. More details can be found in their documentation . A sample policy, which has the descheduler enabled for lowcpuutilization of nodes (where it covers the scenarios for both underutilized and overutilized), removing pods for too many restarts and others : apiVersion : \"descheduler/v1alpha1\" kind : \"DeschedulerPolicy\" strategies : \"RemoveDuplicates\" : enabled : true \"RemovePodsViolatingInterPodAntiAffinity\" : enabled : true \"LowNodeUtilization\" : enabled : true params : nodeResourceUtilizationThresholds : thresholds : \"cpu\" : 20 \"memory\" : 20 \"pods\" : 20 targetThresholds : \"cpu\" : 50 \"memory\" : 50 \"pods\" : 50 \"RemovePodsHavingTooManyRestarts\" : enabled : true params : podsHavingTooManyRestarts : podRestartThresholds : 100 includingInitContainers : true Cluster Turndown Cluster Turndown is an automated scaledown and scaleup of a Kubernetes cluster's backing nodes based on a custom schedule and turndown criteria. This feature can be used to reduce spend during down hours and/or reduce surface area for security reasons. The most common use case is to scale non-prod environments (e.g. dev clusters) to zero during off hours. Cluster Turndown is currently in ALPHA release. Cluster Turndown uses a Kubernetes Custom Resource Definition to create schedules. The following schedule will create a schedule that starts by turning down at the designated start date-time and turning back up at the designated end date-time (times should be in RFC3339 format, i.e. times based on offsets to UTC). apiVersion : kubecost.k8s.io/v1alpha1 kind : TurndownSchedule metadata : name : example-schedule finalizers : - \"finalizer.kubecost.k8s.io\" spec : start : 2020-03-12T00:00:00Z end : 2020-03-12T12:00:00Z repeat : daily Use LimitRanges and Resource Quotas to help manage costs by constraining the amount of resources allocated at an Namespace level \u00b6 By default, containers run with unbounded compute resources on a Kubernetes cluster. With resource quotas, cluster administrators can restrict resource consumption and creation on a namespace basis. Within a namespace, a Pod or Container can consume as much CPU and memory as defined by the namespace\u2019s resource quota. There is a concern that one Pod or Container could monopolize all available resources. Kubernetes controls the allocation of resources such as CPU, memory, PersistentVolumeClaims and others using Resource Quotas and Limit Ranges. ResourceQuota is at the Namespace level, while a LimitRange applies at an container level. Limit Ranges A LimitRange is a policy to constrain resource allocations (to Pods or Containers) in a namespace. The following is an example of setting an default memory request and a default memory limit using Limit Range. apiVersion : v1 kind : LimitRange metadata : name : mem-limit-range spec : limits : - default : memory : 512Mi defaultRequest : memory : 256Mi type : Container More examples are available in the Kubernetes documentation . Resource Quotas When several users or teams share a cluster with a fixed number of nodes, there is a concern that one team could use more than its fair share of resources. Resource quotas are a tool for administrators to address this concern. The following is an example of how to set quotas for the total amount memory and CPU that can be used by all Containers running in a namespace, by specifying quotas in a ResourceQuota object. This specifies that a Container must have a memory request, memory limit, cpu request, and cpu limit, and should not exceed the threshold set in the ResourceQuota. apiVersion : v1 kind : ResourceQuota metadata : name : mem-cpu-demo spec : hard : requests.cpu : \"1\" requests.memory : 1Gi limits.cpu : \"2\" limits.memory : 2Gi More examples are available in the Kubernetes documentation . Use pricing models for effective utilization \u00b6 The pricing details for Amazon EKS are given in the pricing page . There is a common control plane cost for both Amazon EKS on Fargate and EC2. If you are using AWS Fargate, pricing is calculated based on the vCPU and memory resources used from the time you start to download your container image until the Amazon EKS pod terminates, rounded up to the nearest second. A minimum charge of 1 minute applies. See detailed pricing information on the AWS Fargate pricing page . Amazon EKS on EC2: Amazon EC2 provides a wide selection of instance types optimized to fit different use cases. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity and give you the flexibility to choose the appropriate mix of resources for your applications. Each instance type includes one or more instance sizes, allowing you to scale your resources to the requirements of your target workload. One of the key decision parameters apart from number of CPUs, memory, processor family type related to the instance type is the number of Elastic network interfaces(ENI's) , which in-turn has a bearing on the maximum number of pods you can run on that EC2 Instance. The list of max pods per EC2 Instance type is maintained in a github. *On-Demand EC2 Instances: * With On-Demand instances , you pay for compute capacity by the hour or the second depending on which instances you run. No longer-term commitments or upfront payments are needed. Amazon EC2 A1 instances deliver significant cost savings and are ideally suited for scale-out and ARM-based workloads that are supported by the extensive Arm ecosystem. You can now use Amazon Elastic Container Service for Kubernetes (EKS) to run containers on Amazon EC2 A1 Instances as part of a public developer preview . Amazon ECR now supports multi-architecture container images , which makes it simpler to deploy container images for different architectures and operating systems from the same image repository. You can use the AWS Simple Monthly Calculator or the new pricing calculator to get pricing for the On-Demand EC2 instances for the EKS workder nodes. Use Spot EC2 Instances: \u00b6 Amazon EC2 Spot instances allow you to request spare Amazon EC2 computing capacity for up to 90% off the On-Demand price. Spot Instances are often a great fit for stateless containerized workloads because the approach to containers and Spot Instances are similar; ephemeral and autoscaled capacity. This means they both can be added and removed while adhering to SLAs and without impacting the performance or availability of your applications. You can create multiple nodegroups with a mix of on-demand instance types and EC2 Spot instances to leverage the advantages of pricing between these two instance types. (Image source: https://ec2spotworkshops.com/using_ec2_spot_instances_with_eks/spotworkers/workers_eksctl.html) A sample yaml file for eksctl to create a nodegroup with EC2 spot instances is given below. During the creation of the Node Group, we have configured a node-label so that kubernetes knows what type of nodes we have provisioned. We set the lifecycle for the nodes as Ec2Spot. We are also tainting with PreferNoSchedule to prefer pods not be scheduled on Spot Instances. This is a \u201cpreference\u201d or \u201csoft\u201d version of NoSchedule, i.e. the system will try to avoid placing a pod that does not tolerate the taint on the node, but it is not required. We are using this technique to make sure that only the right type of workloads are scheduled on Spot Instances. apiVersion : eksctl.io/v1alpha5 kind : ClusterConfig metadata : name : my-cluster-testscaling region : us-west-2 nodeGroups : - name : ng-spot labels : lifecycle : Ec2Spot taints : spotInstance : true:PreferNoSchedule minSize : 2 maxSize : 5 instancesDistribution : # At least two instance types should be specified instanceTypes : - m4.large - c4.large - c5.large onDemandBaseCapacity : 0 onDemandPercentageAboveBaseCapacity : 0 # all the instances will be spot instances spotInstancePools : 2 Use the node-labels to identify the lifecycle of the nodes. $ kubectl get nodes --label-columns = lifecycle --selector = lifecycle = Ec2Spot We should also deploy the AWS Node Termination Handler on each Spot Instance. This will monitor the EC2 metadata service on the instance for an interruption notice. The termination handler consists of a ServiceAccount, ClusterRole, ClusterRoleBinding, and a DaemonSet. AWS Node Termination Handler is not only for Spot Instances, it can also catch general EC2 maintenance events, so it can be used across all the worker nodes in the cluster. If a customer is well diversified and uses the capacity-optimized allocation strategy, Spot Instances will be available. You can use Node Affinity in your manifest file to configure this, to prefer Spot Instances, but not require them. This would allow the pods to be scheduled on On-Demand nodes if no spot instances were available or correctly labelled. affinity : nodeAffinity : preferredDuringSchedulingIgnoredDuringExecution : - weight : 1 preference : matchExpressions : - key : lifecycle operator : In values : - Ec2Spot tolerations : - key : \"spotInstance\" operator : \"Equal\" value : \"true\" effect : \"PreferNoSchedule\" You can do a complete workshop with EC2 spot instances at the online EC2 Spot Workshop . Use Compute Savings Plan \u00b6 Compute Savings Plans, a flexible discount model that provides you with the same discounts as Reserved Instances, in exchange for a commitment to use a specific amount (measured in dollars per hour) of compute power over a one or three year period. The details are covered in the Savings Plan launch FAQ .The plans automatically apply to any EC2 worker node regardless of region, instance family, operating system, or tenancy, including those that are part of EKS clusters. For example, you can shift from C4 to C5 instances, move a workload from Dublin to London benefiting from Savings Plan prices along the way, without having to do anything. The AWS Cost Explorer will help you to choose a Savings Plan, and will guide you through the purchase process. Note - The compute savings plans now also applies to AWS Fargate for AWS Elastic Kubernetes Service (EKS) . Note - The above pricing does not include the other AWS services like Data transfer charges, CloudWatch, Elastic Load Balancer and other AWS services that may be used by the Kubernetes applications. Resources \u00b6 Refer to the following resources to learn more about best practices for cost optimization. Videos \u00b6 AWS re:Invent 2019: Save up to 90% and run production workloads on Spot Instances (CMP331-R1) Documentation and Blogs \u00b6 Cost optimization for Kubernetes on AWS Building for Cost optimization and Resilience for EKS with Spot Instances Autoscaling EKS on Fargate with custom metrics AWS Fargate considerations Using Spot Instances with EKS Extending the EKS API: Managed Node Groups Autoscaling with Amazon EKS Amazon EKS pricing AWS Fargate pricing Savings Plan Saving Cloud Costs with Kubernetes on AWS Tools \u00b6 Kube downscaler Kubernetes Descheduler Cluster TurnDown","title":"Cost-effective resources"},{"location":"cost_optimization/cost-effective/#cost-effective-resources","text":"Cost Effective resources means using the appropriate services, resources, and configurations for your workloads running on a Kubernetes cluster, which will result in cost savings.","title":"Cost-effective resources"},{"location":"cost_optimization/cost-effective/#recommendations","text":"","title":"Recommendations"},{"location":"cost_optimization/cost-effective/#ensure-that-the-infrastructure-used-to-deploy-the-containerized-service-matches-the-application-profile-and-scaling-needs","text":"There are several types of Kubernetes autoscaling supported in Amazon EKS - Cluster Autoscaler , Horizontal Pod Autoscaler and Vertical Pod Autoscaler . This section covers two of them, Cluster Auto Scaler and Horizontal Pod Autoscaler.","title":"Ensure that the infrastructure used to deploy the containerized service matches the application profile and scaling needs"},{"location":"cost_optimization/cost-effective/#use-cluster-autoscaler-to-adjust-the-size-of-a-kubernetes-cluster-to-meet-the-current-needs","text":"The Kubernetes Cluster Autoscaler automatically adjusts the number of nodes in the EKS cluster when pods fail to launch due to lack of resources or when nodes in the cluster are underutilized and their pods can be rescheduled onto other nodes in the cluster. The Cluster Autoscaler scales worker nodes within any specified Auto Scaling group and runs as a deployment in your EKS cluster. Amazon EKS with EC2 managed node groups automate the provisioning and lifecycle management of nodes (Amazon EC2 instances) for Amazon EKS Kubernetes clusters. All managed nodes are provisioned as part of an Amazon EC2 Auto Scaling group that is managed for you by Amazon EKS and all resources including Amazon EC2 instances and Auto Scaling groups run within your AWS account. Amazon EKS tags managed node group resources so that they can be discovered the Kubernetes Cluster Autoscaler. The documentation at https://docs.aws.amazon.com/eks/latest/userguide/cluster-autoscaler.html provides detailed guidance on setting up a Managed Node Group and then deploying Kubernetes Cluster Auto Scaler. If you are running a stateful application across multiple Availability Zones that is backed by Amazon EBS volumes and using the Kubernetes Cluster Autoscaler, you should configure multiple node groups, each scoped to a single Availability Zone. Cluster Autoscaler logs for EC2 based Worker Nodes - When a pod cannot be scheduled due to lack of available resources, Cluster Autoscaler determines that the cluster must scale out and increases the size of the node group. When multiple node groups are used, Cluster Autoscaler chooses one based on the Expander configuration. Currently, the following strategies are supported in EKS: + random - default expander, selects the instance group randomly + most-pods - selects the instance group that schedules the most amount of pods. + least-waste - selects the node group that will have the least idle CPU (if tied, unused memory) after scale-up. This is useful when you have different classes of nodes, for example, high CPU or high memory nodes, and only want to expand those when there are pending pods that need a lot of those resources. + priority - selects the node group that has the highest priority assigned by the user You can use the random placement strategy for the Expander in Cluster Autoscaler, if EC2 Spot instances are being used as worker nodes. This is the default expander, and arbitrarily chooses a node-group when the cluster must scale out. The random expander maximizes your ability to leverage multiple Spot capacity pools. Priority based expander selects an expansion option based on priorities assigned by a user to scaling groups. Sample priorities can be to let Autoscaler first try to scale out a spot instance node group and then, if it cannot, falls back to scaling out an on-demand node group. most-pods based expander is useful when you are using nodeSelector to make sure certain pods land on certain nodes. From the documentation to specify least-waste as the expander type for the Cluster Autoscaling configuration: spec: containers: - command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=aws - --skip-nodes-with-local-storage=false - --expander=least-waste - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/<YOUR CLUSTER NAME> - --balance-similar-node-groups - --skip-nodes-with-system-pods=false","title":"Use Cluster Autoscaler to adjust the size of a Kubernetes cluster to meet the current needs"},{"location":"cost_optimization/cost-effective/#deploy-horizontal-pod-autoscaling-to-automatically-scales-the-number-of-pods-in-a-deployment-replication-controller-or-replica-set-based-on-that-resources-cpu-utilization-or-other-application-related-metrics","text":"The Kubernetes Horizontal Pod Autoscaler automatically scales the number of pods in a deployment, replication controller, or replica set based on resource metrics like CPU utilization or with custom metrics support, on some other application-provided metrics. This can help your applications scale out to meet increased demand or scale in when resources are not needed, thus freeing up your worker nodes for other applications. When you set a target metric utilization percentage, the Horizontal Pod Autoscaler scales your application in or out to try to meet that target. The k8s-cloudwatch-adapter is an implementation of the Kubernetes Custom Metrics API and External Metrics API with integration for CloudWatch metrics. It allows you to scale your Kubernetes deployment using the Horizontal Pod Autoscaler (HPA) with CloudWatch metrics. For an example of scaling using a resource metric like CPU, follow https://eksworkshop.com/beginner/080_scaling/test_hpa/ to deploy a sample app, perform a simple load test to test the autoscaling of pod and simulate pod autoscaling. Refer to this blog for an example of a custom metric for an application to scale according to the number of messages in the Amazon SQS (Simple Queue Service) queue. An example of an external metric from Amazon SQS from the blog: apiVersion : metrics.aws/v1alpha1 kind : ExternalMetric : metadata : name : hello-queue-length spec : name : hello-queue-length resource : resource : \"deployment\" queries : - id : sqs_helloworld metricStat : metric : namespace : \"AWS/SQS\" metricName : \"ApproximateNumberOfMessagesVisible\" dimensions : - name : QueueName value : \"helloworld\" period : 300 stat : Average unit : Count returnData : true An example of an HPA utilizing this external metric: kind : HorizontalPodAutoscaler apiVersion : autoscaling/v2beta1 metadata : name : sqs-consumer-scaler spec : scaleTargetRef : apiVersion : apps/v1beta1 kind : Deployment name : sqs-consumer minReplicas : 1 maxReplicas : 10 metrics : - type : External external : metricName : hello-queue-length targetAverageValue : 30 The combination of Cluster Auto Scaler for the Kubernetes worker nodes and Horizontal Pod Autoscaler for the pods, will ensure that the provisioned resources will be as close to the actual utilization as possible. (Image source: https://aws.amazon.com/blogs/containers/cost-optimization-for-kubernetes-on-aws/) Amazon EKS with Fargate *Horizontal Pod Autoscaling of Pods * Autoscaling EKS on Fargate can be done using the following mechanisms: Using the Kubernetes metrics server and configure auto-scaling based on CPU and/or memory usage. Configure autoscaling based on custom metrics like HTTP traffic using Prometheus and Prometheus metrics adapter Configure autoscaling based on App Mesh traffic The above scenarios are explained in a hands-on blog on \"Autoscaling EKS on Fargate with custom metrics *Vertical Pod Autoscaling * Use the Vertical Pod Autoscaler with pods running on Fargate to optimize the CPU and memory used for your applications. However, because changing the resource allocation for a pod requires the pod to be restarted, you must set the pod update policy to either Auto or Recreate to ensure correct functionality.","title":"Deploy Horizontal Pod Autoscaling to automatically scales the number of pods in a deployment, replication controller, or replica set based on that resource's CPU utilization or other application related metrics"},{"location":"cost_optimization/cost-effective/#recommendations_1","text":"","title":"Recommendations"},{"location":"cost_optimization/cost-effective/#use-down-scaling-to-scale-down-kubernetes-deployments-statefulsets-andor-horizontalpodautoscalers-during-non-work-hours","text":"As part of controlling costs Down-Scaling resources that are not in-use can also have an huge impact on the overall costs. There are tools like kube-downscaler and Descheduler for Kubernetes . Kube-descaler , can be used to Scale down Kubernetes deployments after work hours or during set periods of time. Descheduler for Kubernetes , based on its policy, can find pods that can be moved and evicts them. In its current implementation, the kubernetes descheduler does not reschedule evicted pods but relies on the default scheduler for that Kube-descaler Installation of kube-downscaler : git clone https://github.com/hjacobs/kube-downscaler cd kube-downscaler kubectl apply -k deploy/ The example configuration uses the --dry-run as a safety flag to prevent downscaling --- remove it to enable the downscaler, e.g. by editing the deployment: $ kubectl edit deploy kube-downscaler Deploy an nginx pod and schedule it to be run in the time zone - Mon-Fri 09:00-17:00 Asia/Kolkata: $ kubectl run nginx1 --image = nginx $ kubectl annotate deploy nginx1 'downscaler/uptime=Mon-Fri 09:00-17:00 Asia/Kolkata' Note The default grace period of 15 minutes applies to the new nginx deployment, i.e. if the current time is not within Mon-Fri 9-17 (Asia/Kolkata timezone), it will downscale not immediately, but after 15 minutes. More advanced downscaling deployment scenarios are available at the kube-down-scaler github project . Kubernetes descheduler The descheduler can be run as a Job or CronJob inside of a k8s cluster. Descheduler's policy is configurable and includes strategies that can be enabled or disabled. Seven strategies RemoveDuplicates , LowNodeUtilization , RemovePodsViolatingInterPodAntiAffinity , RemovePodsViolatingNodeAffinity , RemovePodsViolatingNodeTaints , RemovePodsHavingTooManyRestarts , and PodLifeTime are currently implemented. More details can be found in their documentation . A sample policy, which has the descheduler enabled for lowcpuutilization of nodes (where it covers the scenarios for both underutilized and overutilized), removing pods for too many restarts and others : apiVersion : \"descheduler/v1alpha1\" kind : \"DeschedulerPolicy\" strategies : \"RemoveDuplicates\" : enabled : true \"RemovePodsViolatingInterPodAntiAffinity\" : enabled : true \"LowNodeUtilization\" : enabled : true params : nodeResourceUtilizationThresholds : thresholds : \"cpu\" : 20 \"memory\" : 20 \"pods\" : 20 targetThresholds : \"cpu\" : 50 \"memory\" : 50 \"pods\" : 50 \"RemovePodsHavingTooManyRestarts\" : enabled : true params : podsHavingTooManyRestarts : podRestartThresholds : 100 includingInitContainers : true Cluster Turndown Cluster Turndown is an automated scaledown and scaleup of a Kubernetes cluster's backing nodes based on a custom schedule and turndown criteria. This feature can be used to reduce spend during down hours and/or reduce surface area for security reasons. The most common use case is to scale non-prod environments (e.g. dev clusters) to zero during off hours. Cluster Turndown is currently in ALPHA release. Cluster Turndown uses a Kubernetes Custom Resource Definition to create schedules. The following schedule will create a schedule that starts by turning down at the designated start date-time and turning back up at the designated end date-time (times should be in RFC3339 format, i.e. times based on offsets to UTC). apiVersion : kubecost.k8s.io/v1alpha1 kind : TurndownSchedule metadata : name : example-schedule finalizers : - \"finalizer.kubecost.k8s.io\" spec : start : 2020-03-12T00:00:00Z end : 2020-03-12T12:00:00Z repeat : daily","title":"Use Down Scaling to scale down Kubernetes Deployments, StatefulSets, and/or HorizontalPodAutoscalers during non-work hours."},{"location":"cost_optimization/cost-effective/#use-limitranges-and-resource-quotas-to-help-manage-costs-by-constraining-the-amount-of-resources-allocated-at-an-namespace-level","text":"By default, containers run with unbounded compute resources on a Kubernetes cluster. With resource quotas, cluster administrators can restrict resource consumption and creation on a namespace basis. Within a namespace, a Pod or Container can consume as much CPU and memory as defined by the namespace\u2019s resource quota. There is a concern that one Pod or Container could monopolize all available resources. Kubernetes controls the allocation of resources such as CPU, memory, PersistentVolumeClaims and others using Resource Quotas and Limit Ranges. ResourceQuota is at the Namespace level, while a LimitRange applies at an container level. Limit Ranges A LimitRange is a policy to constrain resource allocations (to Pods or Containers) in a namespace. The following is an example of setting an default memory request and a default memory limit using Limit Range. apiVersion : v1 kind : LimitRange metadata : name : mem-limit-range spec : limits : - default : memory : 512Mi defaultRequest : memory : 256Mi type : Container More examples are available in the Kubernetes documentation . Resource Quotas When several users or teams share a cluster with a fixed number of nodes, there is a concern that one team could use more than its fair share of resources. Resource quotas are a tool for administrators to address this concern. The following is an example of how to set quotas for the total amount memory and CPU that can be used by all Containers running in a namespace, by specifying quotas in a ResourceQuota object. This specifies that a Container must have a memory request, memory limit, cpu request, and cpu limit, and should not exceed the threshold set in the ResourceQuota. apiVersion : v1 kind : ResourceQuota metadata : name : mem-cpu-demo spec : hard : requests.cpu : \"1\" requests.memory : 1Gi limits.cpu : \"2\" limits.memory : 2Gi More examples are available in the Kubernetes documentation .","title":"Use LimitRanges and Resource Quotas to help manage costs by constraining the amount of resources allocated at an Namespace level"},{"location":"cost_optimization/cost-effective/#use-pricing-models-for-effective-utilization","text":"The pricing details for Amazon EKS are given in the pricing page . There is a common control plane cost for both Amazon EKS on Fargate and EC2. If you are using AWS Fargate, pricing is calculated based on the vCPU and memory resources used from the time you start to download your container image until the Amazon EKS pod terminates, rounded up to the nearest second. A minimum charge of 1 minute applies. See detailed pricing information on the AWS Fargate pricing page . Amazon EKS on EC2: Amazon EC2 provides a wide selection of instance types optimized to fit different use cases. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity and give you the flexibility to choose the appropriate mix of resources for your applications. Each instance type includes one or more instance sizes, allowing you to scale your resources to the requirements of your target workload. One of the key decision parameters apart from number of CPUs, memory, processor family type related to the instance type is the number of Elastic network interfaces(ENI's) , which in-turn has a bearing on the maximum number of pods you can run on that EC2 Instance. The list of max pods per EC2 Instance type is maintained in a github. *On-Demand EC2 Instances: * With On-Demand instances , you pay for compute capacity by the hour or the second depending on which instances you run. No longer-term commitments or upfront payments are needed. Amazon EC2 A1 instances deliver significant cost savings and are ideally suited for scale-out and ARM-based workloads that are supported by the extensive Arm ecosystem. You can now use Amazon Elastic Container Service for Kubernetes (EKS) to run containers on Amazon EC2 A1 Instances as part of a public developer preview . Amazon ECR now supports multi-architecture container images , which makes it simpler to deploy container images for different architectures and operating systems from the same image repository. You can use the AWS Simple Monthly Calculator or the new pricing calculator to get pricing for the On-Demand EC2 instances for the EKS workder nodes.","title":"Use pricing models for effective utilization"},{"location":"cost_optimization/cost-effective/#use-spot-ec2-instances","text":"Amazon EC2 Spot instances allow you to request spare Amazon EC2 computing capacity for up to 90% off the On-Demand price. Spot Instances are often a great fit for stateless containerized workloads because the approach to containers and Spot Instances are similar; ephemeral and autoscaled capacity. This means they both can be added and removed while adhering to SLAs and without impacting the performance or availability of your applications. You can create multiple nodegroups with a mix of on-demand instance types and EC2 Spot instances to leverage the advantages of pricing between these two instance types. (Image source: https://ec2spotworkshops.com/using_ec2_spot_instances_with_eks/spotworkers/workers_eksctl.html) A sample yaml file for eksctl to create a nodegroup with EC2 spot instances is given below. During the creation of the Node Group, we have configured a node-label so that kubernetes knows what type of nodes we have provisioned. We set the lifecycle for the nodes as Ec2Spot. We are also tainting with PreferNoSchedule to prefer pods not be scheduled on Spot Instances. This is a \u201cpreference\u201d or \u201csoft\u201d version of NoSchedule, i.e. the system will try to avoid placing a pod that does not tolerate the taint on the node, but it is not required. We are using this technique to make sure that only the right type of workloads are scheduled on Spot Instances. apiVersion : eksctl.io/v1alpha5 kind : ClusterConfig metadata : name : my-cluster-testscaling region : us-west-2 nodeGroups : - name : ng-spot labels : lifecycle : Ec2Spot taints : spotInstance : true:PreferNoSchedule minSize : 2 maxSize : 5 instancesDistribution : # At least two instance types should be specified instanceTypes : - m4.large - c4.large - c5.large onDemandBaseCapacity : 0 onDemandPercentageAboveBaseCapacity : 0 # all the instances will be spot instances spotInstancePools : 2 Use the node-labels to identify the lifecycle of the nodes. $ kubectl get nodes --label-columns = lifecycle --selector = lifecycle = Ec2Spot We should also deploy the AWS Node Termination Handler on each Spot Instance. This will monitor the EC2 metadata service on the instance for an interruption notice. The termination handler consists of a ServiceAccount, ClusterRole, ClusterRoleBinding, and a DaemonSet. AWS Node Termination Handler is not only for Spot Instances, it can also catch general EC2 maintenance events, so it can be used across all the worker nodes in the cluster. If a customer is well diversified and uses the capacity-optimized allocation strategy, Spot Instances will be available. You can use Node Affinity in your manifest file to configure this, to prefer Spot Instances, but not require them. This would allow the pods to be scheduled on On-Demand nodes if no spot instances were available or correctly labelled. affinity : nodeAffinity : preferredDuringSchedulingIgnoredDuringExecution : - weight : 1 preference : matchExpressions : - key : lifecycle operator : In values : - Ec2Spot tolerations : - key : \"spotInstance\" operator : \"Equal\" value : \"true\" effect : \"PreferNoSchedule\" You can do a complete workshop with EC2 spot instances at the online EC2 Spot Workshop .","title":"Use Spot EC2 Instances:"},{"location":"cost_optimization/cost-effective/#use-compute-savings-plan","text":"Compute Savings Plans, a flexible discount model that provides you with the same discounts as Reserved Instances, in exchange for a commitment to use a specific amount (measured in dollars per hour) of compute power over a one or three year period. The details are covered in the Savings Plan launch FAQ .The plans automatically apply to any EC2 worker node regardless of region, instance family, operating system, or tenancy, including those that are part of EKS clusters. For example, you can shift from C4 to C5 instances, move a workload from Dublin to London benefiting from Savings Plan prices along the way, without having to do anything. The AWS Cost Explorer will help you to choose a Savings Plan, and will guide you through the purchase process. Note - The compute savings plans now also applies to AWS Fargate for AWS Elastic Kubernetes Service (EKS) . Note - The above pricing does not include the other AWS services like Data transfer charges, CloudWatch, Elastic Load Balancer and other AWS services that may be used by the Kubernetes applications.","title":"Use Compute Savings Plan"},{"location":"cost_optimization/cost-effective/#resources","text":"Refer to the following resources to learn more about best practices for cost optimization.","title":"Resources"},{"location":"cost_optimization/cost-effective/#videos","text":"AWS re:Invent 2019: Save up to 90% and run production workloads on Spot Instances (CMP331-R1)","title":"Videos"},{"location":"cost_optimization/cost-effective/#documentation-and-blogs","text":"Cost optimization for Kubernetes on AWS Building for Cost optimization and Resilience for EKS with Spot Instances Autoscaling EKS on Fargate with custom metrics AWS Fargate considerations Using Spot Instances with EKS Extending the EKS API: Managed Node Groups Autoscaling with Amazon EKS Amazon EKS pricing AWS Fargate pricing Savings Plan Saving Cloud Costs with Kubernetes on AWS","title":"Documentation and Blogs"},{"location":"cost_optimization/cost-effective/#tools","text":"Kube downscaler Kubernetes Descheduler Cluster TurnDown","title":"Tools"},{"location":"cost_optimization/cost_optimization_index/","text":"Amazon EKS Best Practices Guide for Cost Optimization \u00b6 Cost Optimization is achieving your business outcomes at the lowest price point. By following the documentation in this guide you will optimize your Amazon EKS workloads. General Guidelines \u00b6 In the cloud, there are a number of general guidelines that can help you achieve cost optimization of your microservices: + Ensure that workloads running on Amazon EKS are independent of specific infrastructure types for running your containers, this will give greater flexibility with regards to running them on the least expensive types of infrastructure. While using Amazon EKS with EC2, there can be exceptions when we have workloads that require specific type of EC2 Instance types like requiring a GPU or other instance types, due to the nature of the workload. + Select optimally profiled container instances \u2014 profile your production or pre-production environments and monitor critical metrics like CPU and memory, using services like Amazon CloudWatch Container Insights for Amazon EKS or third party tools that are available in the Kubernetes ecosystem. This will ensure that we can allocate the right amount of resources and avoid wastage of resources. + Take advantage of the different purchasing options that are available in AWS for running EKS with EC2, e.g. On-Demand, Spot and Savings Plan. EKS Cost Optimization Best Practices \u00b6 There are three general best practice areas for cost optimization in the cloud: Cost-effective resources (Auto Scaling, Down Scaling, Policies and Purchasing Options) Expenditure awareness (Using AWS and third party tools) Optimizing over time (Right Sizing) As with any guidance there are trade-offs. Ensure you work with your organization to understand the priorities for this workload and which best practices are most important. How to use this guide \u00b6 This guide is meant for devops teams who are responsible for implementing and managing the EKS clusters and the workloads they support. The guide is organized into different best practice areas for easier consumption. Each topic has a list of recommendations, tools to use and best practices for cost optimization of your EKS clusters. The topics do not need to read in a particular order. Key AWS Services and Kubernetes features \u00b6 Cost optimization is supported by the following AWS services and features: + EC2 Instance types, Savings Plan (and Reserved Instances) and Spot Instances, at different prices. + Auto Scaling along with Kubernetes native Auto Scaling policies. Consider Savings Plan (Previously Reserved Instances) for predictable workloads. Use managed data stores like EBS and EFS, for elasticity and durability of the application data. + The Billing and Cost Management console dashboard along with AWS Cost Explorer provides an overview of your AWS usage. Use AWS Organizations for granular billing details. Details of several third party tools have also been shared. + Amazon CloudWatch Container Metrics provides metrics around usage of resources by the EKS cluster. In addition to the Kubernetes dashboard, there are several tools in the Kubernetes ecosystem that can be used to reduce wastage. This guide includes a set of recommendations that you can use to improve the cost optimization of your Amazon EKS cluster. Feedback \u00b6 This guide is being released on GitHub so as to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. Our intention is to update the guide periodically as new features are added to the service or when a new best practice evolves.","title":"Amazon EKS Best Practices Guide for Cost Optimization"},{"location":"cost_optimization/cost_optimization_index/#amazon-eks-best-practices-guide-for-cost-optimization","text":"Cost Optimization is achieving your business outcomes at the lowest price point. By following the documentation in this guide you will optimize your Amazon EKS workloads.","title":"Amazon EKS Best Practices Guide for Cost Optimization"},{"location":"cost_optimization/cost_optimization_index/#general-guidelines","text":"In the cloud, there are a number of general guidelines that can help you achieve cost optimization of your microservices: + Ensure that workloads running on Amazon EKS are independent of specific infrastructure types for running your containers, this will give greater flexibility with regards to running them on the least expensive types of infrastructure. While using Amazon EKS with EC2, there can be exceptions when we have workloads that require specific type of EC2 Instance types like requiring a GPU or other instance types, due to the nature of the workload. + Select optimally profiled container instances \u2014 profile your production or pre-production environments and monitor critical metrics like CPU and memory, using services like Amazon CloudWatch Container Insights for Amazon EKS or third party tools that are available in the Kubernetes ecosystem. This will ensure that we can allocate the right amount of resources and avoid wastage of resources. + Take advantage of the different purchasing options that are available in AWS for running EKS with EC2, e.g. On-Demand, Spot and Savings Plan.","title":"General Guidelines"},{"location":"cost_optimization/cost_optimization_index/#eks-cost-optimization-best-practices","text":"There are three general best practice areas for cost optimization in the cloud: Cost-effective resources (Auto Scaling, Down Scaling, Policies and Purchasing Options) Expenditure awareness (Using AWS and third party tools) Optimizing over time (Right Sizing) As with any guidance there are trade-offs. Ensure you work with your organization to understand the priorities for this workload and which best practices are most important.","title":"EKS Cost Optimization Best Practices"},{"location":"cost_optimization/cost_optimization_index/#how-to-use-this-guide","text":"This guide is meant for devops teams who are responsible for implementing and managing the EKS clusters and the workloads they support. The guide is organized into different best practice areas for easier consumption. Each topic has a list of recommendations, tools to use and best practices for cost optimization of your EKS clusters. The topics do not need to read in a particular order.","title":"How to use this guide"},{"location":"cost_optimization/cost_optimization_index/#key-aws-services-and-kubernetes-features","text":"Cost optimization is supported by the following AWS services and features: + EC2 Instance types, Savings Plan (and Reserved Instances) and Spot Instances, at different prices. + Auto Scaling along with Kubernetes native Auto Scaling policies. Consider Savings Plan (Previously Reserved Instances) for predictable workloads. Use managed data stores like EBS and EFS, for elasticity and durability of the application data. + The Billing and Cost Management console dashboard along with AWS Cost Explorer provides an overview of your AWS usage. Use AWS Organizations for granular billing details. Details of several third party tools have also been shared. + Amazon CloudWatch Container Metrics provides metrics around usage of resources by the EKS cluster. In addition to the Kubernetes dashboard, there are several tools in the Kubernetes ecosystem that can be used to reduce wastage. This guide includes a set of recommendations that you can use to improve the cost optimization of your Amazon EKS cluster.","title":"Key AWS Services and Kubernetes features"},{"location":"cost_optimization/cost_optimization_index/#feedback","text":"This guide is being released on GitHub so as to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. Our intention is to update the guide periodically as new features are added to the service or when a new best practice evolves.","title":"Feedback"},{"location":"cost_optimization/optimizing/","text":"Optimizing over time (Right Sizing) \u00b6 Right Sizing as per the AWS Well-Architected Framework, is \u201c\u2026 using the lowest cost resource that still meets the technical specifications of a specific workload\u201d. When you specify the resource requests for the Containers in a Pod, the scheduler uses this information to decide which node to place the Pod on. When you specify a resource limits for a Container, the kubelet enforces those limits so that the running container is not allowed to use more of that resource than the limit you set. The details of how Kubernetes manages resources for containers are given in the documentation . In Kubernetes, this means setting the right compute resources ( CPU and memory are collectively referred to as compute resources ) - setting the resource requests that align as close as possible to the actual utilization. The tools for getting the actual resource usags of Pods are given in the section on Rexommendations below. Amazon EKS on AWS Fargate : When pods are scheduled on Fargate, the vCPU and memory reservations within the pod specification determine how much CPU and memory to provision for the pod. If you do not specify a vCPU and memory combination, then the smallest available combination is used (.25 vCPU and 0.5 GB memory). The list of vCPU and memory combinations that are available for pods running on Fargate are listed in the Amazon EKS User Guide . Amazon EKS on EC2 : When you create a Pod, you can specify how much of each resource like CPU and Memory, a Container needs. It is important we do not over-provision (which will lead to wastage) or under-provision (will lead to throttling) the resources allocated to the containers. Recommendations \u00b6 Use tools to help you allocate resources based on observed data \u00b6 There are tools like kube resource report which can help with right sizing of pods deployed on Amazon EKS with EC2 nodes. Deployment steps for kube resource report: $ git clone https://github.com/hjacobs/kube-resource-report $ cd kube-resource-report $ helm install kube-resource-report ./unsupported/chart/kube-resource-report $ helm status kube-resource-report $ export POD_NAME = $( kubectl get pods --namespace default -l \"app.kubernetes.io/name=kube-resource-report,app.kubernetes.io/instance=kube-resource-report\" -o jsonpath = \"{.items[0].metadata.name}\" ) $ echo \"Visit http://127.0.0.1:8080 to use your application\" $ kubectl port-forward $POD_NAME 8080 :8080 Screenshots from a sample reports from this tool: FairwindsOps Goldilocks : The FairwindsOps Goldilocks is a tool that creates a Vertical Pod Autoscaler (VPA) for each deployment in a namespace and then queries them for information. Once the VPAs are in place, we see recommendations appear in the Goldilocks dashboard. Deploy the Vertical Pod Autoscaler as per the documentation . Enable Namespace - Pick an application namespace and label it like so in order to see some data, in the following example we are specifying the default namespace: $ kubectl label ns default goldilocks.fairwinds.com/enabled = true Viewing the Dashboard - The default installation creates a ClusterIP service for the dashboard. You can access via port forward: $ kubectl -n goldilocks port-forward svc/goldilocks-dashboard 8080 :80 Then open your browser to http://localhost:8080 Use Application Profiling tools like CloudWatch Container Insights and Prometheus Metrics in Amazon CloudWatch \u00b6 Use CloudWatch Container Insights to see how you can use native CloudWatch features to monitor your EKS Cluster performance. You can use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices running on Amazon Elastic Kubernetes Service. The metrics include utilization for resources such as CPU, memory, disk, and network - which can help with right-sizing Pods and save costs. Container Insights Prometheus Metrics Monitoring At present, support for Prometheus metrics is still in beta. CloudWatch Container Insights monitoring for Prometheus automates the discovery of Prometheus metrics from containerized systems and workloads. Prometheus is an open-source systems monitoring and alerting toolkit. All Prometheus metrics are collected in the ContainerInsights/Prometheus namespace. The Metrics provided by cAdvisor and kube-state-metrics can be used for monitoring pods on Amazon EKS on AWS Fargate using Prometheus and Grafana, which can then be used to implement requests in your containers. Please refer to this blog for more details. Right Size Guide : The right size guide (rsg) is a simple CLI tool that provides you with memory and CPU recommendations for your application. This tool works across container orchestrators, including Kubernetes and easy to deploy. By using tools like CloudWatch Container Insights, Kube Resource Report, Goldilocks and others, applications running in the Kubernetes cluster can be right sized and potentially lower your costs. Resources \u00b6 Refer to the following resources to learn more about best practices for cost optimization. Documentation and Blogs \u00b6 Amazon EKS Workshop - Setting up EKS CloudWatch Container Insights Using Prometheus Metrics in Amazon CloudWatch Monitoring Amazon EKS on AWS Fargate using Prometheus and Grafana Tools \u00b6 Kube resource report Right size guide Fargate count FairwindsOps Goldilocks Choose Right Node Size","title":"Optimizing over time (Right Sizing)"},{"location":"cost_optimization/optimizing/#optimizing-over-time-right-sizing","text":"Right Sizing as per the AWS Well-Architected Framework, is \u201c\u2026 using the lowest cost resource that still meets the technical specifications of a specific workload\u201d. When you specify the resource requests for the Containers in a Pod, the scheduler uses this information to decide which node to place the Pod on. When you specify a resource limits for a Container, the kubelet enforces those limits so that the running container is not allowed to use more of that resource than the limit you set. The details of how Kubernetes manages resources for containers are given in the documentation . In Kubernetes, this means setting the right compute resources ( CPU and memory are collectively referred to as compute resources ) - setting the resource requests that align as close as possible to the actual utilization. The tools for getting the actual resource usags of Pods are given in the section on Rexommendations below. Amazon EKS on AWS Fargate : When pods are scheduled on Fargate, the vCPU and memory reservations within the pod specification determine how much CPU and memory to provision for the pod. If you do not specify a vCPU and memory combination, then the smallest available combination is used (.25 vCPU and 0.5 GB memory). The list of vCPU and memory combinations that are available for pods running on Fargate are listed in the Amazon EKS User Guide . Amazon EKS on EC2 : When you create a Pod, you can specify how much of each resource like CPU and Memory, a Container needs. It is important we do not over-provision (which will lead to wastage) or under-provision (will lead to throttling) the resources allocated to the containers.","title":"Optimizing over time (Right Sizing)"},{"location":"cost_optimization/optimizing/#recommendations","text":"","title":"Recommendations"},{"location":"cost_optimization/optimizing/#use-tools-to-help-you-allocate-resources-based-on-observed-data","text":"There are tools like kube resource report which can help with right sizing of pods deployed on Amazon EKS with EC2 nodes. Deployment steps for kube resource report: $ git clone https://github.com/hjacobs/kube-resource-report $ cd kube-resource-report $ helm install kube-resource-report ./unsupported/chart/kube-resource-report $ helm status kube-resource-report $ export POD_NAME = $( kubectl get pods --namespace default -l \"app.kubernetes.io/name=kube-resource-report,app.kubernetes.io/instance=kube-resource-report\" -o jsonpath = \"{.items[0].metadata.name}\" ) $ echo \"Visit http://127.0.0.1:8080 to use your application\" $ kubectl port-forward $POD_NAME 8080 :8080 Screenshots from a sample reports from this tool: FairwindsOps Goldilocks : The FairwindsOps Goldilocks is a tool that creates a Vertical Pod Autoscaler (VPA) for each deployment in a namespace and then queries them for information. Once the VPAs are in place, we see recommendations appear in the Goldilocks dashboard. Deploy the Vertical Pod Autoscaler as per the documentation . Enable Namespace - Pick an application namespace and label it like so in order to see some data, in the following example we are specifying the default namespace: $ kubectl label ns default goldilocks.fairwinds.com/enabled = true Viewing the Dashboard - The default installation creates a ClusterIP service for the dashboard. You can access via port forward: $ kubectl -n goldilocks port-forward svc/goldilocks-dashboard 8080 :80 Then open your browser to http://localhost:8080","title":"Use tools to help you allocate resources based on observed data"},{"location":"cost_optimization/optimizing/#use-application-profiling-tools-like-cloudwatch-container-insights-and-prometheus-metrics-in-amazon-cloudwatch","text":"Use CloudWatch Container Insights to see how you can use native CloudWatch features to monitor your EKS Cluster performance. You can use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices running on Amazon Elastic Kubernetes Service. The metrics include utilization for resources such as CPU, memory, disk, and network - which can help with right-sizing Pods and save costs. Container Insights Prometheus Metrics Monitoring At present, support for Prometheus metrics is still in beta. CloudWatch Container Insights monitoring for Prometheus automates the discovery of Prometheus metrics from containerized systems and workloads. Prometheus is an open-source systems monitoring and alerting toolkit. All Prometheus metrics are collected in the ContainerInsights/Prometheus namespace. The Metrics provided by cAdvisor and kube-state-metrics can be used for monitoring pods on Amazon EKS on AWS Fargate using Prometheus and Grafana, which can then be used to implement requests in your containers. Please refer to this blog for more details. Right Size Guide : The right size guide (rsg) is a simple CLI tool that provides you with memory and CPU recommendations for your application. This tool works across container orchestrators, including Kubernetes and easy to deploy. By using tools like CloudWatch Container Insights, Kube Resource Report, Goldilocks and others, applications running in the Kubernetes cluster can be right sized and potentially lower your costs.","title":"Use Application Profiling tools like CloudWatch Container Insights and Prometheus Metrics in Amazon CloudWatch"},{"location":"cost_optimization/optimizing/#resources","text":"Refer to the following resources to learn more about best practices for cost optimization.","title":"Resources"},{"location":"cost_optimization/optimizing/#documentation-and-blogs","text":"Amazon EKS Workshop - Setting up EKS CloudWatch Container Insights Using Prometheus Metrics in Amazon CloudWatch Monitoring Amazon EKS on AWS Fargate using Prometheus and Grafana","title":"Documentation and Blogs"},{"location":"cost_optimization/optimizing/#tools","text":"Kube resource report Right size guide Fargate count FairwindsOps Goldilocks Choose Right Node Size","title":"Tools"},{"location":"karpenter/","text":"Karpenter Best Practices \u00b6 Karpenter \u00b6 Karpenter is an open-source cluster autoscaler that automatically provisions new nodes in response to unschedulable pods. Karpenter evaluates the aggregate resource requirements of the pending pods and chooses the optimal instance type to run them. It will automatically scale-in or terminate instances that don\u2019t have any non-daemonset pods to reduce waste. It also supports a consolidation feature which will actively move pods around and either delete or replace nodes with cheaper versions to reduce cluster cost. Reasons to use Karpenter Before the launch of Karpenter, Kubernetes users relied primarily on Amazon EC2 Auto Scaling groups and the Kubernetes Cluster Autoscaler (CAS) to dynamically adjust the compute capacity of their clusters. With Karpenter, you don\u2019t need to create dozens of node groups to achieve the flexibility and diversity you get with Karpenter. Moreover, Karpenter is not as tightly coupled to Kubernetes versions (as CAS is) and doesn\u2019t require you to jump between AWS and Kubernetes APIs. Karpenter consolidates instance orchestration responsibilities within a single system, which is simpler, more stable and cluster-aware. Karpenter was designed to overcome some of the challenges presented by Cluster Autoscaler by providing simplified ways to: Provision nodes based on workload requirements. Create diverse node configurations by instance type, using flexible workload provisioner options. Instead of managing many specific custom node groups, Karpenter could let you manage diverse workload capacity with a single, flexible provisioner. Achieve improved pod scheduling at scale by quickly launching nodes and scheduling pods. For information and documentation on using Karpenter, visit the karpenter.sh site. Recommendations \u00b6 Best practices are divided into sections on Karpenter itself, provisioners, and pod scheduling. Karpenter best practices \u00b6 The following best practices cover topics related to Karpenter itself. Use Karpenter for workloads with changing capacity needs \u00b6 Karpenter brings scaling management closer to Kubernetes native APIs than do Autoscaling Groups (ASGs) and Managed Node Groups (MNGs). ASGs and MNGs are AWS-native abstractions where scaling is triggered based on AWS level metrics, such as EC2 CPU load. Cluster Autoscaler bridges the Kubernetes abstractions into AWS abstractions, but loses some flexibility because of that, such as scheduling for a specific availability zone. Karpenter removes a layer of AWS abstraction to bring some of the flexibility directly into Kubernetes. Karpenter is best used for clusters with workloads that encounter periods of high, spiky demand or have diverse compute requirements. MNGs and ASGs are good for clusters running workloads that tend to be more static and consistent. You can use a mix of dynamically and statically managed nodes, depending on your requirements. Consider other autoscaling projects when... \u00b6 You need features that are still being developed in Karpenter. Because Karpenter is a relatively new project, consider other autoscaling projects for the time being if you have a need for features that are not yet part of Karpenter. Run the Karpenter controller on EKS Fargate or on a worker node that belongs to a node group \u00b6 Karpenter is installed using a Helm chart . The Helm chart installs the Karpenter controller and a webhook pod as a Deployment that needs to run before the controller can be used for scaling your cluster. We recommend a minimum of one small node group with at least one worker node. As an alternative, you can run these pods on EKS Fargate by creating a Fargate profile for the karpenter namespace. Doing so will cause all pods deployed into this namespace to run on EKS Fargate. Do not run Karpenter on a node that is managed by Karpenter. Avoid using custom launch templates with Karpenter \u00b6 Karpenter strongly recommends against using custom launch templates. Using custom launch templates prevents multi-architecture support, the ability to automatically upgrade nodes, and securityGroup discovery. Using launch templates may also cause confusion because certain fields are duplicated within Karpenter\u2019s provisioners while others are ignored by Karpenter, e.g. subnets and instance types. You can often avoid using launch templates by using custom user data and/or directly specifying custom AMIs in the AWS node template. More information on how to do this is available at Customer User Data and Ami . Granted, there may be times when you will want to use your own custom launch template, rather than using what Karpenter uses by default. The reasons to create custom launch templates may include the need to: Integrate with existing infrastructure. Meet compliance requirements. To learn more, see Launch Templates and Custom Images in the Karpenter documentation. For background on building custom AMIs, see Amazon EKS AMI Build using EC2 Image Builder , Packer scripts , and Create custom Amazon Linux AMIs for Amazon EKS . Exclude instance types that do not fit your workload \u00b6 Consider excluding specific instances types with the node.kubernetes.io/instance-type key if they are not required by workloads running in your cluster. The following example shows how to avoid provisioning large Graviton instances. - key : node.kubernetes.io/instance-type operator : NotIn values : 'm6g.16xlarge' 'm6gd.16xlarge' 'r6g.16xlarge' 'r6gd.16xlarge' 'c6g.16xlarge' Install the AWS Node Termination Handler when using Spot \u00b6 At present, Karpenter does not handle the Spot Interruption Termination Notice (ITN) two-minute warning. In lieu of this, you can install AWS Node Termination Handler to gracefully cordon and drain your spot nodes when they are interrupted. Pods that require checkpointing or other forms of graceful draining, requiring the 2-mins before shutdown, will need NTH. Amazon EKS private cluster without outbound internet access \u00b6 When provisioning an EKS Cluster into a VPC with no route to the internet, you have to make sure you\u2019ve configured your environment in accordance with the private cluster requirements that appear in EKS documentation. In addition, you need to make sure you\u2019ve created an STS VPC regional endpoint in your VPC. If not, you will see errors similar to those that appear below. ERROR controller.controller.metrics Reconciler error {\"commit\": \"5047f3c\", \"reconciler group\": \"karpenter.sh\", \"reconciler kind\": \"Provisioner\", \"name\": \"default\", \"namespace\": \"\", \"error\": \"fetching instance types using ec2.DescribeInstanceTypes, WebIdentityErr: failed to retrieve credentials\\ncaused by: RequestError: send request failed\\ncaused by: Post \\\"https://sts.<region>.amazonaws.com/\\\": dial tcp x.x.x.x:443: i/o timeout\"} These changes are necessary in a private cluster because the Karpenter Controller uses IAM Roles for Service Accounts (IRSA). Pods configured with IRSA acquire credentials by calling the AWS Security Token Service (AWS STS) API. If there is no outbound internet access, you must create and use an AWS STS VPC endpoint in your VPC . Private clusters also require you to create a VPC endpoint for SSM . When Karpenter tries to provision a new node, it queries the Launch template configs and an SSM parameter. If you do not have a SSM VPC endpoint in your VPC, it will cause the following error: INFO controller.provisioning Waiting for unschedulable pods {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} INFO controller.provisioning Batched 3 pods in 1.000572709s {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} INFO controller.provisioning Computed packing of 1 node(s) for 3 pod(s) with instance type option(s) [c4.xlarge c6i.xlarge c5.xlarge c5d.xlarge c5a.xlarge c5n.xlarge m6i.xlarge m4.xlarge m6a.xlarge m5ad.xlarge m5d.xlarge t3.xlarge m5a.xlarge t3a.xlarge m5.xlarge r4.xlarge r3.xlarge r5ad.xlarge r6i.xlarge r5a.xlarge] {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} ERROR controller.provisioning Could not launch node, launching instances, getting launch template configs, getting launch templates, getting ssm parameter, RequestError: send request failed caused by: Post \"https://ssm.<region>.amazonaws.com/\": dial tcp x.x.x.x:443: i/o timeout {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} There is no VPC endpoint for the Price List Query API . As a result, pricing data will go stale over time. Karpenter gets around this by including on-demand pricing data in its binary, but only updates that data when Karpenter is upgraded. Failed requests for pricing data will result in the following error messages: ERROR controller.aws.pricing updating on-demand pricing, RequestError: send request failed caused by: Post \"https://api.pricing.us-east-1.amazonaws.com/\": dial tcp 52.94.231.236:443: i/o timeout; RequestError: send request failed caused by: Post \"https://api.pricing.us-east-1.amazonaws.com/\": dial tcp 52.94.231.236:443: i/o timeout, using existing pricing data from 2022-08-17T00:19:52Z {\"commit\": \"4b5f953\"} In summary, to use Karpenter in a completely Private EKS Clusters, you need to create the following VPC endpoints: com.amazonaws.<region>.ec2 com.amazonaws.<region>.ecr.api com.amazonaws.<region>.ecr.dkr com.amazonaws.<region>.s3 \u2013 For pulling container images com.amazonaws.<region>.sts \u2013 For IAM roles for service accounts com.amazonaws.<region>.ssm - If using Karpenter Note Karpenter (controller and webhook deployment) container images must be in or copied to Amazon ECR private or to a another private registry accessible from inside the VPC. The reason for this is that the Karpenter controller and webhook pods currently use Public ECR images. If these are not available from within the VPC, or from networks peered with the VPC, you will get Image pull errors when Kubernetes tries to pull these images from ECR public. For further information, see Issue 988 and Issue 1157 . Creating provisioners \u00b6 The following best practices cover topics related to creating provisioners. Create multiple provisioners when... \u00b6 When different teams are sharing a cluster and need to run their workloads on different worker nodes, or have different OS or instance type requirements, create multiple provisioners. For example, one team may want to use Bottlerocket, while another may want to use Amazon Linux. Likewise, one team might have access to expensive GPU hardware that wouldn\u2019t be needed by another team. Using multiple provisioners makes sure that the most appropriate assets are available to each team. Create provisioners that are mutually exclusive or weighted \u00b6 It is recommended to create Provisioners that are either mutually exclusive or weighted to provide consistent scheduling behavior. If they are not and multiple Provisioners are matched, Karpenter will randomly choose which to use, causing unexpected results. Useful examples for creating multiple provisioners include the following: Creating a Provisioner with GPU and only allowing special workloads to run on these (expensive) nodes: # Provisioner for GPU Instances with Taints apiVersion : karpenter.sh/v1alpha5 kind : Provisioner metadata : name : gpu spec : requirements : - key : node.kubernetes.io/instance-type operator : In values : - p3.8xlarge - p3.16xlarge taints : - effect : NoSchedule key : nvidia.com/gpu value : \"true\" ttlSecondsAfterEmpty : 60 Deployment with toleration for the taint: # Deployment of GPU Workload will have tolerations defined apiVersion : apps/v1 kind : Deployment metadata : name : inflate-gpu spec : ... spec : tolerations : - key : \"nvidia.com/gpu\" operator : \"Exists\" effect : \"NoSchedule\" For a general deployment for another team, the provisioner spec could include nodeAffinify. A Deployment could then use nodeSelectorTerms to match billing-team . # Provisioner for regular EC2 instances apiVersion : karpenter.sh/v1alpha5 kind : Provisioner metadata : name : generalcompute spec : labels : billing-team : my-team requirements : - key : node.kubernetes.io/instance-type operator : In values : - m5.large - m5.xlarge - m5.2xlarge - c5.large - c5.xlarge - c5a.large - c5a.xlarge - r5.large - r5.xlarge Deployment using nodeAffinity: # Deployment will have spec.affinity.nodeAffinity defined kind : Deployment metadata : name : workload-my-team spec : replicas : 200 ... spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : \"billing-team\" operator : \"In\" values : [ \"my-team\" ] Use timers (TTL) to automatically delete nodes from the cluster \u00b6 You can use timers on provisioned nodes to set when to delete nodes that are devoid of workload pods or have reached an expiration time. Node expiry can be used as a means of upgrading, so that nodes are retired and replaced with updated versions. See How Karpenter nodes are deprovisioned in the Karpenter documentation for information on using ttlSecondsUntilExpired and ttlSecondsAfterEmpty to deprovision nodes. Avoid overly constraining the Instance Types that Karpenter can provision, especially when utilizing Spot \u00b6 When using Spot, Karpenter uses the Capacity Optimized Prioritized allocation strategy to provision EC2 instances. The Capacity Optimized allocation strategy will instruct EC2 to provision instances from deeper spot pools in order to decrease the likelihood of interruption. The more instance types you allow Karpenter to utilize, the better EC2 can optimize your spot instance\u2019s runtime. By default, Karpenter will use all Instance Types EC2 offers in the region and availability zones your cluster is deployed in. Karpenter intelligently chooses from the set of all instance types based on pending pods to make sure your pods are scheduled onto appropriately sized and equipped instances. For example, if your pod does not require a GPU, Karpenter will not schedule your pod to an EC2 instance type supporting a GPU. When you're unsure about which instance types to use, you can run the Amazon ec2-instance-selector to generate a list of instance types that match your compute requirements. For example, the CLI takes memory vCPU, architecture, and region as input parameters and provides you with a list of EC2 instances that satisfy those constraints. $ ec2-instance-selector --memory 4 --vcpus 2 --cpu-architecture x86_64 -r ap-southeast-1 c5.large c5a.large c5ad.large c5d.large c6i.large t2.medium t3.medium t3a.medium You shouldn\u2019t place too many constraints on Karpenter when using Spot instances because doing so can affect the availability of your applications. Say, for example, all of the instances of a particular type are reclaimed and there are no suitable alternatives available to replace them. Your pods will remain in a pending state until the spot capacity for the configured instance types is replenished. You can reduce the risk of insufficient capacity errors by spreading your instances across different availability zones, because spot pools are different across AZs. That said, the general best practice is to allow Karpenter to use a diverse set of instance types when using Spot. Scheduling Pods \u00b6 The following best practices relate to deploying pods In a cluster using Karpenter for node provisioning. Follow EKS best practices for high availability \u00b6 If you need to run highly available applications, follow general EKS best practice recommendations . See Topology Spread in Karpenter documentation for details on how to spread pods across nodes and zones. Use Disruption Budgets to set the minimum available pods that need to be maintained, in case there are attempts to evict or delete pods. Use layered Constraints to constrain the compute features available from your cloud provider \u00b6 Karpenter\u2019s model of layered constraints allows you to create a complex set of provisioner and pod deployment constraints to get the best possible matches for pod scheduling. Examples of constraints that a pod spec can request include the following: Needing to run in availability zones where only particular applications are available. Say, for example, you have pod that has to communicate with another application that runs on an EC2 instance residing in a particular availability zone. If your aim is to reduce cross-AZ traffic in your VPC, you may want to co-locate the pods in the AZ where the EC2 instance is located. This sort of targeting is often accomplished using node selectors. For additional information on Node selectors , please refer to the Kubernetes documentation. Requiring certain kinds of processors or other hardware. See the Accelerators section of the Karpenter docs for a podspec example that requires the pod to run on a GPU processor. Create billing alarms to monitor your compute spend \u00b6 When you configure your cluster to automatically scale, you should create billing alarms to warn you when your spend has exceeded a threshold and add resource limits to your Karpenter configuration. Setting resource limits with Karpenter is similar to setting an AWS autoscaling group\u2019s maximum capacity in that it represents the maximum amount of compute resources that can be instantiated by a Karpenter provisioner. Note It is not possible to set a global limit for the whole cluster. Limits apply to specific provisioners. The snippet below tells Karpenter to only provision a maximum of 1000 CPU cores and 1000Gi of memory. Karpenter will stop adding capacity only when the limit is met or exceeded. When a limit is exceeded the Karpenter controller will write memory resource usage of 1001 exceeds limit of 1000 or a similar looking message to the controller\u2019s logs. If you are routing your container logs to CloudWatch logs, you can create a metrics filter to look for specific patterns or terms in your logs and then create a CloudWatch alarm to alert you when your configured metrics threshold is breached. For further information using limits with Karpenter, see Setting Resource Limits in the Karpenter documentation. spec : limits : resources : cpu : 1000 memory : 1000Gi Note Setting GPU limits is not supported at this time. If you don\u2019t use limits or constrain the instance types that Karpenter can provision, Karpenter will continue adding compute capacity to your cluster as needed. While configuring Karpenter in this way allows your cluster to scale freely, it can also have significant cost implications. It is for this reason that we recommend that configuring billing alarms. Billing alarms allow you to be alerted and proactively notified when the calculated estimated charges in your account(s) exceed a defined threshold. See Setting up an Amazon CloudWatch Billing Alarm to Proactively Monitor Estimated Charges for additional information. You may also want to enable Cost Anomaly Detection which is an AWS Cost Management feature that uses machine learning to continuously monitor your cost and usage to detect unusual spends. Further information can be found in the AWS Cost Anomaly Detection Getting Started guide. If you\u2019ve gone so far as to create a budget in AWS Budgets, you can also configure an action to notify you when a specific threshold has been breached. With budget actions you can send an email, post a message to an SNS topic, or send a message to a chatbot like Slack. For further information see Configuring AWS Budgets actions . Use the do-not-evict annotation to prevent Karpenter from deprovisioning a node \u00b6 If you are running a critical application on a Karpenter-provisioned node, such as a long running batch job or stateful application, and the node\u2019s TTL has expired, the application will be interrupted when the instance is terminated. By adding a karpenter.sh/do-not-evict annotation to the pod, you are instructing Karpenter to preserve the node until the Pod is terminated or the do-not-evict annotation is removed. See Deprovisioning documentation for further information. If the only non-daemonset pods left on a node are those associated with jobs, Karpenter is able to target and terminate those nodes so long as the job status is succeed or failed. Configure the Node Termination Handler to use queue processor mode \u00b6 Node Termination Handler operates in two modes, using Instance Metadata Services (IMDS) or using a Queue Processor. The IMDS service runs a pod on each node to monitor the events and act accordingly. Whereas the queue processor uses Amazon Simple Queue Service (Amazon SQS) to receive Auto Scaling Group (ASG) lifecycle events, EC2 status change events, Spot interruption termination notice events, and Spot rebalance recommendation events. These events can be configured to be published to Amazon EventBridge. In Karpenter\u2019s case, Auto Scaling Group lifecycle events should not be considered because the instances provisioned using Karpenter are not part of an ASG. When following the installation instructions , you can skip the steps for Set up a Termination Lifecycle Hook on an Auto Scaling group and Tag the Auto Scaling groups because instances provisioned by Karpenter do not belong to an autoscaling group. In the step Create Amazon Eventbridge Rules , skip the step to create Auto Scaling event rules. If you are deploying the Helm chart for the Node Termination Handler Queue Processor, use the following values: ## Queue processor values.yaml enableSqsTerminationDraining : true queueURL : \"<specify your queue URl>\" awsRegion : \"<specify your region>\" serviceAccount : create : false name : nth # <-- adjust to your service account checkASGTagBeforeDraining : false # <-- set to false as instances do not belong to any ASG enableSpotInterruptionDraining : true Configure requests=limits for all non-CPU resources when using consolidation \u00b6 Consolidation and scheduling in general work by comparing the pods resource requests vs the amount of allocatable resources on a node. The resource limits are not considered. As an example, pods that have a memory limit that is larger than the memory request can burst above the request. If several pods on the same node burst at the same time, this can cause some of the pods to be terminated due to an out of memory (OOM) condition. Consolidation can make this more likely to occur as it works to pack pods onto nodes only considering their requests. Use LimitRanges to configure defaults for resource requests and limits \u00b6 Because Kubernetes doesn\u2019t set default requests or limits, a container\u2019s consumption of resources from the underlying host, CPU, and memory is unbound. The Kubernetes scheduler looks at a pod\u2019s total requests (the higher of the total requests from the pod\u2019s containers or the total resources from the pod\u2019s Init containers) to determine which worker node to schedule the pod onto. Similarly, Karpenter considers a pod\u2019s requests to determine which type of instance it provisions. You can use a limit range to apply a sensible default for a namespace, in case resource requests are not specified by some pods. See Configure Default Memory Requests and Limits for a Namespace Apply accurate resource requests to all workloads \u00b6 Karpenter is able to launch nodes that best fit your workloads when its information about your workloads requirements is accurate. This is particularly important if using Karpenter's consolidation feature. See Configure and Size Resource Requests/Limits for all Workloads Additional Resources \u00b6 Karpenter/Spot Workshop Karpenter Node Provisioner TGIK Karpenter Karpenter vs. Cluster Autoscaler Groupless Autoscaling with Karpenter","title":"Karpenter"},{"location":"karpenter/#karpenter-best-practices","text":"","title":"Karpenter Best Practices"},{"location":"karpenter/#karpenter","text":"Karpenter is an open-source cluster autoscaler that automatically provisions new nodes in response to unschedulable pods. Karpenter evaluates the aggregate resource requirements of the pending pods and chooses the optimal instance type to run them. It will automatically scale-in or terminate instances that don\u2019t have any non-daemonset pods to reduce waste. It also supports a consolidation feature which will actively move pods around and either delete or replace nodes with cheaper versions to reduce cluster cost. Reasons to use Karpenter Before the launch of Karpenter, Kubernetes users relied primarily on Amazon EC2 Auto Scaling groups and the Kubernetes Cluster Autoscaler (CAS) to dynamically adjust the compute capacity of their clusters. With Karpenter, you don\u2019t need to create dozens of node groups to achieve the flexibility and diversity you get with Karpenter. Moreover, Karpenter is not as tightly coupled to Kubernetes versions (as CAS is) and doesn\u2019t require you to jump between AWS and Kubernetes APIs. Karpenter consolidates instance orchestration responsibilities within a single system, which is simpler, more stable and cluster-aware. Karpenter was designed to overcome some of the challenges presented by Cluster Autoscaler by providing simplified ways to: Provision nodes based on workload requirements. Create diverse node configurations by instance type, using flexible workload provisioner options. Instead of managing many specific custom node groups, Karpenter could let you manage diverse workload capacity with a single, flexible provisioner. Achieve improved pod scheduling at scale by quickly launching nodes and scheduling pods. For information and documentation on using Karpenter, visit the karpenter.sh site.","title":"Karpenter"},{"location":"karpenter/#recommendations","text":"Best practices are divided into sections on Karpenter itself, provisioners, and pod scheduling.","title":"Recommendations"},{"location":"karpenter/#karpenter-best-practices_1","text":"The following best practices cover topics related to Karpenter itself.","title":"Karpenter best practices"},{"location":"karpenter/#use-karpenter-for-workloads-with-changing-capacity-needs","text":"Karpenter brings scaling management closer to Kubernetes native APIs than do Autoscaling Groups (ASGs) and Managed Node Groups (MNGs). ASGs and MNGs are AWS-native abstractions where scaling is triggered based on AWS level metrics, such as EC2 CPU load. Cluster Autoscaler bridges the Kubernetes abstractions into AWS abstractions, but loses some flexibility because of that, such as scheduling for a specific availability zone. Karpenter removes a layer of AWS abstraction to bring some of the flexibility directly into Kubernetes. Karpenter is best used for clusters with workloads that encounter periods of high, spiky demand or have diverse compute requirements. MNGs and ASGs are good for clusters running workloads that tend to be more static and consistent. You can use a mix of dynamically and statically managed nodes, depending on your requirements.","title":"Use Karpenter for workloads with changing capacity needs"},{"location":"karpenter/#consider-other-autoscaling-projects-when","text":"You need features that are still being developed in Karpenter. Because Karpenter is a relatively new project, consider other autoscaling projects for the time being if you have a need for features that are not yet part of Karpenter.","title":"Consider other autoscaling projects when..."},{"location":"karpenter/#run-the-karpenter-controller-on-eks-fargate-or-on-a-worker-node-that-belongs-to-a-node-group","text":"Karpenter is installed using a Helm chart . The Helm chart installs the Karpenter controller and a webhook pod as a Deployment that needs to run before the controller can be used for scaling your cluster. We recommend a minimum of one small node group with at least one worker node. As an alternative, you can run these pods on EKS Fargate by creating a Fargate profile for the karpenter namespace. Doing so will cause all pods deployed into this namespace to run on EKS Fargate. Do not run Karpenter on a node that is managed by Karpenter.","title":"Run the Karpenter controller on EKS Fargate or on a worker node that belongs to a node group"},{"location":"karpenter/#avoid-using-custom-launch-templates-with-karpenter","text":"Karpenter strongly recommends against using custom launch templates. Using custom launch templates prevents multi-architecture support, the ability to automatically upgrade nodes, and securityGroup discovery. Using launch templates may also cause confusion because certain fields are duplicated within Karpenter\u2019s provisioners while others are ignored by Karpenter, e.g. subnets and instance types. You can often avoid using launch templates by using custom user data and/or directly specifying custom AMIs in the AWS node template. More information on how to do this is available at Customer User Data and Ami . Granted, there may be times when you will want to use your own custom launch template, rather than using what Karpenter uses by default. The reasons to create custom launch templates may include the need to: Integrate with existing infrastructure. Meet compliance requirements. To learn more, see Launch Templates and Custom Images in the Karpenter documentation. For background on building custom AMIs, see Amazon EKS AMI Build using EC2 Image Builder , Packer scripts , and Create custom Amazon Linux AMIs for Amazon EKS .","title":"Avoid using custom launch templates with Karpenter"},{"location":"karpenter/#exclude-instance-types-that-do-not-fit-your-workload","text":"Consider excluding specific instances types with the node.kubernetes.io/instance-type key if they are not required by workloads running in your cluster. The following example shows how to avoid provisioning large Graviton instances. - key : node.kubernetes.io/instance-type operator : NotIn values : 'm6g.16xlarge' 'm6gd.16xlarge' 'r6g.16xlarge' 'r6gd.16xlarge' 'c6g.16xlarge'","title":"Exclude instance types that do not fit your workload"},{"location":"karpenter/#install-the-aws-node-termination-handler-when-using-spot","text":"At present, Karpenter does not handle the Spot Interruption Termination Notice (ITN) two-minute warning. In lieu of this, you can install AWS Node Termination Handler to gracefully cordon and drain your spot nodes when they are interrupted. Pods that require checkpointing or other forms of graceful draining, requiring the 2-mins before shutdown, will need NTH.","title":"Install the AWS Node Termination Handler when using Spot"},{"location":"karpenter/#amazon-eks-private-cluster-without-outbound-internet-access","text":"When provisioning an EKS Cluster into a VPC with no route to the internet, you have to make sure you\u2019ve configured your environment in accordance with the private cluster requirements that appear in EKS documentation. In addition, you need to make sure you\u2019ve created an STS VPC regional endpoint in your VPC. If not, you will see errors similar to those that appear below. ERROR controller.controller.metrics Reconciler error {\"commit\": \"5047f3c\", \"reconciler group\": \"karpenter.sh\", \"reconciler kind\": \"Provisioner\", \"name\": \"default\", \"namespace\": \"\", \"error\": \"fetching instance types using ec2.DescribeInstanceTypes, WebIdentityErr: failed to retrieve credentials\\ncaused by: RequestError: send request failed\\ncaused by: Post \\\"https://sts.<region>.amazonaws.com/\\\": dial tcp x.x.x.x:443: i/o timeout\"} These changes are necessary in a private cluster because the Karpenter Controller uses IAM Roles for Service Accounts (IRSA). Pods configured with IRSA acquire credentials by calling the AWS Security Token Service (AWS STS) API. If there is no outbound internet access, you must create and use an AWS STS VPC endpoint in your VPC . Private clusters also require you to create a VPC endpoint for SSM . When Karpenter tries to provision a new node, it queries the Launch template configs and an SSM parameter. If you do not have a SSM VPC endpoint in your VPC, it will cause the following error: INFO controller.provisioning Waiting for unschedulable pods {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} INFO controller.provisioning Batched 3 pods in 1.000572709s {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} INFO controller.provisioning Computed packing of 1 node(s) for 3 pod(s) with instance type option(s) [c4.xlarge c6i.xlarge c5.xlarge c5d.xlarge c5a.xlarge c5n.xlarge m6i.xlarge m4.xlarge m6a.xlarge m5ad.xlarge m5d.xlarge t3.xlarge m5a.xlarge t3a.xlarge m5.xlarge r4.xlarge r3.xlarge r5ad.xlarge r6i.xlarge r5a.xlarge] {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} ERROR controller.provisioning Could not launch node, launching instances, getting launch template configs, getting launch templates, getting ssm parameter, RequestError: send request failed caused by: Post \"https://ssm.<region>.amazonaws.com/\": dial tcp x.x.x.x:443: i/o timeout {\"commit\": \"5047f3c\", \"provisioner\": \"default\"} There is no VPC endpoint for the Price List Query API . As a result, pricing data will go stale over time. Karpenter gets around this by including on-demand pricing data in its binary, but only updates that data when Karpenter is upgraded. Failed requests for pricing data will result in the following error messages: ERROR controller.aws.pricing updating on-demand pricing, RequestError: send request failed caused by: Post \"https://api.pricing.us-east-1.amazonaws.com/\": dial tcp 52.94.231.236:443: i/o timeout; RequestError: send request failed caused by: Post \"https://api.pricing.us-east-1.amazonaws.com/\": dial tcp 52.94.231.236:443: i/o timeout, using existing pricing data from 2022-08-17T00:19:52Z {\"commit\": \"4b5f953\"} In summary, to use Karpenter in a completely Private EKS Clusters, you need to create the following VPC endpoints: com.amazonaws.<region>.ec2 com.amazonaws.<region>.ecr.api com.amazonaws.<region>.ecr.dkr com.amazonaws.<region>.s3 \u2013 For pulling container images com.amazonaws.<region>.sts \u2013 For IAM roles for service accounts com.amazonaws.<region>.ssm - If using Karpenter Note Karpenter (controller and webhook deployment) container images must be in or copied to Amazon ECR private or to a another private registry accessible from inside the VPC. The reason for this is that the Karpenter controller and webhook pods currently use Public ECR images. If these are not available from within the VPC, or from networks peered with the VPC, you will get Image pull errors when Kubernetes tries to pull these images from ECR public. For further information, see Issue 988 and Issue 1157 .","title":"Amazon EKS private cluster without outbound internet access"},{"location":"karpenter/#creating-provisioners","text":"The following best practices cover topics related to creating provisioners.","title":"Creating provisioners"},{"location":"karpenter/#create-multiple-provisioners-when","text":"When different teams are sharing a cluster and need to run their workloads on different worker nodes, or have different OS or instance type requirements, create multiple provisioners. For example, one team may want to use Bottlerocket, while another may want to use Amazon Linux. Likewise, one team might have access to expensive GPU hardware that wouldn\u2019t be needed by another team. Using multiple provisioners makes sure that the most appropriate assets are available to each team.","title":"Create multiple provisioners when..."},{"location":"karpenter/#create-provisioners-that-are-mutually-exclusive-or-weighted","text":"It is recommended to create Provisioners that are either mutually exclusive or weighted to provide consistent scheduling behavior. If they are not and multiple Provisioners are matched, Karpenter will randomly choose which to use, causing unexpected results. Useful examples for creating multiple provisioners include the following: Creating a Provisioner with GPU and only allowing special workloads to run on these (expensive) nodes: # Provisioner for GPU Instances with Taints apiVersion : karpenter.sh/v1alpha5 kind : Provisioner metadata : name : gpu spec : requirements : - key : node.kubernetes.io/instance-type operator : In values : - p3.8xlarge - p3.16xlarge taints : - effect : NoSchedule key : nvidia.com/gpu value : \"true\" ttlSecondsAfterEmpty : 60 Deployment with toleration for the taint: # Deployment of GPU Workload will have tolerations defined apiVersion : apps/v1 kind : Deployment metadata : name : inflate-gpu spec : ... spec : tolerations : - key : \"nvidia.com/gpu\" operator : \"Exists\" effect : \"NoSchedule\" For a general deployment for another team, the provisioner spec could include nodeAffinify. A Deployment could then use nodeSelectorTerms to match billing-team . # Provisioner for regular EC2 instances apiVersion : karpenter.sh/v1alpha5 kind : Provisioner metadata : name : generalcompute spec : labels : billing-team : my-team requirements : - key : node.kubernetes.io/instance-type operator : In values : - m5.large - m5.xlarge - m5.2xlarge - c5.large - c5.xlarge - c5a.large - c5a.xlarge - r5.large - r5.xlarge Deployment using nodeAffinity: # Deployment will have spec.affinity.nodeAffinity defined kind : Deployment metadata : name : workload-my-team spec : replicas : 200 ... spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : \"billing-team\" operator : \"In\" values : [ \"my-team\" ]","title":"Create provisioners that are mutually exclusive or weighted"},{"location":"karpenter/#use-timers-ttl-to-automatically-delete-nodes-from-the-cluster","text":"You can use timers on provisioned nodes to set when to delete nodes that are devoid of workload pods or have reached an expiration time. Node expiry can be used as a means of upgrading, so that nodes are retired and replaced with updated versions. See How Karpenter nodes are deprovisioned in the Karpenter documentation for information on using ttlSecondsUntilExpired and ttlSecondsAfterEmpty to deprovision nodes.","title":"Use timers (TTL) to automatically delete nodes from the cluster"},{"location":"karpenter/#avoid-overly-constraining-the-instance-types-that-karpenter-can-provision-especially-when-utilizing-spot","text":"When using Spot, Karpenter uses the Capacity Optimized Prioritized allocation strategy to provision EC2 instances. The Capacity Optimized allocation strategy will instruct EC2 to provision instances from deeper spot pools in order to decrease the likelihood of interruption. The more instance types you allow Karpenter to utilize, the better EC2 can optimize your spot instance\u2019s runtime. By default, Karpenter will use all Instance Types EC2 offers in the region and availability zones your cluster is deployed in. Karpenter intelligently chooses from the set of all instance types based on pending pods to make sure your pods are scheduled onto appropriately sized and equipped instances. For example, if your pod does not require a GPU, Karpenter will not schedule your pod to an EC2 instance type supporting a GPU. When you're unsure about which instance types to use, you can run the Amazon ec2-instance-selector to generate a list of instance types that match your compute requirements. For example, the CLI takes memory vCPU, architecture, and region as input parameters and provides you with a list of EC2 instances that satisfy those constraints. $ ec2-instance-selector --memory 4 --vcpus 2 --cpu-architecture x86_64 -r ap-southeast-1 c5.large c5a.large c5ad.large c5d.large c6i.large t2.medium t3.medium t3a.medium You shouldn\u2019t place too many constraints on Karpenter when using Spot instances because doing so can affect the availability of your applications. Say, for example, all of the instances of a particular type are reclaimed and there are no suitable alternatives available to replace them. Your pods will remain in a pending state until the spot capacity for the configured instance types is replenished. You can reduce the risk of insufficient capacity errors by spreading your instances across different availability zones, because spot pools are different across AZs. That said, the general best practice is to allow Karpenter to use a diverse set of instance types when using Spot.","title":"Avoid overly constraining the Instance Types that Karpenter can provision, especially when utilizing Spot"},{"location":"karpenter/#scheduling-pods","text":"The following best practices relate to deploying pods In a cluster using Karpenter for node provisioning.","title":"Scheduling Pods"},{"location":"karpenter/#follow-eks-best-practices-for-high-availability","text":"If you need to run highly available applications, follow general EKS best practice recommendations . See Topology Spread in Karpenter documentation for details on how to spread pods across nodes and zones. Use Disruption Budgets to set the minimum available pods that need to be maintained, in case there are attempts to evict or delete pods.","title":"Follow EKS best practices for high availability"},{"location":"karpenter/#use-layered-constraints-to-constrain-the-compute-features-available-from-your-cloud-provider","text":"Karpenter\u2019s model of layered constraints allows you to create a complex set of provisioner and pod deployment constraints to get the best possible matches for pod scheduling. Examples of constraints that a pod spec can request include the following: Needing to run in availability zones where only particular applications are available. Say, for example, you have pod that has to communicate with another application that runs on an EC2 instance residing in a particular availability zone. If your aim is to reduce cross-AZ traffic in your VPC, you may want to co-locate the pods in the AZ where the EC2 instance is located. This sort of targeting is often accomplished using node selectors. For additional information on Node selectors , please refer to the Kubernetes documentation. Requiring certain kinds of processors or other hardware. See the Accelerators section of the Karpenter docs for a podspec example that requires the pod to run on a GPU processor.","title":"Use layered Constraints to constrain the compute features available from your cloud provider"},{"location":"karpenter/#create-billing-alarms-to-monitor-your-compute-spend","text":"When you configure your cluster to automatically scale, you should create billing alarms to warn you when your spend has exceeded a threshold and add resource limits to your Karpenter configuration. Setting resource limits with Karpenter is similar to setting an AWS autoscaling group\u2019s maximum capacity in that it represents the maximum amount of compute resources that can be instantiated by a Karpenter provisioner. Note It is not possible to set a global limit for the whole cluster. Limits apply to specific provisioners. The snippet below tells Karpenter to only provision a maximum of 1000 CPU cores and 1000Gi of memory. Karpenter will stop adding capacity only when the limit is met or exceeded. When a limit is exceeded the Karpenter controller will write memory resource usage of 1001 exceeds limit of 1000 or a similar looking message to the controller\u2019s logs. If you are routing your container logs to CloudWatch logs, you can create a metrics filter to look for specific patterns or terms in your logs and then create a CloudWatch alarm to alert you when your configured metrics threshold is breached. For further information using limits with Karpenter, see Setting Resource Limits in the Karpenter documentation. spec : limits : resources : cpu : 1000 memory : 1000Gi Note Setting GPU limits is not supported at this time. If you don\u2019t use limits or constrain the instance types that Karpenter can provision, Karpenter will continue adding compute capacity to your cluster as needed. While configuring Karpenter in this way allows your cluster to scale freely, it can also have significant cost implications. It is for this reason that we recommend that configuring billing alarms. Billing alarms allow you to be alerted and proactively notified when the calculated estimated charges in your account(s) exceed a defined threshold. See Setting up an Amazon CloudWatch Billing Alarm to Proactively Monitor Estimated Charges for additional information. You may also want to enable Cost Anomaly Detection which is an AWS Cost Management feature that uses machine learning to continuously monitor your cost and usage to detect unusual spends. Further information can be found in the AWS Cost Anomaly Detection Getting Started guide. If you\u2019ve gone so far as to create a budget in AWS Budgets, you can also configure an action to notify you when a specific threshold has been breached. With budget actions you can send an email, post a message to an SNS topic, or send a message to a chatbot like Slack. For further information see Configuring AWS Budgets actions .","title":"Create billing alarms to monitor your compute spend"},{"location":"karpenter/#use-the-do-not-evict-annotation-to-prevent-karpenter-from-deprovisioning-a-node","text":"If you are running a critical application on a Karpenter-provisioned node, such as a long running batch job or stateful application, and the node\u2019s TTL has expired, the application will be interrupted when the instance is terminated. By adding a karpenter.sh/do-not-evict annotation to the pod, you are instructing Karpenter to preserve the node until the Pod is terminated or the do-not-evict annotation is removed. See Deprovisioning documentation for further information. If the only non-daemonset pods left on a node are those associated with jobs, Karpenter is able to target and terminate those nodes so long as the job status is succeed or failed.","title":"Use the do-not-evict annotation to prevent Karpenter from deprovisioning a node"},{"location":"karpenter/#configure-the-node-termination-handler-to-use-queue-processor-mode","text":"Node Termination Handler operates in two modes, using Instance Metadata Services (IMDS) or using a Queue Processor. The IMDS service runs a pod on each node to monitor the events and act accordingly. Whereas the queue processor uses Amazon Simple Queue Service (Amazon SQS) to receive Auto Scaling Group (ASG) lifecycle events, EC2 status change events, Spot interruption termination notice events, and Spot rebalance recommendation events. These events can be configured to be published to Amazon EventBridge. In Karpenter\u2019s case, Auto Scaling Group lifecycle events should not be considered because the instances provisioned using Karpenter are not part of an ASG. When following the installation instructions , you can skip the steps for Set up a Termination Lifecycle Hook on an Auto Scaling group and Tag the Auto Scaling groups because instances provisioned by Karpenter do not belong to an autoscaling group. In the step Create Amazon Eventbridge Rules , skip the step to create Auto Scaling event rules. If you are deploying the Helm chart for the Node Termination Handler Queue Processor, use the following values: ## Queue processor values.yaml enableSqsTerminationDraining : true queueURL : \"<specify your queue URl>\" awsRegion : \"<specify your region>\" serviceAccount : create : false name : nth # <-- adjust to your service account checkASGTagBeforeDraining : false # <-- set to false as instances do not belong to any ASG enableSpotInterruptionDraining : true","title":"Configure the Node Termination Handler to use queue processor mode"},{"location":"karpenter/#configure-requestslimits-for-all-non-cpu-resources-when-using-consolidation","text":"Consolidation and scheduling in general work by comparing the pods resource requests vs the amount of allocatable resources on a node. The resource limits are not considered. As an example, pods that have a memory limit that is larger than the memory request can burst above the request. If several pods on the same node burst at the same time, this can cause some of the pods to be terminated due to an out of memory (OOM) condition. Consolidation can make this more likely to occur as it works to pack pods onto nodes only considering their requests.","title":"Configure requests=limits for all non-CPU resources when using consolidation"},{"location":"karpenter/#use-limitranges-to-configure-defaults-for-resource-requests-and-limits","text":"Because Kubernetes doesn\u2019t set default requests or limits, a container\u2019s consumption of resources from the underlying host, CPU, and memory is unbound. The Kubernetes scheduler looks at a pod\u2019s total requests (the higher of the total requests from the pod\u2019s containers or the total resources from the pod\u2019s Init containers) to determine which worker node to schedule the pod onto. Similarly, Karpenter considers a pod\u2019s requests to determine which type of instance it provisions. You can use a limit range to apply a sensible default for a namespace, in case resource requests are not specified by some pods. See Configure Default Memory Requests and Limits for a Namespace","title":"Use LimitRanges to configure defaults for resource requests and limits"},{"location":"karpenter/#apply-accurate-resource-requests-to-all-workloads","text":"Karpenter is able to launch nodes that best fit your workloads when its information about your workloads requirements is accurate. This is particularly important if using Karpenter's consolidation feature. See Configure and Size Resource Requests/Limits for all Workloads","title":"Apply accurate resource requests to all workloads"},{"location":"karpenter/#additional-resources","text":"Karpenter/Spot Workshop Karpenter Node Provisioner TGIK Karpenter Karpenter vs. Cluster Autoscaler Groupless Autoscaling with Karpenter","title":"Additional Resources"},{"location":"networking/custom-networking/","text":"Custom Networking \u00b6 By default, Amazon VPC CNI will assign Pods an IP address selected from the primary subnet. The primary subnet is the subnet CIDR that the primary ENI is attached to, usually the subnet of the node/host. If the subnet CIDR is too small, the CNI may not be able to acquire enough secondary IP addresses to assign to your Pods. This is a common challenge for EKS IPv4 clusters. Custom networking is one solution to this problem. Custom networking addresses the IP exhaustion issue by assigning the node and Pod IPs from secondary VPC address spaces (CIDR). Custom networking support supports ENIConfig custom resource. The ENIConfig includes an alternate subnet CIDR range (carved from a secondary VPC CIDR), along with the security group(s) that the Pods will belong to. When custom networking is enabled, the VPC CNI creates secondary ENIs in the subnet defined under ENIConfig. The CNI assigns Pods an IP addresses from a CIDR range defined in a ENIConfig CRD. Since the primary ENI is not used by custom networking, the maximum number of Pods you can run on a node is lower. The host network Pods continue to use IP address assigned to the primary ENI. Additionally, the primary ENI is used to handle source network translation and route Pods traffic outside the node. Example Configuration \u00b6 While custom networking will accept valid VPC range for secondary CIDR range, we recommend that you use CIDRs (/16) from the CG-NAT space, i.e. 100.64.0.0/10 or 198.19.0.0/16 as those are less likely to be used in a corporate setting than other RFC1918 ranges. For additional information about the permitted and restricted CIDR block associations you can use with your VPC, see IPv4 CIDR block association restrictions in the VPC and subnet sizing section of the VPC documentation. As shown in the diagram below, the primary Elastic Network Interface ( ENI ) of the worker node still uses the primary VPC CIDR range (in this case 10.0.0.0/16) but the secondary ENIs use the secondary VPC CIDR Range (in this case 100.64.0.0/16). Now, in order to have the Pods use the 100.64.0.0/16 CIDR range, you must configure the CNI plugin to use custom networking. You can follow through the steps as documented here . If you want the CNI to use custom networking, set the AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG environment variable to true . kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true When AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true , the CNI will assign Pod IP address from a subnet defined in ENIConfig . The ENIConfig custom resource is used to define the subnet in which Pods will be scheduled. apiVersion : crd . k8s . amazonaws . com / v1alpha1 kind : ENIConfig metadata : name : us - west - 2 a spec : securityGroups : - sg - 0 dff111a1d11c1c11 subnet : subnet - 011 b111c1f11fdf11 Upon creating the ENIconfig custom resources, you will need to create new worker nodes and drain the existing nodes. The existing worker nodes and Pods will remain unaffected. Recommendations \u00b6 Use Custom Networking When \u00b6 We recommend you to consider custom networking if you are dealing with IPv4 exhaustion and can\u2019t use IPv6 yet. Amazon EKS support for RFC6598 space enables you to scale Pods beyond RFC1918 address exhaustion challenges. Please consider using prefix delegation with custom networking to increase the Pods density on a node. You might consider custom networking if you have a security requirement to run Pods on a different network with different security group requirements. When custom networking enabled, the pods use different subnet or security groups as defined in the ENIConfig than the node's primary network interface. Custom networking is indeed an ideal option for deploying multiple EKS clusters and applications to connect on-premise datacenter services. You can increase the number of private addresses (RFC1918) accessible to EKS in your VPC for services such as Amazon Elastic Load Balancing and NAT-GW, while using non-routable CG-NAT space for your Pods across multiple clusters. Custom networking with the transit gateway and a Shared Services VPC (including NAT gateways across several Availability Zones for high availability) enables you to deliver scalable and predictable traffic flows. This blog post describes an architectural pattern that is one of the most recommended ways to connect EKS Pods to a datacenter network using custom networking. Avoid Custom Networking When \u00b6 Ready to Implement IPv6 \u00b6 Custom networking can mitigate IP exhaustion issues, but it requires additional operational overhead. If you are currently deploying a dual-stack (IPv4/IPv6) VPC or if your plan includes IPv6 support, we recommend implementing IPv6 clusters instead. You can set up IPv6 EKS clusters and migrate your apps. In an IPv6 EKS cluster, both Kubernetes and Pods get an IPv6 address and can communicate in and out to both IPv4 and IPv6 endpoints. Please review best practices for Running IPv6 EKS Clusters . Exhausted CG-NAT Space \u00b6 Furthermore, if you're currently utilizing CIDRs from the CG-NAT space or are unable to link a secondary CIDR with your cluster VPC, you may need to explore other options, such as using an alternative CNI. We strongly recommend that you either obtain commercial support or possess the in-house knowledge to debug and submit patches to the open source CNI plugin project. Refer Alternate CNI Plugins user guide for more details. Use Private NAT Gateway \u00b6 Amazon VPC now offers private NAT gateway capabilities. Amazon's private NAT Gateway enables instances in private subnets to connect to other VPCs and on-premises networks with overlapping CIDRs. Consider utilizing the method described on this blog post to employ a private NAT gateway to overcome communication issues for the EKS workloads caused by overlapping CIDRs, a significant complaint expressed by our clients. Custom networking cannot address the overlapping CIDR difficulties on its own, and it adds to the configuration challenges. The network architecture used in this blog post implementation follows the recommendations under Enable communication between overlapping networks in Amazon VPC documentation. As demonstrated in this blog post, you may expand the usage of private NAT Gateway in conjunction with RFC6598 addresses to manage customers' private IP exhaustion issues. The EKS clusters, worker nodes are deployed in the non-routable 100.64.0.0/16 VPC secondary CIDR range, whereas the private NAT gateway, NAT gateway are deployed to the routable RFC1918 CIDR ranges. The blog explains how a transit gateway is used to connect VPCs in order to facilitate communication across VPCs with overlapping non-routable CIDR ranges. For use cases in which EKS resources in a VPC's non-routable address range need to communicate with other VPCs that do not have overlapping address ranges, customers have the option of using VPC Peering to interconnect such VPCs. This method could provide potential cost savings as all data transit within an Availability Zone via a VPC peering connection is now free. Unique network for nodes and Pods \u00b6 If you need to isolate your nodes and Pods to a specific network for security reasons, we recommend that you deploy nodes and Pods to a subnet from a larger secondary CIDR block (e.g. 100.64.0.0/8). Following the installation of the new CIDR in your VPC, you can deploy another node group using the secondary CIDR and drain the original nodes to automatically redeploy the pods to the new worker nodes. For more information on how to implement this, see this blog post. Custom networking is not used in the setup represented in the diagram below. Rather, Kubernetes worker nodes are deployed on subnets from your VPC's secondary VPC CIDR range, such as 100.64.0.0/10. You can keep the EKS cluster running (the control plane will remain on the original subnet/s), but the nodes and Pods will be moved to a secondary subnet/s. This is yet another, albeit unconventional, technique to mitigate the danger of IP exhaustion in a VPC. We propose draining the old nodes before redeploying the pods to the new worker nodes. Automate Configuration with Availability Zone Labels \u00b6 You can enable Kubernetes to automatically apply the corresponding ENIConfig for the worker node Availability Zone (AZ). Kubernetes automatically adds the tag topology.kubernetes.io/zone to your worker nodes. Amazon EKS recommends using the availability zone as your ENI config name when you only have one secondary subnet (alternate CIDR) per AZ. Note that tag failure-domain.beta.kubernetes.io/zone is deprecated and replaced with the tag topology.kubernetes.io/zone . Set name field to the Availability Zone of your VPC. Enable automatic configuration with this command: kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true if you have multiple secondary subnets per availability zone, you need create a specific ENI_CONFIG_LABEL_DEF . You might consider configuring ENI_CONFIG_LABEL_DEF as k8s.amazonaws.com/eniConfig and label nodes with custom eniConfig names, such as k8s.amazonaws.com/eniConfig=us-west-2a-subnet-1 and k8s.amazonaws.com/eniConfig=us-west-2a-subnet-2 . Replace Pods when Configuring Secondary Networking \u00b6 Enabling custom networking does not modify existing nodes. Custom networking is a disruptive action. Rather than doing a rolling replacement of all the worker nodes in your cluster after enabling custom networking, we suggest updating the AWS CloudFormation template in the EKS Getting Started Guide with a custom resource that calls a Lambda function to update the aws-node Daemonset with the environment variable to enable custom networking before the worker nodes are provisioned. If you had any nodes in your cluster with running Pods before you switched to the custom CNI networking feature, you should cordon and drain the nodes to gracefully shutdown the Pods and then terminate the nodes. Only new nodes matching the ENIConfig label or annotations use custom networking, and hence the Pods scheduled on these new nodes can be assigned an IP from secondary CIDR. Calculate Max Pods per Node \u00b6 Since the node\u2019s primary ENI is no longer used to assign Pod IP addresses, there is a decrease in the number of Pods you can run on a given EC2 instance type. To work around this limitation you can use prefix assignment with custom networking. With prefix assignment, each secondary IP is replaced with a /28 prefix on secondary ENIs. Consider the maximum number of Pods for an m5.large instance with custom networking. The maximum number of Pods you can run without prefix assignment is 29 ((3 ENIs - 1) * (10 secondary IPs per ENI - 1)) + 2 = 20 Enabling prefix attachments increases the number of Pods to 290. (((3 ENIs - 1) * ((10 secondary IPs per ENI - 1) * 16)) + 2 = 290 However we recommend setting max-pods to 110 instead of 290 is because the instance has a relatively low number of vCPUs. On larger instances EKS recommended value is 250. When using prefix attachments with smaller instance types (e.g, m5.large), you\u2019re likely to exhaust the instance\u2019s CPU and memory resources long before you exhaust its IP addresses. However, we suggest setting max-pods to 110 rather than 290 because the instance has a rather small number of virtual CPUs. On bigger instances, EKS recommends a max pods value of 250. When utilizing prefix attachments with smaller instance types (e.g. m5.large), it is possible that you will exhaust the instance's CPU and memory resources well before its IP addresses. Info When the CNI prefix allocates a /28 prefix to an ENI, it has to be a contiguous block of IP addresses. If the subnet that the prefix is generated from is highly fragmented, the prefix attachment may fail. You can mitigate this from happening by creating a new dedicated VPC for the cluster or by reserving subnet a set of CIDR exclusively for prefix attachments. Visit Subnet CIDR reservations for more information on this topic. Identify Existing Usage of CG-NAT Space \u00b6 Custom networking allows you to mitigate IP exhaustion issue, however it can\u2019t solve all the challenges. If you already using CG-NAT space for your cluster, or simply don\u2019t have the ability to associate a secondary CIDR with your cluster VPC, we suggest you to explore other options, like using an alternate CNI or moving to IPv6 clusters.","title":"Custom Networking"},{"location":"networking/custom-networking/#custom-networking","text":"By default, Amazon VPC CNI will assign Pods an IP address selected from the primary subnet. The primary subnet is the subnet CIDR that the primary ENI is attached to, usually the subnet of the node/host. If the subnet CIDR is too small, the CNI may not be able to acquire enough secondary IP addresses to assign to your Pods. This is a common challenge for EKS IPv4 clusters. Custom networking is one solution to this problem. Custom networking addresses the IP exhaustion issue by assigning the node and Pod IPs from secondary VPC address spaces (CIDR). Custom networking support supports ENIConfig custom resource. The ENIConfig includes an alternate subnet CIDR range (carved from a secondary VPC CIDR), along with the security group(s) that the Pods will belong to. When custom networking is enabled, the VPC CNI creates secondary ENIs in the subnet defined under ENIConfig. The CNI assigns Pods an IP addresses from a CIDR range defined in a ENIConfig CRD. Since the primary ENI is not used by custom networking, the maximum number of Pods you can run on a node is lower. The host network Pods continue to use IP address assigned to the primary ENI. Additionally, the primary ENI is used to handle source network translation and route Pods traffic outside the node.","title":"Custom Networking"},{"location":"networking/custom-networking/#example-configuration","text":"While custom networking will accept valid VPC range for secondary CIDR range, we recommend that you use CIDRs (/16) from the CG-NAT space, i.e. 100.64.0.0/10 or 198.19.0.0/16 as those are less likely to be used in a corporate setting than other RFC1918 ranges. For additional information about the permitted and restricted CIDR block associations you can use with your VPC, see IPv4 CIDR block association restrictions in the VPC and subnet sizing section of the VPC documentation. As shown in the diagram below, the primary Elastic Network Interface ( ENI ) of the worker node still uses the primary VPC CIDR range (in this case 10.0.0.0/16) but the secondary ENIs use the secondary VPC CIDR Range (in this case 100.64.0.0/16). Now, in order to have the Pods use the 100.64.0.0/16 CIDR range, you must configure the CNI plugin to use custom networking. You can follow through the steps as documented here . If you want the CNI to use custom networking, set the AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG environment variable to true . kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true When AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true , the CNI will assign Pod IP address from a subnet defined in ENIConfig . The ENIConfig custom resource is used to define the subnet in which Pods will be scheduled. apiVersion : crd . k8s . amazonaws . com / v1alpha1 kind : ENIConfig metadata : name : us - west - 2 a spec : securityGroups : - sg - 0 dff111a1d11c1c11 subnet : subnet - 011 b111c1f11fdf11 Upon creating the ENIconfig custom resources, you will need to create new worker nodes and drain the existing nodes. The existing worker nodes and Pods will remain unaffected.","title":"Example Configuration"},{"location":"networking/custom-networking/#recommendations","text":"","title":"Recommendations"},{"location":"networking/custom-networking/#use-custom-networking-when","text":"We recommend you to consider custom networking if you are dealing with IPv4 exhaustion and can\u2019t use IPv6 yet. Amazon EKS support for RFC6598 space enables you to scale Pods beyond RFC1918 address exhaustion challenges. Please consider using prefix delegation with custom networking to increase the Pods density on a node. You might consider custom networking if you have a security requirement to run Pods on a different network with different security group requirements. When custom networking enabled, the pods use different subnet or security groups as defined in the ENIConfig than the node's primary network interface. Custom networking is indeed an ideal option for deploying multiple EKS clusters and applications to connect on-premise datacenter services. You can increase the number of private addresses (RFC1918) accessible to EKS in your VPC for services such as Amazon Elastic Load Balancing and NAT-GW, while using non-routable CG-NAT space for your Pods across multiple clusters. Custom networking with the transit gateway and a Shared Services VPC (including NAT gateways across several Availability Zones for high availability) enables you to deliver scalable and predictable traffic flows. This blog post describes an architectural pattern that is one of the most recommended ways to connect EKS Pods to a datacenter network using custom networking.","title":"Use Custom Networking When"},{"location":"networking/custom-networking/#avoid-custom-networking-when","text":"","title":"Avoid Custom Networking When"},{"location":"networking/custom-networking/#ready-to-implement-ipv6","text":"Custom networking can mitigate IP exhaustion issues, but it requires additional operational overhead. If you are currently deploying a dual-stack (IPv4/IPv6) VPC or if your plan includes IPv6 support, we recommend implementing IPv6 clusters instead. You can set up IPv6 EKS clusters and migrate your apps. In an IPv6 EKS cluster, both Kubernetes and Pods get an IPv6 address and can communicate in and out to both IPv4 and IPv6 endpoints. Please review best practices for Running IPv6 EKS Clusters .","title":"Ready to Implement IPv6"},{"location":"networking/custom-networking/#exhausted-cg-nat-space","text":"Furthermore, if you're currently utilizing CIDRs from the CG-NAT space or are unable to link a secondary CIDR with your cluster VPC, you may need to explore other options, such as using an alternative CNI. We strongly recommend that you either obtain commercial support or possess the in-house knowledge to debug and submit patches to the open source CNI plugin project. Refer Alternate CNI Plugins user guide for more details.","title":"Exhausted CG-NAT Space"},{"location":"networking/custom-networking/#use-private-nat-gateway","text":"Amazon VPC now offers private NAT gateway capabilities. Amazon's private NAT Gateway enables instances in private subnets to connect to other VPCs and on-premises networks with overlapping CIDRs. Consider utilizing the method described on this blog post to employ a private NAT gateway to overcome communication issues for the EKS workloads caused by overlapping CIDRs, a significant complaint expressed by our clients. Custom networking cannot address the overlapping CIDR difficulties on its own, and it adds to the configuration challenges. The network architecture used in this blog post implementation follows the recommendations under Enable communication between overlapping networks in Amazon VPC documentation. As demonstrated in this blog post, you may expand the usage of private NAT Gateway in conjunction with RFC6598 addresses to manage customers' private IP exhaustion issues. The EKS clusters, worker nodes are deployed in the non-routable 100.64.0.0/16 VPC secondary CIDR range, whereas the private NAT gateway, NAT gateway are deployed to the routable RFC1918 CIDR ranges. The blog explains how a transit gateway is used to connect VPCs in order to facilitate communication across VPCs with overlapping non-routable CIDR ranges. For use cases in which EKS resources in a VPC's non-routable address range need to communicate with other VPCs that do not have overlapping address ranges, customers have the option of using VPC Peering to interconnect such VPCs. This method could provide potential cost savings as all data transit within an Availability Zone via a VPC peering connection is now free.","title":"Use Private NAT Gateway"},{"location":"networking/custom-networking/#unique-network-for-nodes-and-pods","text":"If you need to isolate your nodes and Pods to a specific network for security reasons, we recommend that you deploy nodes and Pods to a subnet from a larger secondary CIDR block (e.g. 100.64.0.0/8). Following the installation of the new CIDR in your VPC, you can deploy another node group using the secondary CIDR and drain the original nodes to automatically redeploy the pods to the new worker nodes. For more information on how to implement this, see this blog post. Custom networking is not used in the setup represented in the diagram below. Rather, Kubernetes worker nodes are deployed on subnets from your VPC's secondary VPC CIDR range, such as 100.64.0.0/10. You can keep the EKS cluster running (the control plane will remain on the original subnet/s), but the nodes and Pods will be moved to a secondary subnet/s. This is yet another, albeit unconventional, technique to mitigate the danger of IP exhaustion in a VPC. We propose draining the old nodes before redeploying the pods to the new worker nodes.","title":"Unique network for nodes and Pods"},{"location":"networking/custom-networking/#automate-configuration-with-availability-zone-labels","text":"You can enable Kubernetes to automatically apply the corresponding ENIConfig for the worker node Availability Zone (AZ). Kubernetes automatically adds the tag topology.kubernetes.io/zone to your worker nodes. Amazon EKS recommends using the availability zone as your ENI config name when you only have one secondary subnet (alternate CIDR) per AZ. Note that tag failure-domain.beta.kubernetes.io/zone is deprecated and replaced with the tag topology.kubernetes.io/zone . Set name field to the Availability Zone of your VPC. Enable automatic configuration with this command: kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true if you have multiple secondary subnets per availability zone, you need create a specific ENI_CONFIG_LABEL_DEF . You might consider configuring ENI_CONFIG_LABEL_DEF as k8s.amazonaws.com/eniConfig and label nodes with custom eniConfig names, such as k8s.amazonaws.com/eniConfig=us-west-2a-subnet-1 and k8s.amazonaws.com/eniConfig=us-west-2a-subnet-2 .","title":"Automate Configuration with Availability Zone Labels"},{"location":"networking/custom-networking/#replace-pods-when-configuring-secondary-networking","text":"Enabling custom networking does not modify existing nodes. Custom networking is a disruptive action. Rather than doing a rolling replacement of all the worker nodes in your cluster after enabling custom networking, we suggest updating the AWS CloudFormation template in the EKS Getting Started Guide with a custom resource that calls a Lambda function to update the aws-node Daemonset with the environment variable to enable custom networking before the worker nodes are provisioned. If you had any nodes in your cluster with running Pods before you switched to the custom CNI networking feature, you should cordon and drain the nodes to gracefully shutdown the Pods and then terminate the nodes. Only new nodes matching the ENIConfig label or annotations use custom networking, and hence the Pods scheduled on these new nodes can be assigned an IP from secondary CIDR.","title":"Replace Pods when Configuring Secondary Networking"},{"location":"networking/custom-networking/#calculate-max-pods-per-node","text":"Since the node\u2019s primary ENI is no longer used to assign Pod IP addresses, there is a decrease in the number of Pods you can run on a given EC2 instance type. To work around this limitation you can use prefix assignment with custom networking. With prefix assignment, each secondary IP is replaced with a /28 prefix on secondary ENIs. Consider the maximum number of Pods for an m5.large instance with custom networking. The maximum number of Pods you can run without prefix assignment is 29 ((3 ENIs - 1) * (10 secondary IPs per ENI - 1)) + 2 = 20 Enabling prefix attachments increases the number of Pods to 290. (((3 ENIs - 1) * ((10 secondary IPs per ENI - 1) * 16)) + 2 = 290 However we recommend setting max-pods to 110 instead of 290 is because the instance has a relatively low number of vCPUs. On larger instances EKS recommended value is 250. When using prefix attachments with smaller instance types (e.g, m5.large), you\u2019re likely to exhaust the instance\u2019s CPU and memory resources long before you exhaust its IP addresses. However, we suggest setting max-pods to 110 rather than 290 because the instance has a rather small number of virtual CPUs. On bigger instances, EKS recommends a max pods value of 250. When utilizing prefix attachments with smaller instance types (e.g. m5.large), it is possible that you will exhaust the instance's CPU and memory resources well before its IP addresses. Info When the CNI prefix allocates a /28 prefix to an ENI, it has to be a contiguous block of IP addresses. If the subnet that the prefix is generated from is highly fragmented, the prefix attachment may fail. You can mitigate this from happening by creating a new dedicated VPC for the cluster or by reserving subnet a set of CIDR exclusively for prefix attachments. Visit Subnet CIDR reservations for more information on this topic.","title":"Calculate Max Pods per Node"},{"location":"networking/custom-networking/#identify-existing-usage-of-cg-nat-space","text":"Custom networking allows you to mitigate IP exhaustion issue, however it can\u2019t solve all the challenges. If you already using CG-NAT space for your cluster, or simply don\u2019t have the ability to associate a secondary CIDR with your cluster VPC, we suggest you to explore other options, like using an alternate CNI or moving to IPv6 clusters.","title":"Identify Existing Usage of CG-NAT Space"},{"location":"networking/index/","text":"Amazon EKS Best Practices Guide for Networking \u00b6 It is critical to understand Kubernetes networking to operate your cluster and applications efficiently. Pod networking, also called the cluster networking, is the center of Kubernetes networking. Kubernetes supports Container Network Interface (CNI) plugins for cluster networking. Amazon EKS officially supports Amazon Virtual Private Cloud (VPC) CNI plugin to implement Kubernetes Pod networking. The VPC CNI provides native integration with AWS VPC and works in underlay mode. In underlay mode, Pods and hosts are located at the same network layer and share the network namespace. The IP address of the Pod is consistent from the cluster and VPC perspective. This guide introduces the Amazon VPC Container Network Interface (VPC CNI) in the context of Kubernetes cluster networking. The VPC CNI is the default networking plugin supported by EKS and hence is the focus of the guide. The VPC CNI is highly configurable to support different use cases. This guide further includes dedicated sections on different VPC CNI use cases, operating modes, sub-components, followed by the recommendations. Amazon EKS runs upstream Kubernetes and is certified Kubernetes conformant. Although you can use alternate CNI plugins, this guide does not provide recommendations for managing alternate CNIs. Check the EKS Alternate CNI documentation for a list of partners and resources for managing alternate CNIs effectively. Kubernetes Networking Model \u00b6 Kubernetes sets the following requirements on cluster networking: Pods scheduled on the same node must be able to communicate with other Pods without using NAT (Network Address Translation). All system daemons (background processes, for example, kubelet ) running on a particular node can communicate with the Pods running on the same node. Pods that use the host network must be able to contact all other Pods on all other nodes without using NAT. See the Kubernetes network model for details on what Kubernetes expects from compatible networking implementations. The following figure illustrates the relationship between Pod network namespaces and the host network namespace. Container Networking Interface (CNI) \u00b6 Kubernetes supports CNI specifications and plugins to implement Kubernetes network model. A CNI consists of a specification (current version 1.0.0) and libraries for writing plugins to configure network interfaces in containers, along with a number of supported plugins. CNI concerns itself only with network connectivity of containers and removing allocated resources when the container is deleted. The CNI plugin is enabled by passing kubelet the --network-plugin=cni command-line option. Kubelet reads a file from --cni-conf-dir (default /etc/cni/net.d) and uses the CNI configuration from that file to set up each Pod\u2019s network. The CNI configuration file must match the CNI specification (minimum v0.4.0) and any required CNI plugins referenced by the configuration must be present in the --cni-bin-dir directory (default /opt/cni/bin). If there are multiple CNI configuration files in the directory, the kubelet uses the configuration file that comes first by name in lexicographic order . Amazon Virtual Private Cloud (VPC) CNI \u00b6 The AWS-provided VPC CNI is the default networking add-on for EKS clusters. VPC CNI add-on is installed by default when you provision EKS clusters. VPC CNI runs on Kubernetes worker nodes. The VPC CNI add-on consists of the CNI binary and the IP Address Management (ipamd) plugin. The CNI assigns an IP address from the VPC network to a Pod. The ipamd manages AWS Elastic Networking Interfaces (ENIs) to each Kubernetes node and maintains the warm pool of IPs. The VPC CNI provides configuration options for pre-allocation of ENIs and IP addresses for fast Pod startup times. Refer to Amazon VPC CNI for recommended plugin management best practices. Amazon EKS recommends you specify subnets in at least two availability zones when you create a cluster. Amazon VPC CNI allocates IP addresses to Pods from the node subnets. We strongly recommend checking the subnets for available IP addresses. Please consider VPC and Subnet recommendations before deploying EKS clusters. Amazon VPC CNI allocates a warm pool of ENIs and secondary IP addresses from the subnet attached to the node\u2019s primary ENI. This mode of VPC CNI is called the \" secondary IP mode .\" The number of IP addresses and hence the number of Pods (Pod density) is defined by the number of ENIs and the IP address per ENI (limits) as defined by the instance type. The secondary mode is the default and works well for small clusters with smaller instance types. Please consider using prefix mode if you are experiencing pod density challenges. You can also increase the available IP addresses on node for Pods by assigning prefixes to ENIs. Amazon VPC CNI natively integrates with AWS VPC and allows users to apply existing AWS VPC networking and security best practices for building Kubernetes clusters. This includes the ability to use VPC flow logs, VPC routing policies, and security groups for network traffic isolation. By default, the Amazon VPC CNI applies security group associated with the primary ENI on the node to the Pods. Consider enabling security groups for Pods when you would like to assign different network rules for a Pod. By default, VPC CNI assigns IP addresses to Pods from the subnet assigned to the primary ENI of a node. It is common to experience a shortage of IPv4 addresses when running large clusters with thousands of workloads. AWS VPC allows you to extend available IPs by assigning a secondary CIDRs to work around exhaustion of IPv4 CIDR blocks. AWS VPC CNI allows you to use a different subnet CIDR range for Pods. This feature of VPC CNI is called custom networking . You might consider using custom networking to use 100.64.0.0/10 and 198.19.0.0/16 CIDRs (CG-NAT) with EKS. This effectively allows you to create an environment where Pods no longer consume any RFC1918 IP addresses from your VPC. Custom networking is one option to address the IPv4 address exhaustion problem, but it requires operational overhead. We recommend IPv6 clusters over custom networking to resolve this problem. Specifically, we recommend migrating to IPv6 clusters if you have completely exhausted all available IPv4 address space for your VPC. Evaluate your organization\u2019s plans to support IPv6, and consider if investing in IPv6 may have more long-term value. EKS\u2019s support for IPv6 is focused on solving the IP exhaustion problem caused by a limited IPv4 address space. In response to customer issues with IPv4 exhaustion, EKS has prioritized IPv6-only Pods over dual-stack Pods. That is, Pods may be able to access IPv4 resources, but they are not assigned an IPv4 address from VPC CIDR range. The VPC CNI assigns IPv6 addresses to Pods from the AWS managed VPC IPv6 CIDR block.","title":"Home"},{"location":"networking/index/#amazon-eks-best-practices-guide-for-networking","text":"It is critical to understand Kubernetes networking to operate your cluster and applications efficiently. Pod networking, also called the cluster networking, is the center of Kubernetes networking. Kubernetes supports Container Network Interface (CNI) plugins for cluster networking. Amazon EKS officially supports Amazon Virtual Private Cloud (VPC) CNI plugin to implement Kubernetes Pod networking. The VPC CNI provides native integration with AWS VPC and works in underlay mode. In underlay mode, Pods and hosts are located at the same network layer and share the network namespace. The IP address of the Pod is consistent from the cluster and VPC perspective. This guide introduces the Amazon VPC Container Network Interface (VPC CNI) in the context of Kubernetes cluster networking. The VPC CNI is the default networking plugin supported by EKS and hence is the focus of the guide. The VPC CNI is highly configurable to support different use cases. This guide further includes dedicated sections on different VPC CNI use cases, operating modes, sub-components, followed by the recommendations. Amazon EKS runs upstream Kubernetes and is certified Kubernetes conformant. Although you can use alternate CNI plugins, this guide does not provide recommendations for managing alternate CNIs. Check the EKS Alternate CNI documentation for a list of partners and resources for managing alternate CNIs effectively.","title":"Amazon EKS Best Practices Guide for Networking"},{"location":"networking/index/#kubernetes-networking-model","text":"Kubernetes sets the following requirements on cluster networking: Pods scheduled on the same node must be able to communicate with other Pods without using NAT (Network Address Translation). All system daemons (background processes, for example, kubelet ) running on a particular node can communicate with the Pods running on the same node. Pods that use the host network must be able to contact all other Pods on all other nodes without using NAT. See the Kubernetes network model for details on what Kubernetes expects from compatible networking implementations. The following figure illustrates the relationship between Pod network namespaces and the host network namespace.","title":"Kubernetes Networking Model"},{"location":"networking/index/#container-networking-interface-cni","text":"Kubernetes supports CNI specifications and plugins to implement Kubernetes network model. A CNI consists of a specification (current version 1.0.0) and libraries for writing plugins to configure network interfaces in containers, along with a number of supported plugins. CNI concerns itself only with network connectivity of containers and removing allocated resources when the container is deleted. The CNI plugin is enabled by passing kubelet the --network-plugin=cni command-line option. Kubelet reads a file from --cni-conf-dir (default /etc/cni/net.d) and uses the CNI configuration from that file to set up each Pod\u2019s network. The CNI configuration file must match the CNI specification (minimum v0.4.0) and any required CNI plugins referenced by the configuration must be present in the --cni-bin-dir directory (default /opt/cni/bin). If there are multiple CNI configuration files in the directory, the kubelet uses the configuration file that comes first by name in lexicographic order .","title":"Container Networking Interface (CNI)"},{"location":"networking/index/#amazon-virtual-private-cloud-vpc-cni","text":"The AWS-provided VPC CNI is the default networking add-on for EKS clusters. VPC CNI add-on is installed by default when you provision EKS clusters. VPC CNI runs on Kubernetes worker nodes. The VPC CNI add-on consists of the CNI binary and the IP Address Management (ipamd) plugin. The CNI assigns an IP address from the VPC network to a Pod. The ipamd manages AWS Elastic Networking Interfaces (ENIs) to each Kubernetes node and maintains the warm pool of IPs. The VPC CNI provides configuration options for pre-allocation of ENIs and IP addresses for fast Pod startup times. Refer to Amazon VPC CNI for recommended plugin management best practices. Amazon EKS recommends you specify subnets in at least two availability zones when you create a cluster. Amazon VPC CNI allocates IP addresses to Pods from the node subnets. We strongly recommend checking the subnets for available IP addresses. Please consider VPC and Subnet recommendations before deploying EKS clusters. Amazon VPC CNI allocates a warm pool of ENIs and secondary IP addresses from the subnet attached to the node\u2019s primary ENI. This mode of VPC CNI is called the \" secondary IP mode .\" The number of IP addresses and hence the number of Pods (Pod density) is defined by the number of ENIs and the IP address per ENI (limits) as defined by the instance type. The secondary mode is the default and works well for small clusters with smaller instance types. Please consider using prefix mode if you are experiencing pod density challenges. You can also increase the available IP addresses on node for Pods by assigning prefixes to ENIs. Amazon VPC CNI natively integrates with AWS VPC and allows users to apply existing AWS VPC networking and security best practices for building Kubernetes clusters. This includes the ability to use VPC flow logs, VPC routing policies, and security groups for network traffic isolation. By default, the Amazon VPC CNI applies security group associated with the primary ENI on the node to the Pods. Consider enabling security groups for Pods when you would like to assign different network rules for a Pod. By default, VPC CNI assigns IP addresses to Pods from the subnet assigned to the primary ENI of a node. It is common to experience a shortage of IPv4 addresses when running large clusters with thousands of workloads. AWS VPC allows you to extend available IPs by assigning a secondary CIDRs to work around exhaustion of IPv4 CIDR blocks. AWS VPC CNI allows you to use a different subnet CIDR range for Pods. This feature of VPC CNI is called custom networking . You might consider using custom networking to use 100.64.0.0/10 and 198.19.0.0/16 CIDRs (CG-NAT) with EKS. This effectively allows you to create an environment where Pods no longer consume any RFC1918 IP addresses from your VPC. Custom networking is one option to address the IPv4 address exhaustion problem, but it requires operational overhead. We recommend IPv6 clusters over custom networking to resolve this problem. Specifically, we recommend migrating to IPv6 clusters if you have completely exhausted all available IPv4 address space for your VPC. Evaluate your organization\u2019s plans to support IPv6, and consider if investing in IPv6 may have more long-term value. EKS\u2019s support for IPv6 is focused on solving the IP exhaustion problem caused by a limited IPv4 address space. In response to customer issues with IPv4 exhaustion, EKS has prioritized IPv6-only Pods over dual-stack Pods. That is, Pods may be able to access IPv4 resources, but they are not assigned an IPv4 address from VPC CIDR range. The VPC CNI assigns IPv6 addresses to Pods from the AWS managed VPC IPv6 CIDR block.","title":"Amazon Virtual Private Cloud (VPC) CNI"},{"location":"networking/ipv6/","text":"Running IPv6 EKS Clusters \u00b6 IPv6 can help alleviate issues with IP exhaustion in your Kubernetes cluster. EKS\u2019s support for IPv6 is focused on resolving the IP exhaustion problem, which is constrained by the limited size of the IPv4 address space. This is a significant concern raised by a number of our customers and is distinct from Kubernetes\u2019 \u201c IPv4/IPv6 dual-stack \u201d feature. In an IPv6 EKS cluster, Pods and services will receive IPv6 addresses while maintaining compatibility with legacy IPv4 Endpoints. This includes the ability for external IPv4 endpoints to access services, and Pods to access external IPv4 addresses. Amazon EKS IPv6 support leverages native VPC IPv6 capabilities. Each VPC is given an IPv4 address prefix (CIDR block size can be from /16 to /28) and a unique /56 IPv6 address prefix (fixed) from within Amazon\u2019s GUA (Global Unicast Address); you can assign a /64 address prefix to each subnet in your VPC. IPv4 features, like Route Tables, Network Access Control Lists, Peering, and DNS resolution, work the same way in an IPv6 enabled VPC. In the IPv6 world, every address is internet routable. By default, VPC allocates IPv6 CIDR from the public GUA range. VPCs do not support assigning private IPv6 addresses from the Unique Local Address (ULA) range as defined by RFC 4193 (fd00::/8 or fc00::/8). This is true even when you would like to assign an IPv6 CIDR owned by you. Private subnets are supported by implementing an egress-only internet gateway (EIGW) in a VPC, allowing outbound traffic while blocking all incoming traffic. Best practices for implementing IPv6 subnets can be found in the VPC user guide . In an IPv6 EKS cluster, nodes and Pods receive public IPv6 addresses. EKS assigns IPv6 addresses to services based on Unique Local IPv6 Unicast Addresses (ULA). The ULA Service CIDR for an IPv6 cluster is automatically assigned during the cluster creation stage and cannot be specified, unlike IPv4. Overview \u00b6 IPv6 is only supported in prefix mode. Review the documentation for other requirements. Prefix assignment only works on AWS Nitro-based EC2 instances and hence IPv6 is supported on nitro instances. Amazon VPC Container Network Interface (CNI) plugin is configured to assign an address from the prefix attached to the primary ENI. Since IPv6 prefix assignment occurs at the node startup, it reduces the risk of getting throttled substantially while increases the performance significantly, especially in large clusters. You will not be required to update any of the warm pool variables as a single IPv6 prefix has many addresses (/80 => ~10^14 addresses per ENI) and is big enough to support very large clusters. Every node gets both IPv4 and IPv6 addresses, along with corresponding DNS entries. For a given node, only a single IPv4 address from the VPC address range is consumed. EKS support for IPv6 enables you to communicate with IPv4 endpoints (AWS, on-premise, internet) through a highly opinionated egress-only IPv4 model. EKS implements a host-local CNI plugin, secondary to the VPC CNI plugin, which allocates and configures a IPv4 address for a Pod. The CNI plugin configures a host-specific non-routable IPv4 address for a Pod from the 169.254.172.0/22 range. The IPv4 address assigned to the Pod is unique to the node and is not advertised to the Kubernetes control plane . 169.254.172.0/22 provides 1024 unique IPv4 addresses and can support large instance types. Pods will perform a DNS lookup for an endpoint and, upon receiving an IPv4 \u201cA\u201d response, will establish a connection with the IPv4 endpoint using the IPv4 address from the host-local 169.254.172.0/22 IP range. Pod\u2019s node-only unique IPv4 address is translated through network address translation (NAT) to the IPv4 (VPC) address of the primary network interface attached to the node. The private IPv4 address of a node is translated by an AWS NAT gateway to the public IPv4 address of the gateway and routed to and from the internet by an AWS internet gateway, as shown in the following picture. Any Pod-to-Pod communication across the nodes always uses an IPv6 address. VPC CNI configures iptables to handle IPv6 while blocking any IPv4 connections. Services will receive only IPv6 addresses from Unique Local IPv6 Unicast Addresses (ULA) . The ULA Service CIDR for an IPv6 cluster is automatically assigned during cluster creation stage and cannot be modified. Services are exposed to the internet using an AWS load balancer. The load balancer receives public IPv4 and IPv6 addresses. For IPv4 clients accessing IPv6 cluster services, the load balancer does IPv4 to IPv6 translation. Amazon EKS recommends running worker nodes and Pods in private subnets. You can create public load balancers in the public subnets that load balance traffic to Pods running on nodes that are in private subnets. Private subnets in IPv6 VPCs are configured with an egress-only internet gateway. Any Pod communication from within private subnets to IPv6 endpoints outside the cluster will be routed via an egress-only internet gateway by default. EKS will provision Cross-Account ENIs (X-ENIs) in dual stack mode (IPv4/IPv6). Kubernetes node components such as kubelet and kube-proxy are configured to support dual stack. Kubelet and kube-proxy run in a hostNetwork mode and bind to both IPv4 and IPv6 addresses attached to the primary network interface of a node. The Kubernetes api-server communicates to Pods and node components via the X-ENIs and use IPv6 address. Pods communicate with the api-server via the same X-ENIs, and Pod to api-server communication always uses IPv6 mode. Recommendations \u00b6 Maintain Access to IPv4 EKS APIs \u00b6 EKS APIs are accessible by IPv4 only. This also includes the Cluster API Endpoint. You will not be able to access cluster endpoints and APIs from an IPv6 only network. It is required that your network supports (1) an IPv6 transition mechanism such as NAT64/DNS64 that facilitates communication between IPv6 and IPv4 hosts and (2) a DNS service that supports translations of IPv4 endpoints. Schedule Based on Compute Resources \u00b6 A single IPv6 prefix is sufficient to run many Pods on a single node. This also effectively removes ENI and IP limitations on the maximum number of Pods on a node. Although IPv6 removes direct dependency on max-Pods, when using prefix attachments with smaller instance types like the m5.large, you\u2019re likely to exhaust the instance\u2019s CPU and memory resources long before you exhaust its IP addresses. You must set the EKS recommended maximum Pod value by hand if you are using self-managed node groups or a managed node group with a custom AMI ID. You can use the following formula to determine the maximum number of Pods you can deploy on a node for a IPv6 EKS cluster. ((Number of network interfaces for instance type (number of prefixes per network interface-1)* 16) + 2 ((3 ENIs) ((10 secondary IPs per ENI-1) 16)) + 2 = 460 (real) Managed node groups automatically calculate the maximum number of Pods for you. Avoid changing EKS\u2019s recommended value for the maximum number of Pods to avoid Pod scheduling failures due to resource limitations. Evaluate Purpose of Existing Custom Networking \u00b6 If custom networking is currently enabled, Amazon EKS recommends re-evaluating your need for it with IPv6. If you chose to use custom networking to address the IPv4 exhaustion issue, it is no longer necessary with IPv6. If you are utilizing custom networking to satisfy a security requirement, such as a separate network for nodes and Pods, you are encouraged to submit an EKS roadmap request . Plan for IPv4 addresses for Fargate Pods \u00b6 EKS supports IPv6 for Pods running on Fargate. Pods running on Fargate do receive both IPv6 and IPv4 addresses from the VPC CIDR range. You will be limited by IPv4 limits if you are deploying Fargate Pods. It is recommended to size your subnets for growth. You will not be able to create new Fargate Pods if the subnets don\u2019t have available IPv4 addresses, irrespective of IPv6 availability. Use AWS Load Balancer Controller \u00b6 The upstream in-tree Kubernetes service controller does not support IPv6. We recommend using the most recent version of the AWS Load Balancer Controller add-on with IPv6 clusters. The AWS load balancer controller manages Elastic Load Balancers for EKS and supports Application Load Balancer (ALB) and Network Load Balancer (NLB) in dual stack IP mode when you add an annotation to your service or ingress. To your service or ingress manifests, add beta.kubernetes.io/aws-load-balancer-ip-address-type: dualstack . AWS Network Load Balancer does not support dual-stack UDP protocol address types. If you have strong requirements for low-latency, real-time streaming, online gaming, and IoT, we recommend running IPv4 clusters. To learn more about managing health checks for UDP services, please refer to \u201cHow to route UDP traffic into Kubernetes\u201d . Identify Dependencies on IMDSv2 \u00b6 EKS in IPv6 mode does not support IMDSv2 endpoints yet. Please open a support ticket if IMDSv2 is a blocker for you to migrate to IPv6.","title":"Running IPv6 Clusters"},{"location":"networking/ipv6/#running-ipv6-eks-clusters","text":"IPv6 can help alleviate issues with IP exhaustion in your Kubernetes cluster. EKS\u2019s support for IPv6 is focused on resolving the IP exhaustion problem, which is constrained by the limited size of the IPv4 address space. This is a significant concern raised by a number of our customers and is distinct from Kubernetes\u2019 \u201c IPv4/IPv6 dual-stack \u201d feature. In an IPv6 EKS cluster, Pods and services will receive IPv6 addresses while maintaining compatibility with legacy IPv4 Endpoints. This includes the ability for external IPv4 endpoints to access services, and Pods to access external IPv4 addresses. Amazon EKS IPv6 support leverages native VPC IPv6 capabilities. Each VPC is given an IPv4 address prefix (CIDR block size can be from /16 to /28) and a unique /56 IPv6 address prefix (fixed) from within Amazon\u2019s GUA (Global Unicast Address); you can assign a /64 address prefix to each subnet in your VPC. IPv4 features, like Route Tables, Network Access Control Lists, Peering, and DNS resolution, work the same way in an IPv6 enabled VPC. In the IPv6 world, every address is internet routable. By default, VPC allocates IPv6 CIDR from the public GUA range. VPCs do not support assigning private IPv6 addresses from the Unique Local Address (ULA) range as defined by RFC 4193 (fd00::/8 or fc00::/8). This is true even when you would like to assign an IPv6 CIDR owned by you. Private subnets are supported by implementing an egress-only internet gateway (EIGW) in a VPC, allowing outbound traffic while blocking all incoming traffic. Best practices for implementing IPv6 subnets can be found in the VPC user guide . In an IPv6 EKS cluster, nodes and Pods receive public IPv6 addresses. EKS assigns IPv6 addresses to services based on Unique Local IPv6 Unicast Addresses (ULA). The ULA Service CIDR for an IPv6 cluster is automatically assigned during the cluster creation stage and cannot be specified, unlike IPv4.","title":"Running IPv6 EKS Clusters"},{"location":"networking/ipv6/#overview","text":"IPv6 is only supported in prefix mode. Review the documentation for other requirements. Prefix assignment only works on AWS Nitro-based EC2 instances and hence IPv6 is supported on nitro instances. Amazon VPC Container Network Interface (CNI) plugin is configured to assign an address from the prefix attached to the primary ENI. Since IPv6 prefix assignment occurs at the node startup, it reduces the risk of getting throttled substantially while increases the performance significantly, especially in large clusters. You will not be required to update any of the warm pool variables as a single IPv6 prefix has many addresses (/80 => ~10^14 addresses per ENI) and is big enough to support very large clusters. Every node gets both IPv4 and IPv6 addresses, along with corresponding DNS entries. For a given node, only a single IPv4 address from the VPC address range is consumed. EKS support for IPv6 enables you to communicate with IPv4 endpoints (AWS, on-premise, internet) through a highly opinionated egress-only IPv4 model. EKS implements a host-local CNI plugin, secondary to the VPC CNI plugin, which allocates and configures a IPv4 address for a Pod. The CNI plugin configures a host-specific non-routable IPv4 address for a Pod from the 169.254.172.0/22 range. The IPv4 address assigned to the Pod is unique to the node and is not advertised to the Kubernetes control plane . 169.254.172.0/22 provides 1024 unique IPv4 addresses and can support large instance types. Pods will perform a DNS lookup for an endpoint and, upon receiving an IPv4 \u201cA\u201d response, will establish a connection with the IPv4 endpoint using the IPv4 address from the host-local 169.254.172.0/22 IP range. Pod\u2019s node-only unique IPv4 address is translated through network address translation (NAT) to the IPv4 (VPC) address of the primary network interface attached to the node. The private IPv4 address of a node is translated by an AWS NAT gateway to the public IPv4 address of the gateway and routed to and from the internet by an AWS internet gateway, as shown in the following picture. Any Pod-to-Pod communication across the nodes always uses an IPv6 address. VPC CNI configures iptables to handle IPv6 while blocking any IPv4 connections. Services will receive only IPv6 addresses from Unique Local IPv6 Unicast Addresses (ULA) . The ULA Service CIDR for an IPv6 cluster is automatically assigned during cluster creation stage and cannot be modified. Services are exposed to the internet using an AWS load balancer. The load balancer receives public IPv4 and IPv6 addresses. For IPv4 clients accessing IPv6 cluster services, the load balancer does IPv4 to IPv6 translation. Amazon EKS recommends running worker nodes and Pods in private subnets. You can create public load balancers in the public subnets that load balance traffic to Pods running on nodes that are in private subnets. Private subnets in IPv6 VPCs are configured with an egress-only internet gateway. Any Pod communication from within private subnets to IPv6 endpoints outside the cluster will be routed via an egress-only internet gateway by default. EKS will provision Cross-Account ENIs (X-ENIs) in dual stack mode (IPv4/IPv6). Kubernetes node components such as kubelet and kube-proxy are configured to support dual stack. Kubelet and kube-proxy run in a hostNetwork mode and bind to both IPv4 and IPv6 addresses attached to the primary network interface of a node. The Kubernetes api-server communicates to Pods and node components via the X-ENIs and use IPv6 address. Pods communicate with the api-server via the same X-ENIs, and Pod to api-server communication always uses IPv6 mode.","title":"Overview"},{"location":"networking/ipv6/#recommendations","text":"","title":"Recommendations"},{"location":"networking/ipv6/#maintain-access-to-ipv4-eks-apis","text":"EKS APIs are accessible by IPv4 only. This also includes the Cluster API Endpoint. You will not be able to access cluster endpoints and APIs from an IPv6 only network. It is required that your network supports (1) an IPv6 transition mechanism such as NAT64/DNS64 that facilitates communication between IPv6 and IPv4 hosts and (2) a DNS service that supports translations of IPv4 endpoints.","title":"Maintain Access to IPv4 EKS APIs"},{"location":"networking/ipv6/#schedule-based-on-compute-resources","text":"A single IPv6 prefix is sufficient to run many Pods on a single node. This also effectively removes ENI and IP limitations on the maximum number of Pods on a node. Although IPv6 removes direct dependency on max-Pods, when using prefix attachments with smaller instance types like the m5.large, you\u2019re likely to exhaust the instance\u2019s CPU and memory resources long before you exhaust its IP addresses. You must set the EKS recommended maximum Pod value by hand if you are using self-managed node groups or a managed node group with a custom AMI ID. You can use the following formula to determine the maximum number of Pods you can deploy on a node for a IPv6 EKS cluster. ((Number of network interfaces for instance type (number of prefixes per network interface-1)* 16) + 2 ((3 ENIs) ((10 secondary IPs per ENI-1) 16)) + 2 = 460 (real) Managed node groups automatically calculate the maximum number of Pods for you. Avoid changing EKS\u2019s recommended value for the maximum number of Pods to avoid Pod scheduling failures due to resource limitations.","title":"Schedule Based on Compute Resources"},{"location":"networking/ipv6/#evaluate-purpose-of-existing-custom-networking","text":"If custom networking is currently enabled, Amazon EKS recommends re-evaluating your need for it with IPv6. If you chose to use custom networking to address the IPv4 exhaustion issue, it is no longer necessary with IPv6. If you are utilizing custom networking to satisfy a security requirement, such as a separate network for nodes and Pods, you are encouraged to submit an EKS roadmap request .","title":"Evaluate Purpose of Existing Custom Networking"},{"location":"networking/ipv6/#plan-for-ipv4-addresses-for-fargate-pods","text":"EKS supports IPv6 for Pods running on Fargate. Pods running on Fargate do receive both IPv6 and IPv4 addresses from the VPC CIDR range. You will be limited by IPv4 limits if you are deploying Fargate Pods. It is recommended to size your subnets for growth. You will not be able to create new Fargate Pods if the subnets don\u2019t have available IPv4 addresses, irrespective of IPv6 availability.","title":"Plan for IPv4 addresses for Fargate Pods"},{"location":"networking/ipv6/#use-aws-load-balancer-controller","text":"The upstream in-tree Kubernetes service controller does not support IPv6. We recommend using the most recent version of the AWS Load Balancer Controller add-on with IPv6 clusters. The AWS load balancer controller manages Elastic Load Balancers for EKS and supports Application Load Balancer (ALB) and Network Load Balancer (NLB) in dual stack IP mode when you add an annotation to your service or ingress. To your service or ingress manifests, add beta.kubernetes.io/aws-load-balancer-ip-address-type: dualstack . AWS Network Load Balancer does not support dual-stack UDP protocol address types. If you have strong requirements for low-latency, real-time streaming, online gaming, and IoT, we recommend running IPv4 clusters. To learn more about managing health checks for UDP services, please refer to \u201cHow to route UDP traffic into Kubernetes\u201d .","title":"Use AWS Load Balancer Controller"},{"location":"networking/ipv6/#identify-dependencies-on-imdsv2","text":"EKS in IPv6 mode does not support IMDSv2 endpoints yet. Please open a support ticket if IMDSv2 is a blocker for you to migrate to IPv6.","title":"Identify Dependencies on IMDSv2"},{"location":"networking/loadbalancing/loadbalancing/","text":"Avoiding Errors & Timeouts with Kubernetes Applications and AWS Load Balancers \u00b6 After creating the necessary Kubernetes resources (Service, Deployment, Ingress, etc), your pods should be able to receive traffic from your clients through an Elastic Load Balancer. However, you may find that errors, timeouts, or connection resets are being generated when you make changes to the application or Kubernetes environment. Those changes could trigger an application deployment or a scaling action (either manual or automatic). Unfortunately, those errors may be generated even when your application is not logging problems. This is because the Kubernetes systems controlling the resources in your cluster may be running faster than the AWS systems that control the Load Balancer's target registration and health. Your Pods may also start receiving traffic before your application is ready to receive requests. Lets review the process through which a pod becomes Ready and how traffic can be routed into the pods. Pod Readiness \u00b6 This diagram from a 2019 Kubecon talk , shows the steps taken for a pod to become Ready and receive traffic for a LoadBalancer service: Ready? A Deep Dive into Pod Readiness Gates for Service Health... - Minhan Xia & Ping Zou When a pod that is a member of a NodePort Service is created, Kubernetes will go through the following steps: The pod is created on the Kubernetes control plane (i.e. from a kubectl command or scaling action). The pod is scheduled by the kube-scheduler and is assigned to a node in the cluster. The kubelet running on the assigned node will receive the update (via watch ) and will communicate with it\u2019s local Container Runtime to start the containers specified in the pod. When the containers have started running (and optionally pass ReadinessProbes ), the kubelet will update the pod status to Ready by sending an update to the kube-apiserver The Endpoint Controller will receive an update (via watch ) that there is a new pod that is Ready to be added to the Endpoints list for the Service and will add the pod IP/Port tuples to the appropriate endpoints array. kube-proxy receives an update (via watch ) that there is a new IP/Port to add to the iptables rules for the Service. The local iptables rules on the worker node will be updated with the additional target pod for the NodePort Service. Note When using an Ingress resource and Ingress Controller (like the AWS Load Balancer Controller) step 5 is handled by the relevant controller instead of kube-proxy . The controller will then take the necessary configuration steps (such as registering/deregistering the target to a load balancer) to allow traffic to flow as expected. When a pod is terminated , or changes to a not-ready state, a similar process occurs. The API server will receive either an update from a controller, kubelet, or kubectl client to terminate the pod. Steps 3-5 continue from there but will remove the Pod IP/Tuple from the endpoints list and iptables rules rather than insert. Impact on Deployments \u00b6 Below is a diagram showing the steps taken when an application deployment triggers the replacement of pods: Ready? A Deep Dive into Pod Readiness Gates for Service Health... - Minhan Xia & Ping Zou Of note in this diagram is that the second Pod will not be deployed until the first pod has reached the \u201cReady\u201d state. Steps 4 and 5 from the previous section will also happen in parallel with the deployment actions above. This means that the actions to propagate the new pod status may still be in-progress when the Deployment controller moves on to the next pods. Since this process also terminates the older version of pods, this could lead to a situation where the pods have reached a Ready status but those changes are still being propagated and the older versions of the pod have been terminated. This problem is exacerbated when working with load balancers from Cloud Providers like AWS as the Kubernetes systems described above do not, by default, take into account registration times or health checks on the Load Balancer. This means the Deployment update could completely cycle through the pods, but the Load Balancer has not finished performing the health checks or registrating the new Pods which could cause an outage. A similar problem occurs when a pod is terminated. Depending on the Load Balancer configuration the Pod may take a minute or two to deregister and stop taking new requests. Kubernetes does not delay rolling deployments for this deregistration, this can lead to a state where the Load Balancer is still sending traffic to the IP/port for a target Pod that has already been terminated. To avoid these problems we can add configuration to ensure the Kubernetes systems take actions more in line with the AWS Load Balancer behavior. Recommendations \u00b6 Use IP Target-Type Load Balancers \u00b6 When creating a LoadBalancer type service the traffic is sent from the load balancer to any node in the cluster via Instance target type registration. Each node then redirects the traffic from the NodePort to a Pod/IP tuple in the Service\u2019s Endpoints array, this target could be running on a separate worker node Note Remember that array should only have \u201cReady\u201d pods This adds an additional hop to your request, and adds complexity to the Load Balancer configuration. For example, if the Load Balancer above was configured with session affinity, that affinity could only hold between the load balancer and the backend node (depending on the affinity configuration). Since the Load Balancer is not communicating with the backend Pod directly, controlling the traffic flow and timing with the Kubernetes systems becomes more difficult. When using the AWS Load Balancer Controller , IP target type can be used to register the Pod IP/Port tuples with the Load Balancer directly: This simplifies the traffic path from the Load Balancer to the target Pods. This means when a new target is registered we can be sure that target is a \u201cReady\u201d Pod IP and port, the health checks from the load balancer will hit the Pod Directly, and when reviewing VPC flow logs or monitoring utilities traffic between the Load Balancer and the Pods will be easily traceable. Using IP registration also allows us to control the timing and configuration of the traffic directly against the backend Pods, rather than trying to manage connections through the NodePort rules as well. Utilize Pod Readiness Gates \u00b6 Pod Readiness Gates are additional requirements that must be met before the Pod is allowed to reach the \u201cReady\u201d state. [...] the AWS Load Balancer controller can set the readiness condition on the pods that constitute your ingress or service backend. The condition status on a pod will be set to True only when the corresponding target in the ALB/NLB target group shows a health state of \u00bbHealthy\u00ab. This prevents the rolling update of a deployment from terminating old pods until the newly created pods are \u00bbHealthy\u00ab in the ALB/NLB target group and ready to take traffic. The readiness gates ensure that Kubernetes doesn\u2019t move \u201ctoo fast\u201d when creating new replicas during a deployment and avoids the situation where Kubernetes has completed the deployment but the new Pods have not completed registration. To enable these you will need to: Deploy the latest version of the AWS Load Balancer Controller ( Refer to the documentation if upgrading older versions ) Label the namespace where the target pods are running with the elbv2.k8s.aws/pod-readiness-gate-inject: enabled label to inject Pod Readiness Gates automatically. To ensure all of your pods in a namespace get the readiness gate config, you need create your Ingress or Service and label the namespace before creating the pods. Ensure Pods are Deregistered from Load Balancers before Termination \u00b6 When a pod is terminated steps 4 and 5 from the pod readiness section occur at the same time that the container processes receive the termination signals. This means that if your container is able to shut down quickly it may shut down faster than the Load Balancer is able to deregister the target. To avoid this situation adjust the Pod spec with: Add a preStop lifecycle hook to allow the application to deregister and gracefully close connections. This hook is called immediately before a container is terminated due to an API request or management event such as a liveness/startup probe failure, preemption, resource contention and others. Critically, this hook is called and allowed to complete before the termination signals are sent , provided the grace period is long enough to accommodate the execution. lifecycle : preStop : exec : command : [ \"/bin/sh\" , \"-c\" , \"sleep 180\" ] A simple sleep command like the one above can be used to introduce a short delay between when the pod is marked Terminating (and Load Balancer deregistration begins) and when the termination signal is sent to the container process. If needed this hook can also be leveraged for more advanced application termination/shutdown procedures. Extend the terminationGracePeriodSeconds to accommodate the entire prestop execution time, as well as the time your application takes to gracefully respond to the termination signal. In the example below the grace period is extended to 200s which allows the entire sleep 180 command to complete and then an extra 20s just to be sure my app can shutdown gracefully. spec : terminationGracePeriodSeconds : 200 containers : - name : webapp image : webapp - st : v1 . 3 [...] lifecycle : preStop : exec : command : [ \"/bin/sh\" , \"-c\" , \"sleep 180\" ] Ensure Pods have Readiness Probes \u00b6 When creating Pods in Kubernetes the default Readiness state is \u201cReady\u201d, however most applications take a moment or two to instantiate and become ready for requests. You can define a readinessProbe in the Pod spec with an exec command or network request that is used to determine if the application has completed its start up and is ready for traffic. Pods that are created with a readinessProbe defined start in a \u201cNotReady\u201d state, and only change to \u201cReady\u201d when the readinessProbe is successful. This ensures that applications are not put \u201cin-service\u201d until the application has completed startup. Liveness probes are recommended to allow for application restarts when entering a broken state, e.g. deadlocks, however care should be taken with stateful applications as liveness failures will trigger a restart of the application. Startup probes can also be leveraged for applications that are slow to start. The below probes use HTTP probes against port 80 to check when the web application becomes ready (the same probe configuration is also used for the liveness probe): [...] ports: - containerPort: 80 livenessProbe: httpGet: path: / port: 80 failureThreshold: 1 periodSeconds: 10 initialDelaySeconds: 5 readinessProbe: httpGet: path: / port: 80 periodSeconds: 5 [...] Configure a Pod Disruption Budget \u00b6 A Pod Disruption Budget (PDB) limits the number of Pods of a replicated application that are down simultaneously from voluntary disruptions . For example, a quorum-based application would like to ensure that the number of replicas running is never brought below the number needed for a quorum. A web front end might want to ensure that the number of replicas serving load never falls below a certain percentage of the total. The PDB will protect the application against things like the nodes being drained, or application deployments. The PDB ensures that a minimum number or percentage of pods remain available while taking these actions. Attention PDB\u2019s will NOT protect the application against involuntary disruptions like a failure in the host OS or loss of network connectivity. The example below ensures that there is always at least 1 Pod available with the label app: echoserver . You can configure the correct replica count for your application or use a percentage : apiVersion : policy / v1beta1 kind : PodDisruptionBudget metadata : name : echoserver - pdb namespace : echoserver spec : minAvailable : 1 selector : matchLabels : app : echoserver Gracefully handle Termination Signals \u00b6 When a pod is Terminated the application running inside the container will receive two Signals . The first is the SIGTERM signal , which is a \u201cpolite\u201d request that the process cease execution. This signal can be blocked or the application could simply ignore this signal, so after the terminationGracePeriodSeconds has elapsed the application will receive the SIGKILL signal . SIGKILL is used to forcibly stop a process, it cannot be blocked, handled or ignored , and is therefore always fatal. These Signals are used by the container runtime to trigger your application to shutdown. The SIGTERM signal will also be sent after the preStop hook has executed. With the above configuration the preStop hook will ensure the pod has been deregistered from the Load Balancer, so the application can then gracefully closes any remaining open connections when the SIGTERM signal is received. Note Signal handling in container environments can be complicated when using \u201cwrapper scripts\u201d for the entrypoint of your application as the script will be PID 1 and may not forward the signal to your application. Be Wary of the Deregistration Delay \u00b6 Elastic Load Balancing stops sending requests to targets that are deregistering. By default, Elastic Load Balancing waits 300 seconds before completing the deregistration process, which can help in-flight requests to the target to complete. To change the amount of time that Elastic Load Balancing waits, update the deregistration delay value. The initial state of a deregistering target is draining . After the deregistration delay elapses, the deregistration process completes and the state of the target is unused . If the target is part of an Auto Scaling group, it can be terminated and replaced. If a deregistering target has no in-flight requests and no active connections, Elastic Load Balancing immediately completes the deregistration process, without waiting for the deregistration delay to elapse. Attention Even though target deregistration is complete, the status of the target is displayed as draining until the deregistration delay timeout expires. After the timeout expires, the target transitions to an unused state. If a deregistering target terminates the connection before the deregistration delay elapses, the client receives a 500-level error response . This can be configured using annotations on the Ingress resource using the alb.ingress.kubernetes.io/target-group-attributes annotation . Example: apiVersion : networking . k8s . io / v1 kind : Ingress metadata : name : echoserver - ip namespace : echoserver annotations : alb . ingress . kubernetes . io / scheme : internet - facing alb . ingress . kubernetes . io / target - type : ip alb . ingress . kubernetes . io / load - balancer - name : echoserver - ip alb . ingress . kubernetes . io / target - group - attributes : deregistration_delay . timeout_seconds = 30 spec : ingressClassName : alb rules : - host : echoserver . example . com http : paths : - path : / pathType : Exact backend : service : name : echoserver - service port : number : 8080","title":"Load Balancing"},{"location":"networking/loadbalancing/loadbalancing/#avoiding-errors-timeouts-with-kubernetes-applications-and-aws-load-balancers","text":"After creating the necessary Kubernetes resources (Service, Deployment, Ingress, etc), your pods should be able to receive traffic from your clients through an Elastic Load Balancer. However, you may find that errors, timeouts, or connection resets are being generated when you make changes to the application or Kubernetes environment. Those changes could trigger an application deployment or a scaling action (either manual or automatic). Unfortunately, those errors may be generated even when your application is not logging problems. This is because the Kubernetes systems controlling the resources in your cluster may be running faster than the AWS systems that control the Load Balancer's target registration and health. Your Pods may also start receiving traffic before your application is ready to receive requests. Lets review the process through which a pod becomes Ready and how traffic can be routed into the pods.","title":"Avoiding Errors &amp; Timeouts with Kubernetes Applications and AWS Load Balancers"},{"location":"networking/loadbalancing/loadbalancing/#pod-readiness","text":"This diagram from a 2019 Kubecon talk , shows the steps taken for a pod to become Ready and receive traffic for a LoadBalancer service: Ready? A Deep Dive into Pod Readiness Gates for Service Health... - Minhan Xia & Ping Zou When a pod that is a member of a NodePort Service is created, Kubernetes will go through the following steps: The pod is created on the Kubernetes control plane (i.e. from a kubectl command or scaling action). The pod is scheduled by the kube-scheduler and is assigned to a node in the cluster. The kubelet running on the assigned node will receive the update (via watch ) and will communicate with it\u2019s local Container Runtime to start the containers specified in the pod. When the containers have started running (and optionally pass ReadinessProbes ), the kubelet will update the pod status to Ready by sending an update to the kube-apiserver The Endpoint Controller will receive an update (via watch ) that there is a new pod that is Ready to be added to the Endpoints list for the Service and will add the pod IP/Port tuples to the appropriate endpoints array. kube-proxy receives an update (via watch ) that there is a new IP/Port to add to the iptables rules for the Service. The local iptables rules on the worker node will be updated with the additional target pod for the NodePort Service. Note When using an Ingress resource and Ingress Controller (like the AWS Load Balancer Controller) step 5 is handled by the relevant controller instead of kube-proxy . The controller will then take the necessary configuration steps (such as registering/deregistering the target to a load balancer) to allow traffic to flow as expected. When a pod is terminated , or changes to a not-ready state, a similar process occurs. The API server will receive either an update from a controller, kubelet, or kubectl client to terminate the pod. Steps 3-5 continue from there but will remove the Pod IP/Tuple from the endpoints list and iptables rules rather than insert.","title":"Pod Readiness"},{"location":"networking/loadbalancing/loadbalancing/#impact-on-deployments","text":"Below is a diagram showing the steps taken when an application deployment triggers the replacement of pods: Ready? A Deep Dive into Pod Readiness Gates for Service Health... - Minhan Xia & Ping Zou Of note in this diagram is that the second Pod will not be deployed until the first pod has reached the \u201cReady\u201d state. Steps 4 and 5 from the previous section will also happen in parallel with the deployment actions above. This means that the actions to propagate the new pod status may still be in-progress when the Deployment controller moves on to the next pods. Since this process also terminates the older version of pods, this could lead to a situation where the pods have reached a Ready status but those changes are still being propagated and the older versions of the pod have been terminated. This problem is exacerbated when working with load balancers from Cloud Providers like AWS as the Kubernetes systems described above do not, by default, take into account registration times or health checks on the Load Balancer. This means the Deployment update could completely cycle through the pods, but the Load Balancer has not finished performing the health checks or registrating the new Pods which could cause an outage. A similar problem occurs when a pod is terminated. Depending on the Load Balancer configuration the Pod may take a minute or two to deregister and stop taking new requests. Kubernetes does not delay rolling deployments for this deregistration, this can lead to a state where the Load Balancer is still sending traffic to the IP/port for a target Pod that has already been terminated. To avoid these problems we can add configuration to ensure the Kubernetes systems take actions more in line with the AWS Load Balancer behavior.","title":"Impact on Deployments"},{"location":"networking/loadbalancing/loadbalancing/#recommendations","text":"","title":"Recommendations"},{"location":"networking/loadbalancing/loadbalancing/#use-ip-target-type-load-balancers","text":"When creating a LoadBalancer type service the traffic is sent from the load balancer to any node in the cluster via Instance target type registration. Each node then redirects the traffic from the NodePort to a Pod/IP tuple in the Service\u2019s Endpoints array, this target could be running on a separate worker node Note Remember that array should only have \u201cReady\u201d pods This adds an additional hop to your request, and adds complexity to the Load Balancer configuration. For example, if the Load Balancer above was configured with session affinity, that affinity could only hold between the load balancer and the backend node (depending on the affinity configuration). Since the Load Balancer is not communicating with the backend Pod directly, controlling the traffic flow and timing with the Kubernetes systems becomes more difficult. When using the AWS Load Balancer Controller , IP target type can be used to register the Pod IP/Port tuples with the Load Balancer directly: This simplifies the traffic path from the Load Balancer to the target Pods. This means when a new target is registered we can be sure that target is a \u201cReady\u201d Pod IP and port, the health checks from the load balancer will hit the Pod Directly, and when reviewing VPC flow logs or monitoring utilities traffic between the Load Balancer and the Pods will be easily traceable. Using IP registration also allows us to control the timing and configuration of the traffic directly against the backend Pods, rather than trying to manage connections through the NodePort rules as well.","title":"Use IP Target-Type Load Balancers"},{"location":"networking/loadbalancing/loadbalancing/#utilize-pod-readiness-gates","text":"Pod Readiness Gates are additional requirements that must be met before the Pod is allowed to reach the \u201cReady\u201d state. [...] the AWS Load Balancer controller can set the readiness condition on the pods that constitute your ingress or service backend. The condition status on a pod will be set to True only when the corresponding target in the ALB/NLB target group shows a health state of \u00bbHealthy\u00ab. This prevents the rolling update of a deployment from terminating old pods until the newly created pods are \u00bbHealthy\u00ab in the ALB/NLB target group and ready to take traffic. The readiness gates ensure that Kubernetes doesn\u2019t move \u201ctoo fast\u201d when creating new replicas during a deployment and avoids the situation where Kubernetes has completed the deployment but the new Pods have not completed registration. To enable these you will need to: Deploy the latest version of the AWS Load Balancer Controller ( Refer to the documentation if upgrading older versions ) Label the namespace where the target pods are running with the elbv2.k8s.aws/pod-readiness-gate-inject: enabled label to inject Pod Readiness Gates automatically. To ensure all of your pods in a namespace get the readiness gate config, you need create your Ingress or Service and label the namespace before creating the pods.","title":"Utilize Pod Readiness Gates"},{"location":"networking/loadbalancing/loadbalancing/#ensure-pods-are-deregistered-from-load-balancers-before-termination","text":"When a pod is terminated steps 4 and 5 from the pod readiness section occur at the same time that the container processes receive the termination signals. This means that if your container is able to shut down quickly it may shut down faster than the Load Balancer is able to deregister the target. To avoid this situation adjust the Pod spec with: Add a preStop lifecycle hook to allow the application to deregister and gracefully close connections. This hook is called immediately before a container is terminated due to an API request or management event such as a liveness/startup probe failure, preemption, resource contention and others. Critically, this hook is called and allowed to complete before the termination signals are sent , provided the grace period is long enough to accommodate the execution. lifecycle : preStop : exec : command : [ \"/bin/sh\" , \"-c\" , \"sleep 180\" ] A simple sleep command like the one above can be used to introduce a short delay between when the pod is marked Terminating (and Load Balancer deregistration begins) and when the termination signal is sent to the container process. If needed this hook can also be leveraged for more advanced application termination/shutdown procedures. Extend the terminationGracePeriodSeconds to accommodate the entire prestop execution time, as well as the time your application takes to gracefully respond to the termination signal. In the example below the grace period is extended to 200s which allows the entire sleep 180 command to complete and then an extra 20s just to be sure my app can shutdown gracefully. spec : terminationGracePeriodSeconds : 200 containers : - name : webapp image : webapp - st : v1 . 3 [...] lifecycle : preStop : exec : command : [ \"/bin/sh\" , \"-c\" , \"sleep 180\" ]","title":"Ensure Pods are Deregistered from Load Balancers before Termination"},{"location":"networking/loadbalancing/loadbalancing/#ensure-pods-have-readiness-probes","text":"When creating Pods in Kubernetes the default Readiness state is \u201cReady\u201d, however most applications take a moment or two to instantiate and become ready for requests. You can define a readinessProbe in the Pod spec with an exec command or network request that is used to determine if the application has completed its start up and is ready for traffic. Pods that are created with a readinessProbe defined start in a \u201cNotReady\u201d state, and only change to \u201cReady\u201d when the readinessProbe is successful. This ensures that applications are not put \u201cin-service\u201d until the application has completed startup. Liveness probes are recommended to allow for application restarts when entering a broken state, e.g. deadlocks, however care should be taken with stateful applications as liveness failures will trigger a restart of the application. Startup probes can also be leveraged for applications that are slow to start. The below probes use HTTP probes against port 80 to check when the web application becomes ready (the same probe configuration is also used for the liveness probe): [...] ports: - containerPort: 80 livenessProbe: httpGet: path: / port: 80 failureThreshold: 1 periodSeconds: 10 initialDelaySeconds: 5 readinessProbe: httpGet: path: / port: 80 periodSeconds: 5 [...]","title":"Ensure Pods have Readiness Probes"},{"location":"networking/loadbalancing/loadbalancing/#configure-a-pod-disruption-budget","text":"A Pod Disruption Budget (PDB) limits the number of Pods of a replicated application that are down simultaneously from voluntary disruptions . For example, a quorum-based application would like to ensure that the number of replicas running is never brought below the number needed for a quorum. A web front end might want to ensure that the number of replicas serving load never falls below a certain percentage of the total. The PDB will protect the application against things like the nodes being drained, or application deployments. The PDB ensures that a minimum number or percentage of pods remain available while taking these actions. Attention PDB\u2019s will NOT protect the application against involuntary disruptions like a failure in the host OS or loss of network connectivity. The example below ensures that there is always at least 1 Pod available with the label app: echoserver . You can configure the correct replica count for your application or use a percentage : apiVersion : policy / v1beta1 kind : PodDisruptionBudget metadata : name : echoserver - pdb namespace : echoserver spec : minAvailable : 1 selector : matchLabels : app : echoserver","title":"Configure a Pod Disruption Budget"},{"location":"networking/loadbalancing/loadbalancing/#gracefully-handle-termination-signals","text":"When a pod is Terminated the application running inside the container will receive two Signals . The first is the SIGTERM signal , which is a \u201cpolite\u201d request that the process cease execution. This signal can be blocked or the application could simply ignore this signal, so after the terminationGracePeriodSeconds has elapsed the application will receive the SIGKILL signal . SIGKILL is used to forcibly stop a process, it cannot be blocked, handled or ignored , and is therefore always fatal. These Signals are used by the container runtime to trigger your application to shutdown. The SIGTERM signal will also be sent after the preStop hook has executed. With the above configuration the preStop hook will ensure the pod has been deregistered from the Load Balancer, so the application can then gracefully closes any remaining open connections when the SIGTERM signal is received. Note Signal handling in container environments can be complicated when using \u201cwrapper scripts\u201d for the entrypoint of your application as the script will be PID 1 and may not forward the signal to your application.","title":"Gracefully handle Termination Signals"},{"location":"networking/loadbalancing/loadbalancing/#be-wary-of-the-deregistration-delay","text":"Elastic Load Balancing stops sending requests to targets that are deregistering. By default, Elastic Load Balancing waits 300 seconds before completing the deregistration process, which can help in-flight requests to the target to complete. To change the amount of time that Elastic Load Balancing waits, update the deregistration delay value. The initial state of a deregistering target is draining . After the deregistration delay elapses, the deregistration process completes and the state of the target is unused . If the target is part of an Auto Scaling group, it can be terminated and replaced. If a deregistering target has no in-flight requests and no active connections, Elastic Load Balancing immediately completes the deregistration process, without waiting for the deregistration delay to elapse. Attention Even though target deregistration is complete, the status of the target is displayed as draining until the deregistration delay timeout expires. After the timeout expires, the target transitions to an unused state. If a deregistering target terminates the connection before the deregistration delay elapses, the client receives a 500-level error response . This can be configured using annotations on the Ingress resource using the alb.ingress.kubernetes.io/target-group-attributes annotation . Example: apiVersion : networking . k8s . io / v1 kind : Ingress metadata : name : echoserver - ip namespace : echoserver annotations : alb . ingress . kubernetes . io / scheme : internet - facing alb . ingress . kubernetes . io / target - type : ip alb . ingress . kubernetes . io / load - balancer - name : echoserver - ip alb . ingress . kubernetes . io / target - group - attributes : deregistration_delay . timeout_seconds = 30 spec : ingressClassName : alb rules : - host : echoserver . example . com http : paths : - path : / pathType : Exact backend : service : name : echoserver - service port : number : 8080","title":"Be Wary of the Deregistration Delay"},{"location":"networking/prefix-mode/","text":"Prefix Mode \u00b6 Amazon VPC CNI assigns network prefixes to Amazon EC2 network interfaces to increase the number of IP addresses available to nodes and increase pod density per node. You can configure version 1.9.0 or later of the Amazon VPC CNI add-on to assign IPv4 and IPv6 CIDRs instead of assigning individual secondary IP addresses to network interfaces. Prefix mode is enabled by default on IPv6 clusters and is the only option supported. The VPC CNI assigns a /80 IPv6 prefix to a slot on an ENI. Please refer to the IPv6 section of this guide for further information. With prefix assignment mode, the maximum number of elastic network interfaces per instance type remains the same, but you can now configure Amazon VPC CNI to assign /28 (16 IP addresses) IPv4 address prefixes, instead of assigning individual IPv4 addresses to the slots on network interfaces. When ENABLE_PREFIX_DELEGATION is set to true VPC CNI allocates an IP address to a Pod from the prefix assigned to an ENI. Please follow the instructions mentioned in the EKS user guide to enable Prefix IP mode. The maximum number of IP addresses that you can assign to a network interface depends on the instance type. Each prefix that you assign to a network interface counts as one IP address. For example, a c5.large instance has a limit of 10 IPv4 addresses per network interface. Each network interface for this instance has a primary IPv4 address. If a network interface has no secondary IPv4 addresses, you can assign up to 9 prefixes to the network interface. For each additional IPv4 address that you assign to a network interface, you can assign one less prefix to the network interface. Review the AWS EC2 documentation on IP addresses per network interface per instance type and assigning prefixes to network interfaces. During worker node initialization, the VPC CNI assigns one or more prefixes to the primary ENI. The CNI pre-allocates a prefix for faster pod startup by maintaining a warm pool. The number of prefixes to be held in warm pool can be controlled by setting environment variables. WARM_PREFIX_TARGET , the number of prefixes to be allocated in excess of current need. WARM_IP_TARGET , the number of IP addresses to be allocated in excess of current need. MINIMUM_IP_TARGET , the minimum number of IP addresses to be available at any time. WARM_IP_TARGET and MINIMUM_IP_TARGET if set will override WARM_PREFIX_TARGET . As more Pods scheduled additional prefixes will be requested for the existing ENI. First, the VPC CNI attempts to allocate a new prefix to an existing ENI. If the ENI is at capacity, the VPC CNI attempts to allocate a new ENI to the node. New ENIs will be attached until the maximum ENI limit (defined by the instance type) is reached. When a new ENI is attached, ipamd will allocate one or more prefixes needed to maintain the WARM_PREFIX_TARGET , WARM_IP_TARGET , and MINIMUM_IP_TARGET setting. Recommendations \u00b6 Use Prefix Mode when \u00b6 Use prefix mode if you are experiencing Pod density issue on the worker nodes. To avoid VPC CNI errors, we recommend examining the subnets for contiguous block of addresses for /28 prefix before migrate to prefix mode. Please refer \u201c Use Subnet Reservations to Avoid Subnet Fragmentation (IPv4) \u201d section for Subnet reservation details. For backward compatibility, the max-pods limit is set to support secondary IP mode. To increase the pod density, please specify the max-pods value to Kubelet and --use-max-pods=false as the user data for the nodes. You may consider using the max-pod-calculator.sh script to calculate EKS\u2019s recommended maximum number of pods for a given instance type. Refer to the EKS user guide for example user data. ./max-pods-calculator.sh --instance-type m5.large --cni-version ``1.9``.0 --cni-prefix-delegation-enabled Prefix assignment mode is especially relevant for users of CNI custom networking where the primary ENI is not used for pods. With prefix assignment, you can still attach more IPs on nearly every Nitro instance type, even without the primary ENI used for pods. Avoid Prefix Mode when \u00b6 If your subnet is very fragmented and has insufficient available IP addresses to create /28 prefixes, avoid using prefix mode. The prefix attachment may fail if the subnet from which the prefix is produced is fragmented (a heavily used subnet with scattered secondary IP addresses). This problem may be avoided by creating a new subnet and reserving a prefix. In prefix mode, the security group assigned to the worker nodes is shared by the Pods. Consider using Security groups for Pods if you have a security requirement to achieve compliance by running applications with varying network security requirements on shared compute resources. Use Similar Instance Types in the same Node Group \u00b6 Your node group may contain instances of many types. If an instance has a low maximum pod count, that value is applied to all nodes in the node group. Consider using similar instance types in a node group to maximize node use. We recommend configuring node.kubernetes.io/instance-type in the requirements part of the provisioner API if you are using Karpenter for automated node scaling. Warning The maximum pod count for all nodes in a particular node group is defined by the lowest maximum pod count of any single instance type in the node group. Configure WARM_PREFIX_TARGET to conserve IPv4 addresses \u00b6 The installation manifest\u2019s default value for WARM_PREFIX_TARGET is 1. In most cases, the recommended value of 1 for WARM_PREFIX_TARGET will provide a good mix of fast pod launch times while minimizing unused IP addresses assigned to the instance. If you have a need to further conserve IPv4 addresses per node use WARM_IP_TARGET and MINIMUM_IP_TARGET settings, which override WARM_PREFIX_TARGET when configured. By setting WARM_IP_TARGET to a value less than 16, you can prevent the CNI from keeping an entire excess prefix attached. Prefer allocating new prefixes over attaching a new ENI \u00b6 Allocating an additional prefix to an existing ENI is a faster EC2 API operation than creating and attaching a new ENI to the instance. Using prefixes improves performance while being frugal with IPv4 address allocation. Attaching a prefix typically completes in under a second, whereas attaching a new ENI can take up to 10 seconds. For most use cases, the CNI will only need a single ENI per worker node when running in prefix mode. If you can afford (in the worst case) up to 15 unused IPs per node, we strongly recommend using the newer prefix assignment networking mode, and realizing the performance and efficiency gains that come with it. Use Subnet Reservations to Avoid Subnet Fragmentation (IPv4) \u00b6 When EC2 allocates a /28 IPv4 prefix to an ENI, it has to be a contiguous block of IP addresses from your subnet. If the subnet that the prefix is generated from is fragmented (a highly used subnet with scattered secondary IP addresses), the prefix attachment may fail, and you will see the following error message in the VPC CNI logs: failed to allocate a private IP/Prefix address: InsufficientCidrBlocks: There are not enough free cidr blocks in the specified subnet to satisfy the request. To avoid fragmentation and have sufficient contiguous space for creating prefixes, you may use VPC Subnet CIDR reservations to reserve IP space within a subnet for exclusive use by prefixes. Once you create a reservation, the VPC CNI plugin will call EC2 APIs to assign prefixes that are automatically allocated from the reserved space. It is recommended to create a new subnet, reserve space for prefixes, and enable prefix assignment with VPC CNI for worker nodes running in that subnet. If the new subnet is dedicated only to Pods running in your EKS cluster with VPC CNI prefix assignment enabled, then you can skip the prefix reservation step. Avoid downgrading VPC CNI \u00b6 Prefix mode works with VPC CNI version 1.9.0 and later. Downgrading of the Amazon VPC CNI add-on to a version lower than 1.9.0 must be avoided once the prefix mode is enabled and prefixes are assigned to ENIs. You must delete and recreate nodes if you decide to downgrade the VPC CNI. Replace all nodes during the transition to Prefix Delegation \u00b6 It is highly recommended that you create new node groups to increase the number of available IP addresses rather than doing rolling replacement of existing worker nodes. Cordon and drain all the existing nodes to safely evict all of your existing Pods. To prevent service disruptions, we suggest implementing Pod Disruption Budgets on your production clusters for critical workloads. Pods on new nodes will be assigned an IP from a prefix assigned to an ENI. After you confirm the Pods are running, you can delete the old nodes and node groups. If you are using managed node groups, please follow steps mentioned here to safely delete a node group .","title":"Prefix Mode"},{"location":"networking/prefix-mode/#prefix-mode","text":"Amazon VPC CNI assigns network prefixes to Amazon EC2 network interfaces to increase the number of IP addresses available to nodes and increase pod density per node. You can configure version 1.9.0 or later of the Amazon VPC CNI add-on to assign IPv4 and IPv6 CIDRs instead of assigning individual secondary IP addresses to network interfaces. Prefix mode is enabled by default on IPv6 clusters and is the only option supported. The VPC CNI assigns a /80 IPv6 prefix to a slot on an ENI. Please refer to the IPv6 section of this guide for further information. With prefix assignment mode, the maximum number of elastic network interfaces per instance type remains the same, but you can now configure Amazon VPC CNI to assign /28 (16 IP addresses) IPv4 address prefixes, instead of assigning individual IPv4 addresses to the slots on network interfaces. When ENABLE_PREFIX_DELEGATION is set to true VPC CNI allocates an IP address to a Pod from the prefix assigned to an ENI. Please follow the instructions mentioned in the EKS user guide to enable Prefix IP mode. The maximum number of IP addresses that you can assign to a network interface depends on the instance type. Each prefix that you assign to a network interface counts as one IP address. For example, a c5.large instance has a limit of 10 IPv4 addresses per network interface. Each network interface for this instance has a primary IPv4 address. If a network interface has no secondary IPv4 addresses, you can assign up to 9 prefixes to the network interface. For each additional IPv4 address that you assign to a network interface, you can assign one less prefix to the network interface. Review the AWS EC2 documentation on IP addresses per network interface per instance type and assigning prefixes to network interfaces. During worker node initialization, the VPC CNI assigns one or more prefixes to the primary ENI. The CNI pre-allocates a prefix for faster pod startup by maintaining a warm pool. The number of prefixes to be held in warm pool can be controlled by setting environment variables. WARM_PREFIX_TARGET , the number of prefixes to be allocated in excess of current need. WARM_IP_TARGET , the number of IP addresses to be allocated in excess of current need. MINIMUM_IP_TARGET , the minimum number of IP addresses to be available at any time. WARM_IP_TARGET and MINIMUM_IP_TARGET if set will override WARM_PREFIX_TARGET . As more Pods scheduled additional prefixes will be requested for the existing ENI. First, the VPC CNI attempts to allocate a new prefix to an existing ENI. If the ENI is at capacity, the VPC CNI attempts to allocate a new ENI to the node. New ENIs will be attached until the maximum ENI limit (defined by the instance type) is reached. When a new ENI is attached, ipamd will allocate one or more prefixes needed to maintain the WARM_PREFIX_TARGET , WARM_IP_TARGET , and MINIMUM_IP_TARGET setting.","title":"Prefix Mode"},{"location":"networking/prefix-mode/#recommendations","text":"","title":"Recommendations"},{"location":"networking/prefix-mode/#use-prefix-mode-when","text":"Use prefix mode if you are experiencing Pod density issue on the worker nodes. To avoid VPC CNI errors, we recommend examining the subnets for contiguous block of addresses for /28 prefix before migrate to prefix mode. Please refer \u201c Use Subnet Reservations to Avoid Subnet Fragmentation (IPv4) \u201d section for Subnet reservation details. For backward compatibility, the max-pods limit is set to support secondary IP mode. To increase the pod density, please specify the max-pods value to Kubelet and --use-max-pods=false as the user data for the nodes. You may consider using the max-pod-calculator.sh script to calculate EKS\u2019s recommended maximum number of pods for a given instance type. Refer to the EKS user guide for example user data. ./max-pods-calculator.sh --instance-type m5.large --cni-version ``1.9``.0 --cni-prefix-delegation-enabled Prefix assignment mode is especially relevant for users of CNI custom networking where the primary ENI is not used for pods. With prefix assignment, you can still attach more IPs on nearly every Nitro instance type, even without the primary ENI used for pods.","title":"Use Prefix Mode when"},{"location":"networking/prefix-mode/#avoid-prefix-mode-when","text":"If your subnet is very fragmented and has insufficient available IP addresses to create /28 prefixes, avoid using prefix mode. The prefix attachment may fail if the subnet from which the prefix is produced is fragmented (a heavily used subnet with scattered secondary IP addresses). This problem may be avoided by creating a new subnet and reserving a prefix. In prefix mode, the security group assigned to the worker nodes is shared by the Pods. Consider using Security groups for Pods if you have a security requirement to achieve compliance by running applications with varying network security requirements on shared compute resources.","title":"Avoid Prefix Mode when"},{"location":"networking/prefix-mode/#use-similar-instance-types-in-the-same-node-group","text":"Your node group may contain instances of many types. If an instance has a low maximum pod count, that value is applied to all nodes in the node group. Consider using similar instance types in a node group to maximize node use. We recommend configuring node.kubernetes.io/instance-type in the requirements part of the provisioner API if you are using Karpenter for automated node scaling. Warning The maximum pod count for all nodes in a particular node group is defined by the lowest maximum pod count of any single instance type in the node group.","title":"Use Similar Instance Types in the same Node Group"},{"location":"networking/prefix-mode/#configure-warm_prefix_target-to-conserve-ipv4-addresses","text":"The installation manifest\u2019s default value for WARM_PREFIX_TARGET is 1. In most cases, the recommended value of 1 for WARM_PREFIX_TARGET will provide a good mix of fast pod launch times while minimizing unused IP addresses assigned to the instance. If you have a need to further conserve IPv4 addresses per node use WARM_IP_TARGET and MINIMUM_IP_TARGET settings, which override WARM_PREFIX_TARGET when configured. By setting WARM_IP_TARGET to a value less than 16, you can prevent the CNI from keeping an entire excess prefix attached.","title":"Configure WARM_PREFIX_TARGET to conserve IPv4 addresses"},{"location":"networking/prefix-mode/#prefer-allocating-new-prefixes-over-attaching-a-new-eni","text":"Allocating an additional prefix to an existing ENI is a faster EC2 API operation than creating and attaching a new ENI to the instance. Using prefixes improves performance while being frugal with IPv4 address allocation. Attaching a prefix typically completes in under a second, whereas attaching a new ENI can take up to 10 seconds. For most use cases, the CNI will only need a single ENI per worker node when running in prefix mode. If you can afford (in the worst case) up to 15 unused IPs per node, we strongly recommend using the newer prefix assignment networking mode, and realizing the performance and efficiency gains that come with it.","title":"Prefer allocating new prefixes over attaching a new ENI"},{"location":"networking/prefix-mode/#use-subnet-reservations-to-avoid-subnet-fragmentation-ipv4","text":"When EC2 allocates a /28 IPv4 prefix to an ENI, it has to be a contiguous block of IP addresses from your subnet. If the subnet that the prefix is generated from is fragmented (a highly used subnet with scattered secondary IP addresses), the prefix attachment may fail, and you will see the following error message in the VPC CNI logs: failed to allocate a private IP/Prefix address: InsufficientCidrBlocks: There are not enough free cidr blocks in the specified subnet to satisfy the request. To avoid fragmentation and have sufficient contiguous space for creating prefixes, you may use VPC Subnet CIDR reservations to reserve IP space within a subnet for exclusive use by prefixes. Once you create a reservation, the VPC CNI plugin will call EC2 APIs to assign prefixes that are automatically allocated from the reserved space. It is recommended to create a new subnet, reserve space for prefixes, and enable prefix assignment with VPC CNI for worker nodes running in that subnet. If the new subnet is dedicated only to Pods running in your EKS cluster with VPC CNI prefix assignment enabled, then you can skip the prefix reservation step.","title":"Use Subnet Reservations to Avoid Subnet Fragmentation (IPv4)"},{"location":"networking/prefix-mode/#avoid-downgrading-vpc-cni","text":"Prefix mode works with VPC CNI version 1.9.0 and later. Downgrading of the Amazon VPC CNI add-on to a version lower than 1.9.0 must be avoided once the prefix mode is enabled and prefixes are assigned to ENIs. You must delete and recreate nodes if you decide to downgrade the VPC CNI.","title":"Avoid downgrading VPC CNI"},{"location":"networking/prefix-mode/#replace-all-nodes-during-the-transition-to-prefix-delegation","text":"It is highly recommended that you create new node groups to increase the number of available IP addresses rather than doing rolling replacement of existing worker nodes. Cordon and drain all the existing nodes to safely evict all of your existing Pods. To prevent service disruptions, we suggest implementing Pod Disruption Budgets on your production clusters for critical workloads. Pods on new nodes will be assigned an IP from a prefix assigned to an ENI. After you confirm the Pods are running, you can delete the old nodes and node groups. If you are using managed node groups, please follow steps mentioned here to safely delete a node group .","title":"Replace all nodes during the transition to Prefix Delegation"},{"location":"networking/sgpp/","text":"Security Groups Per Pod \u00b6 An AWS security group acts as a virtual firewall for EC2 instances to control inbound and outbound traffic. By default, the Amazon VPC CNI will use security groups associated with the primary ENI on the node. More specifically, every ENI associated with the instance will have the same EC2 Security Groups. Thus, every Pod on a node shares the same security groups as the node it runs on. As seen in the image below, all application Pods operating on worker nodes will have access to the RDS database service (considering RDS inbound allows node security group). Security groups are too coarse grained because they apply to all Pods running on a node. Security groups for Pods provides network segmentation for workloads which is an essential part a good defense in depth strategy. With security groups for Pods, you can improve compute efficiency by running applications with varying network security requirements on shared compute resources. Multiple types of security rules, such as Pod-to-Pod and Pod-to-External AWS services, can be defined in a single place with EC2 security groups and applied to workloads with Kubernetes native APIs. The image below shows security groups applied at the Pod level and how they simplify your application deployment and node architecture. The Pod can now access Amazon RDS database. You can enable security groups for Pods by setting ENABLE_POD_ENI = true for VPC CNI. Once this setting is set to true , for each node in the cluster the add-on adds a label with the value vpc.amazonaws.com/has-trunk-attached=true . When you enable Pod ENI, the \u201c VPC Resource Controller \u201c running on the control plane (managed by EKS) creates and attaches a trunk interface called \u201caws-k8s-trunk-eni\u201c to the node. The trunk interface acts as a standard network interface attached to the instance. To manage trunk interfaces, you must add the AmazonEKSVPCResourceController managed policy to the cluster role that goes with your Amazon EKS cluster. The controller also creates branch interfaces named \"aws-k8s-branch-eni\" and associates them with the trunk interface. Pods are assigned a security group using the SecurityGroupPolicy custom resource and are associated with a branch interface. Since security groups are specified with network interfaces, we are now able to schedule Pods requiring specific security groups on these additional network interfaces. Review the EKS User Guide Section on Security Groups for Pods, including deployment prerequisites. Branch interface capacity is additive to existing instance type limits for secondary IP addresses. Pods that use security groups are not accounted for in the max-pods formula and when you use security group for pods you need to consider raising the max-pods value or be ok with running fewer pods than the node can actually support. A m5.large can have up to 9 branch network interfaces and up to 27 secondary IP addresses assigned to its standard network interfaces. As shown in the example below, the default max-pods for a m5.large is 29, and EKS counts the Pods that use security groups towards the maximum Pods. Please see the EKS user guide for instructions on how to change the max-pods for nodes. When security groups for Pods are used in combination with custom networking , the security group defined in security groups for Pods is used rather than the security group specified in the ENIConfig. As a result, when custom networking is enabled, carefully assess security group ordering while using security groups per Pod. Recommendations \u00b6 Disable TCP Early Demux for Liveness Probe \u00b6 If are you using liveness or readiness probes, you also need to disable TCP early demux, so that the kubelet can connect to Pods on branch network interfaces via TCP. This is only required in strict mode. To do this run the following command: kubectl edit daemonset aws-node -n kube-system Under the initContainer section, change the value for DISABLE_TCP_EARLY_DEMUX to true. Use Security Group For Pods to leverage existing AWS configuration investment. \u00b6 Security groups makes it easier to restrict network access to VPC resources, such as RDS databases or EC2 instances. One clear advantage of security groups per Pod is the opportunity to reuse existing AWS security group resources. If you are using security groups as a network firewall to limit access to your AWS services, we propose applying security groups to Pods using branch ENIs. Consider using security groups for Pods if you are transferring apps from EC2 instances to EKS and limit access to other AWS services with security groups. Configure Pod Security Group Enforcing Mode \u00b6 Amazon VPC CNI plugin version 1.11 added a new setting named POD_SECURITY_GROUP_ENFORCING_MODE (\u201cenforcing mode\u201d). The enforcing mode controls both which security groups apply to the pod, and if source NAT is enabled. You may specify the enforcing mode as either strict or standard. Strict is the default, reflecting the previous behavior of the VPC CNI with ENABLE_POD_ENI set to true . In Strict Mode, only the branch ENI security groups are enforced. The source NAT is also disabled. In Standard Mode, the security groups associated with both the primary ENI and branch ENI (associated with the pod) are applied. Network traffic must comply with both security groups. !!! Warning Any mode change will only impact newly launched Pods. Existing Pods will use the mode that was configured when the Pod was created. Customers will need to recycle existing Pods with security groups if they want to change the traffic behavior. * Enforcing Mode: Use Strict mode for isolating pod and node traffic: \u00b6 By default, security groups for Pods is set to \"strict mode.\" Use this setting if you must completely separate Pod traffic from the rest of the node's traffic. In strict mode, the source NAT is turned off so the branch ENI outbound security groups can be used. Warning When strict mode is enabled, all outbound traffic from a pod will leave the node and enter the VPC network. Traffic between pods on the same node will go over the VPC. This increases VPC traffic and limits node-based features. The NodeLocal DNSCache is not supported with strict mode. Enforcing Mode: Use Standard mode in the following situations \u00b6 Client source IP visible to the containers in the Pod If you need to keep the client source IP visible to the containers in the Pod, consider setting POD_SECURITY_GROUP_ENFORCING_MODE to standard . Kubernetes services support externalTrafficPolicy=local to support preservation of the client source IP (default type cluster). You can now run Kubernetes services of type NodePort and LoadBalancer using instance targets with an externalTrafficPolicy set to Local in the standard mode. Local preserves the client source IP and avoids a second hop for LoadBalancer and NodePort type Services. Deploying NodeLocal DNSCache When using security groups for pods, configure standard mode to support Pods that use NodeLocal DNSCache . NodeLocal DNSCache improves Cluster DNS performance by running a DNS caching agent on cluster nodes as a DaemonSet. This will help the pods that have the highest DNS QPS requirements to query local kube-dns/CoreDNS having a local cache, which will improve the latency. NodeLocal DNSCache is not supported in strict mode as all network traffic, even to the node, enters the VPC. Supporting Kubernetes Network Policy We recommend using standard enforcing mode when using network policy with Pods that have associated security groups. We strongly recommend to utilize security groups for Pods to limit network-level access to AWS services that are not part of a cluster. Consider network policies to restrict network traffic between Pods inside a cluster, often known as East/West traffic. Identify Incompatibilities with Security Groups per Pod \u00b6 Windows-based and non-nitro instances do not support security groups for Pods. To utilize security groups with Pods, the instances must be tagged with isTrunkingEnabled. Use network policies to manage access between Pods rather than security groups if your Pods do not depend on any AWS services within or outside of your VPC. Use Security Groups per Pod to efficiently control traffic to AWS Services \u00b6 If an application running within the EKS cluster has to communicate with another resource within the VPC, e.g. an RDS database, then consider using SGs for pods. While there are policy engines that allow you to specify an CIDR or a DNS name, they are a less optimal choice when communicating with AWS services that have endpoints that reside within a VPC. In contrast, Kubernetes network policies provide a mechanism for controlling ingress and egress traffic both within and outside the cluster. Kubernetes network policies should be considered if your application has limited dependencies on other AWS services. You can configure may configure network policies that specify egress rules based on CIDR ranges to limit access to AWS services as opposed to AWS native semantics like SGs. You may use Kubernetes network policies to control network traffic between Pods (often referred to as East/West traffic) and between Pods and external services. Kubernetes network policies are implemented at OSI levels 3 and 4. Amazon EKS allows you to use network policy engines such as Calico and Cilium . By default, the network policy engines are not installed. Please check the respective install guides for instructions on how to set up. For more information on how to use network policy, see EKS Security best practices . The DNS hostnames feature is available in the enterprise versions of network policy engines, which could be useful for controlling traffic between Kubernetes Services/Pods and resources that run outside of AWS. Also, you can consider DNS hostname support for AWS services that don't support security groups by default. Tag a single Security Group to use AWS Loadbalancer Controller \u00b6 When many security groups are allocated to a Pod, Amazon EKS recommends tagging a single security group with kubernetes.io/cluster/$name shared or owned. The tag allows the AWS Loadbalancer Controller to update the rules of security groups to route traffic to the Pods. If just one security group is given to a Pod, the assignment of a tag is optional. Permissions set in a security group are additive, therefore tagging a single security group is sufficient for the loadbalancer controller to locate and reconcile the rules. It also helps to adhere to the default quotas defined by security groups. Configure NAT for Outbound Traffic \u00b6 Source NAT is disabled for outbound traffic from Pods that are assigned security groups. For Pods using security groups that require access the internet launch worker nodes on private subnets configured with a NAT gateway or instance and enable external SNAT in the CNI. kubectl set env daemonset -n kube-system aws-node AWS_VPC_K8S_CNI_EXTERNALSNAT=true Deploy Pods with Security Groups to Private Subnets \u00b6 Pods that are assigned security groups must be run on nodes that are deployed on to private subnets. Note that Pods with assigned security groups deployed to public subnets will not able to access the internet. Verify terminationGracePeriodSeconds in Pod Specification File \u00b6 Ensure that terminationGracePeriodSeconds is non-zero in your Pod specification file (default 30 seconds). This is essential in order for Amazon VPC CNI to delete the Pod network from the worker node. When set to zero, the CNI plugin does not remove the Pod network from the host, and the branch ENI is not effectively cleaned up.","title":"Security Groups per Pod"},{"location":"networking/sgpp/#security-groups-per-pod","text":"An AWS security group acts as a virtual firewall for EC2 instances to control inbound and outbound traffic. By default, the Amazon VPC CNI will use security groups associated with the primary ENI on the node. More specifically, every ENI associated with the instance will have the same EC2 Security Groups. Thus, every Pod on a node shares the same security groups as the node it runs on. As seen in the image below, all application Pods operating on worker nodes will have access to the RDS database service (considering RDS inbound allows node security group). Security groups are too coarse grained because they apply to all Pods running on a node. Security groups for Pods provides network segmentation for workloads which is an essential part a good defense in depth strategy. With security groups for Pods, you can improve compute efficiency by running applications with varying network security requirements on shared compute resources. Multiple types of security rules, such as Pod-to-Pod and Pod-to-External AWS services, can be defined in a single place with EC2 security groups and applied to workloads with Kubernetes native APIs. The image below shows security groups applied at the Pod level and how they simplify your application deployment and node architecture. The Pod can now access Amazon RDS database. You can enable security groups for Pods by setting ENABLE_POD_ENI = true for VPC CNI. Once this setting is set to true , for each node in the cluster the add-on adds a label with the value vpc.amazonaws.com/has-trunk-attached=true . When you enable Pod ENI, the \u201c VPC Resource Controller \u201c running on the control plane (managed by EKS) creates and attaches a trunk interface called \u201caws-k8s-trunk-eni\u201c to the node. The trunk interface acts as a standard network interface attached to the instance. To manage trunk interfaces, you must add the AmazonEKSVPCResourceController managed policy to the cluster role that goes with your Amazon EKS cluster. The controller also creates branch interfaces named \"aws-k8s-branch-eni\" and associates them with the trunk interface. Pods are assigned a security group using the SecurityGroupPolicy custom resource and are associated with a branch interface. Since security groups are specified with network interfaces, we are now able to schedule Pods requiring specific security groups on these additional network interfaces. Review the EKS User Guide Section on Security Groups for Pods, including deployment prerequisites. Branch interface capacity is additive to existing instance type limits for secondary IP addresses. Pods that use security groups are not accounted for in the max-pods formula and when you use security group for pods you need to consider raising the max-pods value or be ok with running fewer pods than the node can actually support. A m5.large can have up to 9 branch network interfaces and up to 27 secondary IP addresses assigned to its standard network interfaces. As shown in the example below, the default max-pods for a m5.large is 29, and EKS counts the Pods that use security groups towards the maximum Pods. Please see the EKS user guide for instructions on how to change the max-pods for nodes. When security groups for Pods are used in combination with custom networking , the security group defined in security groups for Pods is used rather than the security group specified in the ENIConfig. As a result, when custom networking is enabled, carefully assess security group ordering while using security groups per Pod.","title":"Security Groups Per Pod"},{"location":"networking/sgpp/#recommendations","text":"","title":"Recommendations"},{"location":"networking/sgpp/#disable-tcp-early-demux-for-liveness-probe","text":"If are you using liveness or readiness probes, you also need to disable TCP early demux, so that the kubelet can connect to Pods on branch network interfaces via TCP. This is only required in strict mode. To do this run the following command: kubectl edit daemonset aws-node -n kube-system Under the initContainer section, change the value for DISABLE_TCP_EARLY_DEMUX to true.","title":"Disable TCP Early Demux for Liveness Probe"},{"location":"networking/sgpp/#use-security-group-for-pods-to-leverage-existing-aws-configuration-investment","text":"Security groups makes it easier to restrict network access to VPC resources, such as RDS databases or EC2 instances. One clear advantage of security groups per Pod is the opportunity to reuse existing AWS security group resources. If you are using security groups as a network firewall to limit access to your AWS services, we propose applying security groups to Pods using branch ENIs. Consider using security groups for Pods if you are transferring apps from EC2 instances to EKS and limit access to other AWS services with security groups.","title":"Use Security Group For Pods to leverage existing AWS configuration investment."},{"location":"networking/sgpp/#configure-pod-security-group-enforcing-mode","text":"Amazon VPC CNI plugin version 1.11 added a new setting named POD_SECURITY_GROUP_ENFORCING_MODE (\u201cenforcing mode\u201d). The enforcing mode controls both which security groups apply to the pod, and if source NAT is enabled. You may specify the enforcing mode as either strict or standard. Strict is the default, reflecting the previous behavior of the VPC CNI with ENABLE_POD_ENI set to true . In Strict Mode, only the branch ENI security groups are enforced. The source NAT is also disabled. In Standard Mode, the security groups associated with both the primary ENI and branch ENI (associated with the pod) are applied. Network traffic must comply with both security groups. !!! Warning Any mode change will only impact newly launched Pods. Existing Pods will use the mode that was configured when the Pod was created. Customers will need to recycle existing Pods with security groups if they want to change the traffic behavior. *","title":"Configure Pod Security Group Enforcing Mode"},{"location":"networking/sgpp/#enforcing-mode-use-strict-mode-for-isolating-pod-and-node-traffic","text":"By default, security groups for Pods is set to \"strict mode.\" Use this setting if you must completely separate Pod traffic from the rest of the node's traffic. In strict mode, the source NAT is turned off so the branch ENI outbound security groups can be used. Warning When strict mode is enabled, all outbound traffic from a pod will leave the node and enter the VPC network. Traffic between pods on the same node will go over the VPC. This increases VPC traffic and limits node-based features. The NodeLocal DNSCache is not supported with strict mode.","title":"Enforcing Mode: Use Strict mode for isolating pod and node traffic:"},{"location":"networking/sgpp/#enforcing-mode-use-standard-mode-in-the-following-situations","text":"Client source IP visible to the containers in the Pod If you need to keep the client source IP visible to the containers in the Pod, consider setting POD_SECURITY_GROUP_ENFORCING_MODE to standard . Kubernetes services support externalTrafficPolicy=local to support preservation of the client source IP (default type cluster). You can now run Kubernetes services of type NodePort and LoadBalancer using instance targets with an externalTrafficPolicy set to Local in the standard mode. Local preserves the client source IP and avoids a second hop for LoadBalancer and NodePort type Services. Deploying NodeLocal DNSCache When using security groups for pods, configure standard mode to support Pods that use NodeLocal DNSCache . NodeLocal DNSCache improves Cluster DNS performance by running a DNS caching agent on cluster nodes as a DaemonSet. This will help the pods that have the highest DNS QPS requirements to query local kube-dns/CoreDNS having a local cache, which will improve the latency. NodeLocal DNSCache is not supported in strict mode as all network traffic, even to the node, enters the VPC. Supporting Kubernetes Network Policy We recommend using standard enforcing mode when using network policy with Pods that have associated security groups. We strongly recommend to utilize security groups for Pods to limit network-level access to AWS services that are not part of a cluster. Consider network policies to restrict network traffic between Pods inside a cluster, often known as East/West traffic.","title":"Enforcing Mode: Use Standard mode in the following situations"},{"location":"networking/sgpp/#identify-incompatibilities-with-security-groups-per-pod","text":"Windows-based and non-nitro instances do not support security groups for Pods. To utilize security groups with Pods, the instances must be tagged with isTrunkingEnabled. Use network policies to manage access between Pods rather than security groups if your Pods do not depend on any AWS services within or outside of your VPC.","title":"Identify Incompatibilities with Security Groups per Pod"},{"location":"networking/sgpp/#use-security-groups-per-pod-to-efficiently-control-traffic-to-aws-services","text":"If an application running within the EKS cluster has to communicate with another resource within the VPC, e.g. an RDS database, then consider using SGs for pods. While there are policy engines that allow you to specify an CIDR or a DNS name, they are a less optimal choice when communicating with AWS services that have endpoints that reside within a VPC. In contrast, Kubernetes network policies provide a mechanism for controlling ingress and egress traffic both within and outside the cluster. Kubernetes network policies should be considered if your application has limited dependencies on other AWS services. You can configure may configure network policies that specify egress rules based on CIDR ranges to limit access to AWS services as opposed to AWS native semantics like SGs. You may use Kubernetes network policies to control network traffic between Pods (often referred to as East/West traffic) and between Pods and external services. Kubernetes network policies are implemented at OSI levels 3 and 4. Amazon EKS allows you to use network policy engines such as Calico and Cilium . By default, the network policy engines are not installed. Please check the respective install guides for instructions on how to set up. For more information on how to use network policy, see EKS Security best practices . The DNS hostnames feature is available in the enterprise versions of network policy engines, which could be useful for controlling traffic between Kubernetes Services/Pods and resources that run outside of AWS. Also, you can consider DNS hostname support for AWS services that don't support security groups by default.","title":"Use Security Groups per Pod to efficiently control traffic to AWS Services"},{"location":"networking/sgpp/#tag-a-single-security-group-to-use-aws-loadbalancer-controller","text":"When many security groups are allocated to a Pod, Amazon EKS recommends tagging a single security group with kubernetes.io/cluster/$name shared or owned. The tag allows the AWS Loadbalancer Controller to update the rules of security groups to route traffic to the Pods. If just one security group is given to a Pod, the assignment of a tag is optional. Permissions set in a security group are additive, therefore tagging a single security group is sufficient for the loadbalancer controller to locate and reconcile the rules. It also helps to adhere to the default quotas defined by security groups.","title":"Tag a single Security Group to use AWS Loadbalancer Controller"},{"location":"networking/sgpp/#configure-nat-for-outbound-traffic","text":"Source NAT is disabled for outbound traffic from Pods that are assigned security groups. For Pods using security groups that require access the internet launch worker nodes on private subnets configured with a NAT gateway or instance and enable external SNAT in the CNI. kubectl set env daemonset -n kube-system aws-node AWS_VPC_K8S_CNI_EXTERNALSNAT=true","title":"Configure NAT for Outbound Traffic"},{"location":"networking/sgpp/#deploy-pods-with-security-groups-to-private-subnets","text":"Pods that are assigned security groups must be run on nodes that are deployed on to private subnets. Note that Pods with assigned security groups deployed to public subnets will not able to access the internet.","title":"Deploy Pods with Security Groups to Private Subnets"},{"location":"networking/sgpp/#verify-terminationgraceperiodseconds-in-pod-specification-file","text":"Ensure that terminationGracePeriodSeconds is non-zero in your Pod specification file (default 30 seconds). This is essential in order for Amazon VPC CNI to delete the Pod network from the worker node. When set to zero, the CNI plugin does not remove the Pod network from the host, and the branch ENI is not effectively cleaned up.","title":"Verify terminationGracePeriodSeconds in Pod Specification File"},{"location":"networking/subnets/","text":"VPC and Subnet Considerations \u00b6 Operating an EKS cluster requires knowledge of AWS VPC networking, in addition to Kubernetes networking. We recommend you understand the EKS control plane communication mechanisms before you start designing your VPC or deploying clusters into existing VPCs. Refer to Cluster VPC considerations and Amazon EKS security group considerations when architecting a VPC and subnets to be used with EKS. Overview \u00b6 EKS Cluster Architecture \u00b6 An EKS cluster consists of two VPCs: An AWS-managed VPC that hosts the Kubernetes control plane. This VPC does not appear in the customer account. A customer-managed VPC that hosts the Kubernetes nodes. This is where containers run, as well as other customer-managed AWS infrastructure such as load balancers used by the cluster. This VPC appears in the customer account. You need to create customer-managed VPC prior creating a cluster. The eksctl creates a VPC if you do not provide one. The nodes in the customer VPC need the ability to connect to the managed API server endpoint in the AWS VPC. This allows the nodes to register with the Kubernetes control plane and receive requests to run application Pods. The nodes connect to the EKS control plane through (a) an EKS public endpoint or (b) a Cross-Account elastic network interfaces (X-ENI) managed by EKS. When a cluster is created, you need to specify at least two VPC subnets. EKS places a X-ENI in each subnet specified during cluster create (also called cluster subnets). The Kubernetes API server uses these Cross-Account ENIs to communicate with nodes deployed on the customer-managed cluster VPC subnets. As the node starts, the EKS bootstrap script is executed and Kubernetes node configuration files are installed. As part of the boot process on each instance, the container runtime agents, kubelet, and Kubernetes node agents are launched. To register a node, Kubelet contacts the Kubernetes cluster endpoint. It establishes a connection with either the public endpoint outside of the VPC or the private endpoint within the VPC. Kubelet receives API instructions and provides status updates and heartbeats to the endpoint on a regular basis. EKS Control Plane Communication \u00b6 EKS has two ways to control access to the cluster endpoint . Endpoint access control lets you choose whether the endpoint can be reached from the public internet or only through your VPC. You can turn on the public endpoint (which is the default), the private endpoint, or both at once. The configuration of the cluster API endpoint determines the path that nodes take to communicate to the control plane. Note that these endpoint settings can be changed at any time through the EKS console or API. Public Endpoint \u00b6 This is the default behavior for new Amazon EKS clusters. When only the public endpoint for the cluster is enabled, Kubernetes API requests that originate from within your cluster\u2019s VPC (such as worker node to control plane communication) leave the VPC, but not Amazon\u2019s network. In order for nodes to connect to the control plane, they must have a public IP address and a route to an internet gateway or a route to a NAT gateway where they can use the public IP address of the NAT gateway. Public and Private Endpoint \u00b6 When both the public and private endpoints are enabled, Kubernetes API requests from within the VPC communicate to the control plane via the X-ENIs within your VPC. Your cluster API server is accessible from the internet. Private Endpoint \u00b6 There is no public access to your API server from the internet when only private endpoint is enabled. All traffic to your cluster API server must come from within your cluster\u2019s VPC or a connected network. The nodes communicate to API server via X-ENIs within your VPC. Note that cluster management tools must have access to the private endpoint. Learn more about how to connect to a private Amazon EKS cluster endpoint from outside the Amazon VPC. Note that the cluster's API server endpoint is resolved by public DNS servers to a private IP address from the VPC. In the past, the endpoint could only be resolved from within the VPC. VPC configurations \u00b6 Amazon VPC supports IPv4 and IPv6 addressing. Amazon EKS supports IPv4 by default. A VPC must have an IPv4 CIDR block associated with it. You can optionally associate multiple IPv4 Classless Inter-Domain Routing CIDR blocks and multiple IPv6 CIDR blocks to your VPC. When you create a VPC, you must specify an IPv4 CIDR block for the VPC from the private IPv4 address ranges as specified in RFC 1918 . The allowed block size is between a /16 prefix (65,536 IP addresses) and /28 prefix (16 IP addresses). When creating a new VPC, you can attach a single IPv6 CIDR block, and up to five when changing an existing VPC. The prefix length of the CIDR block is fixed at /64 for IPv6 VPCs, defining a subnet with many more than one trillion IP addresses . You can request an IPv6 CIDR block from the pool of IPv6 addresses maintained by Amazon. Amazon EKS clusters support both IPv4 and IPv6. By default, EKS clusters are created using the IPv4 IP family. Specifying IPv6 address family enables the creation of IPv6 clusters. IPv6 clusters require dual-stack VPC and subnets. Amazon EKS recommends you at least two subnets that are in different Availability Zone during cluster create. The subnets you pass for cluster create are called cluster subnets. When you create a cluster, Amazon EKS creates up to 4 X-ENIs account in the subnets that you specify. The X-ENIs are always installed, and used for cluster administration traffic such as log delivery. Kubernetes control plane which runs in EKS managed account communicates to worker nodes via cross account ENIs for exec/logs functions. Please refer to the EKS user guide for complete VPC and subnet requirement details. Kubernetes worker nodes can run in the cluster subnets, but it is not recommended. You can create new subnets dedicated to run nodes and any Kubernetes resources. Nodes can run in either a public or a private subnet. Whether a subnet is public or private refers to whether traffic within the subnet is routed through an internet gateway . Public subnets have a route table entry to the internet through the internet gateway, but private subnets don't. The traffic that originates somewhere else and reaches your nodes is called ingress . Traffic that originates from the nodes and leaves the network is called egress . Nodes with public or elastic IP addresses within a subnet configured with an internet gateway allow ingress from outside of the VPC. Private subnets usually include a NAT gateway , which only allows ingress traffic to the nodes from within the VPC while still allowing traffic from the nodes to leave the VPC ( egress ). In the IPv6 world, every address is internet routable. The IPv6 addresses associated with the nodes and pods are public. Private subnets are supported by implementing an egress-only internet gateways (EIGW) in a VPC, allowing outbound traffic while blocking all incoming traffic. Best practices for implementing IPv6 subnets can be found in the VPC user guide . You can configure VPC and Subnets in three different ways: \u00b6 Using only public subnets \u00b6 In the same public subnets, both nodes and ingress resources (such as load balancers) are created. Tag the public subnet with kubernetes.io/role/elb to construct load balancers that face the internet. In this configuration, the cluster endpoint can be configured to be public, private, or both (public and private). Using private and public subnets \u00b6 Nodes are created on private subnets, whereas Ingress resources are instantiated in public subnets. You can enable public, private, or both (public and private) access to the cluster endpoint. Depending on the configuration of the cluster endpoint, node traffic will enter via the NAT gateway or the ENI. Using only private subnets \u00b6 Both nodes and ingress are created in private subnets. Using the kubernetes.io/role/internal-elb subnet tag to construct internal load balancers. Accessing your cluster's endpoint will require a VPN connection. You must activate AWS PrivateLink for EC2 and all Amazon ECR and S3 repositories. Only the private endpoint of the cluster should be enabled. We suggest going through the EKS private cluster requirements before provisioning private clusters. Communication across VPCs \u00b6 There are many scenarios when you require multiple VPCs and separate EKS clusters deployed to these VPCs. Multiple VPCs are needed when you have to support security, billing, multiple regions, or internal charge-back requirements. We recommend following the design patterns mentioned in the VPC-to-VPC connectivity guide to integrate multiple Amazon VPCs into a larger virtual network. VPC connectivity is best achieved when using non-overlapping IP ranges for each VPC being connected. For operational efficiency, we strongly recommend deploying EKS clusters and nodes to IP ranges that do not overlap. We suggest Private NAT Gateway , or VPC CNI in custom networking mode in conjunction with transit gateway to integrate workloads on EKS to solve overlapping CIDR challenges while preserving routable RFC1918 IP addresses. Consider utilizing AWS PrivateLink , also known as an endpoint service, if you are the service provider and would want to share your Kubernetes service and ingress (either ALB or NLB) with your customer VPC in separate accounts. Sharing VPC across multiple accounts \u00b6 Customers can share subnets with other AWS accounts inside the same AWS Organization via VPC sharing . Sharing a VPC is advised for larger organizations aiming to achieve separation of roles. VPC sharing is beneficial for a central networking team administering a centrally managed VPC, routing, and IP address allocation, while letting application owners to retain ownership over their own resources, accounts, and security groups. Consider VPC sharing to save costs by reusing NAT gateways, VPC interface endpoints, and intra-Availability Zone traffic. You may increase subnet density and prevent subnet fragmentation with VPC sharing. You can use VPC sharing with EKS clusters. We propose creating distinct subnets and EKS clusters for each application team. Please refer to this blog post to learn more about VPC sharing. Security Groups \u00b6 A security group controls the traffic that is allowed to reach and leave the resources that it is associated with. Amazon EKS uses security groups to manage the communication between the control plane and nodes . When you create a cluster, Amazon EKS creates a security group that's named eks-cluster-sg-my-cluster-uniqueID . EKS associates these security groups to the managed ENIs and the nodes. The default rules allow all traffic to flow freely between your cluster and nodes, and allows all outbound traffic to any destination. When you create a cluster, you can specify your own security groups. Please see recommendation for security groups when you specify own security groups. Recommendations \u00b6 Consider Multi-AZ Deployment \u00b6 AWS Regions provide multiple physically separated and isolated Availability Zones (AZ), which are connected with low-latency, high-throughput, and highly redundant networking. With Availability Zones, you can design and operate applications that automatically fail over between Availability Zones without interruption. Amazon EKS strongly recommends deploying EKS clusters to multiple availability zones. Please consider specifying subnets in at least two availability zones when you create the cluster. Kubelet running on nodes automatically adds labels to the node object such as topology.kubernetes.io/region=us-west-2 , and topology.kubernetes.io/zone=us-west-2d . We recommend to use node labels in conjunction with Pod topology spread constraints to control how Pods are spread across zones. These hints enable Kubernetes scheduler to place Pods for better expected availability, reducing the risk that a correlated failure affects your whole workload. Please refer Assigning nodes to Pods to see examples for node selector and AZ spread constraints. You can define the subnets or availability zones when you create nodes. The nodes are placed in cluster subnets if no subnets are configured. EKS support for managed node groups automatically spreads the nodes across multiple availability zones on available capacity. Karpenter will honor the AZ spread placement by scaling nodes to specified AZs if workloads define topology spread limits. AWS Elastic Load Balancers are managed by the AWS Load Balancer Controller for a Kubernetes cluster. It provisions an Application Load Balancer (ALB) for Kubernetes ingress resources and a Network Load Balancer (NLB) for Kubernetes services of type Loadbalancer. The Elastic Load Balancer controller uses tags to discover the subnets. ELB controller requires a minimum of two availability zones (AZs) to provision ingress resource successfully. Consider setting subnets in at least two AZs to take advantage of geographic redundancy's safety and reliability. Deploy Nodes to Private Subnets \u00b6 A VPC including both private and public subnets is the ideal method for deploying Kubernetes workloads on EKS. Consider setting a minimum of two public subnets and two private subnets in two distinct availability zones. The related route table of a public subnet contains a route to an internet gateway . Pods are able to interact with the Internet via a NAT gateway. Private subnets are supported by egress-only internet gateways in the IPv6 environment (EIGW). Instantiating nodes in private subnets offers maximal control over traffic to the nodes and is effective for the vast majority of Kubernetes applications. Ingress resources (like as load balancers) are instantiated in public subnets and route traffic to Pods operating on private subnets. Consider private only mode if you demand strict security and network isolation. In this configuration, three private subnets are deployed in distinct Availability Zones within the AWS Region's VPC. The resources deployed to the subnets cannot access the internet, nor can the internet access the resources in the subnets. In order for your Kubernetes application to access other AWS services, you must configure PrivateLink interfaces and/or gateway endpoints. You may setup internal load balancers to redirect traffic to Pods using AWS Load Balancer Controller. The private subnets must be tagged ( kubernetes.io/role/internal-elb: 1 ) for the controller to provision load balancers. For nodes to register with the cluster, the cluster endpoint must be set to private mode. Please visit private cluster guide for complete requirements and considerations. Consider Public and Private Mode for Cluster Endpoint \u00b6 Amazon EKS offers public-only, public-and-private, and private-only cluster endpoint modes. The default mode is public-only, however we recommend configuring cluster endpoint in public and private mode. This option allows Kubernetes API calls within your cluster's VPC (such as node-to-control-plane communication) to utilize the private VPC endpoint and traffic to remain within your cluster's VPC. Your cluster API server, on the other hand, can be reached from the internet. However, we strongly recommend limiting the CIDR blocks that can use the public endpoint. Learn how to configure public and private endpoint access, including limiting CIDR blocks. We suggest a private-only endpoint when you need security and network isolation. We recommend using either of the options listed in the EKS user guide to connect to an API server privately. Check available IPs \u00b6 When you create a cluster, Amazon EKS creates up to 4 elastic network interfaces in the cluster subnets. When you upgrade the cluster, Amazon EKS creates new X-ENIs and deletes the old ones when the upgrade is successful. Amazon EKS recommends a netmask of /28 (16 IP addresses) for cluster subnets to accommodate upgrades of the cluster. Before building VPC and subnets, it is advised to work backwards from the required workload scale. When clusters are built using \u201cekstcl\u201d, /19 subnets are created by default. A netmask of /19 is suitable for the majority of workload types. To learn about Pod IP allocations, refer Amazon VPC CNI . Consider using subnet-calc , a tool developed by EKS to help with subnet sizing. For IPv6 VPCs, a subnet's CIDR block has a fixed prefix length of /64 . We recommend to deploy nodes and workloads to cluster subnets to maximize IP usage. Configure Security Groups Carefully \u00b6 Amazon EKS supports using custom security groups. Any custom security groups must allow communication between nodes and the Kubernetes control plane. Please check port requirements and configure rules manually when your organization doesn't allow for open communication. EKS applies the custom security groups that you provide during cluster creation to the managed interfaces (X-ENIs). However, it does not immediately associate them with nodes. While creating node groups, it is strongly recommended to associate custom security groups manually. Please consider enabling securityGroupSelector to enable Karpenter node template discovery of custom security groups during autoscaling of nodes. We strongly recommend creating a security group to allow all inter-node communication traffic. During the bootstrap process, nodes require outbound Internet connectivity to access the cluster endpoint. Evaluate outward access requirements, such as on-premise connection and container registry access, and set rules appropriately. Before putting changes into production, we strongly suggest that you check connections carefully in your development environment. Deploy NAT Gateways in each Availability Zone \u00b6 If you deploy nodes in private subnets (IPv4 and IPv6), consider creating a NAT Gateway in each Availability Zone (AZ) to ensure zone-independent architecture and reduce cross AZ expenditures. Each NAT gateway in an AZ is implemented with redundancy. Use Cloud9 to access Private Clusters \u00b6 AWS Cloud9 is a web-based IDE than can run securely in Private Subnets without ingress access, using AWS Systems Manager. Egress can also be disabled on the Cloud9 instance. Learn more about using Cloud9 to access private clusters and subnets.","title":"VPC and Subnet Considerations"},{"location":"networking/subnets/#vpc-and-subnet-considerations","text":"Operating an EKS cluster requires knowledge of AWS VPC networking, in addition to Kubernetes networking. We recommend you understand the EKS control plane communication mechanisms before you start designing your VPC or deploying clusters into existing VPCs. Refer to Cluster VPC considerations and Amazon EKS security group considerations when architecting a VPC and subnets to be used with EKS.","title":"VPC and Subnet Considerations"},{"location":"networking/subnets/#overview","text":"","title":"Overview"},{"location":"networking/subnets/#eks-cluster-architecture","text":"An EKS cluster consists of two VPCs: An AWS-managed VPC that hosts the Kubernetes control plane. This VPC does not appear in the customer account. A customer-managed VPC that hosts the Kubernetes nodes. This is where containers run, as well as other customer-managed AWS infrastructure such as load balancers used by the cluster. This VPC appears in the customer account. You need to create customer-managed VPC prior creating a cluster. The eksctl creates a VPC if you do not provide one. The nodes in the customer VPC need the ability to connect to the managed API server endpoint in the AWS VPC. This allows the nodes to register with the Kubernetes control plane and receive requests to run application Pods. The nodes connect to the EKS control plane through (a) an EKS public endpoint or (b) a Cross-Account elastic network interfaces (X-ENI) managed by EKS. When a cluster is created, you need to specify at least two VPC subnets. EKS places a X-ENI in each subnet specified during cluster create (also called cluster subnets). The Kubernetes API server uses these Cross-Account ENIs to communicate with nodes deployed on the customer-managed cluster VPC subnets. As the node starts, the EKS bootstrap script is executed and Kubernetes node configuration files are installed. As part of the boot process on each instance, the container runtime agents, kubelet, and Kubernetes node agents are launched. To register a node, Kubelet contacts the Kubernetes cluster endpoint. It establishes a connection with either the public endpoint outside of the VPC or the private endpoint within the VPC. Kubelet receives API instructions and provides status updates and heartbeats to the endpoint on a regular basis.","title":"EKS Cluster Architecture"},{"location":"networking/subnets/#eks-control-plane-communication","text":"EKS has two ways to control access to the cluster endpoint . Endpoint access control lets you choose whether the endpoint can be reached from the public internet or only through your VPC. You can turn on the public endpoint (which is the default), the private endpoint, or both at once. The configuration of the cluster API endpoint determines the path that nodes take to communicate to the control plane. Note that these endpoint settings can be changed at any time through the EKS console or API.","title":"EKS Control Plane Communication"},{"location":"networking/subnets/#public-endpoint","text":"This is the default behavior for new Amazon EKS clusters. When only the public endpoint for the cluster is enabled, Kubernetes API requests that originate from within your cluster\u2019s VPC (such as worker node to control plane communication) leave the VPC, but not Amazon\u2019s network. In order for nodes to connect to the control plane, they must have a public IP address and a route to an internet gateway or a route to a NAT gateway where they can use the public IP address of the NAT gateway.","title":"Public Endpoint"},{"location":"networking/subnets/#public-and-private-endpoint","text":"When both the public and private endpoints are enabled, Kubernetes API requests from within the VPC communicate to the control plane via the X-ENIs within your VPC. Your cluster API server is accessible from the internet.","title":"Public and Private Endpoint"},{"location":"networking/subnets/#private-endpoint","text":"There is no public access to your API server from the internet when only private endpoint is enabled. All traffic to your cluster API server must come from within your cluster\u2019s VPC or a connected network. The nodes communicate to API server via X-ENIs within your VPC. Note that cluster management tools must have access to the private endpoint. Learn more about how to connect to a private Amazon EKS cluster endpoint from outside the Amazon VPC. Note that the cluster's API server endpoint is resolved by public DNS servers to a private IP address from the VPC. In the past, the endpoint could only be resolved from within the VPC.","title":"Private Endpoint"},{"location":"networking/subnets/#vpc-configurations","text":"Amazon VPC supports IPv4 and IPv6 addressing. Amazon EKS supports IPv4 by default. A VPC must have an IPv4 CIDR block associated with it. You can optionally associate multiple IPv4 Classless Inter-Domain Routing CIDR blocks and multiple IPv6 CIDR blocks to your VPC. When you create a VPC, you must specify an IPv4 CIDR block for the VPC from the private IPv4 address ranges as specified in RFC 1918 . The allowed block size is between a /16 prefix (65,536 IP addresses) and /28 prefix (16 IP addresses). When creating a new VPC, you can attach a single IPv6 CIDR block, and up to five when changing an existing VPC. The prefix length of the CIDR block is fixed at /64 for IPv6 VPCs, defining a subnet with many more than one trillion IP addresses . You can request an IPv6 CIDR block from the pool of IPv6 addresses maintained by Amazon. Amazon EKS clusters support both IPv4 and IPv6. By default, EKS clusters are created using the IPv4 IP family. Specifying IPv6 address family enables the creation of IPv6 clusters. IPv6 clusters require dual-stack VPC and subnets. Amazon EKS recommends you at least two subnets that are in different Availability Zone during cluster create. The subnets you pass for cluster create are called cluster subnets. When you create a cluster, Amazon EKS creates up to 4 X-ENIs account in the subnets that you specify. The X-ENIs are always installed, and used for cluster administration traffic such as log delivery. Kubernetes control plane which runs in EKS managed account communicates to worker nodes via cross account ENIs for exec/logs functions. Please refer to the EKS user guide for complete VPC and subnet requirement details. Kubernetes worker nodes can run in the cluster subnets, but it is not recommended. You can create new subnets dedicated to run nodes and any Kubernetes resources. Nodes can run in either a public or a private subnet. Whether a subnet is public or private refers to whether traffic within the subnet is routed through an internet gateway . Public subnets have a route table entry to the internet through the internet gateway, but private subnets don't. The traffic that originates somewhere else and reaches your nodes is called ingress . Traffic that originates from the nodes and leaves the network is called egress . Nodes with public or elastic IP addresses within a subnet configured with an internet gateway allow ingress from outside of the VPC. Private subnets usually include a NAT gateway , which only allows ingress traffic to the nodes from within the VPC while still allowing traffic from the nodes to leave the VPC ( egress ). In the IPv6 world, every address is internet routable. The IPv6 addresses associated with the nodes and pods are public. Private subnets are supported by implementing an egress-only internet gateways (EIGW) in a VPC, allowing outbound traffic while blocking all incoming traffic. Best practices for implementing IPv6 subnets can be found in the VPC user guide .","title":"VPC configurations"},{"location":"networking/subnets/#you-can-configure-vpc-and-subnets-in-three-different-ways","text":"","title":"You can configure VPC and Subnets in three different ways:"},{"location":"networking/subnets/#using-only-public-subnets","text":"In the same public subnets, both nodes and ingress resources (such as load balancers) are created. Tag the public subnet with kubernetes.io/role/elb to construct load balancers that face the internet. In this configuration, the cluster endpoint can be configured to be public, private, or both (public and private).","title":"Using only public subnets"},{"location":"networking/subnets/#using-private-and-public-subnets","text":"Nodes are created on private subnets, whereas Ingress resources are instantiated in public subnets. You can enable public, private, or both (public and private) access to the cluster endpoint. Depending on the configuration of the cluster endpoint, node traffic will enter via the NAT gateway or the ENI.","title":"Using private and public subnets"},{"location":"networking/subnets/#using-only-private-subnets","text":"Both nodes and ingress are created in private subnets. Using the kubernetes.io/role/internal-elb subnet tag to construct internal load balancers. Accessing your cluster's endpoint will require a VPN connection. You must activate AWS PrivateLink for EC2 and all Amazon ECR and S3 repositories. Only the private endpoint of the cluster should be enabled. We suggest going through the EKS private cluster requirements before provisioning private clusters.","title":"Using only private subnets"},{"location":"networking/subnets/#communication-across-vpcs","text":"There are many scenarios when you require multiple VPCs and separate EKS clusters deployed to these VPCs. Multiple VPCs are needed when you have to support security, billing, multiple regions, or internal charge-back requirements. We recommend following the design patterns mentioned in the VPC-to-VPC connectivity guide to integrate multiple Amazon VPCs into a larger virtual network. VPC connectivity is best achieved when using non-overlapping IP ranges for each VPC being connected. For operational efficiency, we strongly recommend deploying EKS clusters and nodes to IP ranges that do not overlap. We suggest Private NAT Gateway , or VPC CNI in custom networking mode in conjunction with transit gateway to integrate workloads on EKS to solve overlapping CIDR challenges while preserving routable RFC1918 IP addresses. Consider utilizing AWS PrivateLink , also known as an endpoint service, if you are the service provider and would want to share your Kubernetes service and ingress (either ALB or NLB) with your customer VPC in separate accounts.","title":"Communication across VPCs"},{"location":"networking/subnets/#sharing-vpc-across-multiple-accounts","text":"Customers can share subnets with other AWS accounts inside the same AWS Organization via VPC sharing . Sharing a VPC is advised for larger organizations aiming to achieve separation of roles. VPC sharing is beneficial for a central networking team administering a centrally managed VPC, routing, and IP address allocation, while letting application owners to retain ownership over their own resources, accounts, and security groups. Consider VPC sharing to save costs by reusing NAT gateways, VPC interface endpoints, and intra-Availability Zone traffic. You may increase subnet density and prevent subnet fragmentation with VPC sharing. You can use VPC sharing with EKS clusters. We propose creating distinct subnets and EKS clusters for each application team. Please refer to this blog post to learn more about VPC sharing.","title":"Sharing VPC across multiple accounts"},{"location":"networking/subnets/#security-groups","text":"A security group controls the traffic that is allowed to reach and leave the resources that it is associated with. Amazon EKS uses security groups to manage the communication between the control plane and nodes . When you create a cluster, Amazon EKS creates a security group that's named eks-cluster-sg-my-cluster-uniqueID . EKS associates these security groups to the managed ENIs and the nodes. The default rules allow all traffic to flow freely between your cluster and nodes, and allows all outbound traffic to any destination. When you create a cluster, you can specify your own security groups. Please see recommendation for security groups when you specify own security groups.","title":"Security Groups"},{"location":"networking/subnets/#recommendations","text":"","title":"Recommendations"},{"location":"networking/subnets/#consider-multi-az-deployment","text":"AWS Regions provide multiple physically separated and isolated Availability Zones (AZ), which are connected with low-latency, high-throughput, and highly redundant networking. With Availability Zones, you can design and operate applications that automatically fail over between Availability Zones without interruption. Amazon EKS strongly recommends deploying EKS clusters to multiple availability zones. Please consider specifying subnets in at least two availability zones when you create the cluster. Kubelet running on nodes automatically adds labels to the node object such as topology.kubernetes.io/region=us-west-2 , and topology.kubernetes.io/zone=us-west-2d . We recommend to use node labels in conjunction with Pod topology spread constraints to control how Pods are spread across zones. These hints enable Kubernetes scheduler to place Pods for better expected availability, reducing the risk that a correlated failure affects your whole workload. Please refer Assigning nodes to Pods to see examples for node selector and AZ spread constraints. You can define the subnets or availability zones when you create nodes. The nodes are placed in cluster subnets if no subnets are configured. EKS support for managed node groups automatically spreads the nodes across multiple availability zones on available capacity. Karpenter will honor the AZ spread placement by scaling nodes to specified AZs if workloads define topology spread limits. AWS Elastic Load Balancers are managed by the AWS Load Balancer Controller for a Kubernetes cluster. It provisions an Application Load Balancer (ALB) for Kubernetes ingress resources and a Network Load Balancer (NLB) for Kubernetes services of type Loadbalancer. The Elastic Load Balancer controller uses tags to discover the subnets. ELB controller requires a minimum of two availability zones (AZs) to provision ingress resource successfully. Consider setting subnets in at least two AZs to take advantage of geographic redundancy's safety and reliability.","title":"Consider Multi-AZ  Deployment"},{"location":"networking/subnets/#deploy-nodes-to-private-subnets","text":"A VPC including both private and public subnets is the ideal method for deploying Kubernetes workloads on EKS. Consider setting a minimum of two public subnets and two private subnets in two distinct availability zones. The related route table of a public subnet contains a route to an internet gateway . Pods are able to interact with the Internet via a NAT gateway. Private subnets are supported by egress-only internet gateways in the IPv6 environment (EIGW). Instantiating nodes in private subnets offers maximal control over traffic to the nodes and is effective for the vast majority of Kubernetes applications. Ingress resources (like as load balancers) are instantiated in public subnets and route traffic to Pods operating on private subnets. Consider private only mode if you demand strict security and network isolation. In this configuration, three private subnets are deployed in distinct Availability Zones within the AWS Region's VPC. The resources deployed to the subnets cannot access the internet, nor can the internet access the resources in the subnets. In order for your Kubernetes application to access other AWS services, you must configure PrivateLink interfaces and/or gateway endpoints. You may setup internal load balancers to redirect traffic to Pods using AWS Load Balancer Controller. The private subnets must be tagged ( kubernetes.io/role/internal-elb: 1 ) for the controller to provision load balancers. For nodes to register with the cluster, the cluster endpoint must be set to private mode. Please visit private cluster guide for complete requirements and considerations.","title":"Deploy Nodes to Private Subnets"},{"location":"networking/subnets/#consider-public-and-private-mode-for-cluster-endpoint","text":"Amazon EKS offers public-only, public-and-private, and private-only cluster endpoint modes. The default mode is public-only, however we recommend configuring cluster endpoint in public and private mode. This option allows Kubernetes API calls within your cluster's VPC (such as node-to-control-plane communication) to utilize the private VPC endpoint and traffic to remain within your cluster's VPC. Your cluster API server, on the other hand, can be reached from the internet. However, we strongly recommend limiting the CIDR blocks that can use the public endpoint. Learn how to configure public and private endpoint access, including limiting CIDR blocks. We suggest a private-only endpoint when you need security and network isolation. We recommend using either of the options listed in the EKS user guide to connect to an API server privately.","title":"Consider Public and Private Mode for Cluster Endpoint"},{"location":"networking/subnets/#check-available-ips","text":"When you create a cluster, Amazon EKS creates up to 4 elastic network interfaces in the cluster subnets. When you upgrade the cluster, Amazon EKS creates new X-ENIs and deletes the old ones when the upgrade is successful. Amazon EKS recommends a netmask of /28 (16 IP addresses) for cluster subnets to accommodate upgrades of the cluster. Before building VPC and subnets, it is advised to work backwards from the required workload scale. When clusters are built using \u201cekstcl\u201d, /19 subnets are created by default. A netmask of /19 is suitable for the majority of workload types. To learn about Pod IP allocations, refer Amazon VPC CNI . Consider using subnet-calc , a tool developed by EKS to help with subnet sizing. For IPv6 VPCs, a subnet's CIDR block has a fixed prefix length of /64 . We recommend to deploy nodes and workloads to cluster subnets to maximize IP usage.","title":"Check available IPs"},{"location":"networking/subnets/#configure-security-groups-carefully","text":"Amazon EKS supports using custom security groups. Any custom security groups must allow communication between nodes and the Kubernetes control plane. Please check port requirements and configure rules manually when your organization doesn't allow for open communication. EKS applies the custom security groups that you provide during cluster creation to the managed interfaces (X-ENIs). However, it does not immediately associate them with nodes. While creating node groups, it is strongly recommended to associate custom security groups manually. Please consider enabling securityGroupSelector to enable Karpenter node template discovery of custom security groups during autoscaling of nodes. We strongly recommend creating a security group to allow all inter-node communication traffic. During the bootstrap process, nodes require outbound Internet connectivity to access the cluster endpoint. Evaluate outward access requirements, such as on-premise connection and container registry access, and set rules appropriately. Before putting changes into production, we strongly suggest that you check connections carefully in your development environment.","title":"Configure Security Groups Carefully"},{"location":"networking/subnets/#deploy-nat-gateways-in-each-availability-zone","text":"If you deploy nodes in private subnets (IPv4 and IPv6), consider creating a NAT Gateway in each Availability Zone (AZ) to ensure zone-independent architecture and reduce cross AZ expenditures. Each NAT gateway in an AZ is implemented with redundancy.","title":"Deploy NAT Gateways in each Availability Zone"},{"location":"networking/subnets/#use-cloud9-to-access-private-clusters","text":"AWS Cloud9 is a web-based IDE than can run securely in Private Subnets without ingress access, using AWS Systems Manager. Egress can also be disabled on the Cloud9 instance. Learn more about using Cloud9 to access private clusters and subnets.","title":"Use Cloud9 to access Private Clusters"},{"location":"networking/vpc-cni/","text":"Amazon VPC CNI \u00b6 Amazon EKS implements cluster networking through the Amazon VPC Container Network Interface (VPC CNI) plugin. The CNI plugin allows Kubernetes Pods to have the same IP address as they do on the VPC network. More specifically, all containers inside the Pod share a network namespace, and they can communicate with each-other using local ports. Amazon VPC CNI has two components: CNI Binary, which will setup Pod network to enable Pod-to-Pod communication. The CNI binary runs on a node root file system and is invoked by the kubelet when a new Pod gets added to, or an existing Pod removed from the node. ipamd, a long-running node-local IP Address Management (IPAM) daemon and is responsible for: managing ENIs on a node, and maintaining a warm-pool of available IP addresses or prefix When an instance is created, EC2 creates and attaches a primary ENI associated with a primary subnet. The primary subnet may be public or private. The Pods that run in hostNetwork mode use the primary IP address assigned to the node primary ENI and share the same network namespace as the host. The CNI plugin manages Elastic Network Interfaces (ENI) on the node. When a node is provisioned, the CNI plugin automatically allocates a pool of slots (IPs or Prefix\u2019s) from the node\u2019s subnet to the primary ENI. This pool is known as the warm pool , and its size is determined by the node\u2019s instance type. Depending on CNI settings, a slot may be an IP address or a prefix. When a slot on an ENI has been assigned, the CNI may attach additional ENIs with warm pool of slots to the nodes. These additional ENIs are called Secondary ENIs. Each ENI can only support a certain number of slots, based on instance type. The CNI attaches more ENIs to instances based on the number of slots needed, which usually corresponds to the number of Pods. This process continues until the node can no longer support additional ENI. The CNI also pre-allocates \u201cwarm\u201d ENIs and slots for faster Pod startup. Note each instance type has a maximum number of ENIs that may be attached. This is one constraint on Pod density (number of Pods per node), in addition to compute resources. The maximum number of network interfaces, and the maximum number of slots that you can use varies by the type of EC2 Instance. Since each Pod consumes an IP address on a slot, the number of Pods you can run on a particular EC2 Instance depends on how many ENIs can be attached to it and how many slots each ENI supports. We suggest setting the maximum Pods per EKS user guide to avoid exhaustion of the instance\u2019s CPU and memory resources. Pods using hostNetwork are excluded from this calculation. You may consider using a script called max-pod-calculator.sh to calculate EKS\u2019s recommended maximum Pods for a given instance type. Overview \u00b6 Secondary IP mode is the default mode for VPC CNI. This guide provides a generic overview of VPC CNI behavior when Secondary IP mode is enabled. The functionality of ipamd (allocation of IP addresses) may vary depending on the configuration settings for VPC CNI, such as Prefix Mode , Security Groups Per Pod , and Custom Networking . The Amazon VPC CNI is deployed as a Kubernetes Daemonset named aws-node on worker nodes. When a worker node is provisioned, it has a default ENI, called the primary ENI, attached to it. The CNI allocates a warm pool of ENIs and secondary IP addresses from the subnet attached to the node\u2019s primary ENI. By default, ipamd attempts to allocate an additional ENI to the node. The IPAMD allocates additional ENI when a single Pod is scheduled and assigned a secondary IP address from the primary ENI. This \"warm\" ENI enables faster Pod networking. As the pool of secondary IP addresses runs out, the CNI adds another ENI to assign more. The number of ENIs and IP addresses in a pool are configured through environment variables called WARM_ENI_TARGET, WARM_IP_TARGET, MINIMUM_IP_TARGET . The aws-node Daemonset will periodically check that a sufficient number of ENIs are attached. A sufficient number of ENIs are attached when all of the WARM_ENI_TARGET , or WARM_IP_TARGET and MINIMUM_IP_TARGET conditions are met. If there are insufficient ENIs attached, the CNI will make an API call to EC2 to attach more until MAX_ENI limit is reached. WARM_ENI_TARGET - Integer, Values >0 indicate requirement Enabled The number of Warm ENIs to be maintained. An ENI is \u201cwarm\u201d when it is attached as a secondary ENI to a node, but it is not in use by any Pod. More specifically, no IP addresses of the ENI have been associated with a Pod. Example: Consider an instance with 2 ENIs, each ENI supporting 5 IP addresses. WARM_ENI_TARGET is set to 1. If exactly 5 IP addresses are associated with the instance, the CNI maintains 2 ENIs attached to the instance. The first ENI is in use, and all 5 possible IP addresses of this ENI are used. The second ENI is \u201cwarm\u201d with all 5 IP addresses in pool. If another Pod is launched on the instance, a 6th IP address will be needed. The CNI will assign this 6th Pod an IP address from the second ENI and from 5 IPs from the pool. The second ENI is now in use, and no longer in a \u201cwarm\u201d status. The CNI will allocate a 3rd ENI to maintain at least 1 warm ENI. Note The warm ENIs still consume IP addresses from the CIDR of your VPC. IP addresses are \u201cunused\u201d or \u201cwarm\u201d until they are associated with a workload, such as a Pod. WARM_IP_TARGET , Integer, Values >0 indicate requirement Enabled The number of Warm IP addresses to be maintained. A Warm IP is available on an actively attached ENI, but has not been assigned to a Pod. In other words, the number of Warm IPs available is the number of IPs that may be assigned to a Pod without requiring an additional ENI. Example: Consider an instance with 1 ENI, each ENI supporting 20 IP addresses. WARM_IP_TARGET is set to 5. WARM_ENI_TARGET is set to 0. Only 1 ENI will be attached until a 16th IP address is needed. Then, the CNI will attach a second ENI, consuming 20 possible addresses from the subnet CIDR. MINIMUM_IP_TARGET , Integer, Values >0 indicate requirement Enabled The minimum number of IP addresses to be allocated at any time. This is commonly used to front-load the assignment of multiple ENIs at instance launch. Example: Consider a newly launched instance. It has 1 ENI and each ENI supports 10 IP addresses. MINIMUM_IP_TARGET is set to 100. The ENI immediately attaches 9 more ENIs for a total of 100 addresses. This happens regardless of any WARM_IP_TARGET or WARM_ENI_TARGET values. When Kubelet receives an add Pod request, the CNI binary queries ipamd for an available IP address, which ipamd then provides to the Pod. The CNI binary wires up the host and Pod network. Pods deployed on a node are, by default, assigned to the same security groups as the primary ENI. Alternatively, Pods may be configured with different security groups. As the pool of IP addresses is depleted, the plugin automatically attaches another elastic network interface to the instance and allocates another set of secondary IP addresses to that interface. This process continues until the node can no longer support additional elastic network interfaces. When a Pod is deleted, VPC CNI places the Pod\u2019s IP address in a 30-second cool down cache. The IPs in a cool down cache are not assigned to new Pods. When the cooling-off period is over, VPC CNI moves Pod IP back to the warm pool. The cooling-off period prevents Pod IP addresses from being recycled prematurely and allows kube-proxy on all cluster nodes to finish updating the iptables rules. When the number of IPs or ENIs exceeds the number of warm pool settings, the ipamd plugin returns IPs and ENIs to the VPC. As described above in Secondary IP mode, each Pod receives one secondary private IP address from one of the ENIs attached to an instance. Since each Pod uses an IP address, the number of Pods you can run on a particular EC2 Instance depends on how many ENIs can be attached to it and how many IP addresses it supports. The VPC CNI checks the limits file to find out how many ENIs and IP addresses are allowed for each type of instance. You can use the following formula to determine maximum number of Pods you can deploy on a node. (Number of network interfaces for the instance type \u00d7 (the number of IP addresses per network interface - 1)) + 2 The +2 indicates Pods that require host networking, such as kube-proxy and VPC CNI. Amazon EKS requires kube-proxy and VPC CNI to be operating on each node, and these requirements are factored into the max-pods value. If you want to run additional host networking pods, consider updating the max-pods value. The +2 indicates Kubernetes Pods that use host networking, such as kube-proxy and VPC CNI. Amazon EKS requires kube-proxy and VPC CNI to be running on every node and are calculated towards max-pods. Consider updating max-pods if you plan to run more host networking Pods. You can specify --kubelet-extra-args \"\u2014max-pods=110\" as user data in the launch template. As an example, on a cluster with 3 c5.large nodes (3 ENIs and max 10 IPs per ENI), when the cluster starts up and has 2 CoreDNS pods, the CNI will consume 49 IP addresses and keeps them in warm pool. The warm pool enables faster Pod launches when the application is deployed. Node 1 (with CoreDNS pod): 2 ENIs, 20 IPs assigned Node 2 (with CoreDNS pod): 2 ENIs, 20 IPs assigned Node 3 (no Pod): 1 ENI. 10 IPs assigned. Keep in mind that infrastructure pods, often running as daemon sets, each contribute to the max-pod count. These can include: CoreDNS Amazon Elastic LoadBalancer Operational pods for metrics-server We suggest that you plan your infrastructure by combining these Pods' capacities. For a list of the maximum number of Pods supported by each instance type, see eni-max-Pods.txt on GitHub. Recommendations \u00b6 Use Secondary IP Mode when \u00b6 Secondary IP mode is an ideal configuration option for ephemeral EKS clusters. Greenfield customers who are either new to EKS or in the process of migrating can take advantage of VPC CNI in secondary mode. Avoid Secondary IP Mode when \u00b6 If you are experiencing Pod density issues, we suggest enabling prefix mode. If you are facing IPv4 depletion issues, we advise migrating to IPv6 clusters. If IPv6 is not on the horizon, you may choose to use custom networking. Deploy VPC CNI Managed Add-On \u00b6 When you provision a cluster, Amazon EKS installs VPC CNI automatically. Amazon EKS nevertheless supports managed add-ons that enable the cluster to interact with underlying AWS resources such as computing, storage, and networking. We highly recommend that you deploy clusters with managed add-ons including VPC CNI. Amazon EKS managed add-on offer VPC CNI installation and management for Amazon EKS clusters. Amazon EKS add-ons include the latest security patches, bug fixes, and are validated by AWS to work with Amazon EKS. The VPC CNI add-on enables you to continuously ensure the security and stability of your Amazon EKS clusters and decrease the amount of effort required to install, configure, and update add-ons. Additionally, a managed add-on can be added, updated, or deleted via the Amazon EKS API, AWS Management Console, AWS CLI, and eksctl. You can find the managed fields of VPC CNI using --show-managed-fields flag with the kubectl get command. kubectl get daemonset aws - node -- show - managed - fields - n kube - system - o yaml Managed add-ons prevents configuration drift by automatically overwriting configurations every 15 minutes. This means that any changes to managed add-ons, made via the Kubernetes API after add-on creation, will overwrite by the automated drift-prevention process and also set to defaults during add-on update process. The fields managed by EKS are listed under managedFields with manager as EKS. Fields managed by EKS include service account, image, image url, liveness probe, readiness probe, labels, volumes, and volume mounts. Info The most frequently used fields such as WARM_ENI_TARGET, WARM_IP_TARGET, and MINIMUM_IP_TARGET are not managed and will not be reconciled. The changes to these fields will be preserved upon updating of the add-on. We suggest testing the add-on behavior in your non-production clusters for a specific configuration before updating production clusters. Additionally, follow the steps in the EKS user guide for add-on configurations. Migrate to Managed Add-On \u00b6 You will manage the version compatibility and update the security patches of self-managed VPC CNI. To update a self-managed add-on, you must use the Kubernetes APIs and instructions outlined in the EKS user guide . We recommend migrating to a managed add-on for existing EKS clusters and highly suggest creating a backup of your current CNI settings prior to migration. To configure managed add-ons, you can utilize the Amazon EKS API, AWS Management Console, or AWS Command Line Interface. kubectl apply view-last-applied daemonset aws-node -n kube-system > aws-k8s-cni-old.yaml Amazon EKS will replace the CNI configuration settings if the field is listed as managed with default settings. We caution against modifying the managed fields. The add-on does not reconcile configuration fields such as the warm environment variables and CNI modes. The Pods and applications will continue to run while you migrate to a managed CNI. Backup CNI Settings Before Update \u00b6 VPC CNI runs on customer data plane (nodes), and hence Amazon EKS does not automatically update the add-on (managed and self-managed) when new versions are released or after you update your cluster to a new Kubernetes minor version. To update the add-on for an existing cluster, you must trigger an update via update-addon API or clicking update now link in the EKS console for add-ons. If you have deployed self-managed add-on, follow steps mentioned under updating self-managed VPC CNI add-on. We strongly recommend that you update one minor version at a time. For example, if your current minor version is 1.9 and you want to update to 1.11 , you should update to the latest patch version of 1.10 first, then update to the latest patch version of 1.11 . Perform an inspection of the aws-node Daemonset before updating Amazon VPC CNI. Take a backup of existing settings. If using a managed add-on, confirm that you have not updated any settings that Amazon EKS might override. We recommend a post update hook in your automation workflow or a manual apply step after an add-on update. kubectl apply view-last-applied daemonset aws-node -n kube-system > aws-k8s-cni-old.yaml For a self-managed add-on, compare the backup with releases on GitHub to see the available versions and familiarize yourself with the changes in the version that you want to update to. We recommend using Helm to manage self-managed add-ons and leverage values files to apply settings. Any update operations involving Daemonset delete will result in application downtime and must be avoided. Understand Security Context \u00b6 We strongly suggest you to understand the security contexts configured for managing VPC CNI efficiently. Amazon VPC CNI has two components CNI binary and ipamd (aws-node) Daemonset. The CNI runs as a binary on a node and has access to node root file system, also has privileged access as it deals with iptables at the node level. The CNI binary is invoked by the kubelet when Pods gets added or removed. The aws-node Daemonset is a long-running process responsible for IP address management at the node level. The aws-node runs in hostNetwork mode and allows access to the loopback device, and network activity of other pods on the same node. The aws-node init-container runs in privileged mode and mounts the CRI socket allowing the Daemonset to monitor IP usage by the Pods running on the node. Amazon EKS is working to remove the privileged requirement of aws-node init container. Additionally, the aws-node needs to update NAT entries and to load the iptables modules and hence runs with NET_ADMIN privileges. Amazon EKS recommends deploying the security policies as defined by the aws-node manifest for IP management for the Pods and networking settings. Please consider updating to the latest version of VPC CNI. Furthermore, please consider opening a GitHub issue if you have a specific security requirement. Use separate IAM role for CNI \u00b6 The AWS VPC CNI requires AWS Identity and Access Management (IAM) permissions. The CNI policy needs to be set up before the IAM role can be used. You can use AmazonEKS_CNI_Policy , which is an AWS managed policy for IPv4 clusters. AmazonEKS CNI managed policy only has permissions for IPv4 clusters. You must create a separate IAM policy for IPv6 clusters with the permissions listed here . By default, VPC CNI inherits the Amazon EKS node IAM role (both managed and self-managed node groups). Configuring a separate IAM role with the relevant policies for Amazon VPC CNI is strongly recommended. If not, the pods of Amazon VPC CNI gets the permission assigned to the node IAM role and have access to the instance profile assigned to the node. The VPC CNI plugin creates and configures a service account called aws-node. By default, the service account binds to the Amazon EKS node IAM role with Amazon EKS CNI policy attached. To use the separate IAM role, we recommend that you create a new service account with Amazon EKS CNI policy attached. To use a new service account you must redeploy the CNI pods . Consider specifying a --service-account-role-arn for VPC CNI managed add-on when creating new clusters. Make sure you remove Amazon EKS CNI policy for both IPv4 and IPv6 from Amazon EKS node role. It is advised that you block access instance metadata to minimize the blast radius of security breach. Handle Liveness/Readiness Probe failures \u00b6 We advise increasing the liveness and readiness probe timeout values (default timeoutSeconds: 10 ) for EKS 1.20 an later clusters to prevent probe failures from causing your application's Pod to become stuck in a containerCreating state. This problem has been seen in data-intensive and batch-processing clusters. High CPU use causes aws-node probe health failures, leading to unfulfilled Pod CPU requests. In addition to modifying the probe timeout, ensure that the CPU resource requests (default CPU: 25m ) for aws-node are correctly configured. We do not suggest updating the settings unless your node is having issues. We highly encourage you to run sudo bash /opt/cni/bin/aws-cni-support.sh on a node while you engage Amazon EKS support. The script will assist in evaluating kubelet logs and memory utilization on the node. Please consider installing SSM Agent on Amazon EKS worker nodes to run the script. Monitor IP Address Inventory \u00b6 You can monitor the IP addresses inventory of subnets using CNI Metrics Helper . maximum number of ENIs the cluster can support number of ENIs already allocated number of IP addresses currently assigned to Pods total and maximum number of IP address available You can also set CloudWatch alarms to get notified if a subnet is running out of IP addresses. Please visit EKS user guide for install instructions of CNI metrics helper . Make sure DISABLE_METRICS variable for VPC CNI is set to false. Plan for Growth \u00b6 We strongly recommend to size your subnets for growth. Right sizing the subnets will prevent your subnets from running out of IP addresses as your Pods and nodes scale. You will not be able to create new Pods or nodes if the subnets don\u2019t have enough available IP addresses. If you need to limit the IP addresses the CNI caches, then you can use warm pool CNI environment variables. If subnets in your VPC run out of available IP addresses, we suggest creating a new subnet using the VPC\u2019s original CIDR blocks. Use the sample EKS Subnet Calculator spreadsheet to plan your network. The spreadsheet calculates IP usage based on workloads and VPC ENI configuration. The IP usage is compared to an IPv4 subnet to determine if the configuration and subnet size is sufficient for your workload. Configure IP and ENI Target values in address constrained environments. \u00b6 Warning Improving your VPC design is the recommended response to IP address exhaustion. Consider solutions like IPv6 and Secondary CIDRs. Adjusting these values to minimize the number of Warm IPs should be a temporary solution after other options are excluded. Misconfiguring these values may interfere with cluster operation. In the default configuration, VPC CNI keeps an entire ENI (and associated IPs) in the warm pool. This may consume a large number of IPs, especially on larger instance types. If your cluster subnet has a limited number of free IP addresses, scrutinize these VPC CNI configuration environment variables: WARM_IP_TARGET MINIMUM_IP_TARGET WARM_ENI_TARGET Configure the value of MINIMUM_IP_TARGET to closely match the number of Pods you expect to run on your nodes. Doing so will ensure that as Pods get created, and the CNI can assign IP addresses from the warm pool without calling the EC2 API. Avoid setting the value of WARM_IP_TARGET too low as it will cause additional calls to the EC2 API, and that might cause throttling of the requests. For large clusters use along with MINIMUM_IP_TARGET to avoid throttling of the requests. To configure these options, download aws-k8s-cni.yaml and set the environment variables. At the time of writing, the latest release is located here . Check the version of the configuration value matches the installed VPC CNI version. Warning The warm settings will be reset to defaults when you update the CNI. Please take a backup of the CNI, before you update the CNI. Review the configuration settings to determine if you need to reapply them after update is successful. Configure Warm ENI value for Batch Workloads \u00b6 We recommend updating the default WARM_ENI_TARGET to match the Pod scale needs for batch workloads. Setting WARM_ENI_TARGET to a high value always maintains the warm IP pool required to run large batch workloads and hence avoid data processing delays. Configure IPTables Forward Policy on non-EKS Optimized AMI Instances \u00b6 If you are using custom AMI, make sure to set iptables forward policy to ACCEPT under kubelet.service . Many systems set the iptables forward policy to DROP. You can build custom AMI using HashiCorp Packer and a build specification with resources and configuration scripts from the Amazon EKS AMI repository on AWS GitHub . You can update the kubelet.service and follow the instructions specified here to create a custom AMI. Routinely Upgrade CNI Version \u00b6 The VPC CNI is backward compatible. The latest version works with all Amazon EKS supported Kubernetes versions. Additionally, the VPC CNI is offered as an EKS add-on (see \u201cDeploy VPC CNI Managed Add-On\u201d above). While EKS add-ons orchestrates upgrades of add-ons, it will not automatically upgrade add-ons like the CNI because they run on the data plane. You are responsible for upgrading the VPC CNI add-on following managed and self-managed worker node upgrades.","title":"Amazon VPC CNI"},{"location":"networking/vpc-cni/#amazon-vpc-cni","text":"Amazon EKS implements cluster networking through the Amazon VPC Container Network Interface (VPC CNI) plugin. The CNI plugin allows Kubernetes Pods to have the same IP address as they do on the VPC network. More specifically, all containers inside the Pod share a network namespace, and they can communicate with each-other using local ports. Amazon VPC CNI has two components: CNI Binary, which will setup Pod network to enable Pod-to-Pod communication. The CNI binary runs on a node root file system and is invoked by the kubelet when a new Pod gets added to, or an existing Pod removed from the node. ipamd, a long-running node-local IP Address Management (IPAM) daemon and is responsible for: managing ENIs on a node, and maintaining a warm-pool of available IP addresses or prefix When an instance is created, EC2 creates and attaches a primary ENI associated with a primary subnet. The primary subnet may be public or private. The Pods that run in hostNetwork mode use the primary IP address assigned to the node primary ENI and share the same network namespace as the host. The CNI plugin manages Elastic Network Interfaces (ENI) on the node. When a node is provisioned, the CNI plugin automatically allocates a pool of slots (IPs or Prefix\u2019s) from the node\u2019s subnet to the primary ENI. This pool is known as the warm pool , and its size is determined by the node\u2019s instance type. Depending on CNI settings, a slot may be an IP address or a prefix. When a slot on an ENI has been assigned, the CNI may attach additional ENIs with warm pool of slots to the nodes. These additional ENIs are called Secondary ENIs. Each ENI can only support a certain number of slots, based on instance type. The CNI attaches more ENIs to instances based on the number of slots needed, which usually corresponds to the number of Pods. This process continues until the node can no longer support additional ENI. The CNI also pre-allocates \u201cwarm\u201d ENIs and slots for faster Pod startup. Note each instance type has a maximum number of ENIs that may be attached. This is one constraint on Pod density (number of Pods per node), in addition to compute resources. The maximum number of network interfaces, and the maximum number of slots that you can use varies by the type of EC2 Instance. Since each Pod consumes an IP address on a slot, the number of Pods you can run on a particular EC2 Instance depends on how many ENIs can be attached to it and how many slots each ENI supports. We suggest setting the maximum Pods per EKS user guide to avoid exhaustion of the instance\u2019s CPU and memory resources. Pods using hostNetwork are excluded from this calculation. You may consider using a script called max-pod-calculator.sh to calculate EKS\u2019s recommended maximum Pods for a given instance type.","title":"Amazon VPC CNI"},{"location":"networking/vpc-cni/#overview","text":"Secondary IP mode is the default mode for VPC CNI. This guide provides a generic overview of VPC CNI behavior when Secondary IP mode is enabled. The functionality of ipamd (allocation of IP addresses) may vary depending on the configuration settings for VPC CNI, such as Prefix Mode , Security Groups Per Pod , and Custom Networking . The Amazon VPC CNI is deployed as a Kubernetes Daemonset named aws-node on worker nodes. When a worker node is provisioned, it has a default ENI, called the primary ENI, attached to it. The CNI allocates a warm pool of ENIs and secondary IP addresses from the subnet attached to the node\u2019s primary ENI. By default, ipamd attempts to allocate an additional ENI to the node. The IPAMD allocates additional ENI when a single Pod is scheduled and assigned a secondary IP address from the primary ENI. This \"warm\" ENI enables faster Pod networking. As the pool of secondary IP addresses runs out, the CNI adds another ENI to assign more. The number of ENIs and IP addresses in a pool are configured through environment variables called WARM_ENI_TARGET, WARM_IP_TARGET, MINIMUM_IP_TARGET . The aws-node Daemonset will periodically check that a sufficient number of ENIs are attached. A sufficient number of ENIs are attached when all of the WARM_ENI_TARGET , or WARM_IP_TARGET and MINIMUM_IP_TARGET conditions are met. If there are insufficient ENIs attached, the CNI will make an API call to EC2 to attach more until MAX_ENI limit is reached. WARM_ENI_TARGET - Integer, Values >0 indicate requirement Enabled The number of Warm ENIs to be maintained. An ENI is \u201cwarm\u201d when it is attached as a secondary ENI to a node, but it is not in use by any Pod. More specifically, no IP addresses of the ENI have been associated with a Pod. Example: Consider an instance with 2 ENIs, each ENI supporting 5 IP addresses. WARM_ENI_TARGET is set to 1. If exactly 5 IP addresses are associated with the instance, the CNI maintains 2 ENIs attached to the instance. The first ENI is in use, and all 5 possible IP addresses of this ENI are used. The second ENI is \u201cwarm\u201d with all 5 IP addresses in pool. If another Pod is launched on the instance, a 6th IP address will be needed. The CNI will assign this 6th Pod an IP address from the second ENI and from 5 IPs from the pool. The second ENI is now in use, and no longer in a \u201cwarm\u201d status. The CNI will allocate a 3rd ENI to maintain at least 1 warm ENI. Note The warm ENIs still consume IP addresses from the CIDR of your VPC. IP addresses are \u201cunused\u201d or \u201cwarm\u201d until they are associated with a workload, such as a Pod. WARM_IP_TARGET , Integer, Values >0 indicate requirement Enabled The number of Warm IP addresses to be maintained. A Warm IP is available on an actively attached ENI, but has not been assigned to a Pod. In other words, the number of Warm IPs available is the number of IPs that may be assigned to a Pod without requiring an additional ENI. Example: Consider an instance with 1 ENI, each ENI supporting 20 IP addresses. WARM_IP_TARGET is set to 5. WARM_ENI_TARGET is set to 0. Only 1 ENI will be attached until a 16th IP address is needed. Then, the CNI will attach a second ENI, consuming 20 possible addresses from the subnet CIDR. MINIMUM_IP_TARGET , Integer, Values >0 indicate requirement Enabled The minimum number of IP addresses to be allocated at any time. This is commonly used to front-load the assignment of multiple ENIs at instance launch. Example: Consider a newly launched instance. It has 1 ENI and each ENI supports 10 IP addresses. MINIMUM_IP_TARGET is set to 100. The ENI immediately attaches 9 more ENIs for a total of 100 addresses. This happens regardless of any WARM_IP_TARGET or WARM_ENI_TARGET values. When Kubelet receives an add Pod request, the CNI binary queries ipamd for an available IP address, which ipamd then provides to the Pod. The CNI binary wires up the host and Pod network. Pods deployed on a node are, by default, assigned to the same security groups as the primary ENI. Alternatively, Pods may be configured with different security groups. As the pool of IP addresses is depleted, the plugin automatically attaches another elastic network interface to the instance and allocates another set of secondary IP addresses to that interface. This process continues until the node can no longer support additional elastic network interfaces. When a Pod is deleted, VPC CNI places the Pod\u2019s IP address in a 30-second cool down cache. The IPs in a cool down cache are not assigned to new Pods. When the cooling-off period is over, VPC CNI moves Pod IP back to the warm pool. The cooling-off period prevents Pod IP addresses from being recycled prematurely and allows kube-proxy on all cluster nodes to finish updating the iptables rules. When the number of IPs or ENIs exceeds the number of warm pool settings, the ipamd plugin returns IPs and ENIs to the VPC. As described above in Secondary IP mode, each Pod receives one secondary private IP address from one of the ENIs attached to an instance. Since each Pod uses an IP address, the number of Pods you can run on a particular EC2 Instance depends on how many ENIs can be attached to it and how many IP addresses it supports. The VPC CNI checks the limits file to find out how many ENIs and IP addresses are allowed for each type of instance. You can use the following formula to determine maximum number of Pods you can deploy on a node. (Number of network interfaces for the instance type \u00d7 (the number of IP addresses per network interface - 1)) + 2 The +2 indicates Pods that require host networking, such as kube-proxy and VPC CNI. Amazon EKS requires kube-proxy and VPC CNI to be operating on each node, and these requirements are factored into the max-pods value. If you want to run additional host networking pods, consider updating the max-pods value. The +2 indicates Kubernetes Pods that use host networking, such as kube-proxy and VPC CNI. Amazon EKS requires kube-proxy and VPC CNI to be running on every node and are calculated towards max-pods. Consider updating max-pods if you plan to run more host networking Pods. You can specify --kubelet-extra-args \"\u2014max-pods=110\" as user data in the launch template. As an example, on a cluster with 3 c5.large nodes (3 ENIs and max 10 IPs per ENI), when the cluster starts up and has 2 CoreDNS pods, the CNI will consume 49 IP addresses and keeps them in warm pool. The warm pool enables faster Pod launches when the application is deployed. Node 1 (with CoreDNS pod): 2 ENIs, 20 IPs assigned Node 2 (with CoreDNS pod): 2 ENIs, 20 IPs assigned Node 3 (no Pod): 1 ENI. 10 IPs assigned. Keep in mind that infrastructure pods, often running as daemon sets, each contribute to the max-pod count. These can include: CoreDNS Amazon Elastic LoadBalancer Operational pods for metrics-server We suggest that you plan your infrastructure by combining these Pods' capacities. For a list of the maximum number of Pods supported by each instance type, see eni-max-Pods.txt on GitHub.","title":"Overview"},{"location":"networking/vpc-cni/#recommendations","text":"","title":"Recommendations"},{"location":"networking/vpc-cni/#use-secondary-ip-mode-when","text":"Secondary IP mode is an ideal configuration option for ephemeral EKS clusters. Greenfield customers who are either new to EKS or in the process of migrating can take advantage of VPC CNI in secondary mode.","title":"Use Secondary IP Mode when"},{"location":"networking/vpc-cni/#avoid-secondary-ip-mode-when","text":"If you are experiencing Pod density issues, we suggest enabling prefix mode. If you are facing IPv4 depletion issues, we advise migrating to IPv6 clusters. If IPv6 is not on the horizon, you may choose to use custom networking.","title":"Avoid Secondary IP Mode when"},{"location":"networking/vpc-cni/#deploy-vpc-cni-managed-add-on","text":"When you provision a cluster, Amazon EKS installs VPC CNI automatically. Amazon EKS nevertheless supports managed add-ons that enable the cluster to interact with underlying AWS resources such as computing, storage, and networking. We highly recommend that you deploy clusters with managed add-ons including VPC CNI. Amazon EKS managed add-on offer VPC CNI installation and management for Amazon EKS clusters. Amazon EKS add-ons include the latest security patches, bug fixes, and are validated by AWS to work with Amazon EKS. The VPC CNI add-on enables you to continuously ensure the security and stability of your Amazon EKS clusters and decrease the amount of effort required to install, configure, and update add-ons. Additionally, a managed add-on can be added, updated, or deleted via the Amazon EKS API, AWS Management Console, AWS CLI, and eksctl. You can find the managed fields of VPC CNI using --show-managed-fields flag with the kubectl get command. kubectl get daemonset aws - node -- show - managed - fields - n kube - system - o yaml Managed add-ons prevents configuration drift by automatically overwriting configurations every 15 minutes. This means that any changes to managed add-ons, made via the Kubernetes API after add-on creation, will overwrite by the automated drift-prevention process and also set to defaults during add-on update process. The fields managed by EKS are listed under managedFields with manager as EKS. Fields managed by EKS include service account, image, image url, liveness probe, readiness probe, labels, volumes, and volume mounts. Info The most frequently used fields such as WARM_ENI_TARGET, WARM_IP_TARGET, and MINIMUM_IP_TARGET are not managed and will not be reconciled. The changes to these fields will be preserved upon updating of the add-on. We suggest testing the add-on behavior in your non-production clusters for a specific configuration before updating production clusters. Additionally, follow the steps in the EKS user guide for add-on configurations.","title":"Deploy VPC CNI Managed Add-On"},{"location":"networking/vpc-cni/#migrate-to-managed-add-on","text":"You will manage the version compatibility and update the security patches of self-managed VPC CNI. To update a self-managed add-on, you must use the Kubernetes APIs and instructions outlined in the EKS user guide . We recommend migrating to a managed add-on for existing EKS clusters and highly suggest creating a backup of your current CNI settings prior to migration. To configure managed add-ons, you can utilize the Amazon EKS API, AWS Management Console, or AWS Command Line Interface. kubectl apply view-last-applied daemonset aws-node -n kube-system > aws-k8s-cni-old.yaml Amazon EKS will replace the CNI configuration settings if the field is listed as managed with default settings. We caution against modifying the managed fields. The add-on does not reconcile configuration fields such as the warm environment variables and CNI modes. The Pods and applications will continue to run while you migrate to a managed CNI.","title":"Migrate to Managed Add-On"},{"location":"networking/vpc-cni/#backup-cni-settings-before-update","text":"VPC CNI runs on customer data plane (nodes), and hence Amazon EKS does not automatically update the add-on (managed and self-managed) when new versions are released or after you update your cluster to a new Kubernetes minor version. To update the add-on for an existing cluster, you must trigger an update via update-addon API or clicking update now link in the EKS console for add-ons. If you have deployed self-managed add-on, follow steps mentioned under updating self-managed VPC CNI add-on. We strongly recommend that you update one minor version at a time. For example, if your current minor version is 1.9 and you want to update to 1.11 , you should update to the latest patch version of 1.10 first, then update to the latest patch version of 1.11 . Perform an inspection of the aws-node Daemonset before updating Amazon VPC CNI. Take a backup of existing settings. If using a managed add-on, confirm that you have not updated any settings that Amazon EKS might override. We recommend a post update hook in your automation workflow or a manual apply step after an add-on update. kubectl apply view-last-applied daemonset aws-node -n kube-system > aws-k8s-cni-old.yaml For a self-managed add-on, compare the backup with releases on GitHub to see the available versions and familiarize yourself with the changes in the version that you want to update to. We recommend using Helm to manage self-managed add-ons and leverage values files to apply settings. Any update operations involving Daemonset delete will result in application downtime and must be avoided.","title":"Backup CNI Settings Before Update"},{"location":"networking/vpc-cni/#understand-security-context","text":"We strongly suggest you to understand the security contexts configured for managing VPC CNI efficiently. Amazon VPC CNI has two components CNI binary and ipamd (aws-node) Daemonset. The CNI runs as a binary on a node and has access to node root file system, also has privileged access as it deals with iptables at the node level. The CNI binary is invoked by the kubelet when Pods gets added or removed. The aws-node Daemonset is a long-running process responsible for IP address management at the node level. The aws-node runs in hostNetwork mode and allows access to the loopback device, and network activity of other pods on the same node. The aws-node init-container runs in privileged mode and mounts the CRI socket allowing the Daemonset to monitor IP usage by the Pods running on the node. Amazon EKS is working to remove the privileged requirement of aws-node init container. Additionally, the aws-node needs to update NAT entries and to load the iptables modules and hence runs with NET_ADMIN privileges. Amazon EKS recommends deploying the security policies as defined by the aws-node manifest for IP management for the Pods and networking settings. Please consider updating to the latest version of VPC CNI. Furthermore, please consider opening a GitHub issue if you have a specific security requirement.","title":"Understand Security Context"},{"location":"networking/vpc-cni/#use-separate-iam-role-for-cni","text":"The AWS VPC CNI requires AWS Identity and Access Management (IAM) permissions. The CNI policy needs to be set up before the IAM role can be used. You can use AmazonEKS_CNI_Policy , which is an AWS managed policy for IPv4 clusters. AmazonEKS CNI managed policy only has permissions for IPv4 clusters. You must create a separate IAM policy for IPv6 clusters with the permissions listed here . By default, VPC CNI inherits the Amazon EKS node IAM role (both managed and self-managed node groups). Configuring a separate IAM role with the relevant policies for Amazon VPC CNI is strongly recommended. If not, the pods of Amazon VPC CNI gets the permission assigned to the node IAM role and have access to the instance profile assigned to the node. The VPC CNI plugin creates and configures a service account called aws-node. By default, the service account binds to the Amazon EKS node IAM role with Amazon EKS CNI policy attached. To use the separate IAM role, we recommend that you create a new service account with Amazon EKS CNI policy attached. To use a new service account you must redeploy the CNI pods . Consider specifying a --service-account-role-arn for VPC CNI managed add-on when creating new clusters. Make sure you remove Amazon EKS CNI policy for both IPv4 and IPv6 from Amazon EKS node role. It is advised that you block access instance metadata to minimize the blast radius of security breach.","title":"Use separate IAM role for CNI"},{"location":"networking/vpc-cni/#handle-livenessreadiness-probe-failures","text":"We advise increasing the liveness and readiness probe timeout values (default timeoutSeconds: 10 ) for EKS 1.20 an later clusters to prevent probe failures from causing your application's Pod to become stuck in a containerCreating state. This problem has been seen in data-intensive and batch-processing clusters. High CPU use causes aws-node probe health failures, leading to unfulfilled Pod CPU requests. In addition to modifying the probe timeout, ensure that the CPU resource requests (default CPU: 25m ) for aws-node are correctly configured. We do not suggest updating the settings unless your node is having issues. We highly encourage you to run sudo bash /opt/cni/bin/aws-cni-support.sh on a node while you engage Amazon EKS support. The script will assist in evaluating kubelet logs and memory utilization on the node. Please consider installing SSM Agent on Amazon EKS worker nodes to run the script.","title":"Handle Liveness/Readiness Probe failures"},{"location":"networking/vpc-cni/#monitor-ip-address-inventory","text":"You can monitor the IP addresses inventory of subnets using CNI Metrics Helper . maximum number of ENIs the cluster can support number of ENIs already allocated number of IP addresses currently assigned to Pods total and maximum number of IP address available You can also set CloudWatch alarms to get notified if a subnet is running out of IP addresses. Please visit EKS user guide for install instructions of CNI metrics helper . Make sure DISABLE_METRICS variable for VPC CNI is set to false.","title":"Monitor IP Address Inventory"},{"location":"networking/vpc-cni/#plan-for-growth","text":"We strongly recommend to size your subnets for growth. Right sizing the subnets will prevent your subnets from running out of IP addresses as your Pods and nodes scale. You will not be able to create new Pods or nodes if the subnets don\u2019t have enough available IP addresses. If you need to limit the IP addresses the CNI caches, then you can use warm pool CNI environment variables. If subnets in your VPC run out of available IP addresses, we suggest creating a new subnet using the VPC\u2019s original CIDR blocks. Use the sample EKS Subnet Calculator spreadsheet to plan your network. The spreadsheet calculates IP usage based on workloads and VPC ENI configuration. The IP usage is compared to an IPv4 subnet to determine if the configuration and subnet size is sufficient for your workload.","title":"Plan for Growth"},{"location":"networking/vpc-cni/#configure-ip-and-eni-target-values-in-address-constrained-environments","text":"Warning Improving your VPC design is the recommended response to IP address exhaustion. Consider solutions like IPv6 and Secondary CIDRs. Adjusting these values to minimize the number of Warm IPs should be a temporary solution after other options are excluded. Misconfiguring these values may interfere with cluster operation. In the default configuration, VPC CNI keeps an entire ENI (and associated IPs) in the warm pool. This may consume a large number of IPs, especially on larger instance types. If your cluster subnet has a limited number of free IP addresses, scrutinize these VPC CNI configuration environment variables: WARM_IP_TARGET MINIMUM_IP_TARGET WARM_ENI_TARGET Configure the value of MINIMUM_IP_TARGET to closely match the number of Pods you expect to run on your nodes. Doing so will ensure that as Pods get created, and the CNI can assign IP addresses from the warm pool without calling the EC2 API. Avoid setting the value of WARM_IP_TARGET too low as it will cause additional calls to the EC2 API, and that might cause throttling of the requests. For large clusters use along with MINIMUM_IP_TARGET to avoid throttling of the requests. To configure these options, download aws-k8s-cni.yaml and set the environment variables. At the time of writing, the latest release is located here . Check the version of the configuration value matches the installed VPC CNI version. Warning The warm settings will be reset to defaults when you update the CNI. Please take a backup of the CNI, before you update the CNI. Review the configuration settings to determine if you need to reapply them after update is successful.","title":"Configure IP and ENI Target values in address constrained environments."},{"location":"networking/vpc-cni/#configure-warm-eni-value-for-batch-workloads","text":"We recommend updating the default WARM_ENI_TARGET to match the Pod scale needs for batch workloads. Setting WARM_ENI_TARGET to a high value always maintains the warm IP pool required to run large batch workloads and hence avoid data processing delays.","title":"Configure Warm ENI value for Batch Workloads"},{"location":"networking/vpc-cni/#configure-iptables-forward-policy-on-non-eks-optimized-ami-instances","text":"If you are using custom AMI, make sure to set iptables forward policy to ACCEPT under kubelet.service . Many systems set the iptables forward policy to DROP. You can build custom AMI using HashiCorp Packer and a build specification with resources and configuration scripts from the Amazon EKS AMI repository on AWS GitHub . You can update the kubelet.service and follow the instructions specified here to create a custom AMI.","title":"Configure IPTables Forward Policy on non-EKS Optimized AMI Instances"},{"location":"networking/vpc-cni/#routinely-upgrade-cni-version","text":"The VPC CNI is backward compatible. The latest version works with all Amazon EKS supported Kubernetes versions. Additionally, the VPC CNI is offered as an EKS add-on (see \u201cDeploy VPC CNI Managed Add-On\u201d above). While EKS add-ons orchestrates upgrades of add-ons, it will not automatically upgrade add-ons like the CNI because they run on the data plane. You are responsible for upgrading the VPC CNI add-on following managed and self-managed worker node upgrades.","title":"Routinely Upgrade CNI Version"},{"location":"operational_excellence/operational_excellence/","text":"","title":"Operational excellence"},{"location":"performance/performance/","text":"Performance Efficiency Pillar \u00b6 The performance efficiency pillar focuses on the efficient use of computing resources to meet requirements and how to maintain that efficiency as demand changes and technologies evolve. This section provides in-depth, best practices guidance for architecting for performance efficiency on AWS. Definition \u00b6 To ensure the efficient use of EKS container services, you should gather data on all aspects of the architecture, from the high-level design to the selection of EKS resource types. By reviewing your choices on a regular basis, you ensure that you are taking advantage of the continually evolving Amazon EKS and Container services. Monitoring will ensure that you are aware of any deviance from expected performance so you can take action on it. Performance efficiency for EKS containers is composed of three areas: Optimize your container Resource Management Scalability Management Best Practices \u00b6 Optimize your container \u00b6 You can run most applications in a Docker container without too much hassle. There are a number of things that you need to do to ensure it's running effectively in a production environment, including streamlining the build process. The following best practices will help you to achieve that. Recommendations \u00b6 Make your container images stateless: A container created with a Docker image should be ephemeral and immutable. In other words, the container should be disposable and independent, i.e. a new one can be built and put in place with absolutely no configuration changes. Design your containers to be stateless. If you would like to use persistent data, use volumes instead. If you would like to store secrets or sensitive application data used by services, you can use solutions like AWS Systems Manager Parameter Store or third-party offerings or open source solutions, such as HashiCorp Valut and Consul , for runtime configurations. Minimal base image : Start with a small base image. Every other instruction in the Dockerfile builds on top of this image. The smaller the base image, the smaller the resulting image is, and the more quickly it can be downloaded. For example, the alpine:3.7 image is 71 MB smaller than the centos:7 image. You can even use the scratch base image, which is an empty image on which you can build your own runtime environment. Avoid unnecessary packages: When building a container image, include only the dependencies what your application needs and avoid installing unnecessary packages. For example if your application does not need an SSH server, don't include one. This will reduce complexity, dependencies, file sizes, and build times. To exclude files not relevant to the build use a .dockerignore file. Use multi-stage build :Multi-stage builds allow you to build your application in a first \"build\" container and use the result in another container, while using the same Dockerfile. To expand a bit on that, in multi-stage builds, you use multiple FROM statements in your Dockerfile. Each FROM instruction can use a different base, and each of them begins a new stage of the build. You can selectively copy artifacts from one stage to another, leaving behind everything you don't want in the final image. This method drastically reduces the size of your final image, without struggling to reduce the number of intermediate layers and files. Minimize number of layers: Each instruction in the Dockerfile adds an extra layer to the Docker image. The number of instructions and layers should be kept to a minimum as this affects build performance and time. For example, the first instruction below will create multiple layers, whereas the second instruction by using &&(chaining) we reduced the number of layers, which will help provide better performance. The is the best way to reduce the number of layers that will be created in your Dockerfile. RUN apt-get -y update RUN apt-get install -y python RUN apt-get -y update && apt-get install -y python Properly tag your images: When building images, always tag them with useful and meaningful tags. This is a good way to organize and document metadata describing an image, for example, by including a unique counter like build id from a CI server (e.g. CodeBuild or Jenkins) to help with identifying the correct image. The tag latest is used by default if you do not provide one in your Docker commands. We recommend not to use the automatically created latest tag, because by using this tag you'll automatically be running future major releases, which could include breaking changes for your application. The best practice is to avoid the latest tag and instead use the unique digest created by your CI server. Use Build Cache to improve build speed : The cache allows you to take advantage of existing cached images, rather than building each image from scratch. For example, you should add the source code of your application as late as possible in your Dockerfile so that the base image and your application's dependencies get cached and aren't rebuilt on every build. To reuse already cached images, By default in Amazon EKS, the kubelet will try to pull each image from the specified registry. However, if the imagePullPolicy property of the container is set to IfNotPresent or Never, then a local image is used (preferentially or exclusively, respectively). Image Security : Using public images may be a great way to start working on containers and deploying it to Kubernetes. However, using them in production can come with a set of challenges. Especially when it comes to security. Ensure to follow the best practices for packaging and distributing the containers/applications. For example, don't build your containers with passwords baked in also you might need to control what's inside them. Recommend to use private repository such as Amazon ECR and leverage the in-built image scanning feature to identify software vulnerabilities in your container images. Right size your containers: As you develop and run applications in containers, there are a few key areas to consider. How you size containers and manage your application deployments can negatively impact the end-user experience of services that you provide. To help you succeed, the following best practices will help you right size your containers. After you determine the number of resources required for your application, you should set requests and limits Kubernetes to ensure that your applications are running correctly. (a) Perform testing of the application : to gather vital statistics and other performance Based upon this data you can work out the optimal configuration, in terms of memory and CPU, for your container. Vital statistics such as : CPU, Latency, I/O, Memory usage, Network . Determine expected, mean, and peak container memory and CPU usage by doing a separate load test if necessary. Also consider all the processes that might potentially run in parallel in the container. Recommend to use CloudWatch Container insights or partner products, which will give you the right information to size containers and the Worker nodes. (b)Test services independently: As many applications depend on each other in a true microservice architecture, you need to test them with a high degree of independence meaning that the services are both able to properly function by themselves, as well as function as part of a cohesive system. Resource Management \u00b6 One of the most common questions that asked in the adoption of Kubernetes is \" What should I put in a Pod? \". For example, a three tier LAMP application container. Should we keep this application in the same pod? Well, this works effectively as a single pod but this is an example of an anti-pattern for Pod creation. There are two reasons for that (a) If you have both the containers in the same Pod, you are forced to use the same scaling strategy which is not ideal for production environment also you can't effectively manage or constraint resources based on the usage. E.g: you might need to scale just the frontend not frontend and backend (MySQL) as a unit also if you would like to increase the resources dedicated just to the backend, you cant just do that. (b) If you have two separate pods, one for frontend and other for backend. Scaling would be very easy and you get a better reliability. The above might not work in all the use-cases. In the above example frontend and backend may land in different machines and they will communicate with each other via network, So you need to ask the question \" Will my application work correctly, If they are placed and run on different machines? \" If the answer is a \" no \" may be because of the application design or for some other technical reasons, then grouping of containers in a single pod makes sense. If the answer is \" Yes \" then multiple Pods is the correct approach. Recommendations \u00b6 Package a single application per container: A container works best when a single application runs inside it. This application should have a single parent process. For example, do not run PHP and MySQL in the same container: it's harder to debug, and you can't horizontally scale the PHP container alone. This separation allows you to better tie the lifecycle of the application to that of the container. Your containers should be both stateless and immutable. Stateless means that any state (persistent data of any kind) is stored outside of the container, for example, you can use different kinds of external storage like Persistent disk, Amazon EBS, and Amazon EFS if needed, or managed database like Amazon RDS. Immutable means that a container will not be modified during its life: no updates, no patches, and no configuration changes. To update the application code or apply a patch, you build a new image and deploy it. Use Labels to Kubernetes Objects: Labels allow Kubernetes objects to be queried and operated upon in bulk. They can also be used to identify and organize Kubernetes objects into groups. As such defining labels should figure right at the top of any Kubernetes best practices list. Setting resource request limits: Setting request limits is the mechanism used to control the amount of system resources that a container can consume such as CPU and memory. These settings are what the container is guaranteed to get when the container initially starts. If a container requests a resource, container orchestrators such as Kubernetes will only schedule it on a node that can provide that resource. Limits, on the other hand, make sure that a container never goes above a certain value. The container is only allowed to go up to the limit, and then it is restricted. In the below example Pod manifest, we add a limit of 1.0 CPU and 256 MB of memory apiVersion: v1 kind: Pod metadata: name: nginx-pod-webserver labels: name: nginx-pod spec: containers: - name: nginx image: nginx:latest resources: limits: memory: \"256Mi\" cpu: \"1000m\" requests: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 80 It's a best practice to define these requests and limits in your pod definitions. If you don't include these values, the scheduler doesn't understand what resources are needed. Without this information, the scheduler might schedule the pod on a node without sufficient resources to provide acceptable application performance. Limit the number of concurrent disruptions: Use PodDisruptionBudget , This settings allows you to set a policy on the minimum available and maximum unavailable pods during voluntary eviction events. An example of an eviction would be when perform maintenance on the node or draining a node. Example: A web frontend might want to ensure that 8 Pods to be available at any given time. In this scenario, an eviction can evict as many pods as it wants, as long as eight are available. apiVersion : policy / v1beta1 kind : PodDisruptionBudget metadata : name : frontend - demo spec : minAvailable : 8 selector : matchLabels : app : frontend N.B: You can also specify pod disruption budget as a percentage by using maxAvailable or maxUnavailable parameter. Use Namespaces: Namespaces allows a physical cluster to be shared by multiple teams. A namespace allows to partition created resources into a logically named group. This allows you to set resource quotas per namespace, Role-Based Access Control (RBAC) per namespace, and also network policies per namespace. It gives you soft multitenancy features. For example, If you have three applications running on a single Amazon EKS cluster accessed by three different teams which requires multiple resource constraints and different levels of QoS each group you could create a namespace per team and give each team a quota on the number of resources that it can utilize, such as CPU and memory. You can also specify default limits in Kubernetes namespaces level by enabling LimitRange admission controller. These default limits will constrain the amount of CPU or memory a given Pod can use unless the defaults are explicitly overridden by the Pod's configuration. Manage Resource Quota: Each namespace can be assigned resource quota. Specifying quota allows to restrict how much of cluster resources can be consumed across all resources in a namespace. Resource quota can be defined by a ResourceQuota object. A presence of ResourceQuota object in a namespace ensures that resource quotas are enforced. Configure Health Checks for Pods: Health checks are a simple way to let the system know if an instance of your app is working or not. If an instance of your app is not working, then other services should not access it or send requests to it. Instead, requests should be sent to another instance of the app that is working. The system also should bring your app back to a healthy state. By default, all the running pods have the restart policy set to always which means the kubelet running within a node will automatically restart a pod when the container encounters an error. Health checks extend this capability of kubelet through the concept of container probes . Kubernetes provides two types of health checks : readiness and liveness probes. For example, consider if one of your applications, which typically runs for long periods of time, transitions to a non-running state and can only recover by being restarted. You can use liveness probes to detect and remedy such situations. Using health checks gives your applications better reliability, and higher uptime. Advanced Scheduling Techniques: Generally, schedulers ensure that pods are placed only on nodes that have sufficient free resources, and across nodes, they try to balance out the resource utilization across nodes, deployments, replicas, and so on. But sometimes you want to control how your pods are scheduled. For example, perhaps you want to ensure that certain pods are only scheduled on nodes with specialized hardware, such as requiring a GPU machine for an ML workload. Or you want to collocate services that communicate frequently. Kubernetes offers many advanced scheduling features and multiple filters/constraints to schedule the pods on the right node. For example, when using Amazon EKS, you can use taints and tolerations to restrict what workloads can run on specific nodes. You can also control pod scheduling using node selectors and affinity and anti-affinity constructs and even have your own custom scheduler built for this purpose. Scalability Management \u00b6 Containers are stateless. They are born and when they die, they are not resurrected. There are many techniques that you can leverage on Amazon EKS, not only to scale out your containerized applications but also the Kubernetes worker node. Recommendations \u00b6 On Amazon EKS, you can configure Horizontal pod autoscaler ,which automatically scales the number of pods in a replication controller, deployment, or replica set based on observed CPU utilization (or use custom metrics based on application-provided metrics). You can use Vertical Pod Autoscaler which automatically adjusts the CPU and memory reservations for your pods to help \"right size\" your applications. This adjustment can improve cluster resource utilization and free up CPU and memory for other pods. This is useful in scenarios like your production database \"MongoDB\" does not scale the same way as a stateless application frontend, In this scenario you could use VPA to scale up the MongoDB Pod. To enable VPA you need to use Kubernetes metrics server, which is an aggregator of resource usage data in your cluster. It is not deployed by default in Amazon EKS clusters. You need to configure it before configure VPA alternatively you can also use Prometheus to provide metrics for the Vertical Pod Autoscaler. While HPA and VPA scale the deployments and pods, Cluster Autoscaler will scale-out and scale-in the size of the pool of worker nodes. It adjusts the size of a Kubernetes cluster based on the current utilization. Cluster Autoscaler increases the size of the cluster when there are pods that failed to schedule on any of the current nodes due to insufficient resources or when adding a new node would increase the overall availability of cluster resources. Please follow this step by step guide to setup Cluster Autoscaler. If you are using Amazon EKS on AWS Fargate, AWS Manages the control plane for you. Please have a look at the reliability pillar for detailed information. Monitoring \u00b6 Deployment Best Practices \u00b6 Trade-Offs \u00b6","title":"Performance Efficiency Pillar"},{"location":"performance/performance/#performance-efficiency-pillar","text":"The performance efficiency pillar focuses on the efficient use of computing resources to meet requirements and how to maintain that efficiency as demand changes and technologies evolve. This section provides in-depth, best practices guidance for architecting for performance efficiency on AWS.","title":"Performance Efficiency Pillar"},{"location":"performance/performance/#definition","text":"To ensure the efficient use of EKS container services, you should gather data on all aspects of the architecture, from the high-level design to the selection of EKS resource types. By reviewing your choices on a regular basis, you ensure that you are taking advantage of the continually evolving Amazon EKS and Container services. Monitoring will ensure that you are aware of any deviance from expected performance so you can take action on it. Performance efficiency for EKS containers is composed of three areas: Optimize your container Resource Management Scalability Management","title":"Definition"},{"location":"performance/performance/#best-practices","text":"","title":"Best Practices"},{"location":"performance/performance/#optimize-your-container","text":"You can run most applications in a Docker container without too much hassle. There are a number of things that you need to do to ensure it's running effectively in a production environment, including streamlining the build process. The following best practices will help you to achieve that.","title":"Optimize your container"},{"location":"performance/performance/#recommendations","text":"Make your container images stateless: A container created with a Docker image should be ephemeral and immutable. In other words, the container should be disposable and independent, i.e. a new one can be built and put in place with absolutely no configuration changes. Design your containers to be stateless. If you would like to use persistent data, use volumes instead. If you would like to store secrets or sensitive application data used by services, you can use solutions like AWS Systems Manager Parameter Store or third-party offerings or open source solutions, such as HashiCorp Valut and Consul , for runtime configurations. Minimal base image : Start with a small base image. Every other instruction in the Dockerfile builds on top of this image. The smaller the base image, the smaller the resulting image is, and the more quickly it can be downloaded. For example, the alpine:3.7 image is 71 MB smaller than the centos:7 image. You can even use the scratch base image, which is an empty image on which you can build your own runtime environment. Avoid unnecessary packages: When building a container image, include only the dependencies what your application needs and avoid installing unnecessary packages. For example if your application does not need an SSH server, don't include one. This will reduce complexity, dependencies, file sizes, and build times. To exclude files not relevant to the build use a .dockerignore file. Use multi-stage build :Multi-stage builds allow you to build your application in a first \"build\" container and use the result in another container, while using the same Dockerfile. To expand a bit on that, in multi-stage builds, you use multiple FROM statements in your Dockerfile. Each FROM instruction can use a different base, and each of them begins a new stage of the build. You can selectively copy artifacts from one stage to another, leaving behind everything you don't want in the final image. This method drastically reduces the size of your final image, without struggling to reduce the number of intermediate layers and files. Minimize number of layers: Each instruction in the Dockerfile adds an extra layer to the Docker image. The number of instructions and layers should be kept to a minimum as this affects build performance and time. For example, the first instruction below will create multiple layers, whereas the second instruction by using &&(chaining) we reduced the number of layers, which will help provide better performance. The is the best way to reduce the number of layers that will be created in your Dockerfile. RUN apt-get -y update RUN apt-get install -y python RUN apt-get -y update && apt-get install -y python Properly tag your images: When building images, always tag them with useful and meaningful tags. This is a good way to organize and document metadata describing an image, for example, by including a unique counter like build id from a CI server (e.g. CodeBuild or Jenkins) to help with identifying the correct image. The tag latest is used by default if you do not provide one in your Docker commands. We recommend not to use the automatically created latest tag, because by using this tag you'll automatically be running future major releases, which could include breaking changes for your application. The best practice is to avoid the latest tag and instead use the unique digest created by your CI server. Use Build Cache to improve build speed : The cache allows you to take advantage of existing cached images, rather than building each image from scratch. For example, you should add the source code of your application as late as possible in your Dockerfile so that the base image and your application's dependencies get cached and aren't rebuilt on every build. To reuse already cached images, By default in Amazon EKS, the kubelet will try to pull each image from the specified registry. However, if the imagePullPolicy property of the container is set to IfNotPresent or Never, then a local image is used (preferentially or exclusively, respectively). Image Security : Using public images may be a great way to start working on containers and deploying it to Kubernetes. However, using them in production can come with a set of challenges. Especially when it comes to security. Ensure to follow the best practices for packaging and distributing the containers/applications. For example, don't build your containers with passwords baked in also you might need to control what's inside them. Recommend to use private repository such as Amazon ECR and leverage the in-built image scanning feature to identify software vulnerabilities in your container images. Right size your containers: As you develop and run applications in containers, there are a few key areas to consider. How you size containers and manage your application deployments can negatively impact the end-user experience of services that you provide. To help you succeed, the following best practices will help you right size your containers. After you determine the number of resources required for your application, you should set requests and limits Kubernetes to ensure that your applications are running correctly. (a) Perform testing of the application : to gather vital statistics and other performance Based upon this data you can work out the optimal configuration, in terms of memory and CPU, for your container. Vital statistics such as : CPU, Latency, I/O, Memory usage, Network . Determine expected, mean, and peak container memory and CPU usage by doing a separate load test if necessary. Also consider all the processes that might potentially run in parallel in the container. Recommend to use CloudWatch Container insights or partner products, which will give you the right information to size containers and the Worker nodes. (b)Test services independently: As many applications depend on each other in a true microservice architecture, you need to test them with a high degree of independence meaning that the services are both able to properly function by themselves, as well as function as part of a cohesive system.","title":"Recommendations"},{"location":"performance/performance/#resource-management","text":"One of the most common questions that asked in the adoption of Kubernetes is \" What should I put in a Pod? \". For example, a three tier LAMP application container. Should we keep this application in the same pod? Well, this works effectively as a single pod but this is an example of an anti-pattern for Pod creation. There are two reasons for that (a) If you have both the containers in the same Pod, you are forced to use the same scaling strategy which is not ideal for production environment also you can't effectively manage or constraint resources based on the usage. E.g: you might need to scale just the frontend not frontend and backend (MySQL) as a unit also if you would like to increase the resources dedicated just to the backend, you cant just do that. (b) If you have two separate pods, one for frontend and other for backend. Scaling would be very easy and you get a better reliability. The above might not work in all the use-cases. In the above example frontend and backend may land in different machines and they will communicate with each other via network, So you need to ask the question \" Will my application work correctly, If they are placed and run on different machines? \" If the answer is a \" no \" may be because of the application design or for some other technical reasons, then grouping of containers in a single pod makes sense. If the answer is \" Yes \" then multiple Pods is the correct approach.","title":"Resource Management"},{"location":"performance/performance/#recommendations_1","text":"Package a single application per container: A container works best when a single application runs inside it. This application should have a single parent process. For example, do not run PHP and MySQL in the same container: it's harder to debug, and you can't horizontally scale the PHP container alone. This separation allows you to better tie the lifecycle of the application to that of the container. Your containers should be both stateless and immutable. Stateless means that any state (persistent data of any kind) is stored outside of the container, for example, you can use different kinds of external storage like Persistent disk, Amazon EBS, and Amazon EFS if needed, or managed database like Amazon RDS. Immutable means that a container will not be modified during its life: no updates, no patches, and no configuration changes. To update the application code or apply a patch, you build a new image and deploy it. Use Labels to Kubernetes Objects: Labels allow Kubernetes objects to be queried and operated upon in bulk. They can also be used to identify and organize Kubernetes objects into groups. As such defining labels should figure right at the top of any Kubernetes best practices list. Setting resource request limits: Setting request limits is the mechanism used to control the amount of system resources that a container can consume such as CPU and memory. These settings are what the container is guaranteed to get when the container initially starts. If a container requests a resource, container orchestrators such as Kubernetes will only schedule it on a node that can provide that resource. Limits, on the other hand, make sure that a container never goes above a certain value. The container is only allowed to go up to the limit, and then it is restricted. In the below example Pod manifest, we add a limit of 1.0 CPU and 256 MB of memory apiVersion: v1 kind: Pod metadata: name: nginx-pod-webserver labels: name: nginx-pod spec: containers: - name: nginx image: nginx:latest resources: limits: memory: \"256Mi\" cpu: \"1000m\" requests: memory: \"128Mi\" cpu: \"500m\" ports: - containerPort: 80 It's a best practice to define these requests and limits in your pod definitions. If you don't include these values, the scheduler doesn't understand what resources are needed. Without this information, the scheduler might schedule the pod on a node without sufficient resources to provide acceptable application performance. Limit the number of concurrent disruptions: Use PodDisruptionBudget , This settings allows you to set a policy on the minimum available and maximum unavailable pods during voluntary eviction events. An example of an eviction would be when perform maintenance on the node or draining a node. Example: A web frontend might want to ensure that 8 Pods to be available at any given time. In this scenario, an eviction can evict as many pods as it wants, as long as eight are available. apiVersion : policy / v1beta1 kind : PodDisruptionBudget metadata : name : frontend - demo spec : minAvailable : 8 selector : matchLabels : app : frontend N.B: You can also specify pod disruption budget as a percentage by using maxAvailable or maxUnavailable parameter. Use Namespaces: Namespaces allows a physical cluster to be shared by multiple teams. A namespace allows to partition created resources into a logically named group. This allows you to set resource quotas per namespace, Role-Based Access Control (RBAC) per namespace, and also network policies per namespace. It gives you soft multitenancy features. For example, If you have three applications running on a single Amazon EKS cluster accessed by three different teams which requires multiple resource constraints and different levels of QoS each group you could create a namespace per team and give each team a quota on the number of resources that it can utilize, such as CPU and memory. You can also specify default limits in Kubernetes namespaces level by enabling LimitRange admission controller. These default limits will constrain the amount of CPU or memory a given Pod can use unless the defaults are explicitly overridden by the Pod's configuration. Manage Resource Quota: Each namespace can be assigned resource quota. Specifying quota allows to restrict how much of cluster resources can be consumed across all resources in a namespace. Resource quota can be defined by a ResourceQuota object. A presence of ResourceQuota object in a namespace ensures that resource quotas are enforced. Configure Health Checks for Pods: Health checks are a simple way to let the system know if an instance of your app is working or not. If an instance of your app is not working, then other services should not access it or send requests to it. Instead, requests should be sent to another instance of the app that is working. The system also should bring your app back to a healthy state. By default, all the running pods have the restart policy set to always which means the kubelet running within a node will automatically restart a pod when the container encounters an error. Health checks extend this capability of kubelet through the concept of container probes . Kubernetes provides two types of health checks : readiness and liveness probes. For example, consider if one of your applications, which typically runs for long periods of time, transitions to a non-running state and can only recover by being restarted. You can use liveness probes to detect and remedy such situations. Using health checks gives your applications better reliability, and higher uptime. Advanced Scheduling Techniques: Generally, schedulers ensure that pods are placed only on nodes that have sufficient free resources, and across nodes, they try to balance out the resource utilization across nodes, deployments, replicas, and so on. But sometimes you want to control how your pods are scheduled. For example, perhaps you want to ensure that certain pods are only scheduled on nodes with specialized hardware, such as requiring a GPU machine for an ML workload. Or you want to collocate services that communicate frequently. Kubernetes offers many advanced scheduling features and multiple filters/constraints to schedule the pods on the right node. For example, when using Amazon EKS, you can use taints and tolerations to restrict what workloads can run on specific nodes. You can also control pod scheduling using node selectors and affinity and anti-affinity constructs and even have your own custom scheduler built for this purpose.","title":"Recommendations"},{"location":"performance/performance/#scalability-management","text":"Containers are stateless. They are born and when they die, they are not resurrected. There are many techniques that you can leverage on Amazon EKS, not only to scale out your containerized applications but also the Kubernetes worker node.","title":"Scalability Management"},{"location":"performance/performance/#recommendations_2","text":"On Amazon EKS, you can configure Horizontal pod autoscaler ,which automatically scales the number of pods in a replication controller, deployment, or replica set based on observed CPU utilization (or use custom metrics based on application-provided metrics). You can use Vertical Pod Autoscaler which automatically adjusts the CPU and memory reservations for your pods to help \"right size\" your applications. This adjustment can improve cluster resource utilization and free up CPU and memory for other pods. This is useful in scenarios like your production database \"MongoDB\" does not scale the same way as a stateless application frontend, In this scenario you could use VPA to scale up the MongoDB Pod. To enable VPA you need to use Kubernetes metrics server, which is an aggregator of resource usage data in your cluster. It is not deployed by default in Amazon EKS clusters. You need to configure it before configure VPA alternatively you can also use Prometheus to provide metrics for the Vertical Pod Autoscaler. While HPA and VPA scale the deployments and pods, Cluster Autoscaler will scale-out and scale-in the size of the pool of worker nodes. It adjusts the size of a Kubernetes cluster based on the current utilization. Cluster Autoscaler increases the size of the cluster when there are pods that failed to schedule on any of the current nodes due to insufficient resources or when adding a new node would increase the overall availability of cluster resources. Please follow this step by step guide to setup Cluster Autoscaler. If you are using Amazon EKS on AWS Fargate, AWS Manages the control plane for you. Please have a look at the reliability pillar for detailed information.","title":"Recommendations"},{"location":"performance/performance/#monitoring","text":"","title":"Monitoring"},{"location":"performance/performance/#deployment-best-practices","text":"","title":"Deployment Best Practices"},{"location":"performance/performance/#trade-offs","text":"","title":"Trade-Offs"},{"location":"reliability/docs/","text":"Amazon EKS Best Practices Guide for Reliability \u00b6 This section provides guidance about making workloads running on EKS resilient and highly-available How to use this guide \u00b6 This guide is meant for developers and architects who want to develop and operate highly-available and fault-tolerant services in EKS. The guide is organized into different topic areas for easier consumption. Each topic starts with a brief overview, followed by a list of recommendations and best practices for the reliability of your EKS clusters. Introduction \u00b6 The reliability best practices for EKS have been grouped under the following topics: Applications Control Plane Data Plane Network What makes a system reliable? If a system can function consistently and meet demands in spite of changes in its environment over a period of time, it can be called reliable. To achieve this, the system has to detect failures, automatically heal itself, and have the ability to scale based on demand. Customers can use Kubernetes as a foundation to operate mission-critical applications and services reliably. But aside from incorporating container-based application design principles, running workloads reliably also requires a reliable infrastructure. In Kubernetes, infrastructure comprises the control plane and data plane. EKS provides a production-grade Kubernetes control plane that is designed to be highly-available and fault-tolerant. In EKS, AWS is responsible for the reliability of the Kubernetes control plane. EKS runs Kubernetes control plane across three availability zones in an AWS Region. It automatically manages the availability and scalability of the Kubernetes API servers and the etcd cluster. The responsibility for the data plane\u2019s reliability is shared between you, the customer, and AWS. EKS offers three options for Kubernetes data plane. Fargate, which is the most managed option, handles provisioning and scaling of the data plane. The second option, managed nodes groups, handles provisioning, and updates of the data plane. And finally, self-managed nodes is the least managed option for the data plane. The more AWS-managed data plane you use, the less responsibility you have Managed node groups automate the provisioning and lifecycle management of EC2 nodes. You can use the EKS API (using EKS console, AWS API, AWS CLI, CloudFormation, Terraform, or eksctl ), to create, scale, and upgrade managed nodes. Managed nodes run EKS-optimized Amazon Linux 2 EC2 instances in your account, and you can install custom software packages by enabling SSH access. When you provision managed nodes, they run as part of an EKS-managed Auto Scaling Group that can span multiple Availability Zones; you control this through the subnets you provide when creating managed nodes. EKS also automatically tags managed nodes so they can be used with Cluster Autoscaler. Amazon EKS follows the shared responsibility model for CVEs and security patches on managed node groups. Because managed nodes run the Amazon EKS-optimized AMIs, Amazon EKS is responsible for building patched versions of these AMIs when bug fixes. However, you are responsible for deploying these patched AMI versions to your managed node groups. EKS also manages updating the nodes although you have to initiate the update process. The process of updating managed node is explained in the EKS documentation. If you run self-managed nodes, you can use Amazon EKS-optimized Linux AMI to create worker nodes. You are responsible for patching and upgrading the AMI and the nodes. It is a best practice to use eksctl , CloudFormation, or infrastructure as code tools to provision self-managed nodes because this will make it easy for you to upgrade self-managed nodes . Consider migrating to new nodes when updating worker nodes because the migration process taints the old node group as NoSchedule and drains the nodes after a new stack is ready to accept the existing pod workload. However, you can also perform an in-place upgrade of self-managed nodes . This guide includes a set of recommendations that you can use to improve the reliability of your EKS data plane, Kubernetes core components, and your applications. Feedback \u00b6 This guide is being released on GitHub to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. We intend to update the guide periodically as new features are added to the service or when a new best practice evolves.","title":"Home"},{"location":"reliability/docs/#amazon-eks-best-practices-guide-for-reliability","text":"This section provides guidance about making workloads running on EKS resilient and highly-available","title":"Amazon EKS Best Practices Guide for Reliability"},{"location":"reliability/docs/#how-to-use-this-guide","text":"This guide is meant for developers and architects who want to develop and operate highly-available and fault-tolerant services in EKS. The guide is organized into different topic areas for easier consumption. Each topic starts with a brief overview, followed by a list of recommendations and best practices for the reliability of your EKS clusters.","title":"How to use this guide"},{"location":"reliability/docs/#introduction","text":"The reliability best practices for EKS have been grouped under the following topics: Applications Control Plane Data Plane Network What makes a system reliable? If a system can function consistently and meet demands in spite of changes in its environment over a period of time, it can be called reliable. To achieve this, the system has to detect failures, automatically heal itself, and have the ability to scale based on demand. Customers can use Kubernetes as a foundation to operate mission-critical applications and services reliably. But aside from incorporating container-based application design principles, running workloads reliably also requires a reliable infrastructure. In Kubernetes, infrastructure comprises the control plane and data plane. EKS provides a production-grade Kubernetes control plane that is designed to be highly-available and fault-tolerant. In EKS, AWS is responsible for the reliability of the Kubernetes control plane. EKS runs Kubernetes control plane across three availability zones in an AWS Region. It automatically manages the availability and scalability of the Kubernetes API servers and the etcd cluster. The responsibility for the data plane\u2019s reliability is shared between you, the customer, and AWS. EKS offers three options for Kubernetes data plane. Fargate, which is the most managed option, handles provisioning and scaling of the data plane. The second option, managed nodes groups, handles provisioning, and updates of the data plane. And finally, self-managed nodes is the least managed option for the data plane. The more AWS-managed data plane you use, the less responsibility you have Managed node groups automate the provisioning and lifecycle management of EC2 nodes. You can use the EKS API (using EKS console, AWS API, AWS CLI, CloudFormation, Terraform, or eksctl ), to create, scale, and upgrade managed nodes. Managed nodes run EKS-optimized Amazon Linux 2 EC2 instances in your account, and you can install custom software packages by enabling SSH access. When you provision managed nodes, they run as part of an EKS-managed Auto Scaling Group that can span multiple Availability Zones; you control this through the subnets you provide when creating managed nodes. EKS also automatically tags managed nodes so they can be used with Cluster Autoscaler. Amazon EKS follows the shared responsibility model for CVEs and security patches on managed node groups. Because managed nodes run the Amazon EKS-optimized AMIs, Amazon EKS is responsible for building patched versions of these AMIs when bug fixes. However, you are responsible for deploying these patched AMI versions to your managed node groups. EKS also manages updating the nodes although you have to initiate the update process. The process of updating managed node is explained in the EKS documentation. If you run self-managed nodes, you can use Amazon EKS-optimized Linux AMI to create worker nodes. You are responsible for patching and upgrading the AMI and the nodes. It is a best practice to use eksctl , CloudFormation, or infrastructure as code tools to provision self-managed nodes because this will make it easy for you to upgrade self-managed nodes . Consider migrating to new nodes when updating worker nodes because the migration process taints the old node group as NoSchedule and drains the nodes after a new stack is ready to accept the existing pod workload. However, you can also perform an in-place upgrade of self-managed nodes . This guide includes a set of recommendations that you can use to improve the reliability of your EKS data plane, Kubernetes core components, and your applications.","title":"Introduction"},{"location":"reliability/docs/#feedback","text":"This guide is being released on GitHub to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. We intend to update the guide periodically as new features are added to the service or when a new best practice evolves.","title":"Feedback"},{"location":"reliability/docs/application/","text":"Running highly-available applications \u00b6 Your customers expect your application to be always available, including when you're making changes and especially during spikes in traffic. A scalable and resilient architecture keeps your applications and services running without disruptions, which keeps your users happy. A scalable infrastructure grows and shrinks based on the needs of the business. Eliminating single points of failure is a critical step towards improving an application\u2019s availability and making it resilient. With Kubernetes, you can operate your applications and run them in a highly-available and resilient fashion. Its declarative management ensures that once you\u2019ve set up the application, Kubernetes will continuously try to match the current state with the desired state . Recommendations \u00b6 Avoid running singleton Pods \u00b6 If your entire application runs in a single Pod, then your application will be unavailable if that Pod gets terminated. Instead of deploying applications using individual pods, create Deployments . If a Pod that is created by a Deployment fails or gets terminated, the Deployment controller will start a new pod to ensure the specified number of replica Pods are always running. Run multiple replicas \u00b6 Running multiple replicas Pods of an app using a Deployment helps it run in a highly-available manner. If one replica fails, the remaining replicas will still function, albeit at reduced capacity until Kubernetes creates another Pod to make up for the loss. Furthermore, you can use the Horizontal Pod Autoscaler to scale replicas automatically based on workload demand. Schedule replicas across nodes \u00b6 Running multiple replicas won\u2019t be very useful if all the replicas are running on the same node, and the node becomes unavailable. Consider using pod anti-affinity to spread replicas of a Deployment across multiple worker nodes. You can further improve a typical application\u2019s reliability by running it across multiple AZs. The manifest below tells Kubernetes scheduler to prefer to place pods on separate nodes and AZs. It doesn\u2019t require distinct nodes or AZ because if it did, then Kubernetes will not be able to schedule any pods once there is a pod running in each AZ. If your application requires just three replicas, you can use requiredDuringSchedulingIgnoredDuringExecution for topologyKey: topology.kubernetes.io/zone , and Kubernetes scheduler will not schedule two pods in the same AZ. piVersion : apps / v1 kind : Deployment metadata : name : spread - host - az labels : app : web - server spec : replicas : 4 selector : matchLabels : app : web - server template : metadata : labels : app : web - server spec : affinity : podAntiAffinity : preferredDuringSchedulingIgnoredDuringExecution : - podAffinityTerm : labelSelector : matchExpressions : - key : app operator : In values : - web - server topologyKey : topology . kubernetes . io / zone weight : 100 - podAffinityTerm : labelSelector : matchExpressions : - key : app operator : In values : - web - server topologyKey : kubernetes . io / hostname weight : 99 containers : - name : web - app image : nginx : 1.16 - alpine In version 1.18, Kubernetes introduced pod topology spread constraints , which allows you to spread Pods across AZs automatically. Run Kubernetes Metrics Server \u00b6 Install the Kubernetes metrics server to help scale your applications. Kubernetes autoscaler add-ons like HPA and VPA need to track metrics of applications to scale them. The metrics-server collects resource metrics that can be used to make scaling decisions. The metrics are collected from kubelets and served in Metrics API format . The metrics server doesn\u2019t retain any data, and it\u2019s not a monitoring solution. Its purpose is to expose CPU and memory usage metrics to other systems. If you want to track your application's state over time, you need a monitoring tool like Prometheus or Amazon CloudWatch. Follow the EKS documentation to install metrics-server in your EKS cluster. Horizontal Pod Autoscaler (HPA) \u00b6 HPA can automatically scale your application in response to demand and help you avoid impacting your customers during peak traffic. It is implemented as a control loop in Kubernetes that periodically queries metrics from APIs that provide resource metrics. HPA can retrieve metrics from the following APIs: 1. metrics.k8s.io also known as Resource Metrics API \u2014 Provides CPU and memory usage for pods 2. custom.metrics.k8s.io \u2014 Provides metrics from other metric collectors like Prometheus; these metrics are internal to your Kubernetes cluster. 3. external.metrics.k8s.io \u2014 Provides metrics that are external to your Kubernetes cluster (E.g., SQS Queue Depth, ELB latency). You must use one of these three APIs to provide the metric to scale your application. Scaling applications based on custom or external metrics \u00b6 You can use custom or external metrics to scale your application on metrics other than CPU or memory utilization. Custom Metrics API servers provide the custom-metrics.k8s.io API that HPA can use to autoscale applications. You can use the Prometheus Adapter for Kubernetes Metrics APIs to collect metrics from Prometheus and use with the HPA. In this case, Prometheus adapter will expose Prometheus metrics in Metrics API format . A list of all custom metrics implementation can be found in Kubernetes Documentation . Once you deploy the Prometheus Adapter, you can query custom metrics using kubectl. kubectl get \u2014raw /apis/custom.metrics.k8s.io/v1beta1/ External metrics , as the name suggests, provide the Horizontal Pod Autoscaler the ability to scale deployments using metrics that are external to the Kubernetes cluster. For example, in batch processing workloads, it is common to scale the number of replicas based on the number of jobs in flight in an SQS queue. To autoscale a Deployment using a CloudWatch metric, for example, scaling a batch-processor application based on SQS queue depth , you can use k8s-cloudwatch-adapter . k8s-cloudwatch-adapter is a community project and not maintained by AWS. Vertical Pod Autoscaler (VPA) \u00b6 VPA automatically adjusts the CPU and memory reservation for your Pods to help you \u201cright-size\u201d your applications. For applications that need to be scaled vertically - which is done by increasing resource allocation - you can use VPA to automatically scale Pod replicas or provide scaling recommendations. Your application may become temporarily unavailable if VPA needs to scale it because VPA\u2019s current implementation does not perform in-place adjustments to Pods; instead, it will recreate the Pod that needs to be scaled. EKS Documentation includes a walkthrough for setting up VPA. Fairwinds Goldilocks project provides a dashboard to visualize VPA recommendations for CPU and memory requests and limits. Its VPA update mode allows you to auto-scale Pods based on VPA recommendations. Updating applications \u00b6 Modern applications require rapid innovation with a high degree of stability and availability. Kubernetes gives you the tools to update your applications continuously without disrupting your customers. Let\u2019s look at some of the best practices that make it possible to quickly deploy changes without sacrificing availability. Have a mechanism to perform rollbacks \u00b6 Having an undo button can evade disasters. It is a best practice to test deployments in a separate lower environment (test or development environment) before updating the production cluster. Using a CI/CD pipeline can help you automate and test deployments. With a continuous deployment pipeline, you can quickly revert to the older version if the upgrade happens to be defective. You can use Deployments to update a running application. This is typically done by updating the container image. You can use kubectl to update a Deployment like this: kubectl --record deployment.apps/nginx-deployment set image nginx-deployment nginx = nginx:1.16.1 The --record argument record the changes to the Deployment and helps you if you need to perform a rollback. kubectl rollout history deployment shows you the recorded changes to Deployments in your cluster. You can rollback a change using kubectl rollout undo deployment <DEPLOYMENT_NAME> . By default, when you update a Deployment that requires a recreation of pods, Deployment will perform a rolling update . In other words, Kubernetes will only update a portion of the running pods in a Deployment and not all the Pods at once. You can control how Kubernetes performs rolling updates through RollingUpdateStrategy property. When performing a rolling update of a Deployment, you can use the Max Unavailable property to specify the maximum number of Pods that can be unavailable during the update. The Max Surge property of Deployment allows you to set the maximum number of Pods that can be created over the desired number of Pods. Consider adjusting max unavailable to ensure that a rollout doesn\u2019t disrupt your customers. For example, Kubernetes sets 25% max unavailable by default, which means if you have 100 Pods, you may have only 75 Pods actively working during a rollout. If your application needs a minimum of 80 Pods, this rollout can be disruptive. Instead, you can set max unavailable to 20% to ensure that there are at least 80 functional Pods throughout the rollout. Use blue/green deployments \u00b6 Changes are inherently risky, but changes that cannot be undone can be potentially catastrophic. Change procedures that allow you to effectively turn back time through a rollback make enhancements and experimentation safer. Blue/green deployments give you a method to quickly retract the changes if things go wrong. In this deployment strategy, you create an environment for the new version. This environment is identical to the current version of the application being updated. Once the new environment is provisioned, traffic is routed to the new environment. If the new version produces the desired results without generating errors, the old environment is terminated. Otherwise, traffic is restored to the old version. You can perform blue/green deployments in Kubernetes by creating a new Deployment that is identical to the existing version\u2019s Deployment. Once you verify that the Pods in the new Deployment are running without errors, you can start sending traffic to the new Deployment by changing the selector spec in the Service that routes traffic to your application\u2019s Pods. Many continuous integration tools such as Flux , Jenkins , and Spinnaker let you automate blue/green deployments. Kubernetes blog includes a walkthrough using Jenkins: Zero-downtime Deployment in Kubernetes with Jenkins Use Canary deployments \u00b6 Canary deployments are a variant of blue/green deployments that can significantly remove risk from changes. In this deployment strategy, you create a new Deployment with fewer Pods alongside your old Deployment, and divert a small percentage of traffic to the new Deployment. If metrics indicate that the new version is performing as well or better than the existing version, you progressively increase traffic to the new Deployment while scaling it up until all traffic is diverted to the new Deployment. If there's an issue, you can route all traffic to the old Deployment and stop sending traffic to the new Deployment. Although Kubernetes offers no native way to perform canary deployments, you can use tools such as Flagger with Istio or App Mesh . Health checks and self-healing \u00b6 No software is bug-free, but Kubernetes can help you to minimize the impact of software failures. In the past, if an application crashed, someone had to remediate the situation by restarting the application manually. Kubernetes gives you the ability to detect software failures in your Pods and automatically replace them with new replicas. With Kubernetes you can monitor the health of your applications and automatically replace unhealthy instances. Kubernetes supports three types of health-checks : Liveness probe Startup probe (supported in Kubernetes version 1.16+) Readiness probe Kubelet , the Kubernetes agent, is responsible for running all the above-mentioned checks. Kubelet can check a Pods' health in three ways: kubelet can either run a shell command inside a Pod's container, send an HTTP GET request to its container, or open a TCP socket on a specified port. If you choose an exec -based probe, which runs a shell script inside a container, ensure that the shell command exits before the timeoutSeconds value expires. Otherwise, your node will have <defunct> processes, leading to node failure. Recommendations \u00b6 Use Liveness Probe to remove unhealthy pods \u00b6 The Liveness probe can detect deadlock conditions where the process continues to run, but the application becomes unresponsive. For example, if you are running a web service that listens on port 80, you can configure a Liveness probe to send an HTTP GET request on Pod\u2019s port 80. Kubelet will periodically send a GET request to the Pod and expect a response; if the Pod responds between 200-399 then the kubelet considers that Pod is healthy; otherwise, the Pod will be marked as unhealthy. If a Pod fails health-checks continuously, the kubelet will terminate it. You can use initialDelaySeconds to delay the first probe. When using the Liveness Probe, ensure that your application doesn\u2019t run into a situation in which all Pods simultaneously fail the Liveness Probe because Kubernetes will try to replace all your Pods, which will render your application offline. Furthermore, Kubernetes will continue to create new Pods that will also fail Liveness Probes, putting unnecessary strain on the control plane. Avoid configuring the Liveness Probe to depend on an a factor that is external to your Pod, for example, a external database. In other words, a non-responsive external-to-your-Pod database shouldn\u2019t make your Pods fail their Liveness Probes. Sandor Sz\u00fccs\u2019s post LIVENESS PROBES ARE DANGEROUS describes problems that can be caused by misconfigured probes. Use Startup Probe for applications that take longer to start \u00b6 When your app needs additional time to startup, you can use the Startup Probe to delay the Liveness and Readiness Probe. For example, a Java app that needs to hydrate cache from a database may need up to two minutes before it is fully functional. Any Liveness or Readiness Probe until it becomes fully functional might fail. Configuring a Startup Probe will allow the Java app to become healthy before Liveness or Readiness Probe are executed. Until the Startup Probe succeeds, all the other Probes are disabled. You can define the maximum time Kubernetes should wait for application startup. If, after the maximum configured time, the Pod still fails Startup Probes, it will be terminated, and a new Pod will be created. The Startup Probe is similar to the Liveness Probe -- if they fail, the Pod is recreated. As Ricardo A. explains in his post Fantastic Probes And How To Configure Them , Startup Probes should be used when the startup time of an application is unpredictable. If you know your application needs ten seconds to start, use should use Liveness/Readiness Probe with initialDelaySeconds instead. Use Readiness Probe to detect partial unavailability \u00b6 While the Liveness probe detects failures in an app that are resolved by terminating the Pod (hence, restarting the app), Readiness Probe detects conditions where the app may be temporarily unavailable. In these situations, the app may become temporarily unresponsive; however, it is expected to be healthy again once this operation completes. For example, during intense disk I/O operations, applications may be temporarily unavailable to handle requests. Here, terminating the application\u2019s Pod is not a remedy; at the same time, additional requests sent to the Pod can fail. You can use the Readiness Probe to detect temporary unavailability in your app and stop sending requests to its Pod until it becomes functional again. Unlike Liveness Probe, where a failure would result in a recreation of Pod, a failed Readiness Probe would mean that Pod will not receive any traffic from Kubernetes Service . When the Readiness Probe succeeds, Pod will resume receiving traffic from Service. Just like the Liveness Probe, avoid configuring Readiness Probes that depend on a resource that\u2019s external to the Pod (such as a database). Here\u2019s a scenario where a poorly configured Readiness can render the application nonfunctional - if a Pod\u2019s Readiness Probe fails when the app\u2019s database is unreachable, other Pod replicas will also fail simultaneously since they share the same health-check criteria. Setting the probe in this way will ensure that whenever the database is unavailable, the Pod\u2019s Readiness Probes will fail, and Kubernetes will stop sending traffic all Pods. A side-effect of using Readiness Probes is that they can increase the time it takes to update Deployments. New replicas will not receive traffic unless Readiness Probes are successful; until then, old replicas will continue to receive traffic. Dealing with disruptions \u00b6 Pods have a finite lifetime - even if you have long-running Pods, it\u2019s prudent to ensure Pods terminate correctly when the time comes. Depending on your upgrade strategy, Kubernetes cluster upgrades may require you to create new worker nodes, which requires all Pods to be recreated on newer nodes. Proper termination handling and Pod Disruption Budgets can help you avoid service disruptions as Pods are removed from older nodes and recreated on newer nodes. The preferred way to upgrade worker nodes is by creating new worker nodes and terminating old ones. Before terminating worker nodes, you should drain it. When a worker node is drained, all its pods are safely evicted. Safely is a key word here; when pods on a worker are evicted, they are not simply sent a SIGKILL signal. Instead, a SIGTERM signal is sent to the main process (PID 1) of each container in the Pods being evicted. After the SIGTERM signal is sent, Kubernetes will give the process some time (grace period) before a SIGKILL signal is sent. This grace period is 30 seconds by default; you can override the default by using grace-period flag in kubectl or declare terminationGracePeriodSeconds in your Podspec. kubectl delete pod <pod name> \u2014grace-period=<seconds> It is common to have containers in which the main process doesn\u2019t have PID 1. Consider this Python-based sample container: $ kubectl exec python-app -it ps PID USER TIME COMMAND 1 root 0 :00 { script.sh } /bin/sh ./script.sh 5 root 0 :00 python app.py In this example, the shell script receives SIGTERM , the main process, which happens to be a Python application in this example, doesn\u2019t get a SIGTERM signal. When the Pod is terminated, the Python application will be killed abruptly. This can be remediated by changing the ENTRYPOINT of the container to launch the Python application. Alternatively, you can use a tool like dumb-init to ensure that your application can handle signals. You can also use Container hooks to execute a script or an HTTP request at container start or stop. The PreStop hook action runs before the container receives a SIGTERM signal and must complete before this signal is sent. The terminationGracePeriodSeconds value applies from when the PreStop hook action begins executing, not when the SIGTERM signal is sent. Recommendations \u00b6 Protect critical workload with Pod Disruption Budgets \u00b6 Pod Disruption Budget or PDB can temporarily halt the eviction process if the number of replicas of an application falls below the declared threshold. The eviction process will continue once the number of available replicas is over the threshold. You can use PDB to declare the minAvailable and maxUnavailable number of replicas. For example, if you want at least three copies of your app to be available, you can create a PDB. apiVersion : policy / v1beta1 kind : PodDisruptionBudget metadata : name : my - svc - pdb spec : minAvailable : 3 selector : matchLabels : app : my - svc The above PDB policy tells Kubernetes to halt the eviction process until three or more replicas are available. Node draining respects PodDisruptionBudgets . During an EKS managed node group upgrade, nodes are drained with a fifteen-minute timeout . After fifteen minutes, if the update is not forced (the option is called Rolling update in the EKS console), the update fails. If the update is forced, the pods are deleted. For self-managed nodes, you can also use tools like AWS Node Termination Handler , which ensures that the Kubernetes control plane responds appropriately to events that can cause your EC2 instance to become unavailable, such as EC2 maintenance events and EC2 Spot interruptions . It uses the Kubernetes API to cordon the node to ensure no new Pods are scheduled, then drains it, terminating any running Pods. You can use Pod anti-affinity to schedule a Deployment\u2018s Pods on different nodes and avoid PDB related delays during node upgrades. Practice chaos engineering \u00b6 Chaos Engineering is the discipline of experimenting on a distributed system in order to build confidence in the system\u2019s capability to withstand turbulent conditions in production. In his blog, Dominik Tornow explains that Kubernetes is a declarative system where \u201c the user supplies a representation of the desired state of the system to the system. The system then considers the current state and the desired state to determine the sequence of commands to transition from the current state to the desired state. \u201d This means Kubernetes always stores the desired state and if the system deviates, Kubernetes will take action to restore the state. For example, if a worker node becomes unavailable, Kubernetes will reschedule the Pods onto another worker node. Similarly, if a replica crashes, the Deployment Contoller will create a new replica . In this way, Kubernetes controllers automatically fix failures. Chaos engineering tools like Gremlin help you test the resiliency of your Kubernetes cluster and identify single points of failure. Tools that introduce artificial chaos in your cluster (and beyond) can uncover systemic weaknesses, present an opportunity to identify bottlenecks and misconfigurations, and rectify problems in a controlled environment. The Chaos Engineering philosophy advocates breaking things on purpose and stress testing infrastructure to minimize unanticipated downtime. Use a Service Mesh \u00b6 You can use a service mesh to improve your application\u2019s resiliency. Service meshes enable service-to-service communication and increase the observability of your microservices network. Most service mesh products work by having a small network proxy run alongside each service that intercepts and inspects the application\u2019s network traffic. You can place your application in a mesh without modifying your application. Using service proxy\u2019s built-in features, you can have it generate network statistics, create access logs, and add HTTP headers to outbound requests for distributed tracing. A service mesh can help you make your microservices more resilient with features like automatic request retries, timeouts, circuit-breaking, and rate-limiting. If you operate multiple clusters, you can use a service mesh to enable cross-cluster service-to-service communication. Service Meshes \u00b6 AWS App Mesh Istio LinkerD Consul Observability \u00b6 Observability is an umbrella term that includes monitoring, logging, and tracing. Microservices based applications are distributed by nature. Unlike monolithic applications where monitoring a single system is sufficient, in a distributed application architecture, you need to monitor each component\u2019s performance. You can use cluster-level monitoring, logging, and distributed tracing systems to identify issues in your cluster before they disrupt your customers. Kubernetes built-in tools for troubleshooting and monitoring are limited. The metrics-server collects resource metrics and stores them in memory but doesn\u2019t persist them. You can view the logs of a Pod using kubectl, but Kubernetes doesn't automatically retain logs. And the implementation of distributed tracing is done either at the application code level or using services meshes. Kubernetes' extensibility shines here. Kubernetes allows you to bring your preferred centralized monitoring, logging, and tracing solution. Recommendations \u00b6 Monitor your applications \u00b6 The number of metrics you need to monitor in modern applications is growing continuously. It helps if you have an automated way to track your applications so you can focus on solving your customer\u2019s challenges. Cluster-wide monitoring tools like Prometheus or CloudWatch Container Insights can monitor your cluster and workload and provide you signals when, or preferably, before things go wrong. Monitoring tools allow you to create alerts that your operations team can subscribe to. Consider rules to activate alarms for events that can, when exacerbated, lead to an outage or impact application performance. If you\u2019re unclear on which metrics you should monitor, you can take inspiration from these methods: RED method . Stands for requests, errors, and duration. USE method . Stands for utilization, saturation, and errors. Sysdig\u2019s post Best practices for alerting on Kubernetes includes a comprehensive list of components that can impact the availability of your applications. Use Prometheus client library to expose application metrics \u00b6 In addition to monitoring the state of the application and aggregating standard metrics, you can also use the Prometheus client library to expose application-specific custom metrics to improve the application's observability. Use centralized logging tools to collect and persist logs \u00b6 Logging in EKS falls under two categories: control plane logs and application logs. EKS control plane logging provides audit and diagnostic logs directly from the control plane to CloudWatch Logs in your account. Application logs are logs produced by Pods running inside your cluster. Application logs include logs produced by Pods that run the business logic applications and Kubernetes system components such as CoreDNS, Cluster Autoscaler, Prometheus, etc. EKS provide five types of control plane logs : Kubernetes API server component logs Audit Authenticator Controller manager Scheduler The controller manager and scheduler logs can help diagnose control plane problems such as bottlenecks and errors. By default, EKS control plane logs aren\u2019t sent to CloudWatch Logs. You can enable control plane logging and select the types of EKS control plane logs you\u2019d like to capture for each cluster in your account Collecting application logs requires installing a log aggregator tool like Fluent Bit , Fluentd , or CloudWatch Container Insights in your cluster. Kubernetes log aggregator tools run as DaemonSets and scrape container logs from nodes. Application logs are then sent to a centralized destination for storage. For example, CloudWatch Container Insights can use either Fluent Bit or Fluentd to collect logs and ship them to CloudWatch Logs for storage. Fluent Bit and Fluentd support many popular log analytics systems such as Elasticsearch and InfluxDB giving you the ability to change the storage backend for your logs by modifying Fluent bit or Fluentd\u2019s log configuration. Use a distributed tracing system to identify bottlenecks \u00b6 A typical modern application has components distributed over the network, and its reliability depends on the proper functioning of each of the components that make up the application. You can use a distributed tracing solution to understand how requests flow and how systems communicate. Traces can show you where bottlenecks exist in your application network and prevent problems that can cause cascading failures. You have two options to implement tracing in your applications: you can either implement distributed tracing at the code level using shared libraries or use a service mesh. Implementing tracing at the code level can be disadvantageous. In this method, you have to make changes to your code. This is further complicated if you have polyglot applications. You\u2019re also responsible for maintaining yet another library, across your services. Service Meshes like LinkerD , Istio , and AWS App Mesh can be used to implement distributed tracing in your application with minimal changes to the application code. You can use service mesh to standardize metrics generation, logging, and tracing. Tracing tools like AWS X-Ray , Jaeger support both shared library and service mesh implementations. Consider using a tracing tool like AWS X-Ray or Jaeger that supports both (shared library and service mesh) implementations so you will not have to switch tools if you later adopt service mesh.","title":"Applications"},{"location":"reliability/docs/application/#running-highly-available-applications","text":"Your customers expect your application to be always available, including when you're making changes and especially during spikes in traffic. A scalable and resilient architecture keeps your applications and services running without disruptions, which keeps your users happy. A scalable infrastructure grows and shrinks based on the needs of the business. Eliminating single points of failure is a critical step towards improving an application\u2019s availability and making it resilient. With Kubernetes, you can operate your applications and run them in a highly-available and resilient fashion. Its declarative management ensures that once you\u2019ve set up the application, Kubernetes will continuously try to match the current state with the desired state .","title":"Running highly-available applications"},{"location":"reliability/docs/application/#recommendations","text":"","title":"Recommendations"},{"location":"reliability/docs/application/#avoid-running-singleton-pods","text":"If your entire application runs in a single Pod, then your application will be unavailable if that Pod gets terminated. Instead of deploying applications using individual pods, create Deployments . If a Pod that is created by a Deployment fails or gets terminated, the Deployment controller will start a new pod to ensure the specified number of replica Pods are always running.","title":"Avoid running singleton Pods"},{"location":"reliability/docs/application/#run-multiple-replicas","text":"Running multiple replicas Pods of an app using a Deployment helps it run in a highly-available manner. If one replica fails, the remaining replicas will still function, albeit at reduced capacity until Kubernetes creates another Pod to make up for the loss. Furthermore, you can use the Horizontal Pod Autoscaler to scale replicas automatically based on workload demand.","title":"Run multiple replicas"},{"location":"reliability/docs/application/#schedule-replicas-across-nodes","text":"Running multiple replicas won\u2019t be very useful if all the replicas are running on the same node, and the node becomes unavailable. Consider using pod anti-affinity to spread replicas of a Deployment across multiple worker nodes. You can further improve a typical application\u2019s reliability by running it across multiple AZs. The manifest below tells Kubernetes scheduler to prefer to place pods on separate nodes and AZs. It doesn\u2019t require distinct nodes or AZ because if it did, then Kubernetes will not be able to schedule any pods once there is a pod running in each AZ. If your application requires just three replicas, you can use requiredDuringSchedulingIgnoredDuringExecution for topologyKey: topology.kubernetes.io/zone , and Kubernetes scheduler will not schedule two pods in the same AZ. piVersion : apps / v1 kind : Deployment metadata : name : spread - host - az labels : app : web - server spec : replicas : 4 selector : matchLabels : app : web - server template : metadata : labels : app : web - server spec : affinity : podAntiAffinity : preferredDuringSchedulingIgnoredDuringExecution : - podAffinityTerm : labelSelector : matchExpressions : - key : app operator : In values : - web - server topologyKey : topology . kubernetes . io / zone weight : 100 - podAffinityTerm : labelSelector : matchExpressions : - key : app operator : In values : - web - server topologyKey : kubernetes . io / hostname weight : 99 containers : - name : web - app image : nginx : 1.16 - alpine In version 1.18, Kubernetes introduced pod topology spread constraints , which allows you to spread Pods across AZs automatically.","title":"Schedule replicas across nodes"},{"location":"reliability/docs/application/#run-kubernetes-metrics-server","text":"Install the Kubernetes metrics server to help scale your applications. Kubernetes autoscaler add-ons like HPA and VPA need to track metrics of applications to scale them. The metrics-server collects resource metrics that can be used to make scaling decisions. The metrics are collected from kubelets and served in Metrics API format . The metrics server doesn\u2019t retain any data, and it\u2019s not a monitoring solution. Its purpose is to expose CPU and memory usage metrics to other systems. If you want to track your application's state over time, you need a monitoring tool like Prometheus or Amazon CloudWatch. Follow the EKS documentation to install metrics-server in your EKS cluster.","title":"Run Kubernetes Metrics Server"},{"location":"reliability/docs/application/#horizontal-pod-autoscaler-hpa","text":"HPA can automatically scale your application in response to demand and help you avoid impacting your customers during peak traffic. It is implemented as a control loop in Kubernetes that periodically queries metrics from APIs that provide resource metrics. HPA can retrieve metrics from the following APIs: 1. metrics.k8s.io also known as Resource Metrics API \u2014 Provides CPU and memory usage for pods 2. custom.metrics.k8s.io \u2014 Provides metrics from other metric collectors like Prometheus; these metrics are internal to your Kubernetes cluster. 3. external.metrics.k8s.io \u2014 Provides metrics that are external to your Kubernetes cluster (E.g., SQS Queue Depth, ELB latency). You must use one of these three APIs to provide the metric to scale your application.","title":"Horizontal Pod Autoscaler (HPA)"},{"location":"reliability/docs/application/#scaling-applications-based-on-custom-or-external-metrics","text":"You can use custom or external metrics to scale your application on metrics other than CPU or memory utilization. Custom Metrics API servers provide the custom-metrics.k8s.io API that HPA can use to autoscale applications. You can use the Prometheus Adapter for Kubernetes Metrics APIs to collect metrics from Prometheus and use with the HPA. In this case, Prometheus adapter will expose Prometheus metrics in Metrics API format . A list of all custom metrics implementation can be found in Kubernetes Documentation . Once you deploy the Prometheus Adapter, you can query custom metrics using kubectl. kubectl get \u2014raw /apis/custom.metrics.k8s.io/v1beta1/ External metrics , as the name suggests, provide the Horizontal Pod Autoscaler the ability to scale deployments using metrics that are external to the Kubernetes cluster. For example, in batch processing workloads, it is common to scale the number of replicas based on the number of jobs in flight in an SQS queue. To autoscale a Deployment using a CloudWatch metric, for example, scaling a batch-processor application based on SQS queue depth , you can use k8s-cloudwatch-adapter . k8s-cloudwatch-adapter is a community project and not maintained by AWS.","title":"Scaling applications based on custom or external metrics"},{"location":"reliability/docs/application/#vertical-pod-autoscaler-vpa","text":"VPA automatically adjusts the CPU and memory reservation for your Pods to help you \u201cright-size\u201d your applications. For applications that need to be scaled vertically - which is done by increasing resource allocation - you can use VPA to automatically scale Pod replicas or provide scaling recommendations. Your application may become temporarily unavailable if VPA needs to scale it because VPA\u2019s current implementation does not perform in-place adjustments to Pods; instead, it will recreate the Pod that needs to be scaled. EKS Documentation includes a walkthrough for setting up VPA. Fairwinds Goldilocks project provides a dashboard to visualize VPA recommendations for CPU and memory requests and limits. Its VPA update mode allows you to auto-scale Pods based on VPA recommendations.","title":"Vertical Pod Autoscaler (VPA)"},{"location":"reliability/docs/application/#updating-applications","text":"Modern applications require rapid innovation with a high degree of stability and availability. Kubernetes gives you the tools to update your applications continuously without disrupting your customers. Let\u2019s look at some of the best practices that make it possible to quickly deploy changes without sacrificing availability.","title":"Updating applications"},{"location":"reliability/docs/application/#have-a-mechanism-to-perform-rollbacks","text":"Having an undo button can evade disasters. It is a best practice to test deployments in a separate lower environment (test or development environment) before updating the production cluster. Using a CI/CD pipeline can help you automate and test deployments. With a continuous deployment pipeline, you can quickly revert to the older version if the upgrade happens to be defective. You can use Deployments to update a running application. This is typically done by updating the container image. You can use kubectl to update a Deployment like this: kubectl --record deployment.apps/nginx-deployment set image nginx-deployment nginx = nginx:1.16.1 The --record argument record the changes to the Deployment and helps you if you need to perform a rollback. kubectl rollout history deployment shows you the recorded changes to Deployments in your cluster. You can rollback a change using kubectl rollout undo deployment <DEPLOYMENT_NAME> . By default, when you update a Deployment that requires a recreation of pods, Deployment will perform a rolling update . In other words, Kubernetes will only update a portion of the running pods in a Deployment and not all the Pods at once. You can control how Kubernetes performs rolling updates through RollingUpdateStrategy property. When performing a rolling update of a Deployment, you can use the Max Unavailable property to specify the maximum number of Pods that can be unavailable during the update. The Max Surge property of Deployment allows you to set the maximum number of Pods that can be created over the desired number of Pods. Consider adjusting max unavailable to ensure that a rollout doesn\u2019t disrupt your customers. For example, Kubernetes sets 25% max unavailable by default, which means if you have 100 Pods, you may have only 75 Pods actively working during a rollout. If your application needs a minimum of 80 Pods, this rollout can be disruptive. Instead, you can set max unavailable to 20% to ensure that there are at least 80 functional Pods throughout the rollout.","title":"Have a mechanism to perform rollbacks"},{"location":"reliability/docs/application/#use-bluegreen-deployments","text":"Changes are inherently risky, but changes that cannot be undone can be potentially catastrophic. Change procedures that allow you to effectively turn back time through a rollback make enhancements and experimentation safer. Blue/green deployments give you a method to quickly retract the changes if things go wrong. In this deployment strategy, you create an environment for the new version. This environment is identical to the current version of the application being updated. Once the new environment is provisioned, traffic is routed to the new environment. If the new version produces the desired results without generating errors, the old environment is terminated. Otherwise, traffic is restored to the old version. You can perform blue/green deployments in Kubernetes by creating a new Deployment that is identical to the existing version\u2019s Deployment. Once you verify that the Pods in the new Deployment are running without errors, you can start sending traffic to the new Deployment by changing the selector spec in the Service that routes traffic to your application\u2019s Pods. Many continuous integration tools such as Flux , Jenkins , and Spinnaker let you automate blue/green deployments. Kubernetes blog includes a walkthrough using Jenkins: Zero-downtime Deployment in Kubernetes with Jenkins","title":"Use blue/green deployments"},{"location":"reliability/docs/application/#use-canary-deployments","text":"Canary deployments are a variant of blue/green deployments that can significantly remove risk from changes. In this deployment strategy, you create a new Deployment with fewer Pods alongside your old Deployment, and divert a small percentage of traffic to the new Deployment. If metrics indicate that the new version is performing as well or better than the existing version, you progressively increase traffic to the new Deployment while scaling it up until all traffic is diverted to the new Deployment. If there's an issue, you can route all traffic to the old Deployment and stop sending traffic to the new Deployment. Although Kubernetes offers no native way to perform canary deployments, you can use tools such as Flagger with Istio or App Mesh .","title":"Use Canary deployments"},{"location":"reliability/docs/application/#health-checks-and-self-healing","text":"No software is bug-free, but Kubernetes can help you to minimize the impact of software failures. In the past, if an application crashed, someone had to remediate the situation by restarting the application manually. Kubernetes gives you the ability to detect software failures in your Pods and automatically replace them with new replicas. With Kubernetes you can monitor the health of your applications and automatically replace unhealthy instances. Kubernetes supports three types of health-checks : Liveness probe Startup probe (supported in Kubernetes version 1.16+) Readiness probe Kubelet , the Kubernetes agent, is responsible for running all the above-mentioned checks. Kubelet can check a Pods' health in three ways: kubelet can either run a shell command inside a Pod's container, send an HTTP GET request to its container, or open a TCP socket on a specified port. If you choose an exec -based probe, which runs a shell script inside a container, ensure that the shell command exits before the timeoutSeconds value expires. Otherwise, your node will have <defunct> processes, leading to node failure.","title":"Health checks and self-healing"},{"location":"reliability/docs/application/#recommendations_1","text":"","title":"Recommendations"},{"location":"reliability/docs/application/#use-liveness-probe-to-remove-unhealthy-pods","text":"The Liveness probe can detect deadlock conditions where the process continues to run, but the application becomes unresponsive. For example, if you are running a web service that listens on port 80, you can configure a Liveness probe to send an HTTP GET request on Pod\u2019s port 80. Kubelet will periodically send a GET request to the Pod and expect a response; if the Pod responds between 200-399 then the kubelet considers that Pod is healthy; otherwise, the Pod will be marked as unhealthy. If a Pod fails health-checks continuously, the kubelet will terminate it. You can use initialDelaySeconds to delay the first probe. When using the Liveness Probe, ensure that your application doesn\u2019t run into a situation in which all Pods simultaneously fail the Liveness Probe because Kubernetes will try to replace all your Pods, which will render your application offline. Furthermore, Kubernetes will continue to create new Pods that will also fail Liveness Probes, putting unnecessary strain on the control plane. Avoid configuring the Liveness Probe to depend on an a factor that is external to your Pod, for example, a external database. In other words, a non-responsive external-to-your-Pod database shouldn\u2019t make your Pods fail their Liveness Probes. Sandor Sz\u00fccs\u2019s post LIVENESS PROBES ARE DANGEROUS describes problems that can be caused by misconfigured probes.","title":"Use Liveness Probe to remove unhealthy pods"},{"location":"reliability/docs/application/#use-startup-probe-for-applications-that-take-longer-to-start","text":"When your app needs additional time to startup, you can use the Startup Probe to delay the Liveness and Readiness Probe. For example, a Java app that needs to hydrate cache from a database may need up to two minutes before it is fully functional. Any Liveness or Readiness Probe until it becomes fully functional might fail. Configuring a Startup Probe will allow the Java app to become healthy before Liveness or Readiness Probe are executed. Until the Startup Probe succeeds, all the other Probes are disabled. You can define the maximum time Kubernetes should wait for application startup. If, after the maximum configured time, the Pod still fails Startup Probes, it will be terminated, and a new Pod will be created. The Startup Probe is similar to the Liveness Probe -- if they fail, the Pod is recreated. As Ricardo A. explains in his post Fantastic Probes And How To Configure Them , Startup Probes should be used when the startup time of an application is unpredictable. If you know your application needs ten seconds to start, use should use Liveness/Readiness Probe with initialDelaySeconds instead.","title":"Use Startup Probe for applications that take longer to start"},{"location":"reliability/docs/application/#use-readiness-probe-to-detect-partial-unavailability","text":"While the Liveness probe detects failures in an app that are resolved by terminating the Pod (hence, restarting the app), Readiness Probe detects conditions where the app may be temporarily unavailable. In these situations, the app may become temporarily unresponsive; however, it is expected to be healthy again once this operation completes. For example, during intense disk I/O operations, applications may be temporarily unavailable to handle requests. Here, terminating the application\u2019s Pod is not a remedy; at the same time, additional requests sent to the Pod can fail. You can use the Readiness Probe to detect temporary unavailability in your app and stop sending requests to its Pod until it becomes functional again. Unlike Liveness Probe, where a failure would result in a recreation of Pod, a failed Readiness Probe would mean that Pod will not receive any traffic from Kubernetes Service . When the Readiness Probe succeeds, Pod will resume receiving traffic from Service. Just like the Liveness Probe, avoid configuring Readiness Probes that depend on a resource that\u2019s external to the Pod (such as a database). Here\u2019s a scenario where a poorly configured Readiness can render the application nonfunctional - if a Pod\u2019s Readiness Probe fails when the app\u2019s database is unreachable, other Pod replicas will also fail simultaneously since they share the same health-check criteria. Setting the probe in this way will ensure that whenever the database is unavailable, the Pod\u2019s Readiness Probes will fail, and Kubernetes will stop sending traffic all Pods. A side-effect of using Readiness Probes is that they can increase the time it takes to update Deployments. New replicas will not receive traffic unless Readiness Probes are successful; until then, old replicas will continue to receive traffic.","title":"Use Readiness Probe to detect partial unavailability"},{"location":"reliability/docs/application/#dealing-with-disruptions","text":"Pods have a finite lifetime - even if you have long-running Pods, it\u2019s prudent to ensure Pods terminate correctly when the time comes. Depending on your upgrade strategy, Kubernetes cluster upgrades may require you to create new worker nodes, which requires all Pods to be recreated on newer nodes. Proper termination handling and Pod Disruption Budgets can help you avoid service disruptions as Pods are removed from older nodes and recreated on newer nodes. The preferred way to upgrade worker nodes is by creating new worker nodes and terminating old ones. Before terminating worker nodes, you should drain it. When a worker node is drained, all its pods are safely evicted. Safely is a key word here; when pods on a worker are evicted, they are not simply sent a SIGKILL signal. Instead, a SIGTERM signal is sent to the main process (PID 1) of each container in the Pods being evicted. After the SIGTERM signal is sent, Kubernetes will give the process some time (grace period) before a SIGKILL signal is sent. This grace period is 30 seconds by default; you can override the default by using grace-period flag in kubectl or declare terminationGracePeriodSeconds in your Podspec. kubectl delete pod <pod name> \u2014grace-period=<seconds> It is common to have containers in which the main process doesn\u2019t have PID 1. Consider this Python-based sample container: $ kubectl exec python-app -it ps PID USER TIME COMMAND 1 root 0 :00 { script.sh } /bin/sh ./script.sh 5 root 0 :00 python app.py In this example, the shell script receives SIGTERM , the main process, which happens to be a Python application in this example, doesn\u2019t get a SIGTERM signal. When the Pod is terminated, the Python application will be killed abruptly. This can be remediated by changing the ENTRYPOINT of the container to launch the Python application. Alternatively, you can use a tool like dumb-init to ensure that your application can handle signals. You can also use Container hooks to execute a script or an HTTP request at container start or stop. The PreStop hook action runs before the container receives a SIGTERM signal and must complete before this signal is sent. The terminationGracePeriodSeconds value applies from when the PreStop hook action begins executing, not when the SIGTERM signal is sent.","title":"Dealing with disruptions"},{"location":"reliability/docs/application/#recommendations_2","text":"","title":"Recommendations"},{"location":"reliability/docs/application/#protect-critical-workload-with-pod-disruption-budgets","text":"Pod Disruption Budget or PDB can temporarily halt the eviction process if the number of replicas of an application falls below the declared threshold. The eviction process will continue once the number of available replicas is over the threshold. You can use PDB to declare the minAvailable and maxUnavailable number of replicas. For example, if you want at least three copies of your app to be available, you can create a PDB. apiVersion : policy / v1beta1 kind : PodDisruptionBudget metadata : name : my - svc - pdb spec : minAvailable : 3 selector : matchLabels : app : my - svc The above PDB policy tells Kubernetes to halt the eviction process until three or more replicas are available. Node draining respects PodDisruptionBudgets . During an EKS managed node group upgrade, nodes are drained with a fifteen-minute timeout . After fifteen minutes, if the update is not forced (the option is called Rolling update in the EKS console), the update fails. If the update is forced, the pods are deleted. For self-managed nodes, you can also use tools like AWS Node Termination Handler , which ensures that the Kubernetes control plane responds appropriately to events that can cause your EC2 instance to become unavailable, such as EC2 maintenance events and EC2 Spot interruptions . It uses the Kubernetes API to cordon the node to ensure no new Pods are scheduled, then drains it, terminating any running Pods. You can use Pod anti-affinity to schedule a Deployment\u2018s Pods on different nodes and avoid PDB related delays during node upgrades.","title":"Protect critical workload with Pod Disruption Budgets"},{"location":"reliability/docs/application/#practice-chaos-engineering","text":"Chaos Engineering is the discipline of experimenting on a distributed system in order to build confidence in the system\u2019s capability to withstand turbulent conditions in production. In his blog, Dominik Tornow explains that Kubernetes is a declarative system where \u201c the user supplies a representation of the desired state of the system to the system. The system then considers the current state and the desired state to determine the sequence of commands to transition from the current state to the desired state. \u201d This means Kubernetes always stores the desired state and if the system deviates, Kubernetes will take action to restore the state. For example, if a worker node becomes unavailable, Kubernetes will reschedule the Pods onto another worker node. Similarly, if a replica crashes, the Deployment Contoller will create a new replica . In this way, Kubernetes controllers automatically fix failures. Chaos engineering tools like Gremlin help you test the resiliency of your Kubernetes cluster and identify single points of failure. Tools that introduce artificial chaos in your cluster (and beyond) can uncover systemic weaknesses, present an opportunity to identify bottlenecks and misconfigurations, and rectify problems in a controlled environment. The Chaos Engineering philosophy advocates breaking things on purpose and stress testing infrastructure to minimize unanticipated downtime.","title":"Practice chaos engineering"},{"location":"reliability/docs/application/#use-a-service-mesh","text":"You can use a service mesh to improve your application\u2019s resiliency. Service meshes enable service-to-service communication and increase the observability of your microservices network. Most service mesh products work by having a small network proxy run alongside each service that intercepts and inspects the application\u2019s network traffic. You can place your application in a mesh without modifying your application. Using service proxy\u2019s built-in features, you can have it generate network statistics, create access logs, and add HTTP headers to outbound requests for distributed tracing. A service mesh can help you make your microservices more resilient with features like automatic request retries, timeouts, circuit-breaking, and rate-limiting. If you operate multiple clusters, you can use a service mesh to enable cross-cluster service-to-service communication.","title":"Use a Service Mesh"},{"location":"reliability/docs/application/#service-meshes","text":"AWS App Mesh Istio LinkerD Consul","title":"Service Meshes"},{"location":"reliability/docs/application/#observability","text":"Observability is an umbrella term that includes monitoring, logging, and tracing. Microservices based applications are distributed by nature. Unlike monolithic applications where monitoring a single system is sufficient, in a distributed application architecture, you need to monitor each component\u2019s performance. You can use cluster-level monitoring, logging, and distributed tracing systems to identify issues in your cluster before they disrupt your customers. Kubernetes built-in tools for troubleshooting and monitoring are limited. The metrics-server collects resource metrics and stores them in memory but doesn\u2019t persist them. You can view the logs of a Pod using kubectl, but Kubernetes doesn't automatically retain logs. And the implementation of distributed tracing is done either at the application code level or using services meshes. Kubernetes' extensibility shines here. Kubernetes allows you to bring your preferred centralized monitoring, logging, and tracing solution.","title":"Observability"},{"location":"reliability/docs/application/#recommendations_3","text":"","title":"Recommendations"},{"location":"reliability/docs/application/#monitor-your-applications","text":"The number of metrics you need to monitor in modern applications is growing continuously. It helps if you have an automated way to track your applications so you can focus on solving your customer\u2019s challenges. Cluster-wide monitoring tools like Prometheus or CloudWatch Container Insights can monitor your cluster and workload and provide you signals when, or preferably, before things go wrong. Monitoring tools allow you to create alerts that your operations team can subscribe to. Consider rules to activate alarms for events that can, when exacerbated, lead to an outage or impact application performance. If you\u2019re unclear on which metrics you should monitor, you can take inspiration from these methods: RED method . Stands for requests, errors, and duration. USE method . Stands for utilization, saturation, and errors. Sysdig\u2019s post Best practices for alerting on Kubernetes includes a comprehensive list of components that can impact the availability of your applications.","title":"Monitor your applications"},{"location":"reliability/docs/application/#use-prometheus-client-library-to-expose-application-metrics","text":"In addition to monitoring the state of the application and aggregating standard metrics, you can also use the Prometheus client library to expose application-specific custom metrics to improve the application's observability.","title":"Use Prometheus client library to expose application metrics"},{"location":"reliability/docs/application/#use-centralized-logging-tools-to-collect-and-persist-logs","text":"Logging in EKS falls under two categories: control plane logs and application logs. EKS control plane logging provides audit and diagnostic logs directly from the control plane to CloudWatch Logs in your account. Application logs are logs produced by Pods running inside your cluster. Application logs include logs produced by Pods that run the business logic applications and Kubernetes system components such as CoreDNS, Cluster Autoscaler, Prometheus, etc. EKS provide five types of control plane logs : Kubernetes API server component logs Audit Authenticator Controller manager Scheduler The controller manager and scheduler logs can help diagnose control plane problems such as bottlenecks and errors. By default, EKS control plane logs aren\u2019t sent to CloudWatch Logs. You can enable control plane logging and select the types of EKS control plane logs you\u2019d like to capture for each cluster in your account Collecting application logs requires installing a log aggregator tool like Fluent Bit , Fluentd , or CloudWatch Container Insights in your cluster. Kubernetes log aggregator tools run as DaemonSets and scrape container logs from nodes. Application logs are then sent to a centralized destination for storage. For example, CloudWatch Container Insights can use either Fluent Bit or Fluentd to collect logs and ship them to CloudWatch Logs for storage. Fluent Bit and Fluentd support many popular log analytics systems such as Elasticsearch and InfluxDB giving you the ability to change the storage backend for your logs by modifying Fluent bit or Fluentd\u2019s log configuration.","title":"Use centralized logging tools to collect and persist logs"},{"location":"reliability/docs/application/#use-a-distributed-tracing-system-to-identify-bottlenecks","text":"A typical modern application has components distributed over the network, and its reliability depends on the proper functioning of each of the components that make up the application. You can use a distributed tracing solution to understand how requests flow and how systems communicate. Traces can show you where bottlenecks exist in your application network and prevent problems that can cause cascading failures. You have two options to implement tracing in your applications: you can either implement distributed tracing at the code level using shared libraries or use a service mesh. Implementing tracing at the code level can be disadvantageous. In this method, you have to make changes to your code. This is further complicated if you have polyglot applications. You\u2019re also responsible for maintaining yet another library, across your services. Service Meshes like LinkerD , Istio , and AWS App Mesh can be used to implement distributed tracing in your application with minimal changes to the application code. You can use service mesh to standardize metrics generation, logging, and tracing. Tracing tools like AWS X-Ray , Jaeger support both shared library and service mesh implementations. Consider using a tracing tool like AWS X-Ray or Jaeger that supports both (shared library and service mesh) implementations so you will not have to switch tools if you later adopt service mesh.","title":"Use a distributed tracing system to identify bottlenecks"},{"location":"reliability/docs/controlplane/","text":"EKS Control Plane \u00b6 Amazon Elastic Kubernetes Service (EKS) is a managed Kubernetes service that makes it easy for you to run Kubernetes on AWS without needing to install, operate, and maintain your own Kubernetes control plane or worker nodes. It runs upstream Kubernetes and is certified Kubernetes conformant. This conformance ensures that EKS supports the Kubernetes APIs, just like the open-source community version that you can install on EC2 or on-premises. Existing applications running on upstream Kubernetes are compatible with Amazon EKS. EKS automatically manages the availability and scalability of the Kubernetes control plane nodes, and it automatically replaces unhealthy control plane nodes. EKS Architecture \u00b6 EKS architecture is designed to eliminate any single points of failure that may compromise the availability and durability of the Kubernetes control plane. The Kubernetes control plane managed by EKS runs inside an EKS managed VPC. The EKS control plane comprises the Kubernetes API server nodes, etcd cluster. Kubernetes API server nodes that run components like the API server, scheduler, and kube-controller-manager run in an auto-scaling group. EKS runs a minimum of two API server nodes in distinct Availability Zones (AZs) within in AWS region. Likewise, for durability, the etcd server nodes also run in an auto-scaling group that spans three AZs. EKS runs a NAT Gateway in each AZ, and API servers and etcd servers run in a private subnet. This architecture ensures that an event in a single AZ doesn\u2019t affect the EKS cluster's availability. When you create a new cluster, Amazon EKS creates a highly-available endpoint for the managed Kubernetes API server that you use to communicate with your cluster (using tools like kubectl ). The managed endpoint uses NLB to load balance Kubernetes API servers. EKS also provisions two ENI s in different AZs to facilitate communication to your worker nodes. You can configure whether your Kubernetes cluster\u2019s API server is reachable from the public internet (using the public endpoint) or through your VPC (using the EKS-managed ENIs) or both. Whether users and worker nodes connect to the API server using the public endpoint or the EKS-managed ENI, there are redundant paths for connection. Recommendations \u00b6 Monitor Control Plane Metrics \u00b6 Monitoring Kubernetes API metrics can give you insights into control plane performance and identify issues. An unhealthy control plane can compromise the availability of the workloads running inside the cluster. For example, poorly written controllers can overload the API servers, affecting your application's availability. Kubernetes exposes control plane metrics at the /metrics endpoint. You can view the metrics exposed using kubectl : kubectl get --raw /metrics These metrics are represented in a Prometheus text format . You can use Prometheus to collect and store these metrics. In May 2020, CloudWatch added support for monitoring Prometheus metrics in CloudWatch Container Insights. So you can also use Amazon CloudWatch to monitor the EKS control plane. You can use Tutorial for Adding a New Prometheus Scrape Target: Prometheus KPI Server Metrics to collect metrics and create CloudWatch dashboard to monitor your cluster\u2019s control plane. You can find Kubernetes API server metrics here . For example, apiserver_request_duration_seconds can indicate how long API requests are taking to run. Consider monitoring these control plane metrics: API Server \u00b6 Metric Description apiserver_request_total Counter of apiserver requests broken out for each verb, dry run value, group, version, resource, scope, component, client, and HTTP response contentType and code. apiserver_request_duration_seconds* Response latency distribution in seconds for each verb, dry run value, group, version, resource, subresource, scope, and component. apiserver_admission_controller_admission_duration_seconds Admission controller latency histogram in seconds, identified by name and broken out for each operation and API resource and type (validate or admit). rest_client_request_duration_seconds Request latency in seconds. Broken down by verb and URL. rest_client_requests_total Number of HTTP requests, partitioned by status code, method, and host. etcd \u00b6 Metric Description etcd_request_duration_seconds Etcd request latency in seconds for each operation and object type. etcd_db_total_size_in_bytes Etcd database size. Consider using the Kubernetes Monitoring Overview Dashboard to visualize and monitor Kubernetes API server requests and latency and etcd latency metrics. The following Prometheus query can be used to monitor the current size of etcd. The query assumes there is job called kube-apiserver for scraping metrics from API metrics endpoint. max(etcd_db_total_size_in_bytes{job=\"kube-apiserver\"} / (8 * 1024 * 1024 * 1024)) Cluster Authentication \u00b6 EKS currently supports two types of authentication: bearer/service account tokens and IAM authentication which uses webhook token authentication . When users call the Kubernetes API, a webhook passes an authentication token included in the request to IAM. The token, a base 64 signed URL, is generated by the AWS Command Line Interface ( AWS CLI ). The IAM user or role that creates the EKS Cluster automatically gets full access to the cluster. You can manage access to the EKS cluster by editing the aws-auth configmap . If you misconfigure the aws-auth configmap and lose access to the cluster, you can still use the cluster creator\u2019s user or role to access your EKS cluster. In the unlikely event that you cannot use the IAM service in the AWS region, you can also use the Kubernetes service account\u2019s bearer token to manage the cluster. Create a \u201csuper-admin\u201d account that is permitted to perform all actions in the cluster: kubectl -n kube-system create serviceaccount super-admin Create a role binding that gives super-admin cluster-admin role: kubectl create clusterrolebinding super-admin-rb --clusterrole=cluster-admin --serviceaccount=kube-system:super-admin Get service account\u2019s secret: SECRET_NAME=`kubectl -n kube-system get serviceaccount/super-admin -o jsonpath='{.secrets[0].name}'` Get token associated with the secret: TOKEN=`kubectl -n kube-system get secret $SECRET_NAME -o jsonpath='{.data.token}'| base64 --decode` Add service account and token to kubeconfig : kubectl config set-credentials super-admin --token=$TOKEN Set the current-context in kubeconfig to use super-admin account: kubectl config set-context --current --user=super-admin Final kubeconfig should look like this: apiVersion : v1 clusters : - cluster : certificate - authority - data :< REDACTED > server : https ://< CLUSTER >. gr7 . us - west - 2 . eks . amazonaws . com name : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > contexts : - context : cluster : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > user : super - admin name : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > current - context : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > kind : Config preferences : {} users : # - name : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > # user : # exec : # apiVersion : client . authentication . k8s . io / v1alpha1 # args : # - -- region # - us - west - 2 # - eks # - get - token # - -- cluster - name # - << cluster name >> # command : aws # env : null - name : super - admin user : token : << super - admin sa \u2019 s secret >> Handling Cluster Upgrades \u00b6 Since April 2021, Kubernetes release cycle has been changed from four releases a year (once a quarter) to three releases a year. A new minor version (like 1. 21 or 1. 22 ) is released approximately every fifteen weeks . Starting with Kubernetes 1.19, each minor version is supported for approximately twelve months after it's first released.. Kubernetes supports compatibility between the control plane and worker nodes for at least two minor versions. In line with the Kubernetes community support for Kubernetes versions, EKS provides at least three production-ready versions of Kubernetes at any given time, with a fourth version in deprecation. EKS will announce the deprecation of a given Kubernetes minor version at least 60 days before the end of support date. On the end of support date, clusters running the deprecated version will begin to be automatically updated to the next EKS-supported version of Kubernetes. EKS performs in-place cluster upgrades for both Kubernetes and EKS platform versions . This simplifies cluster operations and lets you take advantage of the latest Kubernetes features and apply security patches, without any downtime. New Kubernetes versions introduce significant changes, and you cannot downgrade a cluster once upgraded. Having a well-documented process for handling cluster upgrades is necessary for a smooth transition to newer Kubernetes versions. You may consider migrating to new clusters when upgrading to newer Kubernetes versions instead of performing in-place cluster upgrades. Cluster backup and restore tools like VMware\u2019s Velero can help you migrate to a new cluster. You should familiarize yourself with the Kubernetes deprecation policy as newer versions may deprecate APIs and features that may break existing applications. Before upgrading the cluster, you should review the Kubernetes change log and Amazon EKS Kubernetes versions to understand any negative impact to your workloads. Consider testing the cluster upgrade in a non-production environment and identify any impacts to current workloads and controllers. You can automate the testing by building a continuous integration workflow to test the compatibility of your applications, controllers, and custom integrations before moving to a new Kubernetes version. You may also need to upgrade Kubernetes add-ons after upgrading the cluster. Review Updating an Amazon EKS cluster Kubernetes version to validate the compatibility of cluster add-ons with the cluster version. Consider turning on control plane logging and review the logs for any errors. Consider using eksctl to manage EKS cluster. You can use eksctl to update the control plane, add-ons, and worker nodes . EKS control plane upgrade doesn\u2019t include upgrading worker nodes. You are responsible for updating EKS worker nodes. Consider using EKS managed node groups or EKS on Fargate to automate the process of upgrading worker nodes. If required, you can use kubectl convert plugin to convert Kubernetes manifests files between different API versions . Running large clusters \u00b6 EKS actively monitors the load on control plane instances and automatically scales them to ensure high performance. However, you should account for potential performance issues and limits within Kubernetes and quotas in AWS services when running large clusters. Clusters with more than 1000 services may experience network latency with using kube-proxy in iptables mode according to the tests performed by the ProjectCalico team . The solution is to switch to running kube-proxy in ipvs mode . You may also experience EC2 API request throttling if the CNI needs to request IP addresses for Pods or if you need to create new EC2 instances frequently. You can reduce calls EC2 API by configuring the CNI to cache IP addresses. You can use larger EC2 instance types to reduce EC2 scaling events. Know limits and service quotas \u00b6 AWS sets service limits (an upper limit on the number of each resource your team can request) to protect you from accidentally over-provisioning resources. Amazon EKS Service Quotas lists the service limits. There are two types of limits, soft limits, that can be changed using AWS Service Quotas . Hard limits cannot be changed. You should consider these values when architecting your applications. Consider reviewing these service limits periodically and incorporate them during in your application design. Besides the limits from orchestration engines, there are limits in other AWS services, such as Elastic Load Balancing (ELB) and Amazon VPC, that may affect your application performance. More about EC2 limits here: EC2 service limits . Each EC2 instance limits the number of packets that can be sent to the Amazon-provided DNS server to a maximum of 1024 packets per second per network interface. In EKS environment, etcd storage limit is 8GB as per upstream guidance . Please monitor metric etcd_db_total_size_in_bytes to track etcd db size. You can refer to alert rules etcdBackendQuotaLowSpace and etcdExcessiveDatabaseGrowth to setup this monitoring. Additional Resources: \u00b6 De-mystifying cluster networking for Amazon EKS worker nodes Amazon EKS cluster endpoint access control AWS re:Invent 2019: Amazon EKS under the hood (CON421-R1)","title":"Control Plane"},{"location":"reliability/docs/controlplane/#eks-control-plane","text":"Amazon Elastic Kubernetes Service (EKS) is a managed Kubernetes service that makes it easy for you to run Kubernetes on AWS without needing to install, operate, and maintain your own Kubernetes control plane or worker nodes. It runs upstream Kubernetes and is certified Kubernetes conformant. This conformance ensures that EKS supports the Kubernetes APIs, just like the open-source community version that you can install on EC2 or on-premises. Existing applications running on upstream Kubernetes are compatible with Amazon EKS. EKS automatically manages the availability and scalability of the Kubernetes control plane nodes, and it automatically replaces unhealthy control plane nodes.","title":"EKS Control Plane"},{"location":"reliability/docs/controlplane/#eks-architecture","text":"EKS architecture is designed to eliminate any single points of failure that may compromise the availability and durability of the Kubernetes control plane. The Kubernetes control plane managed by EKS runs inside an EKS managed VPC. The EKS control plane comprises the Kubernetes API server nodes, etcd cluster. Kubernetes API server nodes that run components like the API server, scheduler, and kube-controller-manager run in an auto-scaling group. EKS runs a minimum of two API server nodes in distinct Availability Zones (AZs) within in AWS region. Likewise, for durability, the etcd server nodes also run in an auto-scaling group that spans three AZs. EKS runs a NAT Gateway in each AZ, and API servers and etcd servers run in a private subnet. This architecture ensures that an event in a single AZ doesn\u2019t affect the EKS cluster's availability. When you create a new cluster, Amazon EKS creates a highly-available endpoint for the managed Kubernetes API server that you use to communicate with your cluster (using tools like kubectl ). The managed endpoint uses NLB to load balance Kubernetes API servers. EKS also provisions two ENI s in different AZs to facilitate communication to your worker nodes. You can configure whether your Kubernetes cluster\u2019s API server is reachable from the public internet (using the public endpoint) or through your VPC (using the EKS-managed ENIs) or both. Whether users and worker nodes connect to the API server using the public endpoint or the EKS-managed ENI, there are redundant paths for connection.","title":"EKS Architecture"},{"location":"reliability/docs/controlplane/#recommendations","text":"","title":"Recommendations"},{"location":"reliability/docs/controlplane/#monitor-control-plane-metrics","text":"Monitoring Kubernetes API metrics can give you insights into control plane performance and identify issues. An unhealthy control plane can compromise the availability of the workloads running inside the cluster. For example, poorly written controllers can overload the API servers, affecting your application's availability. Kubernetes exposes control plane metrics at the /metrics endpoint. You can view the metrics exposed using kubectl : kubectl get --raw /metrics These metrics are represented in a Prometheus text format . You can use Prometheus to collect and store these metrics. In May 2020, CloudWatch added support for monitoring Prometheus metrics in CloudWatch Container Insights. So you can also use Amazon CloudWatch to monitor the EKS control plane. You can use Tutorial for Adding a New Prometheus Scrape Target: Prometheus KPI Server Metrics to collect metrics and create CloudWatch dashboard to monitor your cluster\u2019s control plane. You can find Kubernetes API server metrics here . For example, apiserver_request_duration_seconds can indicate how long API requests are taking to run. Consider monitoring these control plane metrics:","title":"Monitor Control Plane Metrics"},{"location":"reliability/docs/controlplane/#api-server","text":"Metric Description apiserver_request_total Counter of apiserver requests broken out for each verb, dry run value, group, version, resource, scope, component, client, and HTTP response contentType and code. apiserver_request_duration_seconds* Response latency distribution in seconds for each verb, dry run value, group, version, resource, subresource, scope, and component. apiserver_admission_controller_admission_duration_seconds Admission controller latency histogram in seconds, identified by name and broken out for each operation and API resource and type (validate or admit). rest_client_request_duration_seconds Request latency in seconds. Broken down by verb and URL. rest_client_requests_total Number of HTTP requests, partitioned by status code, method, and host.","title":"API Server"},{"location":"reliability/docs/controlplane/#etcd","text":"Metric Description etcd_request_duration_seconds Etcd request latency in seconds for each operation and object type. etcd_db_total_size_in_bytes Etcd database size. Consider using the Kubernetes Monitoring Overview Dashboard to visualize and monitor Kubernetes API server requests and latency and etcd latency metrics. The following Prometheus query can be used to monitor the current size of etcd. The query assumes there is job called kube-apiserver for scraping metrics from API metrics endpoint. max(etcd_db_total_size_in_bytes{job=\"kube-apiserver\"} / (8 * 1024 * 1024 * 1024))","title":"etcd"},{"location":"reliability/docs/controlplane/#cluster-authentication","text":"EKS currently supports two types of authentication: bearer/service account tokens and IAM authentication which uses webhook token authentication . When users call the Kubernetes API, a webhook passes an authentication token included in the request to IAM. The token, a base 64 signed URL, is generated by the AWS Command Line Interface ( AWS CLI ). The IAM user or role that creates the EKS Cluster automatically gets full access to the cluster. You can manage access to the EKS cluster by editing the aws-auth configmap . If you misconfigure the aws-auth configmap and lose access to the cluster, you can still use the cluster creator\u2019s user or role to access your EKS cluster. In the unlikely event that you cannot use the IAM service in the AWS region, you can also use the Kubernetes service account\u2019s bearer token to manage the cluster. Create a \u201csuper-admin\u201d account that is permitted to perform all actions in the cluster: kubectl -n kube-system create serviceaccount super-admin Create a role binding that gives super-admin cluster-admin role: kubectl create clusterrolebinding super-admin-rb --clusterrole=cluster-admin --serviceaccount=kube-system:super-admin Get service account\u2019s secret: SECRET_NAME=`kubectl -n kube-system get serviceaccount/super-admin -o jsonpath='{.secrets[0].name}'` Get token associated with the secret: TOKEN=`kubectl -n kube-system get secret $SECRET_NAME -o jsonpath='{.data.token}'| base64 --decode` Add service account and token to kubeconfig : kubectl config set-credentials super-admin --token=$TOKEN Set the current-context in kubeconfig to use super-admin account: kubectl config set-context --current --user=super-admin Final kubeconfig should look like this: apiVersion : v1 clusters : - cluster : certificate - authority - data :< REDACTED > server : https ://< CLUSTER >. gr7 . us - west - 2 . eks . amazonaws . com name : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > contexts : - context : cluster : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > user : super - admin name : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > current - context : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > kind : Config preferences : {} users : # - name : arn : aws : eks : us - west - 2 :< account number >: cluster /< cluster name > # user : # exec : # apiVersion : client . authentication . k8s . io / v1alpha1 # args : # - -- region # - us - west - 2 # - eks # - get - token # - -- cluster - name # - << cluster name >> # command : aws # env : null - name : super - admin user : token : << super - admin sa \u2019 s secret >>","title":"Cluster Authentication"},{"location":"reliability/docs/controlplane/#handling-cluster-upgrades","text":"Since April 2021, Kubernetes release cycle has been changed from four releases a year (once a quarter) to three releases a year. A new minor version (like 1. 21 or 1. 22 ) is released approximately every fifteen weeks . Starting with Kubernetes 1.19, each minor version is supported for approximately twelve months after it's first released.. Kubernetes supports compatibility between the control plane and worker nodes for at least two minor versions. In line with the Kubernetes community support for Kubernetes versions, EKS provides at least three production-ready versions of Kubernetes at any given time, with a fourth version in deprecation. EKS will announce the deprecation of a given Kubernetes minor version at least 60 days before the end of support date. On the end of support date, clusters running the deprecated version will begin to be automatically updated to the next EKS-supported version of Kubernetes. EKS performs in-place cluster upgrades for both Kubernetes and EKS platform versions . This simplifies cluster operations and lets you take advantage of the latest Kubernetes features and apply security patches, without any downtime. New Kubernetes versions introduce significant changes, and you cannot downgrade a cluster once upgraded. Having a well-documented process for handling cluster upgrades is necessary for a smooth transition to newer Kubernetes versions. You may consider migrating to new clusters when upgrading to newer Kubernetes versions instead of performing in-place cluster upgrades. Cluster backup and restore tools like VMware\u2019s Velero can help you migrate to a new cluster. You should familiarize yourself with the Kubernetes deprecation policy as newer versions may deprecate APIs and features that may break existing applications. Before upgrading the cluster, you should review the Kubernetes change log and Amazon EKS Kubernetes versions to understand any negative impact to your workloads. Consider testing the cluster upgrade in a non-production environment and identify any impacts to current workloads and controllers. You can automate the testing by building a continuous integration workflow to test the compatibility of your applications, controllers, and custom integrations before moving to a new Kubernetes version. You may also need to upgrade Kubernetes add-ons after upgrading the cluster. Review Updating an Amazon EKS cluster Kubernetes version to validate the compatibility of cluster add-ons with the cluster version. Consider turning on control plane logging and review the logs for any errors. Consider using eksctl to manage EKS cluster. You can use eksctl to update the control plane, add-ons, and worker nodes . EKS control plane upgrade doesn\u2019t include upgrading worker nodes. You are responsible for updating EKS worker nodes. Consider using EKS managed node groups or EKS on Fargate to automate the process of upgrading worker nodes. If required, you can use kubectl convert plugin to convert Kubernetes manifests files between different API versions .","title":"Handling Cluster Upgrades"},{"location":"reliability/docs/controlplane/#running-large-clusters","text":"EKS actively monitors the load on control plane instances and automatically scales them to ensure high performance. However, you should account for potential performance issues and limits within Kubernetes and quotas in AWS services when running large clusters. Clusters with more than 1000 services may experience network latency with using kube-proxy in iptables mode according to the tests performed by the ProjectCalico team . The solution is to switch to running kube-proxy in ipvs mode . You may also experience EC2 API request throttling if the CNI needs to request IP addresses for Pods or if you need to create new EC2 instances frequently. You can reduce calls EC2 API by configuring the CNI to cache IP addresses. You can use larger EC2 instance types to reduce EC2 scaling events.","title":"Running large clusters"},{"location":"reliability/docs/controlplane/#know-limits-and-service-quotas","text":"AWS sets service limits (an upper limit on the number of each resource your team can request) to protect you from accidentally over-provisioning resources. Amazon EKS Service Quotas lists the service limits. There are two types of limits, soft limits, that can be changed using AWS Service Quotas . Hard limits cannot be changed. You should consider these values when architecting your applications. Consider reviewing these service limits periodically and incorporate them during in your application design. Besides the limits from orchestration engines, there are limits in other AWS services, such as Elastic Load Balancing (ELB) and Amazon VPC, that may affect your application performance. More about EC2 limits here: EC2 service limits . Each EC2 instance limits the number of packets that can be sent to the Amazon-provided DNS server to a maximum of 1024 packets per second per network interface. In EKS environment, etcd storage limit is 8GB as per upstream guidance . Please monitor metric etcd_db_total_size_in_bytes to track etcd db size. You can refer to alert rules etcdBackendQuotaLowSpace and etcdExcessiveDatabaseGrowth to setup this monitoring.","title":"Know limits and service quotas"},{"location":"reliability/docs/controlplane/#additional-resources","text":"De-mystifying cluster networking for Amazon EKS worker nodes Amazon EKS cluster endpoint access control AWS re:Invent 2019: Amazon EKS under the hood (CON421-R1)","title":"Additional Resources:"},{"location":"reliability/docs/dataplane/","text":"EKS Data Plane \u00b6 To operate high-available and resilient applications, you need a highly-available and resilient data plane. An elastic data plane ensures that Kubernetes can scale and heal your applications automatically. A resilient data plane consists of two or more worker nodes, can grow and shrink with the workload, and automatically recover from failures. You have two choices for worker nodes with EKS: EC2 instances and Fargate . If you choose EC2 instances, you can manage the worker nodes yourself or use EKS managed node groups . You can have a cluster with a mix of managed, self-managed worker nodes, and Fargate. EKS on Fargate offers the easiest path to a resilient data plane. Fargate runs each Pod in an isolated compute environment. Each Pod running on Fargate gets its own worker node. Fargate automatically scales the data plane as Kubernetes scales pods. You can scale both the data plane and your workload by using the horizontal pod autoscaler . The preferred way to scale EC2 worker nodes is by using Kubernetes Cluster Autoscaler , EC2 Auto Scaling groups or community projects like Atlassian\u2019s Esclator . Recommendations \u00b6 Use EC2 Auto Scaling Groups to create worker nodes \u00b6 It is a best practice to create worker nodes using EC2 Auto Scaling groups instead of creating individual EC2 instances and joining them to the cluster. Auto Scaling Groups will automatically replace any terminated or failed nodes ensuring that the cluster always has the capacity to run your workload. Use Kubernetes Cluster Autoscaler to scale nodes \u00b6 Cluster Autoscaler adjusts the size of the data plane when there are pods that cannot be run because the cluster has insufficient resources, and adding another worker node would help. Although Cluster Autoscaler is a reactive process, it waits until pods are in Pending state due to insufficient capacity in the cluster. When such an event occurs, it adds EC2 instances to the cluster. Whenever the cluster runs out of capacity, new replicas - or new pods - will be unavailable ( in Pending state ) until worker nodes are added. This delay may impact your applications' reliability if the data plane cannot scale fast enough to meet the demands of the workload. If a worker node is consistently underutilized and all of its pods can be scheduled on other worker nodes, Cluster Autoscaler terminates it. Configure over-provisioning with Cluster Autoscaler \u00b6 Cluster Autoscaler triggers a scale-up of the data-plane when Pods in the cluster are already Pending . Hence, there may be a delay between the time your application needs more replicas, and when it, in fact, gets more replicas. An option to account for this possible delay is through adding more than required replicas, inflating the number of replicas for the application. Another pattern that Cluster Autoscaler recommends uses pause Pods and the Priority Preemption feature . The pause Pod runs a pause container , which as the name suggests, does nothing but acts as a placeholder for compute capacity that can be used by other Pods in your cluster. Because it runs with a very low assigned priority , the pause Pod gets evicted from the node when another Pod needs to be created, and the cluster doesn\u2019t have available capacity. The Kubernetes Scheduler notices the eviction of the pause Pod and tries to reschedule it. But since the cluster is running at capacity, the pause Pod remains Pending , to which the Cluster Autoscaler reacts by adding nodes. A Helm chart is available to install cluster overprovisioner . Using Cluster Autoscaler with multiple Auto Scaling Groups \u00b6 Run the Cluster Autoscaler with the --node-group-auto-discovery flag enabled. Doing so will allow the Cluster Autoscaler to find all autoscaling groups that include a particular defined tag and prevents the need to define and maintain each autoscaling group in the manifest. Using Cluster Autoscaler with local storage \u00b6 By default, the Cluster Autoscaler does not scale-down nodes that have pods deployed with local storage attached. Set the --skip-nodes-with-local-storage flag to false to allow Cluster Autoscaler to scale-down these nodes. Spread worker nodes and workload across multiple AZs \u00b6 You can protect your workloads from failures in an individual AZ by running worker nodes and pods in multiple AZs. You can control the AZ the worker nodes are created in using the subnets you create the nodes in. If you are using Kubernetes 1.18+, the recommended method for spreading pods across AZs is to use Topology Spread Constraints for Pods . The deployment below spreads pods across AZs if possible, letting those pods run anyway if not: apiVersion : apps / v1 kind : Deployment metadata : name : web - server spec : replicas : 3 selector : matchLabels : app : web - server template : metadata : labels : app : web - server spec : topologySpreadConstraints : - maxSkew : 1 whenUnsatisfiable : ScheduleAnyway topologyKey : topology . kubernetes . io / zone labelSelector : matchLabels : app : web - server containers : - name : web - app image : nginx resources : requests : cpu : 1 Note kube-scheduler is only aware of topology domains via nodes that exist with those labels. If the above deployment is deployed to a cluster with nodes only in a single zone, all of the pods will schedule on those nodes as kube-scheduler isn't aware of the other zones. For this topology spread to work as expected with the scheduler, nodes must already exist in all zones. This issue will be resolved in Kubernetes 1.24 with the addition of the MinDomainsInPodToplogySpread feature gate which allows specifying a minDomains property to inform the scheduler of the number of eligible domains. Warning Setting whenUnsatisfiable to DoNotSchedule will cause pods to be unschedulable if the topology spread constraint can't be fulfilled. It should only be set if its preferable for pods to not run instead of violating the topology spread constraint. On older versions of Kubernetes, you can use pod anti-affinity rules to schedule pods across multiple AZs. The manifest below informs Kubernetes scheduler to prefer scheduling pods in distinct AZs. apiVersion : apps / v1 kind : Deployment metadata : name : web - server labels : app : web - server spec : replicas : 4 selector : matchLabels : app : web - server template : metadata : labels : app : web - server spec : affinity : podAntiAffinity : preferredDuringSchedulingIgnoredDuringExecution : - podAffinityTerm : labelSelector : matchExpressions : - key : app operator : In values : - web - server topologyKey : failure - domain . beta . kubernetes . io / zone weight : 100 containers : - name : web - app image : nginx Warning Do not require that pods be scheduled across distinct AZs otherwise, the number of pods in a deployment will never exceed the number of AZs. Ensure capacity in each AZ when using EBS volumes \u00b6 If you use Amazon EBS to provide Persistent Volumes , then you need to ensure that the pods and associated EBS volume are located in the same AZ. At the time of writing, EBS volumes are only available within a single AZ. A Pod cannot access EBS-backed persistent volumes located in a different AZ. Kubernetes scheduler knows which AZ a worker node is located in. Kubernetes will always schedule a Pod that requires an EBS volume in the same AZ as the volume. However, if there are no worker nodes available in the AZ where the volume is located, then the Pod cannot be scheduled. Create Auto Scaling Group for each AZ with enough capacity to ensure that the cluster always has capacity to schedule pods in the same AZ as the EBS volumes they need. In addition, you should enable the --balance-similar-node-groups feature in Cluster Autoscaler. If you are running an application that uses EBS volume but has no requirements to be highly available, then you can restrict the deployment of the application to a single AZ. In EKS, worker nodes are automatically added failure-domain.beta.kubernetes.io/zone label, which contains the name of the AZ. You can see the labels attached to your nodes by running kubectl get nodes --show-labels . More information about built-in node labels is available here . You can use node selectors to schedule a pod in a particular AZ. In the example below, the pod will only be scheduled in us-west-2c AZ: apiVersion : v1 kind : Pod metadata : name : single - az - pod spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : failure - domain . beta . kubernetes . io / zone operator : In values : - us - west - 2 c containers : - name : single - az - container image : kubernetes / pause Persistent volumes (backed by EBS) are also automatically labeled with the name of AZ; you can see which AZ your persistent volume belongs to by running kubectl get pv -L topology.ebs.csi.aws.com/zone . When a pod is created and claims a volume, Kubernetes will schedule the Pod on a node in the same AZ as the volume. Consider this scenario; you have an EKS cluster with one node group. This node group has three worker nodes spread across three AZs. You have an application that uses an EBS-backed Persistent Volume. When you create this application and the corresponding volume, its Pod gets created in the first of the three AZs. Then, the worker node that runs this Pod becomes unhealthy and subsequently unavailable for use. Cluster Autoscaler will replace the unhealthy node with a new worker node; however, because the autoscaling group spans across three AZs, the new worker node may get launched in the second or the third AZ, but not in the first AZ as the situation demands. As the AZ-constrained EBS volume only exists in the first AZ, but there are no worker nodes available in that AZ, the Pod cannot be scheduled. Therefore, you should create one node group in each AZ, so there is always enough capacity available to run pods that cannot be scheduled in other AZs. Alternatively, you can use EFS can simplify cluster autoscaling when running applications that need persistent storage. Clients can access EFS file systems concurrently from all the AZs in the region. Even if a Pod using EFS-backed Persistent Volume gets terminated and gets scheduled in different AZ, it will be able to mount the volume. Run node-problem-detector \u00b6 Failures in worker nodes can impact the availability of your applications. node-problem-detector is a Kubernetes add-on that you can install in your cluster to detect worker node issues. You can use a npd\u2019s remedy system to drain and terminate the node automatically. Reserving resources for system and Kubernetes daemons \u00b6 You can improve worker nodes' stability by reserving compute capacity for the operating system and Kubernetes daemons . Pods - especially ones without limits declared - can saturate system resources putting nodes in a situation where operating system processes and Kubernetes daemons ( kubelet , container runtime, etc.) compete with pods for system resources. You can use kubelet flags --system-reserved and --kube-reserved to reserve resources for system process ( udev , sshd , etc.) and Kubernetes daemons respectively. If you use the EKS-optimized Linux AMI , the CPU, memory, and storage are reserved for the system and Kubernetes daemons by default. When worker nodes based on this AMI launch, EC2 user-data is configured to trigger the bootstrap.sh script . This script calculates CPU and memory reservations based on the number of CPU cores and total memory available on the EC2 instance. The calculated values are written to the KubeletConfiguration file located at /etc/kubernetes/kubelet/kubelet-config.json . You may need to increase the system resource reservation if you run custom daemons on the node and the amount of CPU and memory reserved by default is insufficient. eksctl offers the easiest way to customize resource reservation for system and Kubernetes daemons . Implement QoS \u00b6 For critical applications, consider defining requests = limits for the container in the Pod. This will ensure that the container will not be killed if another Pod requests resources. It is a best practice to implement CPU and memory limits for all containers as it prevents a container inadvertently consuming system resources impacting the availability of other co-located processes. Configure and Size Resource Requests/Limits for all Workloads \u00b6 Some general guidance can be applied to sizing resource requests and limits for workloads: Do not specify resource limits on CPU. In the absence of limits, the request acts as a weight on how much relative CPU time containers get . This allows your workloads to use the full CPU without an artificial limit or starvation. For non-CPU resources, configuring requests = limits provides the most predictable behavior. If requests != limits , the container also has its QOS reduced from Guaranteed to Burstable making it more likely to be evicted in the event of node pressure . For non-CPU resources, do not specify a limit that is much larger than the request. The larger limits are configured relative to requests , the more likely nodes will be overcommitted leading to high chances of workload interruption. Correctly sized requests are particularly important when using a node auto-scaling solution like Karpenter or Cluster AutoScaler . These tools look at your workload requests to determine the number and size of nodes to be provisioned. If your requests are too small with larger limits, you may find your workloads evicted or OOM killed if they have been tightly packed on a node. Determining resource requests can be difficult, but tools like the Vertical Pod Autoscaler can help you 'right-size' the requests by observing container resource usage at runtime. Other tools that may be useful for determining request sizes include: Goldilocks Parca Prodfiler rsg Configure resource quotas for namespaces \u00b6 Namespaces are intended for use in environments with many users spread across multiple teams, or projects. They provide a scope for names and are a way to divide cluster resources between multiple teams, projects, workloads. You can limit the aggregate resource consumption in a namespace. The ResourceQuota object can limit the quantity of objects that can be created in a namespace by type, as well as the total amount of compute resources that may be consumed by resources in that project. You can limit the total sum of storage and/or compute (CPU and memory) resources that can be requested in a given namespace. If resource quota is enabled for a namespace for compute resources like CPU and memory, users must specify requests or limits for each container in that namespace. Consider configuring quotas for each namespace. Consider using LimitRanges to automatically apply preconfigured limits to containers within a namespaces. Limit container resource usage within a namespace \u00b6 Resource Quotas help limit the amount of resources a namespace can use. The LimitRange object can help you implement minimum and maximum resources a container can request. Using LimitRange you can set a default request and limits for containers, which is helpful if setting compute resource limits is not a standard practice in your organization. As the name suggests, LimitRange can enforce minimum and maximum compute resources usage per Pod or Container in a namespace. As well as, enforce minimum and maximum storage request per PersistentVolumeClaim in a namespace. Consider using LimitRange in conjunction with ResourceQuota to enforce limits at a container as well as namespace level. Setting these limits will ensure that a container or a namespace does not impinge on resources used by other tenants in the cluster.","title":"Data Plane"},{"location":"reliability/docs/dataplane/#eks-data-plane","text":"To operate high-available and resilient applications, you need a highly-available and resilient data plane. An elastic data plane ensures that Kubernetes can scale and heal your applications automatically. A resilient data plane consists of two or more worker nodes, can grow and shrink with the workload, and automatically recover from failures. You have two choices for worker nodes with EKS: EC2 instances and Fargate . If you choose EC2 instances, you can manage the worker nodes yourself or use EKS managed node groups . You can have a cluster with a mix of managed, self-managed worker nodes, and Fargate. EKS on Fargate offers the easiest path to a resilient data plane. Fargate runs each Pod in an isolated compute environment. Each Pod running on Fargate gets its own worker node. Fargate automatically scales the data plane as Kubernetes scales pods. You can scale both the data plane and your workload by using the horizontal pod autoscaler . The preferred way to scale EC2 worker nodes is by using Kubernetes Cluster Autoscaler , EC2 Auto Scaling groups or community projects like Atlassian\u2019s Esclator .","title":"EKS Data Plane"},{"location":"reliability/docs/dataplane/#recommendations","text":"","title":"Recommendations"},{"location":"reliability/docs/dataplane/#use-ec2-auto-scaling-groups-to-create-worker-nodes","text":"It is a best practice to create worker nodes using EC2 Auto Scaling groups instead of creating individual EC2 instances and joining them to the cluster. Auto Scaling Groups will automatically replace any terminated or failed nodes ensuring that the cluster always has the capacity to run your workload.","title":"Use EC2 Auto Scaling Groups to create worker nodes"},{"location":"reliability/docs/dataplane/#use-kubernetes-cluster-autoscaler-to-scale-nodes","text":"Cluster Autoscaler adjusts the size of the data plane when there are pods that cannot be run because the cluster has insufficient resources, and adding another worker node would help. Although Cluster Autoscaler is a reactive process, it waits until pods are in Pending state due to insufficient capacity in the cluster. When such an event occurs, it adds EC2 instances to the cluster. Whenever the cluster runs out of capacity, new replicas - or new pods - will be unavailable ( in Pending state ) until worker nodes are added. This delay may impact your applications' reliability if the data plane cannot scale fast enough to meet the demands of the workload. If a worker node is consistently underutilized and all of its pods can be scheduled on other worker nodes, Cluster Autoscaler terminates it.","title":"Use Kubernetes Cluster Autoscaler to scale nodes"},{"location":"reliability/docs/dataplane/#configure-over-provisioning-with-cluster-autoscaler","text":"Cluster Autoscaler triggers a scale-up of the data-plane when Pods in the cluster are already Pending . Hence, there may be a delay between the time your application needs more replicas, and when it, in fact, gets more replicas. An option to account for this possible delay is through adding more than required replicas, inflating the number of replicas for the application. Another pattern that Cluster Autoscaler recommends uses pause Pods and the Priority Preemption feature . The pause Pod runs a pause container , which as the name suggests, does nothing but acts as a placeholder for compute capacity that can be used by other Pods in your cluster. Because it runs with a very low assigned priority , the pause Pod gets evicted from the node when another Pod needs to be created, and the cluster doesn\u2019t have available capacity. The Kubernetes Scheduler notices the eviction of the pause Pod and tries to reschedule it. But since the cluster is running at capacity, the pause Pod remains Pending , to which the Cluster Autoscaler reacts by adding nodes. A Helm chart is available to install cluster overprovisioner .","title":"Configure over-provisioning with Cluster Autoscaler"},{"location":"reliability/docs/dataplane/#using-cluster-autoscaler-with-multiple-auto-scaling-groups","text":"Run the Cluster Autoscaler with the --node-group-auto-discovery flag enabled. Doing so will allow the Cluster Autoscaler to find all autoscaling groups that include a particular defined tag and prevents the need to define and maintain each autoscaling group in the manifest.","title":"Using Cluster Autoscaler with multiple Auto Scaling Groups"},{"location":"reliability/docs/dataplane/#using-cluster-autoscaler-with-local-storage","text":"By default, the Cluster Autoscaler does not scale-down nodes that have pods deployed with local storage attached. Set the --skip-nodes-with-local-storage flag to false to allow Cluster Autoscaler to scale-down these nodes.","title":"Using Cluster Autoscaler with local storage"},{"location":"reliability/docs/dataplane/#spread-worker-nodes-and-workload-across-multiple-azs","text":"You can protect your workloads from failures in an individual AZ by running worker nodes and pods in multiple AZs. You can control the AZ the worker nodes are created in using the subnets you create the nodes in. If you are using Kubernetes 1.18+, the recommended method for spreading pods across AZs is to use Topology Spread Constraints for Pods . The deployment below spreads pods across AZs if possible, letting those pods run anyway if not: apiVersion : apps / v1 kind : Deployment metadata : name : web - server spec : replicas : 3 selector : matchLabels : app : web - server template : metadata : labels : app : web - server spec : topologySpreadConstraints : - maxSkew : 1 whenUnsatisfiable : ScheduleAnyway topologyKey : topology . kubernetes . io / zone labelSelector : matchLabels : app : web - server containers : - name : web - app image : nginx resources : requests : cpu : 1 Note kube-scheduler is only aware of topology domains via nodes that exist with those labels. If the above deployment is deployed to a cluster with nodes only in a single zone, all of the pods will schedule on those nodes as kube-scheduler isn't aware of the other zones. For this topology spread to work as expected with the scheduler, nodes must already exist in all zones. This issue will be resolved in Kubernetes 1.24 with the addition of the MinDomainsInPodToplogySpread feature gate which allows specifying a minDomains property to inform the scheduler of the number of eligible domains. Warning Setting whenUnsatisfiable to DoNotSchedule will cause pods to be unschedulable if the topology spread constraint can't be fulfilled. It should only be set if its preferable for pods to not run instead of violating the topology spread constraint. On older versions of Kubernetes, you can use pod anti-affinity rules to schedule pods across multiple AZs. The manifest below informs Kubernetes scheduler to prefer scheduling pods in distinct AZs. apiVersion : apps / v1 kind : Deployment metadata : name : web - server labels : app : web - server spec : replicas : 4 selector : matchLabels : app : web - server template : metadata : labels : app : web - server spec : affinity : podAntiAffinity : preferredDuringSchedulingIgnoredDuringExecution : - podAffinityTerm : labelSelector : matchExpressions : - key : app operator : In values : - web - server topologyKey : failure - domain . beta . kubernetes . io / zone weight : 100 containers : - name : web - app image : nginx Warning Do not require that pods be scheduled across distinct AZs otherwise, the number of pods in a deployment will never exceed the number of AZs.","title":"Spread worker nodes and workload across multiple AZs"},{"location":"reliability/docs/dataplane/#ensure-capacity-in-each-az-when-using-ebs-volumes","text":"If you use Amazon EBS to provide Persistent Volumes , then you need to ensure that the pods and associated EBS volume are located in the same AZ. At the time of writing, EBS volumes are only available within a single AZ. A Pod cannot access EBS-backed persistent volumes located in a different AZ. Kubernetes scheduler knows which AZ a worker node is located in. Kubernetes will always schedule a Pod that requires an EBS volume in the same AZ as the volume. However, if there are no worker nodes available in the AZ where the volume is located, then the Pod cannot be scheduled. Create Auto Scaling Group for each AZ with enough capacity to ensure that the cluster always has capacity to schedule pods in the same AZ as the EBS volumes they need. In addition, you should enable the --balance-similar-node-groups feature in Cluster Autoscaler. If you are running an application that uses EBS volume but has no requirements to be highly available, then you can restrict the deployment of the application to a single AZ. In EKS, worker nodes are automatically added failure-domain.beta.kubernetes.io/zone label, which contains the name of the AZ. You can see the labels attached to your nodes by running kubectl get nodes --show-labels . More information about built-in node labels is available here . You can use node selectors to schedule a pod in a particular AZ. In the example below, the pod will only be scheduled in us-west-2c AZ: apiVersion : v1 kind : Pod metadata : name : single - az - pod spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : failure - domain . beta . kubernetes . io / zone operator : In values : - us - west - 2 c containers : - name : single - az - container image : kubernetes / pause Persistent volumes (backed by EBS) are also automatically labeled with the name of AZ; you can see which AZ your persistent volume belongs to by running kubectl get pv -L topology.ebs.csi.aws.com/zone . When a pod is created and claims a volume, Kubernetes will schedule the Pod on a node in the same AZ as the volume. Consider this scenario; you have an EKS cluster with one node group. This node group has three worker nodes spread across three AZs. You have an application that uses an EBS-backed Persistent Volume. When you create this application and the corresponding volume, its Pod gets created in the first of the three AZs. Then, the worker node that runs this Pod becomes unhealthy and subsequently unavailable for use. Cluster Autoscaler will replace the unhealthy node with a new worker node; however, because the autoscaling group spans across three AZs, the new worker node may get launched in the second or the third AZ, but not in the first AZ as the situation demands. As the AZ-constrained EBS volume only exists in the first AZ, but there are no worker nodes available in that AZ, the Pod cannot be scheduled. Therefore, you should create one node group in each AZ, so there is always enough capacity available to run pods that cannot be scheduled in other AZs. Alternatively, you can use EFS can simplify cluster autoscaling when running applications that need persistent storage. Clients can access EFS file systems concurrently from all the AZs in the region. Even if a Pod using EFS-backed Persistent Volume gets terminated and gets scheduled in different AZ, it will be able to mount the volume.","title":"Ensure capacity in each AZ when using EBS volumes"},{"location":"reliability/docs/dataplane/#run-node-problem-detector","text":"Failures in worker nodes can impact the availability of your applications. node-problem-detector is a Kubernetes add-on that you can install in your cluster to detect worker node issues. You can use a npd\u2019s remedy system to drain and terminate the node automatically.","title":"Run node-problem-detector"},{"location":"reliability/docs/dataplane/#reserving-resources-for-system-and-kubernetes-daemons","text":"You can improve worker nodes' stability by reserving compute capacity for the operating system and Kubernetes daemons . Pods - especially ones without limits declared - can saturate system resources putting nodes in a situation where operating system processes and Kubernetes daemons ( kubelet , container runtime, etc.) compete with pods for system resources. You can use kubelet flags --system-reserved and --kube-reserved to reserve resources for system process ( udev , sshd , etc.) and Kubernetes daemons respectively. If you use the EKS-optimized Linux AMI , the CPU, memory, and storage are reserved for the system and Kubernetes daemons by default. When worker nodes based on this AMI launch, EC2 user-data is configured to trigger the bootstrap.sh script . This script calculates CPU and memory reservations based on the number of CPU cores and total memory available on the EC2 instance. The calculated values are written to the KubeletConfiguration file located at /etc/kubernetes/kubelet/kubelet-config.json . You may need to increase the system resource reservation if you run custom daemons on the node and the amount of CPU and memory reserved by default is insufficient. eksctl offers the easiest way to customize resource reservation for system and Kubernetes daemons .","title":"Reserving resources for system and Kubernetes daemons"},{"location":"reliability/docs/dataplane/#implement-qos","text":"For critical applications, consider defining requests = limits for the container in the Pod. This will ensure that the container will not be killed if another Pod requests resources. It is a best practice to implement CPU and memory limits for all containers as it prevents a container inadvertently consuming system resources impacting the availability of other co-located processes.","title":"Implement QoS"},{"location":"reliability/docs/dataplane/#configure-and-size-resource-requestslimits-for-all-workloads","text":"Some general guidance can be applied to sizing resource requests and limits for workloads: Do not specify resource limits on CPU. In the absence of limits, the request acts as a weight on how much relative CPU time containers get . This allows your workloads to use the full CPU without an artificial limit or starvation. For non-CPU resources, configuring requests = limits provides the most predictable behavior. If requests != limits , the container also has its QOS reduced from Guaranteed to Burstable making it more likely to be evicted in the event of node pressure . For non-CPU resources, do not specify a limit that is much larger than the request. The larger limits are configured relative to requests , the more likely nodes will be overcommitted leading to high chances of workload interruption. Correctly sized requests are particularly important when using a node auto-scaling solution like Karpenter or Cluster AutoScaler . These tools look at your workload requests to determine the number and size of nodes to be provisioned. If your requests are too small with larger limits, you may find your workloads evicted or OOM killed if they have been tightly packed on a node. Determining resource requests can be difficult, but tools like the Vertical Pod Autoscaler can help you 'right-size' the requests by observing container resource usage at runtime. Other tools that may be useful for determining request sizes include: Goldilocks Parca Prodfiler rsg","title":"Configure and Size Resource Requests/Limits for all Workloads"},{"location":"reliability/docs/dataplane/#configure-resource-quotas-for-namespaces","text":"Namespaces are intended for use in environments with many users spread across multiple teams, or projects. They provide a scope for names and are a way to divide cluster resources between multiple teams, projects, workloads. You can limit the aggregate resource consumption in a namespace. The ResourceQuota object can limit the quantity of objects that can be created in a namespace by type, as well as the total amount of compute resources that may be consumed by resources in that project. You can limit the total sum of storage and/or compute (CPU and memory) resources that can be requested in a given namespace. If resource quota is enabled for a namespace for compute resources like CPU and memory, users must specify requests or limits for each container in that namespace. Consider configuring quotas for each namespace. Consider using LimitRanges to automatically apply preconfigured limits to containers within a namespaces.","title":"Configure resource quotas for namespaces"},{"location":"reliability/docs/dataplane/#limit-container-resource-usage-within-a-namespace","text":"Resource Quotas help limit the amount of resources a namespace can use. The LimitRange object can help you implement minimum and maximum resources a container can request. Using LimitRange you can set a default request and limits for containers, which is helpful if setting compute resource limits is not a standard practice in your organization. As the name suggests, LimitRange can enforce minimum and maximum compute resources usage per Pod or Container in a namespace. As well as, enforce minimum and maximum storage request per PersistentVolumeClaim in a namespace. Consider using LimitRange in conjunction with ResourceQuota to enforce limits at a container as well as namespace level. Setting these limits will ensure that a container or a namespace does not impinge on resources used by other tenants in the cluster.","title":"Limit container resource usage within a namespace"},{"location":"reliability/docs/networkmanagement/","text":"Networking in EKS \u00b6 EKS uses Amazon VPC to provide networking capabilities to worker nodes and Kubernetes Pods. An EKS cluster consists of two VPCs: an AWS-managed VPC that hosts the Kubernetes control plane and a second customer-managed VPC that hosts the Kubernetes worker nodes where containers run, as well as other AWS infrastructure (like load balancers) used by the cluster. All worker nodes need the ability to connect to the managed API server endpoint. This connection allows the worker node to register itself with the Kubernetes control plane and to receive requests to run application pods. Worker nodes connect to the EKS control plane through the EKS public endpoint or EKS-managed elastic network interfaces (ENIs). The subnets that you pass when you create the cluster influence where EKS places these ENIs. You need to provide a minimum of two subnets in at least two Availability Zones. The route that worker nodes take to connect is determined by whether you have enabled or disabled the private endpoint for your cluster. EKS uses the EKS-managed ENI to communicate with worker nodes. Insert a diagram about how control plane and worker nodes communicate. Refer to Cluster VPC considerations when architecting a VPC to be used with EKS. If you deploy worker nodes in private subnets then these subnets should have a default route to a NAT Gateway . Recommendations \u00b6 Deploy NAT Gateways in each Availability Zone \u00b6 If you deploy worker nodes in private subnets, consider creating a NAT Gateway in each Availability Zone to ensure zone-independent architecture. Each NAT gateway in an AZ is implemented with redundancy. Amazon VPC CNI \u00b6 Amazon EKS supports native VPC networking via the Amazon VPC Container Network Interface (CNI) plugin for Kubernetes. The CNI plugin allows Kubernetes Pods to have the same IP address inside the Pod as they do on the VPC network. The CNI plugin uses Elastic Network Interface (ENI) for Pod networking. The CNI allocates ENIs to each worker node and uses the secondary IP range from each ENI for pods. The CNI pre-allocates ENIs and IP addresses for faster pod startup. The maximum number of network interfaces, and the maximum number of private IPv4 addresses that you can use varies by the type of EC2 Instance. Since each Pod uses an IP address, the number of Pods you can run on a particular EC2 Instance depends on how many ENIs can be attached to it and how many IP addresses it supports. This file contains the maximum number of pods you can run on an EC2 Instance. The limits in the file are invalid if you use CNI custom networking. The CNI plugin has two components: CNI plugin , which will wire up host\u2019s and pod\u2019s network stack when called. L-IPAMD (aws-node DaemonSet) runs on every node is a long-running node-Local IP Address Management (IPAM) daemon and is responsible for: maintaining a warm-pool of available IP addresses, and assigning an IP address to a Pod. You can find more details in Proposal: CNI plugin for Kubernetes networking over AWS VPC . Recommendations \u00b6 Plan for growth \u00b6 Size the subnets you will use for Pod networking for growth. If you have insufficient IP addresses available in the subnet that the CNI uses, your pods will not get an IP address. And the pods will remain pending until an IP address becomes available. This may impact application autoscaling and compromise its availability. Monitor IP address inventory \u00b6 You can monitor the IP addresses inventory of subnets using CNI Metrics Helper . You can also set CloudWatch alarms to get notified if a subnet is running out of IP addresses. Using public subnets for worker nodes \u00b6 If you use public subnets, then they must have the automatic public IP address assignment setting enabled; otherwise, worker nodes will not be able to communicate with the cluster. Run worker nodes and pods in different subnets \u00b6 Consider creating separate subnets for Pod networking (also called CNI custom networking ) to avoid IP address allocation conflicts between Pods and other resources in the VPC. SNAT \u00b6 If your Pods with private IP address need to communicate with other private IP address spaces (for example, Direct Connect, VPC Peering or Transit VPC), then you need to enable external SNAT in the CNI: kubectl set env daemonset -n kube-system aws-node AWS_VPC_K8S_CNI_EXTERNALSNAT = true Size your subnets for growth \u00b6 The CNI pre-allocates and caches a certain number of IP addresses so that Kubernetes scheduler can schedule pods on these worker nodes. The IP addresses are available on the worker nodes, whether you launch pods or not. When you provision a worker node, the CNI allocates a pool of secondary IP addresses (called warm pool ) from the node\u2019s primary ENI. As the pool gets depleted, the CNI attaches another ENI to assign more IP addresses. This process continues until no more ENIs can be attached to the node. Sizing your subnets for growth will prevent your subnets from running out of IP addresses as your Pods and nodes scale. You will not be able to create new Pods or nodes if the subnets don\u2019t have available IP addresses. If you need to constrain the IP addresses the CNI caches then you can use these CNI environment variables: WARM_IP_TARGET -- Number of free IP addresses the CNI should keep available. Use this if your subnet is small and you want to reduce IP address usage. MINIMUM_IP_TARGET -- Number of minimum IP addresses the CNI should allocate at node startup. To configure these options, you can download aws-k8s-cni.yaml compatible with your cluster and set environment variables. At the time of writing, the latest release is located here . Info Configure the value of MINIMUM_IP_TARGET to closely match the number of Pods you expect to run on your nodes. Doing so will ensure that as Pods get created, the CNI can assign IP addresses from the warm pool without calling the EC2 API. Warning Avoid setting the value of WARM_IP_TARGET too low as it will cause additional calls to the EC2 API, and that might cause throttling of the requests. CNI custom networking \u00b6 By default, the CNI assigns Pod\u2019s IP address from the worker node's primary elastic network interface's (ENI) security groups and subnet. If you don\u2019t have enough IP addresses in the worker node subnet or prefer that the worker nodes and Pods reside in separate subnets, you can use CNI custom networking . Enabling a custom network removes an available elastic network interface (and all of its available IP addresses for pods) from each worker node that uses it. The worker node's primary network interface is not used for pod placement when a custom network is enabled. If you want the CNI to assign IP addresses for Pods from a different subnet, you can set AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG environment variable to true . kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG = true When AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true , the CNI will assign Pod IP address from a subnet defined in ENIConfig . The ENIConfig custom resource is used to define the subnet in which Pods will be scheduled. apiVersion : crd.k8s.amazonaws.com/v1alpha1 kind : ENIConfig metadata : name : us-west-2a spec : securityGroups : - sg-0dff111a1d11c1c11 subnet : subnet-011b111c1f11fdf11 You will need to create an ENIconfig custom resource for each subnet you want to use for Pod networking. - The securityGroups field should have the ID of the security group attached to the worker nodes. - The name field should be the name of the Availability Zone in your VPC. If you name your ENIConfig custom resources after each Availability Zone in your VPC, you can enable Kubernetes to automatically apply the corresponding ENIConfig for the worker node Availability Zone with the following command. kubectl set env daemonset aws-node \\ -n kube-system ENI_CONFIG_LABEL_DEF = failure-domain.beta.kubernetes.io/zone Upon creating the ENIconfig custom resources, you will need to create new worker nodes. The existing worker nodes and Pods will remain unaffected. You will also need to calculate the maximum number of Pods that can be scheduled on each worker node and pass it in worker nodes\u2019 user-data script. To determine the number of Pods for each worker node, you will need to know the number of network interfaces and the IPv4 addresses per network interface the worker node supports . The formula for calculating the maximum number of pods for an EC2 instance is: maxPods = (number of interfaces - 1) * (max IPv4 addresses per interface - 1) + 2 For a c3.large EC2 instance, the calculation will be: Maximum Pods = ((number of interfaces = 3) - 1) * ((max IPv4 addresses = 10) - 1) +2 => Maximum Pods = (3 - 1) * (10 - 1) + 2 => Maximum Pods = 2 * 9 + 2 = 20 You can then pass the max-pods value in the worker nodes\u2019 user-data script: --use-max-pods false --kubelet-extra-args '--max-pods=20' Since the node\u2019s primary ENI is no longer used to assign Pod IP addresses, there is a decline in the number of Pods you can run on a given EC2 instance type. Using alternate CNI plugins \u00b6 AWS VPC CNI plugin is the only officially supported network plugin on EKS. However, since EKS runs upstream Kubernetes and is certified Kubernetes conformant, you can use alternate CNI plugins . A compelling reason to opt for an alternate CNI plugin is to run Pods without using a VPC IP address per Pod. Although, using an alternate CNI plugin can come at the expense of network performance. Refer to EKS documentation for the list alternate compatible CNI plugins . Consider obtaining the CNI vendor\u2019s commercial support if you plan on using an alternate CNI in production. CoreDNS \u00b6 CoreDNS fulfills name resolution and service discovery functions in Kubernetes. It is installed by default on EKS clusters. For interoperability, the Kubernetes Service for CoreDNS is still named kube-dns . CoreDNS Pods run as part of a Deployment in kube-system namespace, and in EKS, by default, it runs two replicas with declared requests and limits. DNS queries are sent to the kube-dns Service that runs in the kube-system Namespace. Recommendations \u00b6 Monitor CoreDNS metrics \u00b6 CoreDNS has built in support for Prometheus . You should especially consider monitoring CoreDNS latency ( coredns_dns_request_duration_seconds_sum ), errors ( coredns_dns_response_rcode_count_total , NXDOMAIN, SERVFAIL, FormErr) and CoreDNS Pod\u2019s memory consumption. For troubleshooting purposes, you can use kubectl to view CoreDNS logs: for p in $( kubectl get pods \u2014namespace = kube-system -l k8s-app = kube-dns -o name ) ; do kubectl logs \u2014namespace = kube-system $p ; done Use NodeLocal DNSCache \u00b6 You can improve the Cluster DNS performance by running NodeLocal DNSCache . This feature runs a DNS caching agent on cluster nodes as a DaemonSet. All the pods use the DNS caching agent running on the node for name resolution instead of using kube-dns Service. Configure cluster-proportional-scaler for CoreDNS \u00b6 Another method of improving Cluster DNS performance is by automatically horizontally scaling the CoreDNS Deployment based on the number of nodes and CPU cores in the cluster. Horizontal cluster-proportional-autoscaler is a container that resizes the number of replicas of a Deployment based on the size of the schedulable data-plane. Nodes and the aggregate of CPU cores in the nodes are the two metrics with which you can scale CoreDNS. You can use both metrics simultaneously. If you use larger nodes, CoreDNS scaling is based on the number of CPU cores. Whereas, if you use smaller nodes, the number of CoreDNS replicas depends on the CPU cores in your data-plane. Proportional autoscaler configuration looks like this: linear: '{\"coresPerReplica\":256,\"min\":1,\"nodesPerReplica\":16}'","title":"Network"},{"location":"reliability/docs/networkmanagement/#networking-in-eks","text":"EKS uses Amazon VPC to provide networking capabilities to worker nodes and Kubernetes Pods. An EKS cluster consists of two VPCs: an AWS-managed VPC that hosts the Kubernetes control plane and a second customer-managed VPC that hosts the Kubernetes worker nodes where containers run, as well as other AWS infrastructure (like load balancers) used by the cluster. All worker nodes need the ability to connect to the managed API server endpoint. This connection allows the worker node to register itself with the Kubernetes control plane and to receive requests to run application pods. Worker nodes connect to the EKS control plane through the EKS public endpoint or EKS-managed elastic network interfaces (ENIs). The subnets that you pass when you create the cluster influence where EKS places these ENIs. You need to provide a minimum of two subnets in at least two Availability Zones. The route that worker nodes take to connect is determined by whether you have enabled or disabled the private endpoint for your cluster. EKS uses the EKS-managed ENI to communicate with worker nodes. Insert a diagram about how control plane and worker nodes communicate. Refer to Cluster VPC considerations when architecting a VPC to be used with EKS. If you deploy worker nodes in private subnets then these subnets should have a default route to a NAT Gateway .","title":"Networking in EKS"},{"location":"reliability/docs/networkmanagement/#recommendations","text":"","title":"Recommendations"},{"location":"reliability/docs/networkmanagement/#deploy-nat-gateways-in-each-availability-zone","text":"If you deploy worker nodes in private subnets, consider creating a NAT Gateway in each Availability Zone to ensure zone-independent architecture. Each NAT gateway in an AZ is implemented with redundancy.","title":"Deploy NAT Gateways in each Availability Zone"},{"location":"reliability/docs/networkmanagement/#amazon-vpc-cni","text":"Amazon EKS supports native VPC networking via the Amazon VPC Container Network Interface (CNI) plugin for Kubernetes. The CNI plugin allows Kubernetes Pods to have the same IP address inside the Pod as they do on the VPC network. The CNI plugin uses Elastic Network Interface (ENI) for Pod networking. The CNI allocates ENIs to each worker node and uses the secondary IP range from each ENI for pods. The CNI pre-allocates ENIs and IP addresses for faster pod startup. The maximum number of network interfaces, and the maximum number of private IPv4 addresses that you can use varies by the type of EC2 Instance. Since each Pod uses an IP address, the number of Pods you can run on a particular EC2 Instance depends on how many ENIs can be attached to it and how many IP addresses it supports. This file contains the maximum number of pods you can run on an EC2 Instance. The limits in the file are invalid if you use CNI custom networking. The CNI plugin has two components: CNI plugin , which will wire up host\u2019s and pod\u2019s network stack when called. L-IPAMD (aws-node DaemonSet) runs on every node is a long-running node-Local IP Address Management (IPAM) daemon and is responsible for: maintaining a warm-pool of available IP addresses, and assigning an IP address to a Pod. You can find more details in Proposal: CNI plugin for Kubernetes networking over AWS VPC .","title":"Amazon VPC CNI"},{"location":"reliability/docs/networkmanagement/#recommendations_1","text":"","title":"Recommendations"},{"location":"reliability/docs/networkmanagement/#plan-for-growth","text":"Size the subnets you will use for Pod networking for growth. If you have insufficient IP addresses available in the subnet that the CNI uses, your pods will not get an IP address. And the pods will remain pending until an IP address becomes available. This may impact application autoscaling and compromise its availability.","title":"Plan for growth"},{"location":"reliability/docs/networkmanagement/#monitor-ip-address-inventory","text":"You can monitor the IP addresses inventory of subnets using CNI Metrics Helper . You can also set CloudWatch alarms to get notified if a subnet is running out of IP addresses.","title":"Monitor IP address inventory"},{"location":"reliability/docs/networkmanagement/#using-public-subnets-for-worker-nodes","text":"If you use public subnets, then they must have the automatic public IP address assignment setting enabled; otherwise, worker nodes will not be able to communicate with the cluster.","title":"Using public subnets for worker nodes"},{"location":"reliability/docs/networkmanagement/#run-worker-nodes-and-pods-in-different-subnets","text":"Consider creating separate subnets for Pod networking (also called CNI custom networking ) to avoid IP address allocation conflicts between Pods and other resources in the VPC.","title":"Run worker nodes and pods in different subnets"},{"location":"reliability/docs/networkmanagement/#snat","text":"If your Pods with private IP address need to communicate with other private IP address spaces (for example, Direct Connect, VPC Peering or Transit VPC), then you need to enable external SNAT in the CNI: kubectl set env daemonset -n kube-system aws-node AWS_VPC_K8S_CNI_EXTERNALSNAT = true","title":"SNAT"},{"location":"reliability/docs/networkmanagement/#size-your-subnets-for-growth","text":"The CNI pre-allocates and caches a certain number of IP addresses so that Kubernetes scheduler can schedule pods on these worker nodes. The IP addresses are available on the worker nodes, whether you launch pods or not. When you provision a worker node, the CNI allocates a pool of secondary IP addresses (called warm pool ) from the node\u2019s primary ENI. As the pool gets depleted, the CNI attaches another ENI to assign more IP addresses. This process continues until no more ENIs can be attached to the node. Sizing your subnets for growth will prevent your subnets from running out of IP addresses as your Pods and nodes scale. You will not be able to create new Pods or nodes if the subnets don\u2019t have available IP addresses. If you need to constrain the IP addresses the CNI caches then you can use these CNI environment variables: WARM_IP_TARGET -- Number of free IP addresses the CNI should keep available. Use this if your subnet is small and you want to reduce IP address usage. MINIMUM_IP_TARGET -- Number of minimum IP addresses the CNI should allocate at node startup. To configure these options, you can download aws-k8s-cni.yaml compatible with your cluster and set environment variables. At the time of writing, the latest release is located here . Info Configure the value of MINIMUM_IP_TARGET to closely match the number of Pods you expect to run on your nodes. Doing so will ensure that as Pods get created, the CNI can assign IP addresses from the warm pool without calling the EC2 API. Warning Avoid setting the value of WARM_IP_TARGET too low as it will cause additional calls to the EC2 API, and that might cause throttling of the requests.","title":"Size your subnets for growth"},{"location":"reliability/docs/networkmanagement/#cni-custom-networking","text":"By default, the CNI assigns Pod\u2019s IP address from the worker node's primary elastic network interface's (ENI) security groups and subnet. If you don\u2019t have enough IP addresses in the worker node subnet or prefer that the worker nodes and Pods reside in separate subnets, you can use CNI custom networking . Enabling a custom network removes an available elastic network interface (and all of its available IP addresses for pods) from each worker node that uses it. The worker node's primary network interface is not used for pod placement when a custom network is enabled. If you want the CNI to assign IP addresses for Pods from a different subnet, you can set AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG environment variable to true . kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG = true When AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true , the CNI will assign Pod IP address from a subnet defined in ENIConfig . The ENIConfig custom resource is used to define the subnet in which Pods will be scheduled. apiVersion : crd.k8s.amazonaws.com/v1alpha1 kind : ENIConfig metadata : name : us-west-2a spec : securityGroups : - sg-0dff111a1d11c1c11 subnet : subnet-011b111c1f11fdf11 You will need to create an ENIconfig custom resource for each subnet you want to use for Pod networking. - The securityGroups field should have the ID of the security group attached to the worker nodes. - The name field should be the name of the Availability Zone in your VPC. If you name your ENIConfig custom resources after each Availability Zone in your VPC, you can enable Kubernetes to automatically apply the corresponding ENIConfig for the worker node Availability Zone with the following command. kubectl set env daemonset aws-node \\ -n kube-system ENI_CONFIG_LABEL_DEF = failure-domain.beta.kubernetes.io/zone Upon creating the ENIconfig custom resources, you will need to create new worker nodes. The existing worker nodes and Pods will remain unaffected. You will also need to calculate the maximum number of Pods that can be scheduled on each worker node and pass it in worker nodes\u2019 user-data script. To determine the number of Pods for each worker node, you will need to know the number of network interfaces and the IPv4 addresses per network interface the worker node supports . The formula for calculating the maximum number of pods for an EC2 instance is: maxPods = (number of interfaces - 1) * (max IPv4 addresses per interface - 1) + 2 For a c3.large EC2 instance, the calculation will be: Maximum Pods = ((number of interfaces = 3) - 1) * ((max IPv4 addresses = 10) - 1) +2 => Maximum Pods = (3 - 1) * (10 - 1) + 2 => Maximum Pods = 2 * 9 + 2 = 20 You can then pass the max-pods value in the worker nodes\u2019 user-data script: --use-max-pods false --kubelet-extra-args '--max-pods=20' Since the node\u2019s primary ENI is no longer used to assign Pod IP addresses, there is a decline in the number of Pods you can run on a given EC2 instance type.","title":"CNI custom networking"},{"location":"reliability/docs/networkmanagement/#using-alternate-cni-plugins","text":"AWS VPC CNI plugin is the only officially supported network plugin on EKS. However, since EKS runs upstream Kubernetes and is certified Kubernetes conformant, you can use alternate CNI plugins . A compelling reason to opt for an alternate CNI plugin is to run Pods without using a VPC IP address per Pod. Although, using an alternate CNI plugin can come at the expense of network performance. Refer to EKS documentation for the list alternate compatible CNI plugins . Consider obtaining the CNI vendor\u2019s commercial support if you plan on using an alternate CNI in production.","title":"Using alternate CNI plugins"},{"location":"reliability/docs/networkmanagement/#coredns","text":"CoreDNS fulfills name resolution and service discovery functions in Kubernetes. It is installed by default on EKS clusters. For interoperability, the Kubernetes Service for CoreDNS is still named kube-dns . CoreDNS Pods run as part of a Deployment in kube-system namespace, and in EKS, by default, it runs two replicas with declared requests and limits. DNS queries are sent to the kube-dns Service that runs in the kube-system Namespace.","title":"CoreDNS"},{"location":"reliability/docs/networkmanagement/#recommendations_2","text":"","title":"Recommendations"},{"location":"reliability/docs/networkmanagement/#monitor-coredns-metrics","text":"CoreDNS has built in support for Prometheus . You should especially consider monitoring CoreDNS latency ( coredns_dns_request_duration_seconds_sum ), errors ( coredns_dns_response_rcode_count_total , NXDOMAIN, SERVFAIL, FormErr) and CoreDNS Pod\u2019s memory consumption. For troubleshooting purposes, you can use kubectl to view CoreDNS logs: for p in $( kubectl get pods \u2014namespace = kube-system -l k8s-app = kube-dns -o name ) ; do kubectl logs \u2014namespace = kube-system $p ; done","title":"Monitor CoreDNS metrics"},{"location":"reliability/docs/networkmanagement/#use-nodelocal-dnscache","text":"You can improve the Cluster DNS performance by running NodeLocal DNSCache . This feature runs a DNS caching agent on cluster nodes as a DaemonSet. All the pods use the DNS caching agent running on the node for name resolution instead of using kube-dns Service.","title":"Use NodeLocal DNSCache"},{"location":"reliability/docs/networkmanagement/#configure-cluster-proportional-scaler-for-coredns","text":"Another method of improving Cluster DNS performance is by automatically horizontally scaling the CoreDNS Deployment based on the number of nodes and CPU cores in the cluster. Horizontal cluster-proportional-autoscaler is a container that resizes the number of replicas of a Deployment based on the size of the schedulable data-plane. Nodes and the aggregate of CPU cores in the nodes are the two metrics with which you can scale CoreDNS. You can use both metrics simultaneously. If you use larger nodes, CoreDNS scaling is based on the number of CPU cores. Whereas, if you use smaller nodes, the number of CoreDNS replicas depends on the CPU cores in your data-plane. Proportional autoscaler configuration looks like this: linear: '{\"coresPerReplica\":256,\"min\":1,\"nodesPerReplica\":16}'","title":"Configure cluster-proportional-scaler for CoreDNS"},{"location":"security/docs/","text":"Amazon EKS Best Practices Guide for Security \u00b6 This guide provides advice about protecting information, systems, and assets that are reliant on EKS while delivering business value through risk assessments and mitigation strategies. The guidance herein is part of a series of best practices guides that AWS is publishing to help customers implement EKS in accordance with best practices. Guides for Performance, Operational Excellence, Cost Optimization, and Reliability will be available in the coming months. How to use this guide \u00b6 This guide is meant for security practitioners who are responsible for implementing and monitoring the effectiveness of security controls for EKS clusters and the workloads they support. The guide is organized into different topic areas for easier consumption. Each topic starts with a brief overview, followed by a list of recommendations and best practices for securing your EKS clusters. The topics do not need to be read in a particular order. Understanding the Shared Responsibility Model \u00b6 Security and compliance are considered shared responsibilities when using a managed service like EKS. Generally speaking, AWS is responsible for security \"of\" the cloud whereas you, the customer, are responsible for security \"in\" the cloud. With EKS, AWS is responsible for managing of the EKS managed Kubernetes control plane. This includes the Kubernetes masters, the ETCD database, and other infrastructure necessary for AWS to deliver a secure and reliable service. As a consumer of EKS, you are largely responsible for the topics in this guide, e.g. IAM, pod security, runtime security, network security, and so forth. When it comes to infrastructure security, AWS will assume additional responsibilities as you move from self-managed workers, to managed node groups, to Fargate. For example, with Fargate, AWS becomes responsible for securing the underlying instance/runtime used to run your Pods. AWS will also assume responsibility of keeping the EKS optimized AMI up to date with Kubernetes patch versions and security patches. Customers using Managed Node Groups (MNG) are responsible for upgrading their Nodegroups to the latest AMI via EKS API, CLI, Cloudformation or AWS Console. Also unlike Fargate, MNGs will not automatically scale your infrastructure/cluster. That can be handled by the cluster-autoscaler or other technologies such as Karpenter , native AWS autoscaling, SpotInst's Ocean , or Atlassian's Escalator . Before designing your system, it is important to know where the line of demarcation is between your responsibilities and the provider of the service (AWS). For additional information about the shared responsibility model, see https://aws.amazon.com/compliance/shared-responsibility-model/ Introduction \u00b6 There are several security best practice areas that are pertinent when using a managed Kubernetes service like EKS: Identity and Access Management Pod Security Runtime Security Network Security Multi-tenancy Detective Controls Infrastructure Security Data Encryption and Secrets Management Regulatory Compliance Incident Response and Forensics Image Security As part of designing any system, you need to think about its security implications and the practices that can affect your security posture. For example, you need to control who can perform actions against a set of resources. You also need the ability to quickly identify security incidents, protect your systems and services from unauthorized access, and maintain the confidentiality and integrity of data through data protection. Having a well-defined and rehearsed set of processes for responding to security incidents will improve your security posture too. These tools and techniques are important because they support objectives such as preventing financial loss or complying with regulatory obligations. AWS helps organizations achieve their security and compliance goals by offering a rich set of security services that have evolved based on feedback from a broad set of security conscious customers. By offering a highly secure foundation, customers can spend less time on \u201cundifferentiated heavy lifting\u201d and more time on achieving their business objectives. Feedback \u00b6 This guide is being released on GitHub so as to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. Our intention is to update the guide periodically as new features are added to the service or when a new best practice evolves. Further Reading \u00b6 Kubernetes Security Whitepaper , sponsored by the Security Audit Working Group, this Whitepaper describes key aspects of the Kubernetes attack surface and security architecture with the aim of helping security practitioners make sound design and implementation decisions. The CNCF published also a white paper on cloud native security. The paper examines how the technology landscape has evolved and advocates for the adoption of security practices that align with DevOps processes and agile methodologies.","title":"Home"},{"location":"security/docs/#amazon-eks-best-practices-guide-for-security","text":"This guide provides advice about protecting information, systems, and assets that are reliant on EKS while delivering business value through risk assessments and mitigation strategies. The guidance herein is part of a series of best practices guides that AWS is publishing to help customers implement EKS in accordance with best practices. Guides for Performance, Operational Excellence, Cost Optimization, and Reliability will be available in the coming months.","title":"Amazon EKS Best Practices Guide for Security"},{"location":"security/docs/#how-to-use-this-guide","text":"This guide is meant for security practitioners who are responsible for implementing and monitoring the effectiveness of security controls for EKS clusters and the workloads they support. The guide is organized into different topic areas for easier consumption. Each topic starts with a brief overview, followed by a list of recommendations and best practices for securing your EKS clusters. The topics do not need to be read in a particular order.","title":"How to use this guide"},{"location":"security/docs/#understanding-the-shared-responsibility-model","text":"Security and compliance are considered shared responsibilities when using a managed service like EKS. Generally speaking, AWS is responsible for security \"of\" the cloud whereas you, the customer, are responsible for security \"in\" the cloud. With EKS, AWS is responsible for managing of the EKS managed Kubernetes control plane. This includes the Kubernetes masters, the ETCD database, and other infrastructure necessary for AWS to deliver a secure and reliable service. As a consumer of EKS, you are largely responsible for the topics in this guide, e.g. IAM, pod security, runtime security, network security, and so forth. When it comes to infrastructure security, AWS will assume additional responsibilities as you move from self-managed workers, to managed node groups, to Fargate. For example, with Fargate, AWS becomes responsible for securing the underlying instance/runtime used to run your Pods. AWS will also assume responsibility of keeping the EKS optimized AMI up to date with Kubernetes patch versions and security patches. Customers using Managed Node Groups (MNG) are responsible for upgrading their Nodegroups to the latest AMI via EKS API, CLI, Cloudformation or AWS Console. Also unlike Fargate, MNGs will not automatically scale your infrastructure/cluster. That can be handled by the cluster-autoscaler or other technologies such as Karpenter , native AWS autoscaling, SpotInst's Ocean , or Atlassian's Escalator . Before designing your system, it is important to know where the line of demarcation is between your responsibilities and the provider of the service (AWS). For additional information about the shared responsibility model, see https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Understanding the Shared Responsibility Model"},{"location":"security/docs/#introduction","text":"There are several security best practice areas that are pertinent when using a managed Kubernetes service like EKS: Identity and Access Management Pod Security Runtime Security Network Security Multi-tenancy Detective Controls Infrastructure Security Data Encryption and Secrets Management Regulatory Compliance Incident Response and Forensics Image Security As part of designing any system, you need to think about its security implications and the practices that can affect your security posture. For example, you need to control who can perform actions against a set of resources. You also need the ability to quickly identify security incidents, protect your systems and services from unauthorized access, and maintain the confidentiality and integrity of data through data protection. Having a well-defined and rehearsed set of processes for responding to security incidents will improve your security posture too. These tools and techniques are important because they support objectives such as preventing financial loss or complying with regulatory obligations. AWS helps organizations achieve their security and compliance goals by offering a rich set of security services that have evolved based on feedback from a broad set of security conscious customers. By offering a highly secure foundation, customers can spend less time on \u201cundifferentiated heavy lifting\u201d and more time on achieving their business objectives.","title":"Introduction"},{"location":"security/docs/#feedback","text":"This guide is being released on GitHub so as to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. Our intention is to update the guide periodically as new features are added to the service or when a new best practice evolves.","title":"Feedback"},{"location":"security/docs/#further-reading","text":"Kubernetes Security Whitepaper , sponsored by the Security Audit Working Group, this Whitepaper describes key aspects of the Kubernetes attack surface and security architecture with the aim of helping security practitioners make sound design and implementation decisions. The CNCF published also a white paper on cloud native security. The paper examines how the technology landscape has evolved and advocates for the adoption of security practices that align with DevOps processes and agile methodologies.","title":"Further Reading"},{"location":"security/docs/compliance/","text":"Compliance \u00b6 Compliance is a shared responsibility between AWS and the consumers of its services. Generally speaking, AWS is responsible for \u201csecurity of the cloud\u201d whereas its users are responsible for \u201csecurity in the cloud.\u201d The line that delineates what AWS and its users are responsible for will vary depending on the service. For example, with Fargate, AWS is responsible for managing the physical security of its data centers, the hardware, the virtual infrastructure (Amazon EC2), and the container runtime (Docker). Users of Fargate are responsible for securing the container image and their application. Knowing who is responsible for what is an important consideration when running workloads that must adhere to compliance standards. The following table shows the compliance programs with which the different container services conform. Compliance Program Amazon ECS Orchestrator Amazon EKS Orchestrator ECS Fargate Amazon ECR PCI DSS Level 1 1 1 1 1 HIPAA Eligible 1 1 1 1 SOC I 1 1 1 1 SOC II 1 1 1 1 SOC III 1 1 1 1 ISO 27001:2013 1 1 1 1 ISO 9001:2015 1 1 1 1 ISO 27017:2015 1 1 1 1 ISO 27018:2019 1 1 1 1 IRAP 1 1 1 1 FedRAMP Moderate (East/West) 1 1 0 1 FedRAMP High (GovCloud) 1 1 0 1 DOD CC SRG 1 DISA Review (IL5) 0 1 HIPAA BAA 1 1 1 1 MTCS 1 1 0 1 C5 1 1 0 1 K-ISMS 1 1 0 1 ENS High 1 1 0 1 OSPAR 1 1 0 1 HITRUST CSF 1 1 1 1 Compliance status changes over time. For the latest status, always refer to https://aws.amazon.com/compliance/services-in-scope/ . For further information about cloud accreditation models and best practices, see the AWS whitepaper, Accreditation Models for Secure Cloud Adoption Shifting Left \u00b6 The concept of shifting left involves catching policy violations and errors earlier in the software development lifecycle. From a security perspective, this can be very beneficial. A developer, for example, can fix issues with their configuration before their application is deployed to the cluster. Catching mistakes like this earlier will help prevent configurations that violate your policies from being deployed. Policy as Code \u00b6 Policy can be thought of as a set of rules for governing behaviors, i.e. behaviors that are allowed or those that are prohibited. For example, you may have a policy that says that all Dockerfiles should include a USER directive that causes the container to run as a non-root user. As a document, a policy like this can be hard to discover and enforce. It may also become outdated as your requirements change. With Policy as Code (PaC) solutions, you can automate security, compliance, and privacy controls that detect, prevent, reduce, and counteract known and persistent threats. Furthermore, they give you mechanism to codify your policies and manage them as you do other code artifacts. The benefit of this approach is that you can reuse your DevOps and GitOps strategies to manage and consistently apply policies across fleets of Kubernetes clusters. Please refer to Pod Security for information about PaC options and the future of PSPs. Recommendations \u00b6 Use policy-as-code tools in pipelines to detect violations before deployment \u00b6 OPA is an open source policy engine that's part of the CNCF. It's used for making policy decisions and can be run a variety of different ways, e.g. as a language library or a service. OPA policies are written in a Domain Specific Language (DSL) called Rego. While it is often run as part of a Kubernetes Dynamic Admission Controller as the Gatekeeper project, OPA can also be incorporated into your CI/CD pipeline. This allows developers to get feedback about their configuration earlier in the release cycle which can subsequently help them resolve issues before they get to production. A collection of common OPA policies can be found in the GitHub repository for this project. Conftest is built on top of OPA and it provides a developer focused experience for testing Kubernetes configuration. sKan is powered by OPA and is \"tailor made\" to check whether their Kubernetes configuration files are compliant with security and operational best practices. Kyverno is a policy engine designed for Kubernetes. With Kyverno, policies are managed as Kubernetes resources and no new language is required to write policies. This allows using familiar tools such as kubectl, git, and kustomize to manage policies. Kyverno policies can validate, mutate, and generate Kubernetes resources plus ensure OCI image supply chain security. The Kyverno CLI can be used to test policies and validate resources as part of a CI/CD pipeline. All the Kyverno community policies can be found on the Kyverno website , and for examples using the Kyverno CLI to write tests in pipelines, see the policies repository . Tools and resources \u00b6 kube-bench docker-bench-security AWS Inspector Kubernetes Security Review A 3rd party security assessment of Kubernetes 1.13.4 (2019)","title":"Regulatory Compliance"},{"location":"security/docs/compliance/#compliance","text":"Compliance is a shared responsibility between AWS and the consumers of its services. Generally speaking, AWS is responsible for \u201csecurity of the cloud\u201d whereas its users are responsible for \u201csecurity in the cloud.\u201d The line that delineates what AWS and its users are responsible for will vary depending on the service. For example, with Fargate, AWS is responsible for managing the physical security of its data centers, the hardware, the virtual infrastructure (Amazon EC2), and the container runtime (Docker). Users of Fargate are responsible for securing the container image and their application. Knowing who is responsible for what is an important consideration when running workloads that must adhere to compliance standards. The following table shows the compliance programs with which the different container services conform. Compliance Program Amazon ECS Orchestrator Amazon EKS Orchestrator ECS Fargate Amazon ECR PCI DSS Level 1 1 1 1 1 HIPAA Eligible 1 1 1 1 SOC I 1 1 1 1 SOC II 1 1 1 1 SOC III 1 1 1 1 ISO 27001:2013 1 1 1 1 ISO 9001:2015 1 1 1 1 ISO 27017:2015 1 1 1 1 ISO 27018:2019 1 1 1 1 IRAP 1 1 1 1 FedRAMP Moderate (East/West) 1 1 0 1 FedRAMP High (GovCloud) 1 1 0 1 DOD CC SRG 1 DISA Review (IL5) 0 1 HIPAA BAA 1 1 1 1 MTCS 1 1 0 1 C5 1 1 0 1 K-ISMS 1 1 0 1 ENS High 1 1 0 1 OSPAR 1 1 0 1 HITRUST CSF 1 1 1 1 Compliance status changes over time. For the latest status, always refer to https://aws.amazon.com/compliance/services-in-scope/ . For further information about cloud accreditation models and best practices, see the AWS whitepaper, Accreditation Models for Secure Cloud Adoption","title":"Compliance"},{"location":"security/docs/compliance/#shifting-left","text":"The concept of shifting left involves catching policy violations and errors earlier in the software development lifecycle. From a security perspective, this can be very beneficial. A developer, for example, can fix issues with their configuration before their application is deployed to the cluster. Catching mistakes like this earlier will help prevent configurations that violate your policies from being deployed.","title":"Shifting Left"},{"location":"security/docs/compliance/#policy-as-code","text":"Policy can be thought of as a set of rules for governing behaviors, i.e. behaviors that are allowed or those that are prohibited. For example, you may have a policy that says that all Dockerfiles should include a USER directive that causes the container to run as a non-root user. As a document, a policy like this can be hard to discover and enforce. It may also become outdated as your requirements change. With Policy as Code (PaC) solutions, you can automate security, compliance, and privacy controls that detect, prevent, reduce, and counteract known and persistent threats. Furthermore, they give you mechanism to codify your policies and manage them as you do other code artifacts. The benefit of this approach is that you can reuse your DevOps and GitOps strategies to manage and consistently apply policies across fleets of Kubernetes clusters. Please refer to Pod Security for information about PaC options and the future of PSPs.","title":"Policy as Code"},{"location":"security/docs/compliance/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/compliance/#use-policy-as-code-tools-in-pipelines-to-detect-violations-before-deployment","text":"OPA is an open source policy engine that's part of the CNCF. It's used for making policy decisions and can be run a variety of different ways, e.g. as a language library or a service. OPA policies are written in a Domain Specific Language (DSL) called Rego. While it is often run as part of a Kubernetes Dynamic Admission Controller as the Gatekeeper project, OPA can also be incorporated into your CI/CD pipeline. This allows developers to get feedback about their configuration earlier in the release cycle which can subsequently help them resolve issues before they get to production. A collection of common OPA policies can be found in the GitHub repository for this project. Conftest is built on top of OPA and it provides a developer focused experience for testing Kubernetes configuration. sKan is powered by OPA and is \"tailor made\" to check whether their Kubernetes configuration files are compliant with security and operational best practices. Kyverno is a policy engine designed for Kubernetes. With Kyverno, policies are managed as Kubernetes resources and no new language is required to write policies. This allows using familiar tools such as kubectl, git, and kustomize to manage policies. Kyverno policies can validate, mutate, and generate Kubernetes resources plus ensure OCI image supply chain security. The Kyverno CLI can be used to test policies and validate resources as part of a CI/CD pipeline. All the Kyverno community policies can be found on the Kyverno website , and for examples using the Kyverno CLI to write tests in pipelines, see the policies repository .","title":"Use policy-as-code tools in pipelines to detect violations before deployment"},{"location":"security/docs/compliance/#tools-and-resources","text":"kube-bench docker-bench-security AWS Inspector Kubernetes Security Review A 3rd party security assessment of Kubernetes 1.13.4 (2019)","title":"Tools and resources"},{"location":"security/docs/data/","text":"Data encryption and secrets management \u00b6 Encryption at rest \u00b6 There are three different AWS-native storage options you can use with Kubernetes: EBS , EFS , and FSx for Lustre . All three offer encryption at rest using a service managed key or a customer master key (CMK). For EBS you can use the in-tree storage driver or the EBS CSI driver . Both include parameters for encrypting volumes and supplying a CMK. For EFS, you can use the EFS CSI driver , however, unlike EBS, the EFS CSI driver does not support dynamic provisioning. If you want to use EFS with EKS, you will need to provision and configure at-rest encryption for the file system prior to creating a PV. For further information about EFS file encryption, please refer to Encrypting Data at Rest . Besides offering at-rest encryption, EFS and FSx for Lustre include an option for encrypting data in transit. FSx for Luster does this by default. For EFS, you can add transport encryption by adding the tls parameter to mountOptions in your PV as in this example: apiVersion : v1 kind : PersistentVolume metadata : name : efs-pv spec : capacity : storage : 5Gi volumeMode : Filesystem accessModes : - ReadWriteOnce persistentVolumeReclaimPolicy : Retain storageClassName : efs-sc mountOptions : - tls csi : driver : efs.csi.aws.com volumeHandle : <file_system_id> The FSx CSI driver supports dynamic provisioning of Lustre file systems. It encrypts data with a service managed key by default, although there is an option to provide your own CMK as in this example: kind : StorageClass apiVersion : storage.k8s.io/v1 metadata : name : fsx-sc provisioner : fsx.csi.aws.com parameters : subnetId : subnet-056da83524edbe641 securityGroupIds : sg-086f61ea73388fb6b deploymentType : PERSISTENT_1 kmsKeyId : <kms_arn> Attention As of May 28, 2020 all data written to the ephemeral volume in EKS Fargate pods is encrypted by default using an industry-standard AES-256 cryptographic algorithm. No modifications to your application are necessary as encryption and decryption are handled seamlessly by the service. Recommendations \u00b6 Encrypt data at rest \u00b6 Encrypting data at rest is considered a best practice. If you're unsure whether encryption is necessary, encrypt your data. Rotate your CMKs periodically \u00b6 Configure KMS to automatically rotate your CMKs. This will rotate your keys once a year while saving old keys indefinitely so that your data can still be decrypted. For additional information see Rotating customer master keys Use EFS access points to simplify access to shared datasets \u00b6 If you have shared datasets with different POSIX file permissions or want to restrict access to part of the shared file system by creating different mount points, consider using EFS access points. To learn more about working with access points, see https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html . Today, if you want to use an access point (AP) you'll need to reference the AP in the PV's volumeHandle parameter. Attention As of March 23, 2021 the EFS CSI driver supports dynamic provisioning of EFS Access Points. Access points are application-specific entry points into an EFS file system that make it easier to share a file system between multiple pods. Each EFS file system can have up to 120 PVs. See Introducing Amazon EFS CSI dynamic provisioning for additional information. Secrets management \u00b6 Kubernetes secrets are used to store sensitive information, such as user certificates, passwords, or API keys. They are persisted in etcd as base64 encoded strings. On EKS, the EBS volumes for etcd nodes are encrypted with EBS encryption . A pod can retrieve a Kubernetes secrets objects by referencing the secret in the podSpec . These secrets can either be mapped to an environment variable or mounted as volume. For additional information on creating secrets, see https://kubernetes.io/docs/concepts/configuration/secret/ . Caution Secrets in a particular namespace can be referenced by all pods in the secret's namespace. Caution The node authorizer allows the Kubelet to read all of the secrets mounted to the node. Recommendations \u00b6 Use AWS KMS for envelope encryption of Kubernetes secrets \u00b6 This allows you to encrypt your secrets with a unique data encryption key (DEK). The DEK is then encrypted using a key encryption key (KEK) from AWS KMS which can be automatically rotated on a recurring schedule. With the KMS plugin for Kubernetes, all Kubernetes secrets are stored in etcd in ciphertext instead of plain text and can only be decrypted by the Kubernetes API server. For additional details, see using EKS encryption provider support for defense in depth Audit the use of Kubernetes Secrets \u00b6 On EKS, turn on audit logging and create a CloudWatch metrics filter and alarm to alert you when a secret is used (optional). The following is an example of a metrics filter for the Kubernetes audit log, {($.verb=\"get\") && ($.objectRef.resource=\"secret\")} . You can also use the following queries with CloudWatch Log Insights: fields @timestamp , @message | sort @timestamp desc | limit 100 | stats count ( * ) by objectRef . name as secret | filter verb = \"get\" and objectRef . resource = \"secrets\" The above query will display the number of times a secret has been accessed within a specific timeframe. fields @timestamp , @message | sort @timestamp desc | limit 100 | filter verb = \"get\" and objectRef . resource = \"secrets\" | display objectRef . namespace , objectRef . name , user . username , responseStatus . code This query will display the secret, along with the namespace and username of the user who attempted to access the secret and the response code. Rotate your secrets periodically \u00b6 Kubernetes doesn't automatically rotate secrets. If you have to rotate secrets, consider using an external secret store, e.g. Vault or AWS Secrets Manager. Use separate namespaces as a way to isolate secrets from different applications \u00b6 If you have secrets that cannot be shared between applications in a namespace, create a separate namespace for those applications. Use volume mounts instead of environment variables \u00b6 The values of environment variables can unintentionally appear in logs. Secrets mounted as volumes are instantiated as tmpfs volumes (a RAM backed file system) that are automatically removed from the node when the pod is deleted. Use an external secrets provider \u00b6 There are several viable alternatives to using Kubernetes secrets, including AWS Secrets Manager and Hashicorp's Vault . These services offer features such as fine grained access controls, strong encryption, and automatic rotation of secrets that are not available with Kubernetes Secrets. Bitnami's Sealed Secrets is another approach that uses asymmetric encryption to create \"sealed secrets\". A public key is used to encrypt the secret while the private key used to decrypt the secret is kept within the cluster, allowing you to safely store sealed secrets in source control systems like Git. See Managing secrets deployment in Kubernetes using Sealed Secrets for further information. As the use of external secrets stores has grown, so has need for integrating them with Kubernetes. The Secret Store CSI Driver is a community project that uses the CSI driver model to fetch secrets from external secret stores. Currently, the Driver has support for AWS Secrets Manager , Azure, Vault, and GCP. The AWS provider supports both AWS Secrets Manager and AWS Parameter Store. It can also be configured to rotate secrets when they expire and can synchronize AWS Secrets Manager secrets to Kubernetes Secrets. Synchronization of secrets can be useful when you need to reference a secret as an environment variable instead of reading them from a volume. Note When the the secret store CSI driver has to fetch a secret, it assumes the IRSA role assigned to the pod that references a secret. The code for this operation can be found here . For additional information about the AWS Secrets & Configuration Provider (ASCP) refer to the following resources: How to use AWS Secrets Configuration Provider with Kubernetes Secret Store CSI Driver Integrating Secrets Manager secrets with Kubernetes Secrets Store CSI Driver external-secrets is yet another way to use an external secret store with Kubernetes. Like the CSI Driver, external-secrets works against a variety of different backends, including AWS Secrets Manager. The difference is, rather than retrieving secrets from the external secret store, external-secrets copies secrets from these backends to Kubernetes as Secrets. This lets you manage secrets using your preferred secret store and interact with secrets in a Kubernetes-native way.","title":"Data Encryption and Secrets Management"},{"location":"security/docs/data/#data-encryption-and-secrets-management","text":"","title":"Data encryption and secrets management"},{"location":"security/docs/data/#encryption-at-rest","text":"There are three different AWS-native storage options you can use with Kubernetes: EBS , EFS , and FSx for Lustre . All three offer encryption at rest using a service managed key or a customer master key (CMK). For EBS you can use the in-tree storage driver or the EBS CSI driver . Both include parameters for encrypting volumes and supplying a CMK. For EFS, you can use the EFS CSI driver , however, unlike EBS, the EFS CSI driver does not support dynamic provisioning. If you want to use EFS with EKS, you will need to provision and configure at-rest encryption for the file system prior to creating a PV. For further information about EFS file encryption, please refer to Encrypting Data at Rest . Besides offering at-rest encryption, EFS and FSx for Lustre include an option for encrypting data in transit. FSx for Luster does this by default. For EFS, you can add transport encryption by adding the tls parameter to mountOptions in your PV as in this example: apiVersion : v1 kind : PersistentVolume metadata : name : efs-pv spec : capacity : storage : 5Gi volumeMode : Filesystem accessModes : - ReadWriteOnce persistentVolumeReclaimPolicy : Retain storageClassName : efs-sc mountOptions : - tls csi : driver : efs.csi.aws.com volumeHandle : <file_system_id> The FSx CSI driver supports dynamic provisioning of Lustre file systems. It encrypts data with a service managed key by default, although there is an option to provide your own CMK as in this example: kind : StorageClass apiVersion : storage.k8s.io/v1 metadata : name : fsx-sc provisioner : fsx.csi.aws.com parameters : subnetId : subnet-056da83524edbe641 securityGroupIds : sg-086f61ea73388fb6b deploymentType : PERSISTENT_1 kmsKeyId : <kms_arn> Attention As of May 28, 2020 all data written to the ephemeral volume in EKS Fargate pods is encrypted by default using an industry-standard AES-256 cryptographic algorithm. No modifications to your application are necessary as encryption and decryption are handled seamlessly by the service.","title":"Encryption at rest"},{"location":"security/docs/data/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/data/#encrypt-data-at-rest","text":"Encrypting data at rest is considered a best practice. If you're unsure whether encryption is necessary, encrypt your data.","title":"Encrypt data at rest"},{"location":"security/docs/data/#rotate-your-cmks-periodically","text":"Configure KMS to automatically rotate your CMKs. This will rotate your keys once a year while saving old keys indefinitely so that your data can still be decrypted. For additional information see Rotating customer master keys","title":"Rotate your CMKs periodically"},{"location":"security/docs/data/#use-efs-access-points-to-simplify-access-to-shared-datasets","text":"If you have shared datasets with different POSIX file permissions or want to restrict access to part of the shared file system by creating different mount points, consider using EFS access points. To learn more about working with access points, see https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html . Today, if you want to use an access point (AP) you'll need to reference the AP in the PV's volumeHandle parameter. Attention As of March 23, 2021 the EFS CSI driver supports dynamic provisioning of EFS Access Points. Access points are application-specific entry points into an EFS file system that make it easier to share a file system between multiple pods. Each EFS file system can have up to 120 PVs. See Introducing Amazon EFS CSI dynamic provisioning for additional information.","title":"Use EFS access points to simplify access to shared datasets"},{"location":"security/docs/data/#secrets-management","text":"Kubernetes secrets are used to store sensitive information, such as user certificates, passwords, or API keys. They are persisted in etcd as base64 encoded strings. On EKS, the EBS volumes for etcd nodes are encrypted with EBS encryption . A pod can retrieve a Kubernetes secrets objects by referencing the secret in the podSpec . These secrets can either be mapped to an environment variable or mounted as volume. For additional information on creating secrets, see https://kubernetes.io/docs/concepts/configuration/secret/ . Caution Secrets in a particular namespace can be referenced by all pods in the secret's namespace. Caution The node authorizer allows the Kubelet to read all of the secrets mounted to the node.","title":"Secrets management"},{"location":"security/docs/data/#recommendations_1","text":"","title":"Recommendations"},{"location":"security/docs/data/#use-aws-kms-for-envelope-encryption-of-kubernetes-secrets","text":"This allows you to encrypt your secrets with a unique data encryption key (DEK). The DEK is then encrypted using a key encryption key (KEK) from AWS KMS which can be automatically rotated on a recurring schedule. With the KMS plugin for Kubernetes, all Kubernetes secrets are stored in etcd in ciphertext instead of plain text and can only be decrypted by the Kubernetes API server. For additional details, see using EKS encryption provider support for defense in depth","title":"Use AWS KMS for envelope encryption of Kubernetes secrets"},{"location":"security/docs/data/#audit-the-use-of-kubernetes-secrets","text":"On EKS, turn on audit logging and create a CloudWatch metrics filter and alarm to alert you when a secret is used (optional). The following is an example of a metrics filter for the Kubernetes audit log, {($.verb=\"get\") && ($.objectRef.resource=\"secret\")} . You can also use the following queries with CloudWatch Log Insights: fields @timestamp , @message | sort @timestamp desc | limit 100 | stats count ( * ) by objectRef . name as secret | filter verb = \"get\" and objectRef . resource = \"secrets\" The above query will display the number of times a secret has been accessed within a specific timeframe. fields @timestamp , @message | sort @timestamp desc | limit 100 | filter verb = \"get\" and objectRef . resource = \"secrets\" | display objectRef . namespace , objectRef . name , user . username , responseStatus . code This query will display the secret, along with the namespace and username of the user who attempted to access the secret and the response code.","title":"Audit the use of Kubernetes Secrets"},{"location":"security/docs/data/#rotate-your-secrets-periodically","text":"Kubernetes doesn't automatically rotate secrets. If you have to rotate secrets, consider using an external secret store, e.g. Vault or AWS Secrets Manager.","title":"Rotate your secrets periodically"},{"location":"security/docs/data/#use-separate-namespaces-as-a-way-to-isolate-secrets-from-different-applications","text":"If you have secrets that cannot be shared between applications in a namespace, create a separate namespace for those applications.","title":"Use separate namespaces as a way to isolate secrets from different applications"},{"location":"security/docs/data/#use-volume-mounts-instead-of-environment-variables","text":"The values of environment variables can unintentionally appear in logs. Secrets mounted as volumes are instantiated as tmpfs volumes (a RAM backed file system) that are automatically removed from the node when the pod is deleted.","title":"Use volume mounts instead of environment variables"},{"location":"security/docs/data/#use-an-external-secrets-provider","text":"There are several viable alternatives to using Kubernetes secrets, including AWS Secrets Manager and Hashicorp's Vault . These services offer features such as fine grained access controls, strong encryption, and automatic rotation of secrets that are not available with Kubernetes Secrets. Bitnami's Sealed Secrets is another approach that uses asymmetric encryption to create \"sealed secrets\". A public key is used to encrypt the secret while the private key used to decrypt the secret is kept within the cluster, allowing you to safely store sealed secrets in source control systems like Git. See Managing secrets deployment in Kubernetes using Sealed Secrets for further information. As the use of external secrets stores has grown, so has need for integrating them with Kubernetes. The Secret Store CSI Driver is a community project that uses the CSI driver model to fetch secrets from external secret stores. Currently, the Driver has support for AWS Secrets Manager , Azure, Vault, and GCP. The AWS provider supports both AWS Secrets Manager and AWS Parameter Store. It can also be configured to rotate secrets when they expire and can synchronize AWS Secrets Manager secrets to Kubernetes Secrets. Synchronization of secrets can be useful when you need to reference a secret as an environment variable instead of reading them from a volume. Note When the the secret store CSI driver has to fetch a secret, it assumes the IRSA role assigned to the pod that references a secret. The code for this operation can be found here . For additional information about the AWS Secrets & Configuration Provider (ASCP) refer to the following resources: How to use AWS Secrets Configuration Provider with Kubernetes Secret Store CSI Driver Integrating Secrets Manager secrets with Kubernetes Secrets Store CSI Driver external-secrets is yet another way to use an external secret store with Kubernetes. Like the CSI Driver, external-secrets works against a variety of different backends, including AWS Secrets Manager. The difference is, rather than retrieving secrets from the external secret store, external-secrets copies secrets from these backends to Kubernetes as Secrets. This lets you manage secrets using your preferred secret store and interact with secrets in a Kubernetes-native way.","title":"Use an external secrets provider"},{"location":"security/docs/detective/","text":"Auditing and logging \u00b6 Collecting and analyzing [audit] logs is useful for a variety of different reasons. Logs can help with root cause analysis and attribution, i.e. ascribing a change to a particular user. When enough logs have been collected, they can be used to detect anomalous behaviors too. On EKS, the audit logs are sent to Amazon Cloudwatch Logs. The audit policy for EKS is as follows: apiVersion : audit.k8s.io/v1beta1 kind : Policy rules : # Log aws-auth configmap changes - level : RequestResponse namespaces : [ \"kube-system\" ] verbs : [ \"update\" , \"patch\" , \"delete\" ] resources : - group : \"\" # core resources : [ \"configmaps\" ] resourceNames : [ \"aws-auth\" ] omitStages : - \"RequestReceived\" - level : None users : [ \"system:kube-proxy\" ] verbs : [ \"watch\" ] resources : - group : \"\" # core resources : [ \"endpoints\" , \"services\" , \"services/status\" ] - level : None users : [ \"kubelet\" ] # legacy kubelet identity verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None userGroups : [ \"system:nodes\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None users : - system:kube-controller-manager - system:kube-scheduler - system:serviceaccount:kube-system:endpoint-controller verbs : [ \"get\" , \"update\" ] namespaces : [ \"kube-system\" ] resources : - group : \"\" # core resources : [ \"endpoints\" ] - level : None users : [ \"system:apiserver\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"namespaces\" , \"namespaces/status\" , \"namespaces/finalize\" ] - level : None users : - system:kube-controller-manager verbs : [ \"get\" , \"list\" ] resources : - group : \"metrics.k8s.io\" - level : None nonResourceURLs : - /healthz* - /version - /swagger* - level : None resources : - group : \"\" # core resources : [ \"events\" ] - level : Request users : [ \"kubelet\" , \"system:node-problem-detector\" , \"system:serviceaccount:kube-system:node-problem-detector\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" - level : Request userGroups : [ \"system:nodes\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" - level : Request users : [ \"system:serviceaccount:kube-system:namespace-controller\" ] verbs : [ \"deletecollection\" ] omitStages : - \"RequestReceived\" # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data, # so only log at the Metadata level. - level : Metadata resources : - group : \"\" # core resources : [ \"secrets\" , \"configmaps\" ] - group : authentication.k8s.io resources : [ \"tokenreviews\" ] omitStages : - \"RequestReceived\" - level : Request resources : - group : \"\" resources : [ \"serviceaccounts/token\" ] - level : Request verbs : [ \"get\" , \"list\" , \"watch\" ] resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for known APIs - level : RequestResponse resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for all other requests. - level : Metadata omitStages : - \"RequestReceived\" Recommendations \u00b6 Enable audit logs \u00b6 The audit logs are part of the EKS managed Kubernetes control plane logs that are managed by EKS. Instructions for enabling/disabling the control plane logs, which includes the logs for the Kubernetes API server, the controller manager, and the scheduler, along with the audit log, can be found here, https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html#enabling-control-plane-log-export . Info When you enable control plane logging, you will incur costs for storing the logs in CloudWatch. This raises a broader issue about the ongoing cost of security. Ultimately you will have to weigh those costs against the cost of a security breach, e.g. financial loss, damage to your reputation, etc. You may find that you can adequately secure your environment by implementing only some of the recommendations in this guide. Warning The maximum size for a CloudWatch Logs entry is 256KB whereas the maximum Kubernetes API request size is 1.5MiB. Log entries greater than 256KB will either be truncated or only include the request metadata. Utilize audit metadata \u00b6 Kubernetes audit logs include two annotations that indicate whether or not a request was authorized authorization.k8s.io/decision and the reason for the decision authorization.k8s.io/reason . Use these attributes to ascertain why a particular API call was allowed. Create alarms for suspicious events \u00b6 Create an alarm to automatically alert you where there is an increase in 403 Forbidden and 401 Unauthorized responses, and then use attributes like host , sourceIPs , and k8s_user.username to find out where those requests are coming from. Analyze logs with Log Insights \u00b6 Use CloudWatch Log Insights to monitor changes to RBAC objects, e.g. Roles, RoleBindings, ClusterRoles, and ClusterRoleBindings. A few sample queries appear below: Lists updates to the aws-auth ConfigMap: fields @timestamp , @message | filter @logStream like \"kube-apiserver-audit\" | filter verb in [ \"update\", \"patch\" ] | filter objectRef . resource = \"configmaps\" and objectRef . name = \"aws-auth\" and objectRef . namespace = \"kube-system\" | sort @timestamp desc Lists creation of new or changes to validation webhooks: fields @timestamp , @message | filter @logStream like \"kube-apiserver-audit\" | filter verb in [ \"create\", \"update\", \"patch\" ] and responseStatus . code = 201 | filter objectRef . resource = \"validatingwebhookconfigurations\" | sort @timestamp desc Lists create, update, delete operations to Roles: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"roles\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Lists create, update, delete operations to RoleBindings: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"rolebindings\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Lists create, update, delete operations to ClusterRoles: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"clusterroles\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Lists create, update, delete operations to ClusterRoleBindings: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"clusterrolebindings\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Plots unauthorized read operations against Secrets: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"secrets\" and verb in [ \"get\", \"watch\", \"list\" ] and responseStatus . code = \"401\" | stats count () by bin ( 1 m ) List of failed anonymous requests: fields @timestamp , @message , sourceIPs .0 | sort @timestamp desc | limit 100 | filter user . username = \"system:anonymous\" and responseStatus . code in [ \"401\", \"403\" ] Audit your CloudTrail logs \u00b6 AWS APIs called by pods that are utilizing IAM Roles for Service Accounts (IRSA) are automatically logged to CloudTrail along with the name of the service account. If the name of a service account that wasn't explicitly authorized to call an API appears in the log, it may be an indication that the IAM role's trust policy was misconfigured. Generally speaking, Cloudtrail is a great way to ascribe AWS API calls to specific IAM principals. Use CloudTrail Insights to unearth suspicious activity \u00b6 CloudTrail insights automatically analyzes write management events from CloudTrail trails and alerts you of unusual activity. This can help you identify when there's an increase in call volume on write APIs in your AWS account, including from pods that use IRSA to assume an IAM role. See Announcing CloudTrail Insights: Identify and Response to Unusual API Activity for further information. Additional resources \u00b6 As the volume of logs increases, parsing and filtering them with Log Insights or another log analysis tool may become ineffective. As an alternative, you might want to consider running Sysdig Falco and ekscloudwatch . Falco analyzes audit logs and flags anomalies or abuse over an extended period of time. The ekscloudwatch project forwards audit log events from CloudWatch to Falco for analysis. Falco provides a set of default audit rules along with the ability to add your own. Yet another option might be to store the audit logs in S3 and use the SageMaker Random Cut Forest algorithm to anomalous behaviors that warrant further investigation. Tooling \u00b6 The following commercial and open source projects can be used to assess your cluster's alignment with established best practices: kubeaudit MKIT kube-scan Assigns a risk score to the workloads running in your cluster in accordance with the Kubernetes Common Configuration Scoring System framework amicontained Reveals which Capabilities are allowed and syscalls that are blocked by the container runtime kubesec.io polaris Starboard kAudit Snyk","title":"Detective Controls"},{"location":"security/docs/detective/#auditing-and-logging","text":"Collecting and analyzing [audit] logs is useful for a variety of different reasons. Logs can help with root cause analysis and attribution, i.e. ascribing a change to a particular user. When enough logs have been collected, they can be used to detect anomalous behaviors too. On EKS, the audit logs are sent to Amazon Cloudwatch Logs. The audit policy for EKS is as follows: apiVersion : audit.k8s.io/v1beta1 kind : Policy rules : # Log aws-auth configmap changes - level : RequestResponse namespaces : [ \"kube-system\" ] verbs : [ \"update\" , \"patch\" , \"delete\" ] resources : - group : \"\" # core resources : [ \"configmaps\" ] resourceNames : [ \"aws-auth\" ] omitStages : - \"RequestReceived\" - level : None users : [ \"system:kube-proxy\" ] verbs : [ \"watch\" ] resources : - group : \"\" # core resources : [ \"endpoints\" , \"services\" , \"services/status\" ] - level : None users : [ \"kubelet\" ] # legacy kubelet identity verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None userGroups : [ \"system:nodes\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None users : - system:kube-controller-manager - system:kube-scheduler - system:serviceaccount:kube-system:endpoint-controller verbs : [ \"get\" , \"update\" ] namespaces : [ \"kube-system\" ] resources : - group : \"\" # core resources : [ \"endpoints\" ] - level : None users : [ \"system:apiserver\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"namespaces\" , \"namespaces/status\" , \"namespaces/finalize\" ] - level : None users : - system:kube-controller-manager verbs : [ \"get\" , \"list\" ] resources : - group : \"metrics.k8s.io\" - level : None nonResourceURLs : - /healthz* - /version - /swagger* - level : None resources : - group : \"\" # core resources : [ \"events\" ] - level : Request users : [ \"kubelet\" , \"system:node-problem-detector\" , \"system:serviceaccount:kube-system:node-problem-detector\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" - level : Request userGroups : [ \"system:nodes\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" - level : Request users : [ \"system:serviceaccount:kube-system:namespace-controller\" ] verbs : [ \"deletecollection\" ] omitStages : - \"RequestReceived\" # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data, # so only log at the Metadata level. - level : Metadata resources : - group : \"\" # core resources : [ \"secrets\" , \"configmaps\" ] - group : authentication.k8s.io resources : [ \"tokenreviews\" ] omitStages : - \"RequestReceived\" - level : Request resources : - group : \"\" resources : [ \"serviceaccounts/token\" ] - level : Request verbs : [ \"get\" , \"list\" , \"watch\" ] resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for known APIs - level : RequestResponse resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for all other requests. - level : Metadata omitStages : - \"RequestReceived\"","title":"Auditing and logging"},{"location":"security/docs/detective/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/detective/#enable-audit-logs","text":"The audit logs are part of the EKS managed Kubernetes control plane logs that are managed by EKS. Instructions for enabling/disabling the control plane logs, which includes the logs for the Kubernetes API server, the controller manager, and the scheduler, along with the audit log, can be found here, https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html#enabling-control-plane-log-export . Info When you enable control plane logging, you will incur costs for storing the logs in CloudWatch. This raises a broader issue about the ongoing cost of security. Ultimately you will have to weigh those costs against the cost of a security breach, e.g. financial loss, damage to your reputation, etc. You may find that you can adequately secure your environment by implementing only some of the recommendations in this guide. Warning The maximum size for a CloudWatch Logs entry is 256KB whereas the maximum Kubernetes API request size is 1.5MiB. Log entries greater than 256KB will either be truncated or only include the request metadata.","title":"Enable audit logs"},{"location":"security/docs/detective/#utilize-audit-metadata","text":"Kubernetes audit logs include two annotations that indicate whether or not a request was authorized authorization.k8s.io/decision and the reason for the decision authorization.k8s.io/reason . Use these attributes to ascertain why a particular API call was allowed.","title":"Utilize audit metadata"},{"location":"security/docs/detective/#create-alarms-for-suspicious-events","text":"Create an alarm to automatically alert you where there is an increase in 403 Forbidden and 401 Unauthorized responses, and then use attributes like host , sourceIPs , and k8s_user.username to find out where those requests are coming from.","title":"Create alarms for suspicious events"},{"location":"security/docs/detective/#analyze-logs-with-log-insights","text":"Use CloudWatch Log Insights to monitor changes to RBAC objects, e.g. Roles, RoleBindings, ClusterRoles, and ClusterRoleBindings. A few sample queries appear below: Lists updates to the aws-auth ConfigMap: fields @timestamp , @message | filter @logStream like \"kube-apiserver-audit\" | filter verb in [ \"update\", \"patch\" ] | filter objectRef . resource = \"configmaps\" and objectRef . name = \"aws-auth\" and objectRef . namespace = \"kube-system\" | sort @timestamp desc Lists creation of new or changes to validation webhooks: fields @timestamp , @message | filter @logStream like \"kube-apiserver-audit\" | filter verb in [ \"create\", \"update\", \"patch\" ] and responseStatus . code = 201 | filter objectRef . resource = \"validatingwebhookconfigurations\" | sort @timestamp desc Lists create, update, delete operations to Roles: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"roles\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Lists create, update, delete operations to RoleBindings: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"rolebindings\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Lists create, update, delete operations to ClusterRoles: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"clusterroles\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Lists create, update, delete operations to ClusterRoleBindings: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"clusterrolebindings\" and verb in [ \"create\", \"update\", \"patch\", \"delete\" ] Plots unauthorized read operations against Secrets: fields @timestamp , @message | sort @timestamp desc | limit 100 | filter objectRef . resource = \"secrets\" and verb in [ \"get\", \"watch\", \"list\" ] and responseStatus . code = \"401\" | stats count () by bin ( 1 m ) List of failed anonymous requests: fields @timestamp , @message , sourceIPs .0 | sort @timestamp desc | limit 100 | filter user . username = \"system:anonymous\" and responseStatus . code in [ \"401\", \"403\" ]","title":"Analyze logs with Log Insights"},{"location":"security/docs/detective/#audit-your-cloudtrail-logs","text":"AWS APIs called by pods that are utilizing IAM Roles for Service Accounts (IRSA) are automatically logged to CloudTrail along with the name of the service account. If the name of a service account that wasn't explicitly authorized to call an API appears in the log, it may be an indication that the IAM role's trust policy was misconfigured. Generally speaking, Cloudtrail is a great way to ascribe AWS API calls to specific IAM principals.","title":"Audit your CloudTrail logs"},{"location":"security/docs/detective/#use-cloudtrail-insights-to-unearth-suspicious-activity","text":"CloudTrail insights automatically analyzes write management events from CloudTrail trails and alerts you of unusual activity. This can help you identify when there's an increase in call volume on write APIs in your AWS account, including from pods that use IRSA to assume an IAM role. See Announcing CloudTrail Insights: Identify and Response to Unusual API Activity for further information.","title":"Use CloudTrail Insights to unearth suspicious activity"},{"location":"security/docs/detective/#additional-resources","text":"As the volume of logs increases, parsing and filtering them with Log Insights or another log analysis tool may become ineffective. As an alternative, you might want to consider running Sysdig Falco and ekscloudwatch . Falco analyzes audit logs and flags anomalies or abuse over an extended period of time. The ekscloudwatch project forwards audit log events from CloudWatch to Falco for analysis. Falco provides a set of default audit rules along with the ability to add your own. Yet another option might be to store the audit logs in S3 and use the SageMaker Random Cut Forest algorithm to anomalous behaviors that warrant further investigation.","title":"Additional resources"},{"location":"security/docs/detective/#tooling","text":"The following commercial and open source projects can be used to assess your cluster's alignment with established best practices: kubeaudit MKIT kube-scan Assigns a risk score to the workloads running in your cluster in accordance with the Kubernetes Common Configuration Scoring System framework amicontained Reveals which Capabilities are allowed and syscalls that are blocked by the container runtime kubesec.io polaris Starboard kAudit Snyk","title":"Tooling"},{"location":"security/docs/hosts/","text":"Protecting the infrastructure (hosts) \u00b6 Inasmuch as it's important to secure your container images, it's equally important to safeguard the infrastructure that runs them. This section explores different ways to mitigate risks from attacks launched directly against the host. These guidelines should be used in conjunction with those outlined in the Runtime Security section. Recommendations \u00b6 Use an OS optimized for running containers \u00b6 Consider using Flatcar Linux, Project Atomic, RancherOS, and Bottlerocket , a special purpose OS from AWS designed for running Linux containers. It includes a reduced attack surface, a disk image that is verified on boot, and enforced permission boundaries using SELinux. Alternately, use the EKS optimized AMI for your Kubernetes worker nodes. The EKS optimized AMI is released regularly and contains a minimal set of OS packages and binaries necessary to run your containerized workloads. Keep your worker node OS updated \u00b6 Regardless of whether you use a container-optimized host OS like Bottlerocket or a larger, but still minimalist, Amazon Machine Image like the EKS optimized AMIs, it is best practice to keep these host OS images up to date with the latest security patches. For the EKS optimized AMIs, regularly check the CHANGELOG and/or release notes channel and automate the rollout of updated worker node images into your cluster. Treat your infrastructure as immutable and automate the replacement of your worker nodes \u00b6 Rather than performing in-place upgrades, replace your workers when a new patch or update becomes available. This can be approached a couple of ways. You can either add instances to an existing autoscaling group using the latest AMI as you sequentially cordon and drain nodes until all of the nodes in the group have been replaced with the latest AMI. Alternatively, you can add instances to a new node group while you sequentially cordon and drain nodes from the old node group until all of the nodes have been replaced. EKS managed node groups uses the first approach and will display a message in the console to upgrade your workers when a new AMI becomes available. eksctl also has a mechanism for creating node groups with the latest AMI and for gracefully cordoning and draining pods from nodes groups before the instances are terminated. If you decide to use a different method for replacing your worker nodes, it is strongly recommended that you automate the process to minimize human oversight as you will likely need to replace workers regularly as new updates/patches are released and when the control plane is upgraded. With EKS Fargate, AWS will automatically update the underlying infrastructure as updates become available. Oftentimes this can be done seamlessly, but there may be times when an update will cause your pod to be rescheduled. Hence, we recommend that you create deployments with multiple replicas when running your application as a Fargate pod. Periodically run kube-bench to verify compliance with CIS benchmarks for Kubernetes \u00b6 kube-bench is an open source project from Aqua that evaluates your cluster against the CIS benchmarks for Kubernetes. The benchmark describes the best practices for securing unmanaged Kubernetes clusters. The CIS Kubernetes Benchmark encompasses the control plane and the data plane. Since Amazon EKS provides a fully managed control plane, not all of the recommendations from the CIS Kubernetes Benchmark are applicable. To ensure this scope reflects how Amazon EKS is implemented, AWS created the CIS Amazon EKS Benchmark . The EKS benchmark inherits from CIS Kubernetes Benchmark with additional inputs from the community with specific configuration considerations for EKS clusters. When running kube-bench against an EKS cluster, follow these instructions from Aqua Security. For further information see Introducing The CIS Amazon EKS Benchmark . Minimize access to worker nodes \u00b6 Instead of enabling SSH access, use SSM Session Manager when you need to remote into a host. Unlike SSH keys which can be lost, copied, or shared, Session Manager allows you to control access to EC2 instances using IAM. Moreover, it provides an audit trail and log of the commands that were run on the instance. As of August 19th, 2020 Managed Node Groups support custom AMIs and EC2 Launch Templates. This allows you to embed the SSM agent into the AMI or install it as the worker node is being bootstrapped. If you rather not modify the Optimized AMI or the ASG's launch template, you can install the SSM agent with a DaemonSet as in this example, https://github.com/aws-samples/ssm-agent-daemonset-installer. Minimal IAM policy for SSM based SSH Access \u00b6 The AmazonSSMManagedInstanceCore AWS managed policy contains a number of permissions that are not required for SSM Session Manager / SSM RunCommand if you're just looking to avoid SSH access. Of concern specifically is the * permissions for ssm:GetParameter(s) which would allow for the role to access all parameters in Parameter Store (including SecureStrings with the AWS managed KMS key configured). The following IAM policy contains the minimal set of permissions to enable node access via SSM Systems Manager. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"EnableAccessViaSSMSessionManager\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"ssmmessages:OpenDataChannel\" , \"ssmmessages:OpenControlChannel\" , \"ssmmessages:CreateDataChannel\" , \"ssmmessages:CreateControlChannel\" , \"ssm:UpdateInstanceInformation\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"EnableSSMRunCommand\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"ssm:UpdateInstanceInformation\" , \"ec2messages:SendReply\" , \"ec2messages:GetMessages\" , \"ec2messages:GetEndpoint\" , \"ec2messages:FailMessage\" , \"ec2messages:DeleteMessage\" , \"ec2messages:AcknowledgeMessage\" ], \"Resource\" : \"*\" } ] } With this policy in place and the Session Manager plugin installed, you can then run aws ssm start-session --target [ INSTANCE_ID_OF_EKS_NODE ] to access the node. Note You may also want to consider adding permissions to enable Session Manager logging . Deploy workers onto private subnets \u00b6 By deploying workers onto private subnets, you minimize their exposure to the Internet where attacks often originate. Beginning April 22, 2020, the assignment of public IP addresses to nodes in a managed node groups will be controlled by the subnet they are deployed onto. Prior to this, nodes in a Managed Node Group were automatically assigned a public IP. If you choose to deploy your worker nodes on to public subnets, implement restrictive AWS security group rules to limit their exposure. Run Amazon Inspector to assess hosts for exposure, vulnerabilities, and deviations from best practices \u00b6 You can use Amazon Inspector to check for unintended network access to your nodes and for vulnerabilities on the underlying Amazon EC2 instances. Amazon Inspector can provide common vulnerabilities and exposures (CVE) data for your Amazon EC2 instances only if the Amazon EC2 Systems Manager (SSM) agent is installed and enabled. This agent is preinstalled on several Amazon Machine Images (AMIs) including EKS optimized Amazon Linux AMIs . Regardless of SSM agent status, all of your Amazon EC2 instances are scanned for network reachability issues. For more information about configuring scans for Amazon EC2, see Scanning Amazon EC2 instances . Attention Inspector cannot be run on the infrastructure used to run Fargate pods. Alternatives \u00b6 Run SELinux \u00b6 Info Available on Red Hat Enterprise Linux (RHEL), CentOS, and CoreOS SELinux provides an additional layer of security to keep containers isolated from each other and from the host. SELinux allows administrators to enforce mandatory access controls (MAC) for every user, application, process, and file. Think of it as a backstop that restricts the operations that can be performed against to specific resources based on a set of labels. On EKS, SELinux can be used to prevent containers from accessing each other's resources. Container SELinux policies are defined in the container-selinux package. Docker CE requires this package (along with its dependencies) so that the processes and files created by Docker (or other container runtimes) run with limited system access. Containers leverage the container_t label which is an alias to svirt_lxc_net_t . These policies effectively prevent containers from accessing certain features of the host. When you configure SELinux for Docker, Docker automatically labels workloads container_t as a type and gives each container a unique MCS level. This will isolate containers from one another. If you need looser restrictions, you can create your own profile in SElinux which grants a container permissions to specific areas of the file system. This is similar to PSPs in that you can create different profiles for different containers/pods. For example, you can have a profile for general workloads with a set of restrictive controls and another for things that require privileged access. SELinux for Containers has a set of options that can be configured to modify the default restrictions. The following SELinux Booleans can be enabled or disabled based on your needs: Boolean Default Description container_connect_any off Allow containers to access privileged ports on the host. For example, if you have a container that needs to map ports to 443 or 80 on the host. container_manage_cgroup off Allow containers to manage cgroup configuration. For example, a container running systemd will need this to be enabled. container_use_cephfs off Allow containers to use a ceph file system. By default, containers are allowed to read/execute under /usr and read most content from /etc . The files under /var/lib/docker and /var/lib/containers have the label container_var_lib_t . To view a full list of default, labels see the container.fc file. docker container run -it \\ -v /var/lib/docker/image/overlay2/repositories.json:/host/repositories.json \\ centos:7 cat /host/repositories.json # cat: /host/repositories.json: Permission denied docker container run -it \\ -v /etc/passwd:/host/etc/passwd \\ centos:7 cat /host/etc/passwd # cat: /host/etc/passwd: Permission denied Files labeled with container_file_t are the only files that are writable by containers. If you want a volume mount to be writeable, you will needed to specify :z or :Z at the end. :z will re-label the files so that the container can read/write :Z will re-label the files so that only the container can read/write ls -Z /var/lib/misc # -rw-r--r--. root root system_u:object_r:var_lib_t:s0 postfix.aliasesdb-stamp docker container run -it \\ -v /var/lib/misc:/host/var/lib/misc:z \\ centos:7 echo \"Relabeled!\" ls -Z /var/lib/misc #-rw-r--r--. root root system_u:object_r:container_file_t:s0 postfix.aliasesdb-stamp docker container run -it \\ -v /var/log:/host/var/log:Z \\ fluentbit:latest In Kubernetes, relabeling is slightly different. Rather than having Docker automatically relabel the files, you can specify a custom MCS label to run the pod. Volumes that support relabeling will automatically be relabeled so that they are accessible. Pods with a matching MCS label will be able to access the volume. If you need strict isolation, set a different MCS label for each pod. securityContext : seLinuxOptions : # Provide a unique MCS label per container # You can specify user, role, and type also # enforcement based on type and level (svert) level : s0:c144:c154 In this example s0:c144:c154 corresponds to an MCS label assigned to a file that the container is allowed to access. On EKS you could create policies that allow for privileged containers to run, like FluentD and create an SELinux policy to allow it to read from /var/log on the host without needing to relabel the host directory. Pods with the same label will be able to access the same host volumes. We have implemented sample AMIs for Amazon EKS that have SELinux configured on CentOS 7 and RHEL 7. These AMIs were developed to demonstrate sample implementations that meet requirements of highly regulated customers, such as STIG, CJIS, and C2S. Caution SELinux will ignore containers where the type is unconfined. Additional resources \u00b6 SELinux Kubernetes RBAC and Shipping Security Policies for On-prem Applications Iterative Hardening of Kubernetes Audit2Allow SEAlert Generate SELinux policies for containers with Udica describes a tool that looks at container spec files for Linux capabilities, ports, and mount points, and generates a set of SELinux rules that allow the container to run properly AMI Hardening playbooks for hardening the OS to meet different regulatory requirements Tools \u00b6 Keiko Upgrade Manager an open source project from Intuit that orchestrates the rotation of worker nodes. Sysdig Secure eksctl","title":"Infrastructure Security"},{"location":"security/docs/hosts/#protecting-the-infrastructure-hosts","text":"Inasmuch as it's important to secure your container images, it's equally important to safeguard the infrastructure that runs them. This section explores different ways to mitigate risks from attacks launched directly against the host. These guidelines should be used in conjunction with those outlined in the Runtime Security section.","title":"Protecting the infrastructure (hosts)"},{"location":"security/docs/hosts/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/hosts/#use-an-os-optimized-for-running-containers","text":"Consider using Flatcar Linux, Project Atomic, RancherOS, and Bottlerocket , a special purpose OS from AWS designed for running Linux containers. It includes a reduced attack surface, a disk image that is verified on boot, and enforced permission boundaries using SELinux. Alternately, use the EKS optimized AMI for your Kubernetes worker nodes. The EKS optimized AMI is released regularly and contains a minimal set of OS packages and binaries necessary to run your containerized workloads.","title":"Use an OS optimized for running containers"},{"location":"security/docs/hosts/#keep-your-worker-node-os-updated","text":"Regardless of whether you use a container-optimized host OS like Bottlerocket or a larger, but still minimalist, Amazon Machine Image like the EKS optimized AMIs, it is best practice to keep these host OS images up to date with the latest security patches. For the EKS optimized AMIs, regularly check the CHANGELOG and/or release notes channel and automate the rollout of updated worker node images into your cluster.","title":"Keep your worker node OS updated"},{"location":"security/docs/hosts/#treat-your-infrastructure-as-immutable-and-automate-the-replacement-of-your-worker-nodes","text":"Rather than performing in-place upgrades, replace your workers when a new patch or update becomes available. This can be approached a couple of ways. You can either add instances to an existing autoscaling group using the latest AMI as you sequentially cordon and drain nodes until all of the nodes in the group have been replaced with the latest AMI. Alternatively, you can add instances to a new node group while you sequentially cordon and drain nodes from the old node group until all of the nodes have been replaced. EKS managed node groups uses the first approach and will display a message in the console to upgrade your workers when a new AMI becomes available. eksctl also has a mechanism for creating node groups with the latest AMI and for gracefully cordoning and draining pods from nodes groups before the instances are terminated. If you decide to use a different method for replacing your worker nodes, it is strongly recommended that you automate the process to minimize human oversight as you will likely need to replace workers regularly as new updates/patches are released and when the control plane is upgraded. With EKS Fargate, AWS will automatically update the underlying infrastructure as updates become available. Oftentimes this can be done seamlessly, but there may be times when an update will cause your pod to be rescheduled. Hence, we recommend that you create deployments with multiple replicas when running your application as a Fargate pod.","title":"Treat your infrastructure as immutable and automate the replacement of your worker nodes"},{"location":"security/docs/hosts/#periodically-run-kube-bench-to-verify-compliance-with-cis-benchmarks-for-kubernetes","text":"kube-bench is an open source project from Aqua that evaluates your cluster against the CIS benchmarks for Kubernetes. The benchmark describes the best practices for securing unmanaged Kubernetes clusters. The CIS Kubernetes Benchmark encompasses the control plane and the data plane. Since Amazon EKS provides a fully managed control plane, not all of the recommendations from the CIS Kubernetes Benchmark are applicable. To ensure this scope reflects how Amazon EKS is implemented, AWS created the CIS Amazon EKS Benchmark . The EKS benchmark inherits from CIS Kubernetes Benchmark with additional inputs from the community with specific configuration considerations for EKS clusters. When running kube-bench against an EKS cluster, follow these instructions from Aqua Security. For further information see Introducing The CIS Amazon EKS Benchmark .","title":"Periodically run kube-bench to verify compliance with CIS benchmarks for Kubernetes"},{"location":"security/docs/hosts/#minimize-access-to-worker-nodes","text":"Instead of enabling SSH access, use SSM Session Manager when you need to remote into a host. Unlike SSH keys which can be lost, copied, or shared, Session Manager allows you to control access to EC2 instances using IAM. Moreover, it provides an audit trail and log of the commands that were run on the instance. As of August 19th, 2020 Managed Node Groups support custom AMIs and EC2 Launch Templates. This allows you to embed the SSM agent into the AMI or install it as the worker node is being bootstrapped. If you rather not modify the Optimized AMI or the ASG's launch template, you can install the SSM agent with a DaemonSet as in this example, https://github.com/aws-samples/ssm-agent-daemonset-installer.","title":"Minimize access to worker nodes"},{"location":"security/docs/hosts/#minimal-iam-policy-for-ssm-based-ssh-access","text":"The AmazonSSMManagedInstanceCore AWS managed policy contains a number of permissions that are not required for SSM Session Manager / SSM RunCommand if you're just looking to avoid SSH access. Of concern specifically is the * permissions for ssm:GetParameter(s) which would allow for the role to access all parameters in Parameter Store (including SecureStrings with the AWS managed KMS key configured). The following IAM policy contains the minimal set of permissions to enable node access via SSM Systems Manager. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"EnableAccessViaSSMSessionManager\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"ssmmessages:OpenDataChannel\" , \"ssmmessages:OpenControlChannel\" , \"ssmmessages:CreateDataChannel\" , \"ssmmessages:CreateControlChannel\" , \"ssm:UpdateInstanceInformation\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"EnableSSMRunCommand\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"ssm:UpdateInstanceInformation\" , \"ec2messages:SendReply\" , \"ec2messages:GetMessages\" , \"ec2messages:GetEndpoint\" , \"ec2messages:FailMessage\" , \"ec2messages:DeleteMessage\" , \"ec2messages:AcknowledgeMessage\" ], \"Resource\" : \"*\" } ] } With this policy in place and the Session Manager plugin installed, you can then run aws ssm start-session --target [ INSTANCE_ID_OF_EKS_NODE ] to access the node. Note You may also want to consider adding permissions to enable Session Manager logging .","title":"Minimal IAM policy for SSM based SSH Access"},{"location":"security/docs/hosts/#deploy-workers-onto-private-subnets","text":"By deploying workers onto private subnets, you minimize their exposure to the Internet where attacks often originate. Beginning April 22, 2020, the assignment of public IP addresses to nodes in a managed node groups will be controlled by the subnet they are deployed onto. Prior to this, nodes in a Managed Node Group were automatically assigned a public IP. If you choose to deploy your worker nodes on to public subnets, implement restrictive AWS security group rules to limit their exposure.","title":"Deploy workers onto private subnets"},{"location":"security/docs/hosts/#run-amazon-inspector-to-assess-hosts-for-exposure-vulnerabilities-and-deviations-from-best-practices","text":"You can use Amazon Inspector to check for unintended network access to your nodes and for vulnerabilities on the underlying Amazon EC2 instances. Amazon Inspector can provide common vulnerabilities and exposures (CVE) data for your Amazon EC2 instances only if the Amazon EC2 Systems Manager (SSM) agent is installed and enabled. This agent is preinstalled on several Amazon Machine Images (AMIs) including EKS optimized Amazon Linux AMIs . Regardless of SSM agent status, all of your Amazon EC2 instances are scanned for network reachability issues. For more information about configuring scans for Amazon EC2, see Scanning Amazon EC2 instances . Attention Inspector cannot be run on the infrastructure used to run Fargate pods.","title":"Run Amazon Inspector to assess hosts for exposure, vulnerabilities, and deviations from best practices"},{"location":"security/docs/hosts/#alternatives","text":"","title":"Alternatives"},{"location":"security/docs/hosts/#run-selinux","text":"Info Available on Red Hat Enterprise Linux (RHEL), CentOS, and CoreOS SELinux provides an additional layer of security to keep containers isolated from each other and from the host. SELinux allows administrators to enforce mandatory access controls (MAC) for every user, application, process, and file. Think of it as a backstop that restricts the operations that can be performed against to specific resources based on a set of labels. On EKS, SELinux can be used to prevent containers from accessing each other's resources. Container SELinux policies are defined in the container-selinux package. Docker CE requires this package (along with its dependencies) so that the processes and files created by Docker (or other container runtimes) run with limited system access. Containers leverage the container_t label which is an alias to svirt_lxc_net_t . These policies effectively prevent containers from accessing certain features of the host. When you configure SELinux for Docker, Docker automatically labels workloads container_t as a type and gives each container a unique MCS level. This will isolate containers from one another. If you need looser restrictions, you can create your own profile in SElinux which grants a container permissions to specific areas of the file system. This is similar to PSPs in that you can create different profiles for different containers/pods. For example, you can have a profile for general workloads with a set of restrictive controls and another for things that require privileged access. SELinux for Containers has a set of options that can be configured to modify the default restrictions. The following SELinux Booleans can be enabled or disabled based on your needs: Boolean Default Description container_connect_any off Allow containers to access privileged ports on the host. For example, if you have a container that needs to map ports to 443 or 80 on the host. container_manage_cgroup off Allow containers to manage cgroup configuration. For example, a container running systemd will need this to be enabled. container_use_cephfs off Allow containers to use a ceph file system. By default, containers are allowed to read/execute under /usr and read most content from /etc . The files under /var/lib/docker and /var/lib/containers have the label container_var_lib_t . To view a full list of default, labels see the container.fc file. docker container run -it \\ -v /var/lib/docker/image/overlay2/repositories.json:/host/repositories.json \\ centos:7 cat /host/repositories.json # cat: /host/repositories.json: Permission denied docker container run -it \\ -v /etc/passwd:/host/etc/passwd \\ centos:7 cat /host/etc/passwd # cat: /host/etc/passwd: Permission denied Files labeled with container_file_t are the only files that are writable by containers. If you want a volume mount to be writeable, you will needed to specify :z or :Z at the end. :z will re-label the files so that the container can read/write :Z will re-label the files so that only the container can read/write ls -Z /var/lib/misc # -rw-r--r--. root root system_u:object_r:var_lib_t:s0 postfix.aliasesdb-stamp docker container run -it \\ -v /var/lib/misc:/host/var/lib/misc:z \\ centos:7 echo \"Relabeled!\" ls -Z /var/lib/misc #-rw-r--r--. root root system_u:object_r:container_file_t:s0 postfix.aliasesdb-stamp docker container run -it \\ -v /var/log:/host/var/log:Z \\ fluentbit:latest In Kubernetes, relabeling is slightly different. Rather than having Docker automatically relabel the files, you can specify a custom MCS label to run the pod. Volumes that support relabeling will automatically be relabeled so that they are accessible. Pods with a matching MCS label will be able to access the volume. If you need strict isolation, set a different MCS label for each pod. securityContext : seLinuxOptions : # Provide a unique MCS label per container # You can specify user, role, and type also # enforcement based on type and level (svert) level : s0:c144:c154 In this example s0:c144:c154 corresponds to an MCS label assigned to a file that the container is allowed to access. On EKS you could create policies that allow for privileged containers to run, like FluentD and create an SELinux policy to allow it to read from /var/log on the host without needing to relabel the host directory. Pods with the same label will be able to access the same host volumes. We have implemented sample AMIs for Amazon EKS that have SELinux configured on CentOS 7 and RHEL 7. These AMIs were developed to demonstrate sample implementations that meet requirements of highly regulated customers, such as STIG, CJIS, and C2S. Caution SELinux will ignore containers where the type is unconfined.","title":"Run SELinux"},{"location":"security/docs/hosts/#additional-resources","text":"SELinux Kubernetes RBAC and Shipping Security Policies for On-prem Applications Iterative Hardening of Kubernetes Audit2Allow SEAlert Generate SELinux policies for containers with Udica describes a tool that looks at container spec files for Linux capabilities, ports, and mount points, and generates a set of SELinux rules that allow the container to run properly AMI Hardening playbooks for hardening the OS to meet different regulatory requirements","title":"Additional resources"},{"location":"security/docs/hosts/#tools","text":"Keiko Upgrade Manager an open source project from Intuit that orchestrates the rotation of worker nodes. Sysdig Secure eksctl","title":"Tools"},{"location":"security/docs/iam/","text":"Identity and Access Management \u00b6 Identity and Access Management (IAM) is an AWS service that performs two essential functions: Authentication and Authorization. Authentication involves the verification of a identity whereas authorization governs the actions that can be performed by AWS resources. Within AWS, a resource can be another AWS service, e.g. EC2, or an AWS principal such as an IAM User or Role . The rules governing the actions that a resource is allowed to perform are expressed as IAM policies . Controlling Access to EKS Clusters \u00b6 The Kubernetes project supports a variety of different strategies to authenticate requests to the kube-apiserver service, e.g. Bearer Tokens, X.509 certificates, OIDC, etc. EKS currently has native support for webhook token authentication , service account tokens , and as of February 21, 2021, OIDC authentication. The webhook authentication strategy calls a webhook that verifies bearer tokens. On EKS, these bearer tokens are generated by the AWS CLI or the aws-iam-authenticator client when you run kubectl commands. As you execute commands, the token is passed to the kube-apiserver which forwards it to the authentication webhook. If the request is well-formed, the webhook calls a pre-signed URL embedded in the token's body. This URL validates the request's signature and returns information about the user, e.g. the user's account, Arn, and UserId to the kube-apiserver. To manually generate a authentication token, type the following command in a terminal window: aws eks get-token --cluster <cluster_name> You can also get a token programmatically. Below is an example written in Go: package main import ( \"fmt\" \"log\" \"sigs.k8s.io/aws-iam-authenticator/pkg/token\" ) func main () { g , _ := token . NewGenerator ( false , false ) tk , err := g . Get ( \"<cluster_name>\" ) if err != nil { log . Fatal ( err ) } fmt . Println ( tk ) } The output should resemble this: { \"kind\" : \"ExecCredential\" , \"apiVersion\" : \"client.authentication.k8s.io/v1alpha1\" , \"spec\" : {}, \"status\" : { \"expirationTimestamp\" : \"2020-02-19T16:08:27Z\" , \"token\" : \"k8s-aws-v1.aHR0cHM6Ly9zdHMuYW1hem9uYXdzLmNvbS8_QWN0aW9uPUdldENhbGxlcklkZW50aXR5JlZlcnNpb249MjAxMS0wNi0xNSZYLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFKTkdSSUxLTlNSQzJXNVFBJTJGMjAyMDAyMTklMkZ1cy1lYXN0LTElMkZzdHMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIwMDIxOVQxNTU0MjdaJlgtQW16LUV4cGlyZXM9NjAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JTNCeC1rOHMtYXdzLWlkJlgtQW16LVNpZ25hdHVyZT0yMjBmOGYzNTg1ZTMyMGRkYjVlNjgzYTVjOWE0MDUzMDFhZDc2NTQ2ZjI0ZjI4MTExZmRhZDA5Y2Y2NDhhMzkz\" } } Each token starts with k8s-aws-v1. followed by a base64 encoded string. The string, when decoded, should resemble this: https://sts.amazonaws.com/?Action = GetCallerIdentity & Version = 2011 -06-15 & X-Amz-Algorithm = AWS4-HMAC-SHA256 & X-Amz-Credential = AKIAJPFRILKNSRC2W5QA%2F20200219%2Fus-east-1%2Fsts%2Faws4_request & X-Amz-Date = 20200219T155427Z & X-Amz-Expires = 60 & X-Amz-SignedHeaders = host%3Bx-k8s-aws-id & X-Amz-Signature = 220f8f3285e320ddb5e683a5c9a405301ad76546f24f28111fdad09cf648a393 The token consists of a pre-signed URL that includes an Amazon credential and signature. For additional details see https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html . The token has a time to live (TTL) of 15 minutes after which a new token will need to be generated. This is handled automatically when you use a client like kubectl , however, if you're using the Kubernetes dashboard, you will need to generate a new token and re-authenticate each time the token expires. Once the user's identity has been authenticated by the AWS IAM service, the kube-apiserver reads the aws-auth ConfigMap in the kube-system Namespace to determine the RBAC group to associate with the user. The aws-auth ConfigMap is used to create a static mapping between IAM principals, i.e. IAM Users and Roles, and Kubernetes RBAC groups. RBAC groups can be referenced in Kubernetes RoleBindings or ClusterRoleBindings. They are similar to IAM Roles in that they define a set of actions (verbs) that can be performed against a collection of Kubernetes resources (objects). Recommendations \u00b6 Don't use a service account token for authentication \u00b6 A service account token is a long-lived, static credential. If it is compromised, lost, or stolen, an attacker may be able to perform all the actions associated with that token until the service account is deleted. At times, you may need to grant an exception for applications that have to consume the Kubernetes API from outside the cluster, e.g. a CI/CD pipeline application. If such applications run on AWS infrastructure, like EC2 instances, consider using an instance profile and mapping that to a Kubernetes RBAC role in the aws-auth ConfigMap instead. Employ least privileged access to AWS Resources \u00b6 An IAM User does not need to be assigned privileges to AWS resources to access the Kubernetes API. If you need to grant an IAM user access to an EKS cluster, create an entry in the aws-auth ConfigMap for that user that maps to a specific Kubernetes RBAC group. Use IAM Roles when multiple users need identical access to the cluster \u00b6 Rather than creating an entry for each individual IAM User in the aws-auth ConfigMap, allow those users to assume an IAM Role and map that role to a Kubernetes RBAC group. This will be easier to maintain, especially as the number of users that require access grows. Attention When accessing the EKS cluster with the IAM entity mapped by aws-auth ConfigMap, the username described in aws-auth ConfigMap is recorded in the user field of the Kubernetes audit log. If you're using an IAM role, the actual users who assume that role aren't recorded and can't be audited. When assigning K8s RBAC permissions to an IAM role using mapRoles in aws-auth ConfigMap, you should include {{SessionName}} in your username. That way, the audit log will record the session name so you can track who the actual user assume this role along with the CloudTrail log. - rolearn : arn:aws:iam::XXXXXXXXXXXX:role/testRole username : testRole:{{SessionName}} groups : - system:masters In Kubernetes 1.20 and above, this change is no longer required, since user.extra.sessionName.0 was added to the Kubernetes audit log. Employ least privileged access when creating RoleBindings and ClusterRoleBindings \u00b6 Like the earlier point about granting access to AWS Resources, RoleBindings and ClusterRoleBindings should only include the set of permissions necessary to perform a specific function. Avoid using [\"*\"] in your Roles and ClusterRoles unless it's absolutely necessary. If you're unsure what permissions to assign, consider using a tool like audit2rbac to automatically generate Roles and binding based on the observed API calls in the Kubernetes Audit Log. Make the EKS Cluster Endpoint private \u00b6 By default when you provision an EKS cluster, the API cluster endpoint is set to public, i.e. it can be accessed from the Internet. Despite being accessible from the Internet, the endpoint is still considered secure because it requires all API requests to be authenticated by IAM and then authorized by Kubernetes RBAC. That said, if your corporate security policy mandates that you restrict access to the API from the Internet or prevents you from routing traffic outside the cluster VPC, you can: Configure the EKS cluster endpoint to be private. See Modifying Cluster Endpoint Access for further information on this topic. Leave the cluster endpoint public and specify which CIDR blocks can communicate with the cluster endpoint. The blocks are effectively a whitelisted set of public IP addresses that are allowed to access the cluster endpoint. Configure public access with a set of whitelisted CIDR blocks and set private endpoint access to enabled. This will allow public access from a specific range of public IPs while forcing all network traffic between the kubelets (workers) and the Kubernetes API through the cross-account ENIs that get provisioned into the cluster VPC when the control plane is provisioned. Create the cluster with a dedicated IAM role \u00b6 When you create an Amazon EKS cluster, the IAM entity user or role, such as a federated user that creates the cluster, is automatically granted system:masters permissions in the cluster's RBAC configuration. This access cannot be removed and is not managed through the aws-auth ConfigMap. Therefore it is a good idea to create the cluster with a dedicated IAM role and regularly audit who can assume this role. This role should not be used to perform routine actions on the cluster, and instead additional users should be granted access to the cluster through the aws-auth ConfigMap for this purpose. After the aws-auth ConfigMap is configured, the role can be deleted and only recreated in an emergency / break glass scenario where the aws-auth ConfigMap is corrupted and the cluster is otherwise inaccessible. This can be particularly useful in production clusters which do not usually have direct user access configured. Use tools to make changes to the aws-auth ConfigMap \u00b6 An improperly formatted aws-auth ConfigMap may cause you to lose access to the cluster. If you need to make changes to the ConfigMap, use a tool. eksctl The eksctl CLI includes a command for adding identity mappings to the aws-auth ConfigMap. View CLI Help: eksctl create iamidentitymapping --help Make an IAM Role a Cluster Admin: eksctl create iamidentitymapping -- cluster < clusterName > -- region =< region > -- arn arn:aws: iam :: 123456 : role / testing -- group system: masters -- username admin For more information, review eksctl docs aws-auth by keikoproj aws-auth by keikoproj includes both a cli and a go library. Download and view help CLI help: go get github . com / keikoproj / aws - auth aws - auth help Alternatively, install aws-auth with the krew plugin manager for kubectl. kubectl krew install aws-auth kubectl aws-auth Review the aws-auth docs on GitHub for more information, including the go library. AWS IAM Authenticator CLI The aws-iam-authenticator project includes a CLI for updating the ConfigMap. Download a release on GitHub. Add cluster permissions to an IAM Role: ./aws-iam-authenticator add role --rolearn arn:aws:iam::185309785115:role/lil-dev-role-cluster --username lil-dev-user --groups system:masters --kubeconfig ~/.kube/config Regularly audit access to the cluster \u00b6 Who requires access is likely to change over time. Plan to periodically audit the aws-auth ConfigMap to see who has been granted access and the rights they've been assigned. You can also use open source tooling like kubectl-who-can , or rbac-lookup to examine the roles bound to a particular service account, user, or group. We'll explore this topic further when we get to the section on auditing . Additional ideas can be found in this article from NCC Group. Alternative Approaches to Authentication and Access Management \u00b6 While IAM is the preferred way to authenticate users who need access to an EKS cluster, it is possible to use an OIDC identity provider such as GitHub using an authentication proxy and Kubernetes impersonation . Posts for two such solutions have been published on the AWS Open Source blog: Authenticating to EKS Using GitHub Credentials with Teleport Consistent OIDC authentication across multiple EKS clusters using kube-oidc-proxy Attention EKS natively supports OIDC authentication without using a proxy. For further information, please read the launch blog, Introducing OIDC identity provider authentication for Amazon EKS . For an example showing how to configure EKS with Dex, a popular open source OIDC provider with connectors for a variety of different authention methods, see Using Dex & dex-k8s-authenticator to authenticate to Amazon EKS . As described in the blogs, the username/group of users authenticated by an OIDC provider will appear in the Kubernetes audit log. You can also use AWS SSO to federate AWS with an external identity provider, e.g. Azure AD. If you decide to use this, the AWS CLI v2.0 includes an option to create a named profile that makes it easy to associate an SSO session with your current CLI session and assume an IAM role. Know that you must assume a role prior to running kubectl as the IAM role is used to determine the user's Kubernetes RBAC group. Additional Resources \u00b6 rbac.dev A list of additional resources, including blogs and tools, for Kubernetes RBAC Pods Identities \u00b6 Certain applications that run within a Kubernetes cluster need permission to call the Kubernetes API to function properly. For example, the AWS Load Balancer Controller needs to be able to list a Service's Endpoints. The controller also needs to be able to invoke AWS APIs to provision and configure an ALB. In this section we will explore the best practices for assigning rights and privileges to Pods. Kubernetes Service Accounts \u00b6 A service account is a special type of object that allows you to assign a Kubernetes RBAC role to a pod. A default service account is created automatically for each Namespace within a cluster. When you deploy a pod into a Namespace without referencing a specific service account, the default service account for that Namespace will automatically get assigned to the Pod and the Secret, i.e. the service account (JWT) token for that service account, will get mounted to the pod as a volume at /var/run/secrets/kubernetes.io/serviceaccount . Decoding the service account token in that directory will reveal the following metadata: { \"iss\" : \"kubernetes/serviceaccount\" , \"kubernetes.io/serviceaccount/namespace\" : \"default\" , \"kubernetes.io/serviceaccount/secret.name\" : \"default-token-5pv4z\" , \"kubernetes.io/serviceaccount/service-account.name\" : \"default\" , \"kubernetes.io/serviceaccount/service-account.uid\" : \"3b36ddb5-438c-11ea-9438-063a49b60fba\" , \"sub\" : \"system:serviceaccount:default:default\" } The default service account has the following permissions to the Kubernetes API. apiVersion : rbac.authorization.k8s.io/v1 kind : ClusterRole metadata : annotations : rbac.authorization.kubernetes.io/autoupdate : \"true\" creationTimestamp : \"2020-01-30T18:13:25Z\" labels : kubernetes.io/bootstrapping : rbac-defaults name : system:discovery resourceVersion : \"43\" selfLink : /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Adiscovery uid : 350d2ab8-438c-11ea-9438-063a49b60fba rules : - nonResourceURLs : - /api - /api/* - /apis - /apis/* - /healthz - /openapi - /openapi/* - /version - /version/ verbs : - get This role authorizes unauthenticated and authenticated users to read API information and is deemed safe to be publicly accessible. When an application running within a Pod calls the Kubernetes APIs, the Pod needs to be assigned a service account that explicitly grants it permission to call those APIs. Similar to guidelines for user access, the Role or ClusterRole bound to a service account should be restricted to the API resources and methods that the application needs to function and nothing else. To use a non-default service account simply set the spec.serviceAccountName field of a Pod to the name of the service account you wish to use. For additional information about creating service accounts, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#service-account-permissions . Note Prior to Kubernetes 1.24, Kubernetes would automatically create a secret for each a service account. This secret was mounted to the pod at /var/run/secrets/kubernetes.io/serviceaccount and would be used by the pod to authenticate to the Kubernetes API server. In Kubernetes 1.24, a service account token is dynamically generated when the pod runs and is only valid for an hour by default. A secret for the service account will not be created. If you have an application that runs outside the cluster that needs to authenticate to the Kubernetes API, e.g. Jenkins, you will need to create a secret of type kubernetes.io/service-account-token along with an annotation that references the service account such as metadata.annotations.kubernetes.io/service-account.name: <SERVICE_ACCOUNT_NAME> . Secrets created in this way do not expire. IAM Roles for Service Accounts (IRSA) \u00b6 IRSA is a feature that allows you to assign an IAM role to a Kubernetes service account. It works by leveraging a Kubernetes feature known as Service Account Token Volume Projection . When Pods are configured with a Service Account that references an IAM Role, the Kubernetes API server will call the public OIDC discovery endpoint for the cluster on startup. The endpoint cryptographically signs the OIDC token issued by Kubernetes and the resulting token mounted as a volume. This signed token allows the Pod to call the AWS APIs associated IAM role. When an AWS API is invoked, the AWS SDKs calls sts:AssumeRoleWithWebIdentity . After validating the token's signature, IAM exchanges the Kubernetes issued token for a temporary AWS role credential. Decoding the (JWT) token for IRSA will produce output similar to the example you see below: { \"aud\" : [ \"sts.amazonaws.com\" ], \"exp\" : 1582306514 , \"iat\" : 1582220114 , \"iss\" : \"https://oidc.eks.us-west-2.amazonaws.com/id/D43CF17C27A865933144EA99A26FB128\" , \"kubernetes.io\" : { \"namespace\" : \"default\" , \"pod\" : { \"name\" : \"alpine-57b5664646-rf966\" , \"uid\" : \"5a20f883-5407-11ea-a85c-0e62b7a4a436\" }, \"serviceaccount\" : { \"name\" : \"s3-read-only\" , \"uid\" : \"a720ba5c-5406-11ea-9438-063a49b60fba\" } }, \"nbf\" : 1582220114 , \"sub\" : \"system:serviceaccount:default:s3-read-only\" } This particular token grants the Pod view-only privileges to S3. When the application attempts to read from S3, the token is exchanged for a temporary set of IAM credentials that resembles this: { \"AssumedRoleUser\" : { \"AssumedRoleId\" : \"AROA36C6WWEJULFUYMPB6:abc\" , \"Arn\" : \"arn:aws:sts::123456789012:assumed-role/eksctl-winterfell-addon-iamserviceaccount-de-Role1-1D61LT75JH3MB/abc\" }, \"Audience\" : \"sts.amazonaws.com\" , \"Provider\" : \"arn:aws:iam::123456789012:oidc-provider/oidc.eks.us-west-2.amazonaws.com/id/D43CF17C27A865933144EA99A26FB128\" , \"SubjectFromWebIdentityToken\" : \"system:serviceaccount:default:s3-read-only\" , \"Credentials\" : { \"SecretAccessKey\" : \"ORJ+8Adk+wW+nU8FETq7+mOqeA8Z6jlPihnV8hX1\" , \"SessionToken\" : \"FwoGZXIvYXdzEGMaDMLxAZkuLpmSwYXShiL9A1S0X87VBC1mHCrRe/pB2oes+l1eXxUYnPJyC9ayOoXMvqXQsomq0xs6OqZ3vaa5Iw1HIyA4Cv1suLaOCoU3hNvOIJ6C94H1vU0siQYk7DIq9Av5RZe+uE2FnOctNBvYLd3i0IZo1ajjc00yRK3v24VRq9nQpoPLuqyH2jzlhCEjXuPScPbi5KEVs9fNcOTtgzbVf7IG2gNiwNs5aCpN4Bv/Zv2A6zp5xGz9cWj2f0aD9v66vX4bexOs5t/YYhwuwAvkkJPSIGvxja0xRThnceHyFHKtj0H+bi/PWAtlI8YJcDX69cM30JAHDdQH+ltm/4scFptW1hlvMaP+WReCAaCrsHrAT+yka7ttw5YlUyvZ8EPog+j6fwHlxmrXM9h1BqdikomyJU00gm1++FJelfP+1zAwcyrxCnbRl3ARFrAt8hIlrT6Vyu8WvWtLxcI8KcLcJQb/LgkW+sCTGlYcY8z3zkigJMbYn07ewTL5Ss7LazTJJa758I7PZan/v3xQHd5DEc5WBneiV3iOznDFgup0VAMkIviVjVCkszaPSVEdK2NU7jtrh6Jfm7bU/3P6ZG+CkyDLIa8MBn9KPXeJd/y+jTk5Ii+fIwO/+mDpGNUribg6TPxhzZ8b/XdZO1kS1gVgqjXyVC+M+BRBh6C4H21w/eMzjCtDIpoxt5rGKL6Nu/IFMipoC4fgx6LIIHwtGYMG7SWQi7OsMAkiwZRg0n68/RqWgLzBt/4pfjSRYuk=\" , \"Expiration\" : \"2020-02-20T18:49:50Z\" , \"AccessKeyId\" : \"ASIA36C6WWEJUMHA3L7Z\" } } A mutating webhook that runs as part of the EKS control plane injects the AWS Role ARN and the path to a web identity token file into the Pod as environment variables. These values can also be supplied manually. AWS_ROLE_ARN = arn : aws : iam :: AWS_ACCOUNT_ID : role / IAM_ROLE_NAME AWS_WEB_IDENTITY_TOKEN_FILE =/ var / run / secrets / eks . amazonaws . com / serviceaccount / token The kubelet will automatically rotate the projected token when it is older than 80% of its total TTL, or after 24 hours. The AWS SDKs are responsible for reloading the token when it rotates. For further information about IRSA, see https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts-technical-overview.html . Recommendations \u00b6 Update the aws-node daemonset to use IRSA \u00b6 At present, the aws-node daemonset is configured to use a role assigned to the EC2 instances to assign IPs to pods. This role includes several AWS managed policies, e.g. AmazonEKS_CNI_Policy and EC2ContainerRegistryReadOnly that effectively allow all pods running on a node to attach/detach ENIs, assign/unassign IP addresses, or pull images from ECR. Since this presents a risk to your cluster, it is recommended that you update the aws-node daemonset to use IRSA. A script for doing this can be found in the repository for this guide. Restrict access to the instance profile assigned to the worker node \u00b6 When you use IRSA, it updates the credential chain of the pod to use the IRSA token, however, the pod can still inherit the rights of the instance profile assigned to the worker node . When using IRSA, it is strongly recommended that you block access instance metadata to minimize the blast radius of a breach. Caution Blocking access to instance metadata will prevent pods that do not use IRSA from inheriting the role assigned to the worker node. You can block access to instance metadata by requiring the instance to use IMDSv2 only and updating the hop count to 1 as in the example below. You can also include these settings in the node group's launch template. Do not disable instance metadata as this will prevent components like the node termination handler and other things that rely on instance metadata from working properly. aws ec2 modify-instance-metadata-options --instance-id <value> --http-tokens required --http-put-response-hop-limit 1 You can also block a pod's access to EC2 metadata by manipulating iptables on the node. For further information about this method, see Limiting access to the instance metadata service . If you have an application that is using an older version of the AWS SDK that doesn't support IRSA, and you want the pod to inherit the role assigned to the instance, consider using Kubernetes network policies to selectively allow access EC2 metadata. Start with a policy that blocks access to the metadata service from all Pods: apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : deny-metadata-access namespace : example spec : podSelector : {} policyTypes : - Egress egress : - to : - ipBlock : cidr : 0.0.0.0/0 except : - 169.254.169.254/32 Then allow access from select pods by adding following policy, modifying the PodSelector as appropriate. apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : allow-metadata-access namespace : example spec : podSelector : matchLabels : app : myapp policyTypes : - Egress egress : - to : - ipBlock : cidr : 169.254.169.254/32 Scope the IAM Role trust policy for IRSA to the service account name \u00b6 The trust policy can be scoped to a Namespace or a specific service account within a Namespace. When using IRSA it's best to make the role trust policy as explicit as possible by including the service account name. This will effectively prevent other Pods within the same Namespace from assuming the role. The CLI eksctl will do this automatically when you use it to create service accounts/IAM roles. See https://eksctl.io/usage/iamserviceaccounts/ for further information. When your application needs access to IMDS, use IMDSv2 and increase the hop limit on EC2 instances to 2 \u00b6 IMDSv2 requires you use a PUT request to get a session token. The initial PUT request has to include a TTL for the session token. Newer versions of the AWS SDKs will handle this and the renewal of said token automatically. It's also important to be aware that the default hop limit on EC2 instances is intentionally set to 1 to prevent IP forwarding. As a consequence, Pods that request a session token that are run on EC2 instances may eventually time out and fallback to using the IMDSv1 data flow. EKS adds support IMDSv2 by enabling both v1 and v2 and changing the hop limit to 2 on nodes provisioned by eksctl or with the official CloudFormation templates. Disable auto-mounting of service account tokens \u00b6 If your application doesn't need to call the Kubernetes API set the automountServiceAccountToken attribute to false in the PodSpec for your application or patch the default service account in each namespace so that it's no longer mounted to pods automatically. For example: kubectl patch serviceaccount default -p $'automountServiceAccountToken: false' Use dedicated service accounts for each application \u00b6 Each application should have its own dedicated service account. This applies to service accounts for the Kubernetes API as well as IRSA. Attention If you employ a blue/green approach to cluster upgrades instead of performing an in-place cluster upgrade, you will need to update the trust policy of each of the IRSA IAM roles with the OIDC endpoint of the new cluster. A blue/green cluster upgrade is where you create a cluster running a newer version of Kubernetes alongside the old cluster and use a load balancer or a service mesh to seamlessly shift traffic from services running on the old cluster to the new cluster. Run the application as a non-root user \u00b6 Containers run as root by default. While this allows them to read the web identity token file, running a container as root is not considered a best practice. As an alternative, consider adding the spec.securityContext.runAsUser attribute to the PodSpec. The value of runAsUser is arbitrary value. In the following example, all processes within the Pod will run under the user ID specified in the runAsUser field. apiVersion : v1 kind : Pod metadata : name : security-context-demo spec : securityContext : runAsUser : 1000 runAsGroup : 3000 containers : - name : sec-ctx-demo image : busybox command : [ \"sh\" , \"-c\" , \"sleep 1h\" ] When you run a container as a non-root user, it prevents the container from reading the IRSA service account token because the token is assigned 0600 [root] permissions by default. If you update the securityContext for your container to include fsgroup=65534 [Nobody] it will allow the container to read the token. spec : securityContext : fsGroup : 65534 In Kubernetes 1.19 and above, this change is no longer required. Grant least privileged access to applications \u00b6 Action Hero is a utility that you can run alongside your application to identify the AWS API calls and corresponding IAM permissions your application needs to function properly. It is similar to IAM Access Advisor in that it helps you gradually limit the scope of IAM roles assigned to applications. Consult the documentation on granting least privileged access to AWS resources for further information. Review and revoke unnecessary anonymous access \u00b6 Ideally anonymous access should be disabled for all API actions. Anonymous access is granted by creating a RoleBinding or ClusterRoleBinding for the Kubernetes built-in user system:anonymous. You can use the rbac-lookup tool to identify permissions that system:anonymous user has on your cluster: ./rbac-lookup | grep -P 'system:(anonymous)|(unauthenticated)' system:anonymous cluster-wide ClusterRole/system:discovery system:unauthenticated cluster-wide ClusterRole/system:discovery system:unauthenticated cluster-wide ClusterRole/system:public-info-viewer Any role or ClusterRole other than system:public-info-viewer should not be bound to system:anonymous user or system:unauthenticated group. There may be some legitimate reasons to enable anonymous access on specific APIs. If this is the case for your cluster ensure that only those specific APIs are accessible by anonymous user and exposing those APIs without authentication doesn\u2019t make your cluster vulnerable. Prior to Kubernetes/EKS Version 1.14, system:unauthenticated group was associated to system:discovery and system:basic-user ClusterRoles by default. Note that even if you have updated your cluster to version 1.14 or higher, these permissions may still be enabled on your cluster, since cluster updates do not revoke these permissions. To check which ClusterRoles have \"system:unauthenticated\" except system:public-info-viewer you can run the following command (requires jq util): kubectl get ClusterRoleBinding -o json | jq -r '.items[] | select(.subjects[]?.name ==\"system:unauthenticated\") | select(.metadata.name != \"system:public-info-viewer\") | .metadata.name' And \"system:unauthenticated\" can be removed from all the roles except \"system:public-info-viewer\" using: kubectl get ClusterRoleBinding -o json | jq -r '.items[] | select(.subjects[]?.name ==\"system:unauthenticated\") | select(.metadata.name != \"system:public-info-viewer\") | del(.subjects[] | select(.name ==\"system:unauthenticated\"))' | kubectl apply -f - Alternatively, you can check and remove it manually by kubectl describe and kubectl edit. To check if system:unauthenticated group has system:discovery permissions on your cluster run the following command: kubectl describe clusterrolebindings system:discovery Name: system:discovery Labels: kubernetes.io/bootstrapping=rbac-defaults Annotations: rbac.authorization.kubernetes.io/autoupdate: true Role: Kind: ClusterRole Name: system:discovery Subjects: Kind Name Namespace ---- ---- --------- Group system:authenticated Group system:unauthenticated To check if system:unauthenticated group has system:basic-user permission on your cluster run the following command: kubectl describe clusterrolebindings system:basic-user Name: system:basic-user Labels: kubernetes.io/bootstrapping=rbac-defaults Annotations: rbac.authorization.kubernetes.io/autoupdate: true Role: Kind: ClusterRole Name: system:basic-user Subjects: Kind Name Namespace ---- ---- --------- Group system:authenticated Group system:unauthenticated If system:unauthenticated group is bound to system:discovery and/or system:basic-user ClusterRoles on your cluster, you should disassociate these roles from system:unauthenticated group. Edit system:discovery ClusterRoleBinding using the following command: kubectl edit clusterrolebindings system:discovery The above command will open the current definition of system:discovery ClusterRoleBinding in an editor as shown below: # Please edit the object below . Lines beginning with a '#' will be ignored , # and an empty file will abort the edit . If an error occurs while saving this file will be # reopened with the relevant failures . # apiVersion : rbac . authorization . k8s . io / v1 kind : ClusterRoleBinding metadata : annotations : rbac . authorization . kubernetes . io / autoupdate : \"true\" creationTimestamp : \"2021-06-17T20:50:49Z\" labels : kubernetes . io / bootstrapping : rbac - defaults name : system : discovery resourceVersion : \"24502985\" selfLink : / apis / rbac . authorization . k8s . io / v1 / clusterrolebindings / system % 3 Adiscovery uid : b7936268 - 5043 - 431 a - a0e1 - 171 a423abeb6 roleRef : apiGroup : rbac . authorization . k8s . io kind : ClusterRole name : system : discovery subjects : - apiGroup : rbac . authorization . k8s . io kind : Group name : system : authenticated - apiGroup : rbac . authorization . k8s . io kind : Group name : system : unauthenticated Delete the entry for system:unauthenticated group from the \u201csubjects\u201d section in the above editor screen. Repeat the same steps for system:basic-user ClusterRoleBinding. Alternative approaches \u00b6 While IRSA is the preferred way to assign an AWS \"identity\" to a pod, it requires that you include recent version of the AWS SDKs in your application. For a complete listing of the SDKs that currently support IRSA, see https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts-minimum-sdk.html . If you have an application that you can't immediately update with a IRSA-compatible SDK, there are several community-built solutions available for assigning IAM roles to Kubernetes pods, including kube2iam and kiam . Although AWS doesn't endorse or condone the use of these solutions, they are frequently used by the community at large to achieve similar results as IRSA.","title":"Identity and Access Management"},{"location":"security/docs/iam/#identity-and-access-management","text":"Identity and Access Management (IAM) is an AWS service that performs two essential functions: Authentication and Authorization. Authentication involves the verification of a identity whereas authorization governs the actions that can be performed by AWS resources. Within AWS, a resource can be another AWS service, e.g. EC2, or an AWS principal such as an IAM User or Role . The rules governing the actions that a resource is allowed to perform are expressed as IAM policies .","title":"Identity and Access Management"},{"location":"security/docs/iam/#controlling-access-to-eks-clusters","text":"The Kubernetes project supports a variety of different strategies to authenticate requests to the kube-apiserver service, e.g. Bearer Tokens, X.509 certificates, OIDC, etc. EKS currently has native support for webhook token authentication , service account tokens , and as of February 21, 2021, OIDC authentication. The webhook authentication strategy calls a webhook that verifies bearer tokens. On EKS, these bearer tokens are generated by the AWS CLI or the aws-iam-authenticator client when you run kubectl commands. As you execute commands, the token is passed to the kube-apiserver which forwards it to the authentication webhook. If the request is well-formed, the webhook calls a pre-signed URL embedded in the token's body. This URL validates the request's signature and returns information about the user, e.g. the user's account, Arn, and UserId to the kube-apiserver. To manually generate a authentication token, type the following command in a terminal window: aws eks get-token --cluster <cluster_name> You can also get a token programmatically. Below is an example written in Go: package main import ( \"fmt\" \"log\" \"sigs.k8s.io/aws-iam-authenticator/pkg/token\" ) func main () { g , _ := token . NewGenerator ( false , false ) tk , err := g . Get ( \"<cluster_name>\" ) if err != nil { log . Fatal ( err ) } fmt . Println ( tk ) } The output should resemble this: { \"kind\" : \"ExecCredential\" , \"apiVersion\" : \"client.authentication.k8s.io/v1alpha1\" , \"spec\" : {}, \"status\" : { \"expirationTimestamp\" : \"2020-02-19T16:08:27Z\" , \"token\" : \"k8s-aws-v1.aHR0cHM6Ly9zdHMuYW1hem9uYXdzLmNvbS8_QWN0aW9uPUdldENhbGxlcklkZW50aXR5JlZlcnNpb249MjAxMS0wNi0xNSZYLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFKTkdSSUxLTlNSQzJXNVFBJTJGMjAyMDAyMTklMkZ1cy1lYXN0LTElMkZzdHMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDIwMDIxOVQxNTU0MjdaJlgtQW16LUV4cGlyZXM9NjAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JTNCeC1rOHMtYXdzLWlkJlgtQW16LVNpZ25hdHVyZT0yMjBmOGYzNTg1ZTMyMGRkYjVlNjgzYTVjOWE0MDUzMDFhZDc2NTQ2ZjI0ZjI4MTExZmRhZDA5Y2Y2NDhhMzkz\" } } Each token starts with k8s-aws-v1. followed by a base64 encoded string. The string, when decoded, should resemble this: https://sts.amazonaws.com/?Action = GetCallerIdentity & Version = 2011 -06-15 & X-Amz-Algorithm = AWS4-HMAC-SHA256 & X-Amz-Credential = AKIAJPFRILKNSRC2W5QA%2F20200219%2Fus-east-1%2Fsts%2Faws4_request & X-Amz-Date = 20200219T155427Z & X-Amz-Expires = 60 & X-Amz-SignedHeaders = host%3Bx-k8s-aws-id & X-Amz-Signature = 220f8f3285e320ddb5e683a5c9a405301ad76546f24f28111fdad09cf648a393 The token consists of a pre-signed URL that includes an Amazon credential and signature. For additional details see https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html . The token has a time to live (TTL) of 15 minutes after which a new token will need to be generated. This is handled automatically when you use a client like kubectl , however, if you're using the Kubernetes dashboard, you will need to generate a new token and re-authenticate each time the token expires. Once the user's identity has been authenticated by the AWS IAM service, the kube-apiserver reads the aws-auth ConfigMap in the kube-system Namespace to determine the RBAC group to associate with the user. The aws-auth ConfigMap is used to create a static mapping between IAM principals, i.e. IAM Users and Roles, and Kubernetes RBAC groups. RBAC groups can be referenced in Kubernetes RoleBindings or ClusterRoleBindings. They are similar to IAM Roles in that they define a set of actions (verbs) that can be performed against a collection of Kubernetes resources (objects).","title":"Controlling Access to EKS Clusters"},{"location":"security/docs/iam/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/iam/#dont-use-a-service-account-token-for-authentication","text":"A service account token is a long-lived, static credential. If it is compromised, lost, or stolen, an attacker may be able to perform all the actions associated with that token until the service account is deleted. At times, you may need to grant an exception for applications that have to consume the Kubernetes API from outside the cluster, e.g. a CI/CD pipeline application. If such applications run on AWS infrastructure, like EC2 instances, consider using an instance profile and mapping that to a Kubernetes RBAC role in the aws-auth ConfigMap instead.","title":"Don't use a service account token for authentication"},{"location":"security/docs/iam/#employ-least-privileged-access-to-aws-resources","text":"An IAM User does not need to be assigned privileges to AWS resources to access the Kubernetes API. If you need to grant an IAM user access to an EKS cluster, create an entry in the aws-auth ConfigMap for that user that maps to a specific Kubernetes RBAC group.","title":"Employ least privileged access to AWS Resources"},{"location":"security/docs/iam/#use-iam-roles-when-multiple-users-need-identical-access-to-the-cluster","text":"Rather than creating an entry for each individual IAM User in the aws-auth ConfigMap, allow those users to assume an IAM Role and map that role to a Kubernetes RBAC group. This will be easier to maintain, especially as the number of users that require access grows. Attention When accessing the EKS cluster with the IAM entity mapped by aws-auth ConfigMap, the username described in aws-auth ConfigMap is recorded in the user field of the Kubernetes audit log. If you're using an IAM role, the actual users who assume that role aren't recorded and can't be audited. When assigning K8s RBAC permissions to an IAM role using mapRoles in aws-auth ConfigMap, you should include {{SessionName}} in your username. That way, the audit log will record the session name so you can track who the actual user assume this role along with the CloudTrail log. - rolearn : arn:aws:iam::XXXXXXXXXXXX:role/testRole username : testRole:{{SessionName}} groups : - system:masters In Kubernetes 1.20 and above, this change is no longer required, since user.extra.sessionName.0 was added to the Kubernetes audit log.","title":"Use IAM Roles when multiple users need identical access to the cluster"},{"location":"security/docs/iam/#employ-least-privileged-access-when-creating-rolebindings-and-clusterrolebindings","text":"Like the earlier point about granting access to AWS Resources, RoleBindings and ClusterRoleBindings should only include the set of permissions necessary to perform a specific function. Avoid using [\"*\"] in your Roles and ClusterRoles unless it's absolutely necessary. If you're unsure what permissions to assign, consider using a tool like audit2rbac to automatically generate Roles and binding based on the observed API calls in the Kubernetes Audit Log.","title":"Employ least privileged access when creating RoleBindings and ClusterRoleBindings"},{"location":"security/docs/iam/#make-the-eks-cluster-endpoint-private","text":"By default when you provision an EKS cluster, the API cluster endpoint is set to public, i.e. it can be accessed from the Internet. Despite being accessible from the Internet, the endpoint is still considered secure because it requires all API requests to be authenticated by IAM and then authorized by Kubernetes RBAC. That said, if your corporate security policy mandates that you restrict access to the API from the Internet or prevents you from routing traffic outside the cluster VPC, you can: Configure the EKS cluster endpoint to be private. See Modifying Cluster Endpoint Access for further information on this topic. Leave the cluster endpoint public and specify which CIDR blocks can communicate with the cluster endpoint. The blocks are effectively a whitelisted set of public IP addresses that are allowed to access the cluster endpoint. Configure public access with a set of whitelisted CIDR blocks and set private endpoint access to enabled. This will allow public access from a specific range of public IPs while forcing all network traffic between the kubelets (workers) and the Kubernetes API through the cross-account ENIs that get provisioned into the cluster VPC when the control plane is provisioned.","title":"Make the EKS Cluster Endpoint private"},{"location":"security/docs/iam/#create-the-cluster-with-a-dedicated-iam-role","text":"When you create an Amazon EKS cluster, the IAM entity user or role, such as a federated user that creates the cluster, is automatically granted system:masters permissions in the cluster's RBAC configuration. This access cannot be removed and is not managed through the aws-auth ConfigMap. Therefore it is a good idea to create the cluster with a dedicated IAM role and regularly audit who can assume this role. This role should not be used to perform routine actions on the cluster, and instead additional users should be granted access to the cluster through the aws-auth ConfigMap for this purpose. After the aws-auth ConfigMap is configured, the role can be deleted and only recreated in an emergency / break glass scenario where the aws-auth ConfigMap is corrupted and the cluster is otherwise inaccessible. This can be particularly useful in production clusters which do not usually have direct user access configured.","title":"Create the cluster with a dedicated IAM role"},{"location":"security/docs/iam/#use-tools-to-make-changes-to-the-aws-auth-configmap","text":"An improperly formatted aws-auth ConfigMap may cause you to lose access to the cluster. If you need to make changes to the ConfigMap, use a tool. eksctl The eksctl CLI includes a command for adding identity mappings to the aws-auth ConfigMap. View CLI Help: eksctl create iamidentitymapping --help Make an IAM Role a Cluster Admin: eksctl create iamidentitymapping -- cluster < clusterName > -- region =< region > -- arn arn:aws: iam :: 123456 : role / testing -- group system: masters -- username admin For more information, review eksctl docs aws-auth by keikoproj aws-auth by keikoproj includes both a cli and a go library. Download and view help CLI help: go get github . com / keikoproj / aws - auth aws - auth help Alternatively, install aws-auth with the krew plugin manager for kubectl. kubectl krew install aws-auth kubectl aws-auth Review the aws-auth docs on GitHub for more information, including the go library. AWS IAM Authenticator CLI The aws-iam-authenticator project includes a CLI for updating the ConfigMap. Download a release on GitHub. Add cluster permissions to an IAM Role: ./aws-iam-authenticator add role --rolearn arn:aws:iam::185309785115:role/lil-dev-role-cluster --username lil-dev-user --groups system:masters --kubeconfig ~/.kube/config","title":"Use tools to make changes to the aws-auth ConfigMap"},{"location":"security/docs/iam/#regularly-audit-access-to-the-cluster","text":"Who requires access is likely to change over time. Plan to periodically audit the aws-auth ConfigMap to see who has been granted access and the rights they've been assigned. You can also use open source tooling like kubectl-who-can , or rbac-lookup to examine the roles bound to a particular service account, user, or group. We'll explore this topic further when we get to the section on auditing . Additional ideas can be found in this article from NCC Group.","title":"Regularly audit access to the cluster"},{"location":"security/docs/iam/#alternative-approaches-to-authentication-and-access-management","text":"While IAM is the preferred way to authenticate users who need access to an EKS cluster, it is possible to use an OIDC identity provider such as GitHub using an authentication proxy and Kubernetes impersonation . Posts for two such solutions have been published on the AWS Open Source blog: Authenticating to EKS Using GitHub Credentials with Teleport Consistent OIDC authentication across multiple EKS clusters using kube-oidc-proxy Attention EKS natively supports OIDC authentication without using a proxy. For further information, please read the launch blog, Introducing OIDC identity provider authentication for Amazon EKS . For an example showing how to configure EKS with Dex, a popular open source OIDC provider with connectors for a variety of different authention methods, see Using Dex & dex-k8s-authenticator to authenticate to Amazon EKS . As described in the blogs, the username/group of users authenticated by an OIDC provider will appear in the Kubernetes audit log. You can also use AWS SSO to federate AWS with an external identity provider, e.g. Azure AD. If you decide to use this, the AWS CLI v2.0 includes an option to create a named profile that makes it easy to associate an SSO session with your current CLI session and assume an IAM role. Know that you must assume a role prior to running kubectl as the IAM role is used to determine the user's Kubernetes RBAC group.","title":"Alternative Approaches to Authentication and Access Management"},{"location":"security/docs/iam/#additional-resources","text":"rbac.dev A list of additional resources, including blogs and tools, for Kubernetes RBAC","title":"Additional Resources"},{"location":"security/docs/iam/#pods-identities","text":"Certain applications that run within a Kubernetes cluster need permission to call the Kubernetes API to function properly. For example, the AWS Load Balancer Controller needs to be able to list a Service's Endpoints. The controller also needs to be able to invoke AWS APIs to provision and configure an ALB. In this section we will explore the best practices for assigning rights and privileges to Pods.","title":"Pods Identities"},{"location":"security/docs/iam/#kubernetes-service-accounts","text":"A service account is a special type of object that allows you to assign a Kubernetes RBAC role to a pod. A default service account is created automatically for each Namespace within a cluster. When you deploy a pod into a Namespace without referencing a specific service account, the default service account for that Namespace will automatically get assigned to the Pod and the Secret, i.e. the service account (JWT) token for that service account, will get mounted to the pod as a volume at /var/run/secrets/kubernetes.io/serviceaccount . Decoding the service account token in that directory will reveal the following metadata: { \"iss\" : \"kubernetes/serviceaccount\" , \"kubernetes.io/serviceaccount/namespace\" : \"default\" , \"kubernetes.io/serviceaccount/secret.name\" : \"default-token-5pv4z\" , \"kubernetes.io/serviceaccount/service-account.name\" : \"default\" , \"kubernetes.io/serviceaccount/service-account.uid\" : \"3b36ddb5-438c-11ea-9438-063a49b60fba\" , \"sub\" : \"system:serviceaccount:default:default\" } The default service account has the following permissions to the Kubernetes API. apiVersion : rbac.authorization.k8s.io/v1 kind : ClusterRole metadata : annotations : rbac.authorization.kubernetes.io/autoupdate : \"true\" creationTimestamp : \"2020-01-30T18:13:25Z\" labels : kubernetes.io/bootstrapping : rbac-defaults name : system:discovery resourceVersion : \"43\" selfLink : /apis/rbac.authorization.k8s.io/v1/clusterroles/system%3Adiscovery uid : 350d2ab8-438c-11ea-9438-063a49b60fba rules : - nonResourceURLs : - /api - /api/* - /apis - /apis/* - /healthz - /openapi - /openapi/* - /version - /version/ verbs : - get This role authorizes unauthenticated and authenticated users to read API information and is deemed safe to be publicly accessible. When an application running within a Pod calls the Kubernetes APIs, the Pod needs to be assigned a service account that explicitly grants it permission to call those APIs. Similar to guidelines for user access, the Role or ClusterRole bound to a service account should be restricted to the API resources and methods that the application needs to function and nothing else. To use a non-default service account simply set the spec.serviceAccountName field of a Pod to the name of the service account you wish to use. For additional information about creating service accounts, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#service-account-permissions . Note Prior to Kubernetes 1.24, Kubernetes would automatically create a secret for each a service account. This secret was mounted to the pod at /var/run/secrets/kubernetes.io/serviceaccount and would be used by the pod to authenticate to the Kubernetes API server. In Kubernetes 1.24, a service account token is dynamically generated when the pod runs and is only valid for an hour by default. A secret for the service account will not be created. If you have an application that runs outside the cluster that needs to authenticate to the Kubernetes API, e.g. Jenkins, you will need to create a secret of type kubernetes.io/service-account-token along with an annotation that references the service account such as metadata.annotations.kubernetes.io/service-account.name: <SERVICE_ACCOUNT_NAME> . Secrets created in this way do not expire.","title":"Kubernetes Service Accounts"},{"location":"security/docs/iam/#iam-roles-for-service-accounts-irsa","text":"IRSA is a feature that allows you to assign an IAM role to a Kubernetes service account. It works by leveraging a Kubernetes feature known as Service Account Token Volume Projection . When Pods are configured with a Service Account that references an IAM Role, the Kubernetes API server will call the public OIDC discovery endpoint for the cluster on startup. The endpoint cryptographically signs the OIDC token issued by Kubernetes and the resulting token mounted as a volume. This signed token allows the Pod to call the AWS APIs associated IAM role. When an AWS API is invoked, the AWS SDKs calls sts:AssumeRoleWithWebIdentity . After validating the token's signature, IAM exchanges the Kubernetes issued token for a temporary AWS role credential. Decoding the (JWT) token for IRSA will produce output similar to the example you see below: { \"aud\" : [ \"sts.amazonaws.com\" ], \"exp\" : 1582306514 , \"iat\" : 1582220114 , \"iss\" : \"https://oidc.eks.us-west-2.amazonaws.com/id/D43CF17C27A865933144EA99A26FB128\" , \"kubernetes.io\" : { \"namespace\" : \"default\" , \"pod\" : { \"name\" : \"alpine-57b5664646-rf966\" , \"uid\" : \"5a20f883-5407-11ea-a85c-0e62b7a4a436\" }, \"serviceaccount\" : { \"name\" : \"s3-read-only\" , \"uid\" : \"a720ba5c-5406-11ea-9438-063a49b60fba\" } }, \"nbf\" : 1582220114 , \"sub\" : \"system:serviceaccount:default:s3-read-only\" } This particular token grants the Pod view-only privileges to S3. When the application attempts to read from S3, the token is exchanged for a temporary set of IAM credentials that resembles this: { \"AssumedRoleUser\" : { \"AssumedRoleId\" : \"AROA36C6WWEJULFUYMPB6:abc\" , \"Arn\" : \"arn:aws:sts::123456789012:assumed-role/eksctl-winterfell-addon-iamserviceaccount-de-Role1-1D61LT75JH3MB/abc\" }, \"Audience\" : \"sts.amazonaws.com\" , \"Provider\" : \"arn:aws:iam::123456789012:oidc-provider/oidc.eks.us-west-2.amazonaws.com/id/D43CF17C27A865933144EA99A26FB128\" , \"SubjectFromWebIdentityToken\" : \"system:serviceaccount:default:s3-read-only\" , \"Credentials\" : { \"SecretAccessKey\" : \"ORJ+8Adk+wW+nU8FETq7+mOqeA8Z6jlPihnV8hX1\" , \"SessionToken\" : \"FwoGZXIvYXdzEGMaDMLxAZkuLpmSwYXShiL9A1S0X87VBC1mHCrRe/pB2oes+l1eXxUYnPJyC9ayOoXMvqXQsomq0xs6OqZ3vaa5Iw1HIyA4Cv1suLaOCoU3hNvOIJ6C94H1vU0siQYk7DIq9Av5RZe+uE2FnOctNBvYLd3i0IZo1ajjc00yRK3v24VRq9nQpoPLuqyH2jzlhCEjXuPScPbi5KEVs9fNcOTtgzbVf7IG2gNiwNs5aCpN4Bv/Zv2A6zp5xGz9cWj2f0aD9v66vX4bexOs5t/YYhwuwAvkkJPSIGvxja0xRThnceHyFHKtj0H+bi/PWAtlI8YJcDX69cM30JAHDdQH+ltm/4scFptW1hlvMaP+WReCAaCrsHrAT+yka7ttw5YlUyvZ8EPog+j6fwHlxmrXM9h1BqdikomyJU00gm1++FJelfP+1zAwcyrxCnbRl3ARFrAt8hIlrT6Vyu8WvWtLxcI8KcLcJQb/LgkW+sCTGlYcY8z3zkigJMbYn07ewTL5Ss7LazTJJa758I7PZan/v3xQHd5DEc5WBneiV3iOznDFgup0VAMkIviVjVCkszaPSVEdK2NU7jtrh6Jfm7bU/3P6ZG+CkyDLIa8MBn9KPXeJd/y+jTk5Ii+fIwO/+mDpGNUribg6TPxhzZ8b/XdZO1kS1gVgqjXyVC+M+BRBh6C4H21w/eMzjCtDIpoxt5rGKL6Nu/IFMipoC4fgx6LIIHwtGYMG7SWQi7OsMAkiwZRg0n68/RqWgLzBt/4pfjSRYuk=\" , \"Expiration\" : \"2020-02-20T18:49:50Z\" , \"AccessKeyId\" : \"ASIA36C6WWEJUMHA3L7Z\" } } A mutating webhook that runs as part of the EKS control plane injects the AWS Role ARN and the path to a web identity token file into the Pod as environment variables. These values can also be supplied manually. AWS_ROLE_ARN = arn : aws : iam :: AWS_ACCOUNT_ID : role / IAM_ROLE_NAME AWS_WEB_IDENTITY_TOKEN_FILE =/ var / run / secrets / eks . amazonaws . com / serviceaccount / token The kubelet will automatically rotate the projected token when it is older than 80% of its total TTL, or after 24 hours. The AWS SDKs are responsible for reloading the token when it rotates. For further information about IRSA, see https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts-technical-overview.html .","title":"IAM Roles for Service Accounts (IRSA)"},{"location":"security/docs/iam/#recommendations_1","text":"","title":"Recommendations"},{"location":"security/docs/iam/#update-the-aws-node-daemonset-to-use-irsa","text":"At present, the aws-node daemonset is configured to use a role assigned to the EC2 instances to assign IPs to pods. This role includes several AWS managed policies, e.g. AmazonEKS_CNI_Policy and EC2ContainerRegistryReadOnly that effectively allow all pods running on a node to attach/detach ENIs, assign/unassign IP addresses, or pull images from ECR. Since this presents a risk to your cluster, it is recommended that you update the aws-node daemonset to use IRSA. A script for doing this can be found in the repository for this guide.","title":"Update the aws-node daemonset to use IRSA"},{"location":"security/docs/iam/#restrict-access-to-the-instance-profile-assigned-to-the-worker-node","text":"When you use IRSA, it updates the credential chain of the pod to use the IRSA token, however, the pod can still inherit the rights of the instance profile assigned to the worker node . When using IRSA, it is strongly recommended that you block access instance metadata to minimize the blast radius of a breach. Caution Blocking access to instance metadata will prevent pods that do not use IRSA from inheriting the role assigned to the worker node. You can block access to instance metadata by requiring the instance to use IMDSv2 only and updating the hop count to 1 as in the example below. You can also include these settings in the node group's launch template. Do not disable instance metadata as this will prevent components like the node termination handler and other things that rely on instance metadata from working properly. aws ec2 modify-instance-metadata-options --instance-id <value> --http-tokens required --http-put-response-hop-limit 1 You can also block a pod's access to EC2 metadata by manipulating iptables on the node. For further information about this method, see Limiting access to the instance metadata service . If you have an application that is using an older version of the AWS SDK that doesn't support IRSA, and you want the pod to inherit the role assigned to the instance, consider using Kubernetes network policies to selectively allow access EC2 metadata. Start with a policy that blocks access to the metadata service from all Pods: apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : deny-metadata-access namespace : example spec : podSelector : {} policyTypes : - Egress egress : - to : - ipBlock : cidr : 0.0.0.0/0 except : - 169.254.169.254/32 Then allow access from select pods by adding following policy, modifying the PodSelector as appropriate. apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : allow-metadata-access namespace : example spec : podSelector : matchLabels : app : myapp policyTypes : - Egress egress : - to : - ipBlock : cidr : 169.254.169.254/32","title":"Restrict access to the instance profile assigned to the worker node"},{"location":"security/docs/iam/#scope-the-iam-role-trust-policy-for-irsa-to-the-service-account-name","text":"The trust policy can be scoped to a Namespace or a specific service account within a Namespace. When using IRSA it's best to make the role trust policy as explicit as possible by including the service account name. This will effectively prevent other Pods within the same Namespace from assuming the role. The CLI eksctl will do this automatically when you use it to create service accounts/IAM roles. See https://eksctl.io/usage/iamserviceaccounts/ for further information.","title":"Scope the IAM Role trust policy for IRSA to the service account name"},{"location":"security/docs/iam/#when-your-application-needs-access-to-imds-use-imdsv2-and-increase-the-hop-limit-on-ec2-instances-to-2","text":"IMDSv2 requires you use a PUT request to get a session token. The initial PUT request has to include a TTL for the session token. Newer versions of the AWS SDKs will handle this and the renewal of said token automatically. It's also important to be aware that the default hop limit on EC2 instances is intentionally set to 1 to prevent IP forwarding. As a consequence, Pods that request a session token that are run on EC2 instances may eventually time out and fallback to using the IMDSv1 data flow. EKS adds support IMDSv2 by enabling both v1 and v2 and changing the hop limit to 2 on nodes provisioned by eksctl or with the official CloudFormation templates.","title":"When your application needs access to IMDS, use IMDSv2 and increase the hop limit on EC2 instances to 2"},{"location":"security/docs/iam/#disable-auto-mounting-of-service-account-tokens","text":"If your application doesn't need to call the Kubernetes API set the automountServiceAccountToken attribute to false in the PodSpec for your application or patch the default service account in each namespace so that it's no longer mounted to pods automatically. For example: kubectl patch serviceaccount default -p $'automountServiceAccountToken: false'","title":"Disable auto-mounting of service account tokens"},{"location":"security/docs/iam/#use-dedicated-service-accounts-for-each-application","text":"Each application should have its own dedicated service account. This applies to service accounts for the Kubernetes API as well as IRSA. Attention If you employ a blue/green approach to cluster upgrades instead of performing an in-place cluster upgrade, you will need to update the trust policy of each of the IRSA IAM roles with the OIDC endpoint of the new cluster. A blue/green cluster upgrade is where you create a cluster running a newer version of Kubernetes alongside the old cluster and use a load balancer or a service mesh to seamlessly shift traffic from services running on the old cluster to the new cluster.","title":"Use dedicated service accounts for each application"},{"location":"security/docs/iam/#run-the-application-as-a-non-root-user","text":"Containers run as root by default. While this allows them to read the web identity token file, running a container as root is not considered a best practice. As an alternative, consider adding the spec.securityContext.runAsUser attribute to the PodSpec. The value of runAsUser is arbitrary value. In the following example, all processes within the Pod will run under the user ID specified in the runAsUser field. apiVersion : v1 kind : Pod metadata : name : security-context-demo spec : securityContext : runAsUser : 1000 runAsGroup : 3000 containers : - name : sec-ctx-demo image : busybox command : [ \"sh\" , \"-c\" , \"sleep 1h\" ] When you run a container as a non-root user, it prevents the container from reading the IRSA service account token because the token is assigned 0600 [root] permissions by default. If you update the securityContext for your container to include fsgroup=65534 [Nobody] it will allow the container to read the token. spec : securityContext : fsGroup : 65534 In Kubernetes 1.19 and above, this change is no longer required.","title":"Run the application as a non-root user"},{"location":"security/docs/iam/#grant-least-privileged-access-to-applications","text":"Action Hero is a utility that you can run alongside your application to identify the AWS API calls and corresponding IAM permissions your application needs to function properly. It is similar to IAM Access Advisor in that it helps you gradually limit the scope of IAM roles assigned to applications. Consult the documentation on granting least privileged access to AWS resources for further information.","title":"Grant least privileged access to applications"},{"location":"security/docs/iam/#review-and-revoke-unnecessary-anonymous-access","text":"Ideally anonymous access should be disabled for all API actions. Anonymous access is granted by creating a RoleBinding or ClusterRoleBinding for the Kubernetes built-in user system:anonymous. You can use the rbac-lookup tool to identify permissions that system:anonymous user has on your cluster: ./rbac-lookup | grep -P 'system:(anonymous)|(unauthenticated)' system:anonymous cluster-wide ClusterRole/system:discovery system:unauthenticated cluster-wide ClusterRole/system:discovery system:unauthenticated cluster-wide ClusterRole/system:public-info-viewer Any role or ClusterRole other than system:public-info-viewer should not be bound to system:anonymous user or system:unauthenticated group. There may be some legitimate reasons to enable anonymous access on specific APIs. If this is the case for your cluster ensure that only those specific APIs are accessible by anonymous user and exposing those APIs without authentication doesn\u2019t make your cluster vulnerable. Prior to Kubernetes/EKS Version 1.14, system:unauthenticated group was associated to system:discovery and system:basic-user ClusterRoles by default. Note that even if you have updated your cluster to version 1.14 or higher, these permissions may still be enabled on your cluster, since cluster updates do not revoke these permissions. To check which ClusterRoles have \"system:unauthenticated\" except system:public-info-viewer you can run the following command (requires jq util): kubectl get ClusterRoleBinding -o json | jq -r '.items[] | select(.subjects[]?.name ==\"system:unauthenticated\") | select(.metadata.name != \"system:public-info-viewer\") | .metadata.name' And \"system:unauthenticated\" can be removed from all the roles except \"system:public-info-viewer\" using: kubectl get ClusterRoleBinding -o json | jq -r '.items[] | select(.subjects[]?.name ==\"system:unauthenticated\") | select(.metadata.name != \"system:public-info-viewer\") | del(.subjects[] | select(.name ==\"system:unauthenticated\"))' | kubectl apply -f - Alternatively, you can check and remove it manually by kubectl describe and kubectl edit. To check if system:unauthenticated group has system:discovery permissions on your cluster run the following command: kubectl describe clusterrolebindings system:discovery Name: system:discovery Labels: kubernetes.io/bootstrapping=rbac-defaults Annotations: rbac.authorization.kubernetes.io/autoupdate: true Role: Kind: ClusterRole Name: system:discovery Subjects: Kind Name Namespace ---- ---- --------- Group system:authenticated Group system:unauthenticated To check if system:unauthenticated group has system:basic-user permission on your cluster run the following command: kubectl describe clusterrolebindings system:basic-user Name: system:basic-user Labels: kubernetes.io/bootstrapping=rbac-defaults Annotations: rbac.authorization.kubernetes.io/autoupdate: true Role: Kind: ClusterRole Name: system:basic-user Subjects: Kind Name Namespace ---- ---- --------- Group system:authenticated Group system:unauthenticated If system:unauthenticated group is bound to system:discovery and/or system:basic-user ClusterRoles on your cluster, you should disassociate these roles from system:unauthenticated group. Edit system:discovery ClusterRoleBinding using the following command: kubectl edit clusterrolebindings system:discovery The above command will open the current definition of system:discovery ClusterRoleBinding in an editor as shown below: # Please edit the object below . Lines beginning with a '#' will be ignored , # and an empty file will abort the edit . If an error occurs while saving this file will be # reopened with the relevant failures . # apiVersion : rbac . authorization . k8s . io / v1 kind : ClusterRoleBinding metadata : annotations : rbac . authorization . kubernetes . io / autoupdate : \"true\" creationTimestamp : \"2021-06-17T20:50:49Z\" labels : kubernetes . io / bootstrapping : rbac - defaults name : system : discovery resourceVersion : \"24502985\" selfLink : / apis / rbac . authorization . k8s . io / v1 / clusterrolebindings / system % 3 Adiscovery uid : b7936268 - 5043 - 431 a - a0e1 - 171 a423abeb6 roleRef : apiGroup : rbac . authorization . k8s . io kind : ClusterRole name : system : discovery subjects : - apiGroup : rbac . authorization . k8s . io kind : Group name : system : authenticated - apiGroup : rbac . authorization . k8s . io kind : Group name : system : unauthenticated Delete the entry for system:unauthenticated group from the \u201csubjects\u201d section in the above editor screen. Repeat the same steps for system:basic-user ClusterRoleBinding.","title":"Review and revoke unnecessary anonymous access"},{"location":"security/docs/iam/#alternative-approaches","text":"While IRSA is the preferred way to assign an AWS \"identity\" to a pod, it requires that you include recent version of the AWS SDKs in your application. For a complete listing of the SDKs that currently support IRSA, see https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts-minimum-sdk.html . If you have an application that you can't immediately update with a IRSA-compatible SDK, there are several community-built solutions available for assigning IAM roles to Kubernetes pods, including kube2iam and kiam . Although AWS doesn't endorse or condone the use of these solutions, they are frequently used by the community at large to achieve similar results as IRSA.","title":"Alternative approaches"},{"location":"security/docs/image/","text":"Image security \u00b6 You should consider the container image as your first line of defense against an attack. An insecure, poorly constructed image can allow an attacker to escape the bounds of the container and gain access to the host. Once on the host, an attacker can gain access to sensitive information or move laterally within the cluster or with your AWS account. The following best practices will help mitigate risk of this happening. Recommendations \u00b6 Create minimal images \u00b6 Start by removing all extraneous binaries from the container image. If you\u2019re using an unfamiliar image from Dockerhub, inspect the image using an application like Dive which can show you the contents of each of the container\u2019s layers. Remove all binaries with the SETUID and SETGID bits as they can be used to escalate privilege and consider removing all shells and utilities like nc and curl that can be used for nefarious purposes. You can find the files with SETUID and SETGID bits with the following command: find / -perm /6000 -type f -exec ls -ld {} \\; To remove the special permissions from these files, add the following directive to your container image: RUN find / -xdev -perm /6000 -type f -exec chmod a-s {} \\; || true Colloquially, this is known as de-fanging your image. Use multi-stage builds \u00b6 Using multi-stage builds is a way to create minimal images. Oftentimes, multi-stage builds are used to automate parts of the Continuous Integration cycle. For example, multi-stage builds can be used to lint your source code or perform static code analysis. This affords developers an opportunity to get near immediate feedback instead of waiting for a pipeline to execute. Multi-stage builds are attractive from a security standpoint because they allow you to minimize the size of the final image pushed to your container registry. Container images devoid of build tools and other extraneous binaries improves your security posture by reducing the attack surface of the image. For additional information about multi-stage builds, see https://docs.docker.com/develop/develop-images/multistage-build/ . Scan images for vulnerabilities regularly \u00b6 Like their virtual machine counterparts, container images can contain binaries and application libraries with vulnerabilities or develop vulnerabilities over time. The best way to safeguard against exploits is by regularly scanning your images with an image scanner. Images that are stored in Amazon ECR can be scanned on push or on-demand (once during a 24 hour period). ECR currently leverages Clair an open source image scanning solution. After an image is scanned, the results are logged to the event stream for ECR in EventBridge. You can also see the results of a scan from within the ECR console. Images with a HIGH or CRITICAL vulnerability should be deleted or rebuilt. If an image that has been deployed develops a vulnerability, it should be replaced as soon as possible. Knowing where images with vulnerabilities have been deployed is essential to keeping your environment secure. While you could conceivably build an image tracking solution yourself, there are already several commercial offerings that provide this and other advanced capabilities out of the box, including: Anchore Palo Alto - Prisma Cloud (twistcli) Aqua Kubei Trivy Snyk A Kubernetes validation webhook could also be used to validate that images are free of critical vulnerabilities. Validation webhooks are invoked prior to the Kubernetes API. They are typically used to reject requests that don't comply with the validation criteria defined in the webhook. This is an example of a serverless webhook that calls the ECR describeImageScanFindings API to determine whether a pod is pulling an image with critical vulnerabilities. If vulnerabilities are found, the pod is rejected and a message with list of CVEs is returned as an Event. Create IAM policies for ECR repositories \u00b6 Nowadays, it is not uncommon for an organization to have multiple development teams operating independently within a shared AWS account. If these teams don't need to share assets, you may want to create a set of IAM policies that restrict access to the repositories each team can interact with. A good way to implement this is by using ECR namespaces . Namespaces are a way to group similar repositories together. For example, all of the registries for team A can be prefaced with the team-a/ while those for team B can use the team-b/ prefix. The policy to restrict access might look like the following: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"AllowPushPull\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"ecr:GetDownloadUrlForLayer\" , \"ecr:BatchGetImage\" , \"ecr:BatchCheckLayerAvailability\" , \"ecr:PutImage\" , \"ecr:InitiateLayerUpload\" , \"ecr:UploadLayerPart\" , \"ecr:CompleteLayerUpload\" ], \"Resource\" : [ \"arn:aws:ecr:<region>:<account_id>:repository/team-a/*\" ] } ] } Consider using ECR private endpoints \u00b6 The ECR API has a public endpoint. Consequently, ECR registries can be accessed from the Internet so long as the request has been authenticated and authorized by IAM. For those who need to operate in a sandboxed environment where the cluster VPC lacks an Internet Gateway (IGW), you can configure a private endpoint for ECR. Creating a private endpoint enables you to privately access the ECR API through a private IP address instead of routing traffic across the Internet. For additional information on this topic, see https://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html. Implement endpoint policies for ECR \u00b6 The default endpoint policy for allows access to all ECR repositories within a region. This might allow an attacker/insider to exfiltrate data by packaging it as a container image and pushing it to a registry in another AWS account. Mitigating this risk involves creating an endpoint policy that limits API access to ECR repositories. For example, the following policy allows all AWS principles in your account to perform all actions against your and only your ECR repositories: { \"Statement\" : [ { \"Sid\" : \"LimitECRAccess\" , \"Principal\" : \"*\" , \"Action\" : \"*\" , \"Effect\" : \"Allow\" , \"Resource\" : \"arn:aws:ecr:<region>:<account_id>:repository/*\" } ] } You can enhance this further by setting a condition that uses the new PrincipalOrgID attribute which will prevent pushing/pulling of images by an IAM principle that is not part of your AWS Organization. See, aws:PrincipalOrgID for additional details. We recommended applying the same policy to both the com.amazonaws.<region>.ecr.dkr and the com.amazonaws.<region>.ecr.api endpoints. Since EKS pulls images for kube-proxy, coredns, and aws-node from ECR, you will need to add the account ID of the registry, e.g. 602401143452.dkr.ecr.us-west-2.amazonaws.com/* to the list of resources in the endpoint policy or alter the policy to allow pulls from \"*\" and restrict pushes to your account ID. The table below reveals the mapping between the AWS accounts where EKS images are vended from and cluster region. Account Number Region 602401143452 All commercial regions except for those listed below 800184023465 HKG 558608220178 BAH 918309763551 BJS 961992271922 ZHY For further information about using endpoint policies, see Using VPC endpoint policies to control Amazon ECR access . Implement lifecycle policies for ECR \u00b6 The NIST Application Container Security Guide warns about the risk of \"stale images in registries\", noting that over time old images with vulnerable, out-of-date software packages should be removed to prevent accidental deployment and exposure. Each ECR repository can have a lifecycle policy that sets rules for when images expire. The AWS official documentation describes how to set up test rules, evaluate them and then apply them. There are several lifecycle policy examples in the official docs that show different ways of filtering the images in a repository: Filtering by image age or count Filtering by tagged or untagged images Filtering by image tags, either in multiple rules or a single rule Warning If the image for long running application is purged from ECR, it can cause an image pull errors when the application is redeployed or scaled horizontally. When using image lifecycle policies, be sure you have good CI/CD practices in place to keep deployments and the images that they reference up to date and always create [image] expiry rules that account for how often you do releases/deployments. Create a set of curated images \u00b6 Rather than allowing developers to create their own images, consider creating a set of vetted images for the different application stacks in your organization. By doing so, developers can forego learning how to compose Dockerfiles and concentrate on writing code. As changes are merged into Master, a CI/CD pipeline can automatically compile the asset, store it in an artifact repository and copy the artifact into the appropriate image before pushing it to a Docker registry like ECR. At the very least you should create a set of base images from which developers to create their own Dockerfiles. Ideally, you want to avoid pulling images from Dockerhub because a) you don't always know what is in the image and b) about a fifth of the top 1000 images have vulnerabilities. A list of those images and their vulnerabilities can be found at https://vulnerablecontainers.org/. Add the USER directive to your Dockerfiles to run as a non-root user \u00b6 As was mentioned in the pod security section, you should avoid running container as root. While you can configure this as part of the podSpec, it is a good habit to use the USER directive to your Dockerfiles. The USER directive sets the UID to use when running RUN , ENTRYPOINT , or CMD instruction that appears after the USER directive. Lint your Dockerfiles \u00b6 Linting can be used to verify that your Dockerfiles are adhering to a set of predefined guidelines, e.g. the inclusion of the USER directive or the requirement that all images be tagged. dockerfile_lint is an open source project from RedHat that verifies common best practices and includes a rule engine that you can use to build your own rules for linting Dockerfiles. It can be incorporated into a CI pipeline, in that builds with Dockerfiles that violate a rule will automatically fail. Build images from Scratch \u00b6 Reducing the attack surface of your container images should be primary aim when building images. The ideal way to do this is by creating minimal images that are devoid of binaries that can be used to exploit vulnerabilities. Fortunately, Docker has a mechanism to create images from scratch . With languages like Go, you can create a static linked binary and reference it in your Dockerfile as in this example: ############################ # STEP 1 build executable binary ############################ FROM golang:alpine AS builder # Install git. # Git is required for fetching the dependencies. RUN apk update && apk add --no-cache git WORKDIR $GOPATH/src/mypackage/myapp/ COPY . . # Fetch dependencies. # Using go get. RUN go get -d -v # Build the binary. RUN go build -o /go/bin/hello ############################ # STEP 2 build a small image ############################ FROM scratch # Copy our static executable. COPY --from = builder /go/bin/hello /go/bin/hello # Run the hello binary. ENTRYPOINT [ \"/go/bin/hello\" ] This creates a container image that consists of your application and nothing else, making it extremely secure. Use immutable tags with ECR \u00b6 Immutable tags force you to update the image tag on each push to the image repository. This can thwart an attacker from overwriting an image with a malicious version without changing the image's tags. Additionally, it gives you a way to easily and uniquely identify an image. Sign your images \u00b6 When Docker was first introduced, there was no cryptographic model for verifying container images. With v2, Docker added digests to the image manifest. This allowed an image\u2019s configuration to be hashed and for the hash to be used to generate an ID for the image. When image signing is enabled, the [Docker] engine verifies the manifest\u2019s signature, ensuring that the content was produced from a trusted source and no tampering has occurred. After each layer is downloaded, the engine verifies the digest of the layer, ensuring that the content matches the content specified in the manifest. Image signing effectively allows you to create a secure supply chain, through the verification of digital signatures associated with the image. In a Kubernetes environment, you can use a dynamic admission controller to verify that an image has been signed, as in these examples: https://github.com/IBM/portieris and https://github.com/kelseyhightower/grafeas-tutorial. By signing your images, you're verifying the publisher (source) ensuring that the image hasn't been tampered with (integrity). Note ECR intends to support image signing in the future. The issue is being tracked on the container roadmap. Update the packages in your container images \u00b6 You should include RUN apt-get update && apt-get upgrade in your Dockerfiles to upgrade the packages in your images. Although upgrading requires you to run as root, this occurs during image build phase. The application doesn't need to run as root. You can install the updates and then switch to a different user with the USER directive. If your base image runs as a non-root user, switch to root and back; don't solely rely on the maintainers of the base image to install the latest security updates. Run apt-get clean to delete the installer files from /var/cache/apt/archives/ . You can also run rm -rf /var/lib/apt/lists/* after installing packages. This removes the index files or the lists of packages that are available to install. Be aware that these commands may be different for each package manager. For example: RUN apt-get update && apt-get install -y \\ curl \\ git \\ libsqlite3-dev \\ && apt-get clean && rm -rf /var/lib/apt/lists/* Tools \u00b6 Bane An AppArmor profile generator for Docker containers docker-slim Build secure minimal images dockle Verifies that your Dockerfile aligns with best practices for creating secure images dockerfile-lint Rule based linter for Dockerfiles hadolint A smart dockerfile linter Gatekeeper and OPA A policy based admission controller Kyverno A Kubernetes-native policy engine in-toto Allows the user to verify if a step in the supply chain was intended to be performed, and if the step was performed by the right actor Notary A project for signing container images Notary v2 Grafeas An open artifact metadata API to audit and govern your software supply chain","title":"Image Security"},{"location":"security/docs/image/#image-security","text":"You should consider the container image as your first line of defense against an attack. An insecure, poorly constructed image can allow an attacker to escape the bounds of the container and gain access to the host. Once on the host, an attacker can gain access to sensitive information or move laterally within the cluster or with your AWS account. The following best practices will help mitigate risk of this happening.","title":"Image security"},{"location":"security/docs/image/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/image/#create-minimal-images","text":"Start by removing all extraneous binaries from the container image. If you\u2019re using an unfamiliar image from Dockerhub, inspect the image using an application like Dive which can show you the contents of each of the container\u2019s layers. Remove all binaries with the SETUID and SETGID bits as they can be used to escalate privilege and consider removing all shells and utilities like nc and curl that can be used for nefarious purposes. You can find the files with SETUID and SETGID bits with the following command: find / -perm /6000 -type f -exec ls -ld {} \\; To remove the special permissions from these files, add the following directive to your container image: RUN find / -xdev -perm /6000 -type f -exec chmod a-s {} \\; || true Colloquially, this is known as de-fanging your image.","title":"Create minimal images"},{"location":"security/docs/image/#use-multi-stage-builds","text":"Using multi-stage builds is a way to create minimal images. Oftentimes, multi-stage builds are used to automate parts of the Continuous Integration cycle. For example, multi-stage builds can be used to lint your source code or perform static code analysis. This affords developers an opportunity to get near immediate feedback instead of waiting for a pipeline to execute. Multi-stage builds are attractive from a security standpoint because they allow you to minimize the size of the final image pushed to your container registry. Container images devoid of build tools and other extraneous binaries improves your security posture by reducing the attack surface of the image. For additional information about multi-stage builds, see https://docs.docker.com/develop/develop-images/multistage-build/ .","title":"Use multi-stage builds"},{"location":"security/docs/image/#scan-images-for-vulnerabilities-regularly","text":"Like their virtual machine counterparts, container images can contain binaries and application libraries with vulnerabilities or develop vulnerabilities over time. The best way to safeguard against exploits is by regularly scanning your images with an image scanner. Images that are stored in Amazon ECR can be scanned on push or on-demand (once during a 24 hour period). ECR currently leverages Clair an open source image scanning solution. After an image is scanned, the results are logged to the event stream for ECR in EventBridge. You can also see the results of a scan from within the ECR console. Images with a HIGH or CRITICAL vulnerability should be deleted or rebuilt. If an image that has been deployed develops a vulnerability, it should be replaced as soon as possible. Knowing where images with vulnerabilities have been deployed is essential to keeping your environment secure. While you could conceivably build an image tracking solution yourself, there are already several commercial offerings that provide this and other advanced capabilities out of the box, including: Anchore Palo Alto - Prisma Cloud (twistcli) Aqua Kubei Trivy Snyk A Kubernetes validation webhook could also be used to validate that images are free of critical vulnerabilities. Validation webhooks are invoked prior to the Kubernetes API. They are typically used to reject requests that don't comply with the validation criteria defined in the webhook. This is an example of a serverless webhook that calls the ECR describeImageScanFindings API to determine whether a pod is pulling an image with critical vulnerabilities. If vulnerabilities are found, the pod is rejected and a message with list of CVEs is returned as an Event.","title":"Scan images for vulnerabilities regularly"},{"location":"security/docs/image/#create-iam-policies-for-ecr-repositories","text":"Nowadays, it is not uncommon for an organization to have multiple development teams operating independently within a shared AWS account. If these teams don't need to share assets, you may want to create a set of IAM policies that restrict access to the repositories each team can interact with. A good way to implement this is by using ECR namespaces . Namespaces are a way to group similar repositories together. For example, all of the registries for team A can be prefaced with the team-a/ while those for team B can use the team-b/ prefix. The policy to restrict access might look like the following: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"AllowPushPull\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"ecr:GetDownloadUrlForLayer\" , \"ecr:BatchGetImage\" , \"ecr:BatchCheckLayerAvailability\" , \"ecr:PutImage\" , \"ecr:InitiateLayerUpload\" , \"ecr:UploadLayerPart\" , \"ecr:CompleteLayerUpload\" ], \"Resource\" : [ \"arn:aws:ecr:<region>:<account_id>:repository/team-a/*\" ] } ] }","title":"Create IAM policies for ECR repositories"},{"location":"security/docs/image/#consider-using-ecr-private-endpoints","text":"The ECR API has a public endpoint. Consequently, ECR registries can be accessed from the Internet so long as the request has been authenticated and authorized by IAM. For those who need to operate in a sandboxed environment where the cluster VPC lacks an Internet Gateway (IGW), you can configure a private endpoint for ECR. Creating a private endpoint enables you to privately access the ECR API through a private IP address instead of routing traffic across the Internet. For additional information on this topic, see https://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html.","title":"Consider using ECR private endpoints"},{"location":"security/docs/image/#implement-endpoint-policies-for-ecr","text":"The default endpoint policy for allows access to all ECR repositories within a region. This might allow an attacker/insider to exfiltrate data by packaging it as a container image and pushing it to a registry in another AWS account. Mitigating this risk involves creating an endpoint policy that limits API access to ECR repositories. For example, the following policy allows all AWS principles in your account to perform all actions against your and only your ECR repositories: { \"Statement\" : [ { \"Sid\" : \"LimitECRAccess\" , \"Principal\" : \"*\" , \"Action\" : \"*\" , \"Effect\" : \"Allow\" , \"Resource\" : \"arn:aws:ecr:<region>:<account_id>:repository/*\" } ] } You can enhance this further by setting a condition that uses the new PrincipalOrgID attribute which will prevent pushing/pulling of images by an IAM principle that is not part of your AWS Organization. See, aws:PrincipalOrgID for additional details. We recommended applying the same policy to both the com.amazonaws.<region>.ecr.dkr and the com.amazonaws.<region>.ecr.api endpoints. Since EKS pulls images for kube-proxy, coredns, and aws-node from ECR, you will need to add the account ID of the registry, e.g. 602401143452.dkr.ecr.us-west-2.amazonaws.com/* to the list of resources in the endpoint policy or alter the policy to allow pulls from \"*\" and restrict pushes to your account ID. The table below reveals the mapping between the AWS accounts where EKS images are vended from and cluster region. Account Number Region 602401143452 All commercial regions except for those listed below 800184023465 HKG 558608220178 BAH 918309763551 BJS 961992271922 ZHY For further information about using endpoint policies, see Using VPC endpoint policies to control Amazon ECR access .","title":"Implement endpoint policies for ECR"},{"location":"security/docs/image/#implement-lifecycle-policies-for-ecr","text":"The NIST Application Container Security Guide warns about the risk of \"stale images in registries\", noting that over time old images with vulnerable, out-of-date software packages should be removed to prevent accidental deployment and exposure. Each ECR repository can have a lifecycle policy that sets rules for when images expire. The AWS official documentation describes how to set up test rules, evaluate them and then apply them. There are several lifecycle policy examples in the official docs that show different ways of filtering the images in a repository: Filtering by image age or count Filtering by tagged or untagged images Filtering by image tags, either in multiple rules or a single rule Warning If the image for long running application is purged from ECR, it can cause an image pull errors when the application is redeployed or scaled horizontally. When using image lifecycle policies, be sure you have good CI/CD practices in place to keep deployments and the images that they reference up to date and always create [image] expiry rules that account for how often you do releases/deployments.","title":"Implement lifecycle policies for ECR"},{"location":"security/docs/image/#create-a-set-of-curated-images","text":"Rather than allowing developers to create their own images, consider creating a set of vetted images for the different application stacks in your organization. By doing so, developers can forego learning how to compose Dockerfiles and concentrate on writing code. As changes are merged into Master, a CI/CD pipeline can automatically compile the asset, store it in an artifact repository and copy the artifact into the appropriate image before pushing it to a Docker registry like ECR. At the very least you should create a set of base images from which developers to create their own Dockerfiles. Ideally, you want to avoid pulling images from Dockerhub because a) you don't always know what is in the image and b) about a fifth of the top 1000 images have vulnerabilities. A list of those images and their vulnerabilities can be found at https://vulnerablecontainers.org/.","title":"Create a set of curated images"},{"location":"security/docs/image/#add-the-user-directive-to-your-dockerfiles-to-run-as-a-non-root-user","text":"As was mentioned in the pod security section, you should avoid running container as root. While you can configure this as part of the podSpec, it is a good habit to use the USER directive to your Dockerfiles. The USER directive sets the UID to use when running RUN , ENTRYPOINT , or CMD instruction that appears after the USER directive.","title":"Add the USER directive to your Dockerfiles to run as a non-root user"},{"location":"security/docs/image/#lint-your-dockerfiles","text":"Linting can be used to verify that your Dockerfiles are adhering to a set of predefined guidelines, e.g. the inclusion of the USER directive or the requirement that all images be tagged. dockerfile_lint is an open source project from RedHat that verifies common best practices and includes a rule engine that you can use to build your own rules for linting Dockerfiles. It can be incorporated into a CI pipeline, in that builds with Dockerfiles that violate a rule will automatically fail.","title":"Lint your Dockerfiles"},{"location":"security/docs/image/#build-images-from-scratch","text":"Reducing the attack surface of your container images should be primary aim when building images. The ideal way to do this is by creating minimal images that are devoid of binaries that can be used to exploit vulnerabilities. Fortunately, Docker has a mechanism to create images from scratch . With languages like Go, you can create a static linked binary and reference it in your Dockerfile as in this example: ############################ # STEP 1 build executable binary ############################ FROM golang:alpine AS builder # Install git. # Git is required for fetching the dependencies. RUN apk update && apk add --no-cache git WORKDIR $GOPATH/src/mypackage/myapp/ COPY . . # Fetch dependencies. # Using go get. RUN go get -d -v # Build the binary. RUN go build -o /go/bin/hello ############################ # STEP 2 build a small image ############################ FROM scratch # Copy our static executable. COPY --from = builder /go/bin/hello /go/bin/hello # Run the hello binary. ENTRYPOINT [ \"/go/bin/hello\" ] This creates a container image that consists of your application and nothing else, making it extremely secure.","title":"Build images from Scratch"},{"location":"security/docs/image/#use-immutable-tags-with-ecr","text":"Immutable tags force you to update the image tag on each push to the image repository. This can thwart an attacker from overwriting an image with a malicious version without changing the image's tags. Additionally, it gives you a way to easily and uniquely identify an image.","title":"Use immutable tags with ECR"},{"location":"security/docs/image/#sign-your-images","text":"When Docker was first introduced, there was no cryptographic model for verifying container images. With v2, Docker added digests to the image manifest. This allowed an image\u2019s configuration to be hashed and for the hash to be used to generate an ID for the image. When image signing is enabled, the [Docker] engine verifies the manifest\u2019s signature, ensuring that the content was produced from a trusted source and no tampering has occurred. After each layer is downloaded, the engine verifies the digest of the layer, ensuring that the content matches the content specified in the manifest. Image signing effectively allows you to create a secure supply chain, through the verification of digital signatures associated with the image. In a Kubernetes environment, you can use a dynamic admission controller to verify that an image has been signed, as in these examples: https://github.com/IBM/portieris and https://github.com/kelseyhightower/grafeas-tutorial. By signing your images, you're verifying the publisher (source) ensuring that the image hasn't been tampered with (integrity). Note ECR intends to support image signing in the future. The issue is being tracked on the container roadmap.","title":"Sign your images"},{"location":"security/docs/image/#update-the-packages-in-your-container-images","text":"You should include RUN apt-get update && apt-get upgrade in your Dockerfiles to upgrade the packages in your images. Although upgrading requires you to run as root, this occurs during image build phase. The application doesn't need to run as root. You can install the updates and then switch to a different user with the USER directive. If your base image runs as a non-root user, switch to root and back; don't solely rely on the maintainers of the base image to install the latest security updates. Run apt-get clean to delete the installer files from /var/cache/apt/archives/ . You can also run rm -rf /var/lib/apt/lists/* after installing packages. This removes the index files or the lists of packages that are available to install. Be aware that these commands may be different for each package manager. For example: RUN apt-get update && apt-get install -y \\ curl \\ git \\ libsqlite3-dev \\ && apt-get clean && rm -rf /var/lib/apt/lists/*","title":"Update the packages in your container images"},{"location":"security/docs/image/#tools","text":"Bane An AppArmor profile generator for Docker containers docker-slim Build secure minimal images dockle Verifies that your Dockerfile aligns with best practices for creating secure images dockerfile-lint Rule based linter for Dockerfiles hadolint A smart dockerfile linter Gatekeeper and OPA A policy based admission controller Kyverno A Kubernetes-native policy engine in-toto Allows the user to verify if a step in the supply chain was intended to be performed, and if the step was performed by the right actor Notary A project for signing container images Notary v2 Grafeas An open artifact metadata API to audit and govern your software supply chain","title":"Tools"},{"location":"security/docs/incidents/","text":"Incident response and forensics \u00b6 Your ability to react quickly to an incident can help minimize damage caused from a breach. Having a reliable alerting system that can warn you of suspicious behavior is the first step in a good incident response plan. When an incident does arise, you have to quickly decide whether to destroy and replace the effected container, or isolate and inspect the container. If you choose to isolate the container as part of a forensic investigation and root cause analysis, then the following set of activities should be followed: Sample incident response plan \u00b6 Identify the offending Pod and worker node \u00b6 Your first course of action should be to isolate the damage. Start by identifying where the breach occurred and isolate that Pod and its node from the rest of the infrastructure. Identify the offending Pods and worker nodes using workload name \u00b6 If you know the name and namespace of the offending pod, you can identify the the worker node running the pod as follows: kubectl get pods <name> --namespace <namespace> -o=jsonpath='{.spec.nodeName}{\"\\n\"}' If a Workload Resource (https://kubernetes.io/docs/concepts/workloads/controllers/) such as a Deployment has been compromised, it is likely that all the pods that are part of the workload resource are compromised. Use the following command to list all the pods of the Workload Resource and the nodes they are running on: selector=$(kubectl get deployments <name> \\ --namespace <namespace> -o json | jq -j \\ '.spec.selector.matchLabels | to_entries | .[] | \"\\(.key)=\\(.value)\"') kubectl get pods --namespace <namespace> --selector=$selector \\ -o json | jq -r '.items[] | \"\\(.metadata.name) \\(.spec.nodeName)\"' The above command is for deployments. You can run the same command for other workload resources such as replicasets,, statefulsets, etc. Identify the offending Pods and worker nodes using service account name \u00b6 In some cases, you may identify that a service account is compromised. It is likely that pods using the identified service account are compromised. You can identify all the pods using the service account and nodes they are running on with the following command: kubectl get pods -o json --namespace <namespace> | \\ jq -r '.items[] | select(.spec.serviceAccount == \"<service account name>\") | \"\\(.metadata.name) \\(.spec.nodeName)\"' Identify Pods with vulnerable or compromised images and worker nodes \u00b6 In some cases, you may discover that a container image being used in pods on your cluster is malicious or compromised. A container image is malicious or compromised, if it was found to contain malware, is a known bad image or has a CVE that has been exploited. You should consider all the pods using the container image compromised. You can identify the pods using the image and nodes they are running on with the following command: IMAGE=<Name of the malicious/compromised image> kubectl get pods -o json --all-namespaces | \\ jq -r --arg image \"$IMAGE\" '.items[] | select(.spec.containers[] | .image == $image) | \"\\(.metadata.name) \\(.metadata.namespace) \\(.spec.nodeName)\"' Isolate the Pod by creating a Network Policy that denies all ingress and egress traffic to the pod \u00b6 A deny all traffic rule may help stop an attack that is already underway by severing all connections to the pod. The following Network Policy will apply to a pod with the label app=web . apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : default-deny spec : podSelector : matchLabels : app : web policyTypes : - Ingress - Egress Attention A Network Policy may prove ineffective if an attacker has gained access to underlying host. If you suspect that has happened, you can use AWS Security Groups to isolate a compromised host from other hosts. When changing a host's security group, be aware that it will impact all containers running on that host. Revoke temporary security credentials assigned to the pod or worker node if necessary \u00b6 If the worker node has been assigned an IAM role that allows Pods to gain access to other AWS resources, remove those roles from the instance to prevent further damage from the attack. Similarly, if the Pod has been assigned an IAM role, evaluate whether you can safely remove the IAM policies from the role without impacting other workloads. Cordon the worker node \u00b6 By cordoning the impacted worker node, you're informing the scheduler to avoid scheduling pods onto the affected node. This will allow you to remove the node for forensic study without disrupting other workloads. Info This guidance is not applicable to Fargate where each Fargate pod run in its own sandboxed environment. Instead of cordoning, sequester the affected Fargate pods by applying a network policy that denies all ingress and egress traffic. Enable termination protection on impacted worker node \u00b6 An attacker may attempt to erase their misdeeds by terminating an affected node. Enabling termination protection can prevent this from happening. Instance scale-in protection will protect the node from a scale-in event. Warning You cannot enable termination protection on a Spot instance. Label the offending Pod/Node with a label indicating that it is part of an active investigation \u00b6 This will serve as a warning to cluster administrators not to tamper with the affected Pods/Nodes until the investigation is complete. Capture volatile artifacts on the worker node \u00b6 Capture the operating system memory . This will capture the Docker daemon and its subprocess per container. MargaritaShotgun , a remote memory acquisition tool, can aid in this effort. Perform a netstat tree dump of the processes running and the open ports . This will capture the docker daemon and its subprocess per container. Run docker commands before evidence is altered on the worker node . docker container top CONTAINER for processes running. docker container logs CONTAINER for daemon level held logs. docker container port CONTAINER for list of open ports. docker container diff CONTAINER to capture changes to files and directories to container's filesystem since its initial launch. Pause the container for forensic capture . Snapshot the instance's EBS volumes . Redeploy compromised Pod or Workload Resource \u00b6 Once you have gathered data for forensic analysis, you can redeploy the compromised pod or workload resource. First roll out the fix for the vulnerability that was compromised and start new replacement pods. Then delete the vulnerable pods. If the vulnerable pods are managed by a higher-level Kubernetes workload resource (for example, a Deployment or DaemonSet), deleting them will schedule new ones. So vulnerable pods will be launched again. In that case you should deploy a new replacement workload resource after fixing the vulnerability. Then you should delete the vulnerable workload. Recommendations \u00b6 Review the AWS Security Incident Response Whitepaper \u00b6 While this section gives a brief overview along with a few recommendations for handling suspected security breaches, the topic is exhaustively covered in the white paper, AWS Security Incident Response . Practice security game days \u00b6 Divide your security practitioners into 2 teams: red and blue. The red team will be focused on probing different systems for vulnerabilities while the blue team will be responsible for defending against them. If you don't have enough security practitioners to create separate teams, consider hiring an outside entity that has knowledge of Kubernetes exploits. Kubesploit is a penetration testing framework from CyberArk that you can use to conduct game days. Unlike other tools which scan your cluster for vulnerabilities, kubesploit simulates a real-world attack. This gives your blue team an opportunity to practice its response to an attack and gauge its effectiveness. Run penetration tests against your cluster \u00b6 Periodically attacking your own cluster can help you discover vulnerabilities and misconfigurations. Before getting started, follow the penetration test guidelines before conducting a test against your cluster. Tools \u00b6 kube-hunter , a penetration testing tool for Kubernetes. Gremlin , a chaos engineering toolkit that you can use to simulate attacks against your applications and infrastructure. kube-forensics , a Kubernetes controller that triggers a job that collects the state of a running pod and dumps it in an S3 bucket. Attacking and Defending Kubernetes Installations kubesploit Videos \u00b6 Advanced Persistent Threats Kubernetes Practical Attack and Defense Compromising Kubernetes Cluster by Exploiting RBAC Permissions","title":"Incident Response and Forensics"},{"location":"security/docs/incidents/#incident-response-and-forensics","text":"Your ability to react quickly to an incident can help minimize damage caused from a breach. Having a reliable alerting system that can warn you of suspicious behavior is the first step in a good incident response plan. When an incident does arise, you have to quickly decide whether to destroy and replace the effected container, or isolate and inspect the container. If you choose to isolate the container as part of a forensic investigation and root cause analysis, then the following set of activities should be followed:","title":"Incident response and forensics"},{"location":"security/docs/incidents/#sample-incident-response-plan","text":"","title":"Sample incident response plan"},{"location":"security/docs/incidents/#identify-the-offending-pod-and-worker-node","text":"Your first course of action should be to isolate the damage. Start by identifying where the breach occurred and isolate that Pod and its node from the rest of the infrastructure.","title":"Identify the offending Pod and worker node"},{"location":"security/docs/incidents/#identify-the-offending-pods-and-worker-nodes-using-workload-name","text":"If you know the name and namespace of the offending pod, you can identify the the worker node running the pod as follows: kubectl get pods <name> --namespace <namespace> -o=jsonpath='{.spec.nodeName}{\"\\n\"}' If a Workload Resource (https://kubernetes.io/docs/concepts/workloads/controllers/) such as a Deployment has been compromised, it is likely that all the pods that are part of the workload resource are compromised. Use the following command to list all the pods of the Workload Resource and the nodes they are running on: selector=$(kubectl get deployments <name> \\ --namespace <namespace> -o json | jq -j \\ '.spec.selector.matchLabels | to_entries | .[] | \"\\(.key)=\\(.value)\"') kubectl get pods --namespace <namespace> --selector=$selector \\ -o json | jq -r '.items[] | \"\\(.metadata.name) \\(.spec.nodeName)\"' The above command is for deployments. You can run the same command for other workload resources such as replicasets,, statefulsets, etc.","title":"Identify the offending Pods and worker nodes using workload name"},{"location":"security/docs/incidents/#identify-the-offending-pods-and-worker-nodes-using-service-account-name","text":"In some cases, you may identify that a service account is compromised. It is likely that pods using the identified service account are compromised. You can identify all the pods using the service account and nodes they are running on with the following command: kubectl get pods -o json --namespace <namespace> | \\ jq -r '.items[] | select(.spec.serviceAccount == \"<service account name>\") | \"\\(.metadata.name) \\(.spec.nodeName)\"'","title":"Identify the offending Pods and worker nodes using service account name"},{"location":"security/docs/incidents/#identify-pods-with-vulnerable-or-compromised-images-and-worker-nodes","text":"In some cases, you may discover that a container image being used in pods on your cluster is malicious or compromised. A container image is malicious or compromised, if it was found to contain malware, is a known bad image or has a CVE that has been exploited. You should consider all the pods using the container image compromised. You can identify the pods using the image and nodes they are running on with the following command: IMAGE=<Name of the malicious/compromised image> kubectl get pods -o json --all-namespaces | \\ jq -r --arg image \"$IMAGE\" '.items[] | select(.spec.containers[] | .image == $image) | \"\\(.metadata.name) \\(.metadata.namespace) \\(.spec.nodeName)\"'","title":"Identify Pods with vulnerable or compromised images and worker nodes"},{"location":"security/docs/incidents/#isolate-the-pod-by-creating-a-network-policy-that-denies-all-ingress-and-egress-traffic-to-the-pod","text":"A deny all traffic rule may help stop an attack that is already underway by severing all connections to the pod. The following Network Policy will apply to a pod with the label app=web . apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : default-deny spec : podSelector : matchLabels : app : web policyTypes : - Ingress - Egress Attention A Network Policy may prove ineffective if an attacker has gained access to underlying host. If you suspect that has happened, you can use AWS Security Groups to isolate a compromised host from other hosts. When changing a host's security group, be aware that it will impact all containers running on that host.","title":"Isolate the Pod by creating a Network Policy that denies all ingress and egress traffic to the pod"},{"location":"security/docs/incidents/#revoke-temporary-security-credentials-assigned-to-the-pod-or-worker-node-if-necessary","text":"If the worker node has been assigned an IAM role that allows Pods to gain access to other AWS resources, remove those roles from the instance to prevent further damage from the attack. Similarly, if the Pod has been assigned an IAM role, evaluate whether you can safely remove the IAM policies from the role without impacting other workloads.","title":"Revoke temporary security credentials assigned to the pod or worker node if necessary"},{"location":"security/docs/incidents/#cordon-the-worker-node","text":"By cordoning the impacted worker node, you're informing the scheduler to avoid scheduling pods onto the affected node. This will allow you to remove the node for forensic study without disrupting other workloads. Info This guidance is not applicable to Fargate where each Fargate pod run in its own sandboxed environment. Instead of cordoning, sequester the affected Fargate pods by applying a network policy that denies all ingress and egress traffic.","title":"Cordon the worker node"},{"location":"security/docs/incidents/#enable-termination-protection-on-impacted-worker-node","text":"An attacker may attempt to erase their misdeeds by terminating an affected node. Enabling termination protection can prevent this from happening. Instance scale-in protection will protect the node from a scale-in event. Warning You cannot enable termination protection on a Spot instance.","title":"Enable termination protection on impacted worker node"},{"location":"security/docs/incidents/#label-the-offending-podnode-with-a-label-indicating-that-it-is-part-of-an-active-investigation","text":"This will serve as a warning to cluster administrators not to tamper with the affected Pods/Nodes until the investigation is complete.","title":"Label the offending Pod/Node with a label indicating that it is part of an active investigation"},{"location":"security/docs/incidents/#capture-volatile-artifacts-on-the-worker-node","text":"Capture the operating system memory . This will capture the Docker daemon and its subprocess per container. MargaritaShotgun , a remote memory acquisition tool, can aid in this effort. Perform a netstat tree dump of the processes running and the open ports . This will capture the docker daemon and its subprocess per container. Run docker commands before evidence is altered on the worker node . docker container top CONTAINER for processes running. docker container logs CONTAINER for daemon level held logs. docker container port CONTAINER for list of open ports. docker container diff CONTAINER to capture changes to files and directories to container's filesystem since its initial launch. Pause the container for forensic capture . Snapshot the instance's EBS volumes .","title":"Capture volatile artifacts on the worker node"},{"location":"security/docs/incidents/#redeploy-compromised-pod-or-workload-resource","text":"Once you have gathered data for forensic analysis, you can redeploy the compromised pod or workload resource. First roll out the fix for the vulnerability that was compromised and start new replacement pods. Then delete the vulnerable pods. If the vulnerable pods are managed by a higher-level Kubernetes workload resource (for example, a Deployment or DaemonSet), deleting them will schedule new ones. So vulnerable pods will be launched again. In that case you should deploy a new replacement workload resource after fixing the vulnerability. Then you should delete the vulnerable workload.","title":"Redeploy compromised Pod or Workload Resource"},{"location":"security/docs/incidents/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/incidents/#review-the-aws-security-incident-response-whitepaper","text":"While this section gives a brief overview along with a few recommendations for handling suspected security breaches, the topic is exhaustively covered in the white paper, AWS Security Incident Response .","title":"Review the AWS Security Incident Response Whitepaper"},{"location":"security/docs/incidents/#practice-security-game-days","text":"Divide your security practitioners into 2 teams: red and blue. The red team will be focused on probing different systems for vulnerabilities while the blue team will be responsible for defending against them. If you don't have enough security practitioners to create separate teams, consider hiring an outside entity that has knowledge of Kubernetes exploits. Kubesploit is a penetration testing framework from CyberArk that you can use to conduct game days. Unlike other tools which scan your cluster for vulnerabilities, kubesploit simulates a real-world attack. This gives your blue team an opportunity to practice its response to an attack and gauge its effectiveness.","title":"Practice security game days"},{"location":"security/docs/incidents/#run-penetration-tests-against-your-cluster","text":"Periodically attacking your own cluster can help you discover vulnerabilities and misconfigurations. Before getting started, follow the penetration test guidelines before conducting a test against your cluster.","title":"Run penetration tests against your cluster"},{"location":"security/docs/incidents/#tools","text":"kube-hunter , a penetration testing tool for Kubernetes. Gremlin , a chaos engineering toolkit that you can use to simulate attacks against your applications and infrastructure. kube-forensics , a Kubernetes controller that triggers a job that collects the state of a running pod and dumps it in an S3 bucket. Attacking and Defending Kubernetes Installations kubesploit","title":"Tools"},{"location":"security/docs/incidents/#videos","text":"Advanced Persistent Threats Kubernetes Practical Attack and Defense Compromising Kubernetes Cluster by Exploiting RBAC Permissions","title":"Videos"},{"location":"security/docs/multitenancy/","text":"Tenant Isolation \u00b6 When we think of multi-tenancy, we often want to isolate a user or application from other users or applications running on a shared infrastructure. Kubernetes is a single tenant orchestrator , i.e. a single instance of the control plane is shared among all the tenants within a cluster. There are, however, various Kubernetes objects that you can use to create the semblance of multi-tenancy. For example, Namespaces and Role-based access controls (RBAC) can be implemented to logically isolate tenants from each other. Similarly, Quotas and Limit Ranges can be used to control the amount of cluster resources each tenant can consume. Nevertheless, the cluster is the only construct that provides a strong security boundary. This is because an attacker that manages to gain access to a host within the cluster can retrieve all Secrets, ConfigMaps, and Volumes, mounted on that host. They could also impersonate the Kubelet which would allow them to manipulate the attributes of the node and/or move laterally within the cluster. The following sections will explain how to implement tenant isolation while mitigating the risks of using a single tenant orchestrator like Kubernetes. Soft multi-tenancy \u00b6 With soft multi-tenancy, you use native Kubernetes constructs, e.g. namespaces, roles and role bindings, and network policies, to create logical separation between tenants. RBAC, for example, can prevent tenants from accessing or manipulate each other's resources. Quotas and limit ranges control the amount of cluster resources each tenant can consume while network policies can help prevent applications deployed into different namespaces from communicating with each other. None of these controls, however, prevent pods from different tenants from sharing a node. If stronger isolation is required, you can use a node selector, anti-affinity rules, and/or taints and tolerations to force pods from different tenants to be scheduled onto separate nodes; often referred to as sole tenant nodes . This could get rather complicated, and cost prohibitive, in an environment with many tenants. Attention Soft multi-tenancy implemented with Namespaces does not allow you to provide tenants with a filtered list of Namespaces because Namespaces are a globally scoped Type. If a tenant has the ability to view a particular Namespace, it can view all Namespaces within the cluster. Warning With soft-multi-tenancy, tenants retain the ability to query CoreDNS for all services that run within the cluster by default. An attacker could exploit this by running dig SRV . .svc.cluster.local from any pod in the cluster. If you need to restrict access to DNS records of services that run within your clusters, consider using the Firewall or Policy plugins for CoreDNS. For additional information, see https://github.com/coredns/policy#kubernetes-metadata-multi-tenancy-policy . Kiosk is an open source project that can aid in the implementation of soft multi-tenancy. It is implemented as a series of CRDs and controllers that provide the following capabilities: Accounts & Account Users to separate tenants in a shared Kubernetes cluster Self-Service Namespace Provisioning for account users Account Limits to ensure quality of service and fairness when sharing a cluster Namespace Templates for secure tenant isolation and self-service namespace initialization Loft is a commercial offering from the maintainers of Kiosk and DevSpace that adds the following capabilities: Multi-cluster access for granting access to spaces in different clusters Sleep mode scales down deployments in a space during periods of inactivity Single sign-on with OIDC authentication providers like GitHub There are three primary use cases that can be addressed by soft multi-tenancy. Enterprise Setting \u00b6 The first is in an Enterprise setting where the \"tenants\" are semi-trusted in that they are employees, contractors, or are otherwise authorized by the organization. Each tenant will typically align to an administrative division such as a department or team. In this type of setting, a cluster administrator will usually be responsible for creating namespaces and managing policies. They may also implement a delegated administration model where certain individuals are given oversight of a namespace, allowing them to perform CRUD operations for non-policy related objects like deployments, services, pods, jobs, etc. The isolation provided by a container runtime may be acceptable within this setting or it may need to be augmented with additional controls for pod security. It may also be necessary to restrict communication between services in different namespaces if stricter isolation is required. Kubernetes as a Service \u00b6 By contrast, soft multi-tenancy can be used in settings where you want to offer Kubernetes as a service (KaaS). With KaaS, your application is hosted in a shared cluster along with a collection of controllers and CRDs that provide a set of PaaS services. Tenants interact directly with the Kubernetes API server and are permitted to perform CRUD operations on non-policy objects. There is also an element of self-service in that tenants may be allowed to create and manage their own namespaces. In this type of environment, tenants are assumed to be running untrusted code. To isolate tenants in this type of environment, you will likely need to implement strict network policies as well as pod sandboxing . Sandboxing is where you run the containers of a pod inside a micro VM like Firecracker or in a user-space kernel. Today, you can create sandboxed pods with EKS Fargate. Software as a Service (SaaS) \u00b6 The final use case for soft multi-tenancy is in a Software-as-a-Service (SaaS) setting. In this environment, each tenant is associated with a particular instance of an application that's running within the cluster. Each instance often has its own data and uses separate access controls that are usually independent of Kubernetes RBAC. Unlike the other use cases, the tenant in a SaaS setting does not directly interface with the Kubernetes API. Instead, the SaaS application is responsible for interfacing with the Kubernetes API to create the necessary objects to support each tenant. Kubernetes Constructs \u00b6 In each of these instances the following constructs are used to isolate tenants from each other: Namespaces \u00b6 Namespaces are fundamental to implementing soft multi-tenancy. They allow you to divide the cluster into logical partitions. Quotas, network policies, service accounts, and other objects needed to implement multi-tenancy are scoped to a namespace. Network policies \u00b6 By default, all pods in a Kubernetes cluster are allowed to communicate with each other. This behavior can be altered using network policies. Network policies restrict communication between pods using labels or IP address ranges. In a multi-tenant environment where strict network isolation between tenants is required, we recommend starting with a default rule that denies communication between pods, and another rule that allows all pods to query the DNS server for name resolution. With that in place, you can begin adding more permissive rules that allow for communication within a namespace. This can be further refined as required. Attention Network policies are necessary but not sufficient. The enforcement of network policies requires a policy engine such as Calico or Cilium. Role-based access control (RBAC) \u00b6 Roles and role bindings are the Kubernetes objects used to enforce role-based access control (RBAC) in Kubernetes. Roles contain lists of actions that can be performed against objects in your cluster. Role bindings specify the individuals or groups to whom the roles apply. In the enterprise and KaaS settings, RBAC can be used to permit administration of objects by selected groups or individuals. Quotas \u00b6 Quotas are used to define limits on workloads hosted in your cluster. With quotas, you can specify the maximum amount of CPU and memory that a pod can consume, or you can limit the number of resources that can be allocated in a cluster or namespace. Limit ranges allow you to declare minimum, maximum, and default values for each limit. Overcommitting resources in a shared cluster is often beneficial because it allows you maximize your resources. However, unbounded access to a cluster can cause resource starvation, which can lead to performance degradation and loss of application availability. If a pod's requests are set too low and the actual resource utilization exceeds the capacity of the node, the node will begin to experience CPU or memory pressure. When this happens, pods may be restarted and/or evicted from the node. To prevent this from happening, you should plan to impose quotas on namespaces in a multi-tenant environment to force tenants to specify requests and limits when scheduling their pods on the cluster. It will also mitigate a potential denial of service by constraining the amount of resources a pod can consume. You can also use quotas to apportion the cluster's resources to align with a tenant's spend. This is particularly useful in the KaaS scenario. Pod priority and preemption \u00b6 Pod priority and preemption can be useful when you want to provide different qualities of services (QoS) for different customers. For example, with pod priority you can configure pods from customer A to run at a higher priority than customer B. When there's insufficient capacity available, the Kubelet will evict the lower-priority pods from customer B to accommodate the higher-priority pods from customer A. This can be especially handy in a SaaS environment where customers willing to pay a premium receive a higher quality of service. Mitigating controls \u00b6 Your chief concern as an administrator of a multi-tenant environment is preventing an attacker from gaining access to the underlying host. The following controls should be considered to mitigate this risk: Sandboxed execution environments for containers \u00b6 Sandboxing is a technique by which each container is run in its own isolated virtual machine. Technologies that perform pod sandboxing include Firecracker and Weave's Firekube . If you are building your own self-managed Kubernetes cluster on AWS, you may be able to configure alternate container runtimes such as Kata Containers . For additional information about the effort to make Firecracker a supported runtime for EKS, see https://threadreaderapp.com/thread/1238496944684597248.html . Open Policy Agent (OPA) & Gatekeeper \u00b6 Gatekeeper is a Kubernetes admission controller that enforces policies created with OPA . With OPA you can create a policy that runs pods from tenants on separate instances or at a higher priority than other tenants. A collection of common OPA policies can be found in the GitHub repository for this project. There is also an experimental OPA plugin for CoreDNS that allows you to use OPA to filter/control the records returned by CoreDNS. Kyverno \u00b6 Kyverno is a Kubernetes native policy engine that can validate, mutate, and generate configurations with policies as Kubernetes resources. Kyverno uses Kustomize-style overlays for validation, supports JSON Patch and strategic merge patch for mutation, and can clone resources across namespaces based on flexible triggers. You can use Kyverno to isolate namespaces, enforce pod security and other best practices, and generate default configurations such as network policies. Several examples are included in the GitHub repository for this project. Many others are included in the policy library on the Kyverno website. Isolating tenant workloads to specific nodes \u00b6 Restricting tenant workloads to run on specific nodes can be used to increase isolation in the soft multi-tenancy model. With this approach, tenant-specific workloads are only run on nodes provisioned for the respective tenants. To achieve this isolation, native Kubernetes properties (node affinity, and taints and tolerations) are used to target specific nodes for pod scheduling, and prevent pods, from other tenants, from being scheduled on the tenant-specific nodes. Part 1 - Node affinity \u00b6 Kubernetes node affinity is used to target nodes for scheduling, based on node labels . With node affinity rules, the pods are attracted to specific nodes that match the selector terms. In the below pod specification, the requiredDuringSchedulingIgnoredDuringExecution node affinity is applied to the respective pod. The result is that the pod will target nodes that are labeled with the following key/value: tenant: tenants-x . ... spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : tenant operator : In values : - tenants-x ... With this node affinity, the label is required during scheduling, but not during execution; if the underlying nodes' labels change, the pods will not be evicted due solely to that label change. However, future scheduling could be impacted. Info Instead of node affinity, we could have used the node selector . However, node affinity is more expressive and allows for more conditions to be considered during pod scheduling. For additional information about the differences and more advanced scheduling choices, please see this CNCF blog post on Advanced Kubernetes pod to node scheduling . Part 2 - Taints and tolerations \u00b6 Attracting pods to nodes is just the first part of this three-part approach. For this approach to work, we must repel pods from scheduling onto nodes for which the pods are not authorized. To repel unwanted or unauthorized pods, Kubernetes uses node taints . Taints are used to place conditions on nodes that prevent pods from being scheduled. The below taint uses a key-value pair of tenant: tenants-x . ... taints : - key : tenant value : tenants-x effect : NoSchedule ... Given the above node taint , only pods that tolerate the taint will be allowed to be scheduled on the node. To allow authorized pods to be scheduled onto the node, the respective pod specifications must include a toleration to the taint, as seen below. ... tolerations : - effect : NoSchedule key : tenant operator : Equal value : tenants-x ... Pods with the above toleration will not be stopped from scheduling on the node, at least not because of that specific taint. Taints are also used by Kubernetes to temporarily stop pod scheduling during certain conditions, like node resource pressure. With node affinity, and taints and tolerations, we can effectively attract the desired pods to specific nodes and repel unwanted pods. Attention Certain Kubernetes pods are required to run on all nodes. Examples of these pods are those started by the Container Network Interface (CNI) and kube-proxy daemonsets . To that end, the specifications for these pods contain very permissive tolerations, to tolerate different taints. Care should be taken to not change these tolerations. Changing these tolerations could result in incorrect cluster operation. Additionally, policy-management tools, such as OPA/Gatekeeper and Kyverno can be used to write validating policies that prevent unauthorized pods from using these permissive tolerations. Part 3 - Policy-based management for node selection \u00b6 There are several tools that can be used to help manage the node affinity and tolerations of pod specifications, including enforcement of rules in CICD pipelines. However, enforcement of isolation should also be done at the Kubernetes cluster level. For this purpose, policy-management tools can be used to mutate inbound Kubernetes API server requests, based on request payloads, to apply the respective node affinity rules and tolerations mentioned above. For example, pods destined for the tenants-x namespace can be stamped with the correct node affinity and toleration to permit scheduling on the tenants-x nodes. Utilizing policy-management tools configured using the Kubernetes Mutating Admission Webhook , policies can be used to mutate the inbound pod specifications. The mutations add the needed elements to allow desired scheduling. An example OPA/Gatekeeper policy that adds a node affinity is seen below. apiVersion : mutations.gatekeeper.sh/v1alpha1 kind : Assign metadata : name : mutator-add-nodeaffinity-pod annotations : aws-eks-best-practices/description : >- Adds Node affinity - https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity spec : applyTo : - groups : [ \"\" ] kinds : [ \"Pod\" ] versions : [ \"v1\" ] match : namespaces : [ \"tenants-x\" ] location : \"spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms\" parameters : assign : value : - matchExpressions : - key : \"tenant\" operator : In values : - \"tenants-x\" The above policy is applied to a Kubernetes API server request, to apply a pod to the tenants-x namespace. The policy adds the requiredDuringSchedulingIgnoredDuringExecution node affinity rule, so that pods are attracted to nodes with the tenant: tenants-x label. A second policy, seen below, adds the toleration to the same pod specification, using the same matching criteria of target namespace and groups, kinds, and versions. apiVersion : mutations.gatekeeper.sh/v1alpha1 kind : Assign metadata : name : mutator-add-toleration-pod annotations : aws-eks-best-practices/description : >- Adds toleration - https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/ spec : applyTo : - groups : [ \"\" ] kinds : [ \"Pod\" ] versions : [ \"v1\" ] match : namespaces : [ \"tenants-x\" ] location : \"spec.tolerations\" parameters : assign : value : - key : \"tenant\" operator : \"Equal\" value : \"tenants-x\" effect : \"NoSchedule\" The above policies are specific to pods; this is due to the paths to the mutated elements in the policies' location elements. Additional policies could be written to handle resources that create pods, like Deployment and Job resources. The listed policies and other examples can been seen in the companion GitHub project for this guide. The result of these two mutations is that pods are attracted to the desired node, while at the same time, not repelled by the specific node taint. To verify this, we can see the snippets of output from two kubectl calls to get the nodes labeled with tenant=tenants-x , and get the pods in the tenants-x namespace. kubectl get nodes -l tenant = tenants-x NAME ip-10-0-11-255... ip-10-0-28-81... ip-10-0-43-107... kubectl -n tenants-x get pods -owide NAME READY STATUS RESTARTS AGE IP NODE tenant-test-deploy-58b895ff87-2q7xw 1 /1 Running 0 13s 10 .0.42.143 ip-10-0-43-107... tenant-test-deploy-58b895ff87-9b6hg 1 /1 Running 0 13s 10 .0.18.145 ip-10-0-28-81... tenant-test-deploy-58b895ff87-nxvw5 1 /1 Running 0 13s 10 .0.30.117 ip-10-0-28-81... tenant-test-deploy-58b895ff87-vw796 1 /1 Running 0 13s 10 .0.3.113 ip-10-0-11-255... tenant-test-pod 1 /1 Running 0 13s 10 .0.35.83 ip-10-0-43-107... As we can see from the above outputs, all the pods are scheduled on the nodes labeled with tenant=tenants-x . Simply put, the pods will only run on the desired nodes, and the other pods (without the required affinity and tolerations) will not. The tenant workloads are effectively isolated. An example mutated pod specification is seen below. apiVersion : v1 kind : Pod metadata : name : tenant-test-pod namespace : tenants-x spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : tenant operator : In values : - tenants-x ... tolerations : - effect : NoSchedule key : tenant operator : Equal value : tenants-x ... Attention Policy-management tools that are integrated to the Kubernetes API server request flow, using mutating and validating admission webhooks, are designed to respond to the API server's request within a specified timeframe. This is usually 3 seconds or less. If the webhook call fails to return a response within the configured time, the mutation and/or validation of the inbound API sever request may or may not occur. This behavior is based on whether the admission webhook configurations are set to Fail Open or Fail Close . In the above examples, we used policies written for OPA/Gatekeeper. However, there are other policy management tools that handle our node-selection use case as well. For example, this Kyverno policy could be used to handle the node affinity mutation. Tip If operating correctly, mutating policies will effect the desired changes to inbound API server request payloads. However, validating policies should also be included to verify that the desired changes occur, before changes are allowed to persist. This is especially important when using these policies for tenant-to-node isolation. It is also a good idea to include Audit policies to routinely check your cluster for unwanted configurations. References \u00b6 k-rail Designed to help you secure a multi-tenant environment through the enforcement of certain policies. Security Practices for MultiTenant SaaS Applications using Amazon EKS Hard multi-tenancy \u00b6 Hard multi-tenancy can be implemented by provisioning separate clusters for each tenant. While this provides very strong isolation between tenants, it has several drawbacks. First, when you have many tenants, this approach can quickly become expensive. Not only will you have to pay for the control plane costs for each cluster, you will not be able to share compute resources between clusters. This will eventually cause fragmentation where a subset of your clusters are underutilized while others are overutilized. Second, you will likely need to buy or build special tooling to manage all of these clusters. In time, managing hundreds or thousands of clusters may simply become too unwieldy. Finally, creating a cluster per tenant will be slow relative to a creating a namespace. Nevertheless, a hard-tenancy approach may be necessary in highly-regulated industries or in SaaS environments where strong isolation is required. Future directions \u00b6 The Kubernetes community has recognized the current shortcomings of soft multi-tenancy and the challenges with hard multi-tenancy. The Multi-Tenancy Special Interest Group (SIG) is attempting to address these shortcomings through several incubation projects, including Hierarchical Namespace Controller (HNC) and Virtual Cluster. The HNC proposal (KEP) describes a way to create parent-child relationships between namespaces with [policy] object inheritance along with an ability for tenant administrators to create sub-namespaces. The Virtual Cluster proposal describes a mechanism for creating separate instances of the control plane services, including the API server, the controller manager, and scheduler, for each tenant within the cluster (also known as \"Kubernetes on Kubernetes\"). The Multi-Tenancy Benchmarks proposal provides guidelines for sharing clusters using namespaces for isolation and segmentation, and a command line tool kubectl-mtb to validate conformance to the guidelines. Multi-cluster management resources \u00b6 Banzai Cloud Kommander Lens Nirmata Rafay Rancher Weave Flux","title":"Multi-tenancy"},{"location":"security/docs/multitenancy/#tenant-isolation","text":"When we think of multi-tenancy, we often want to isolate a user or application from other users or applications running on a shared infrastructure. Kubernetes is a single tenant orchestrator , i.e. a single instance of the control plane is shared among all the tenants within a cluster. There are, however, various Kubernetes objects that you can use to create the semblance of multi-tenancy. For example, Namespaces and Role-based access controls (RBAC) can be implemented to logically isolate tenants from each other. Similarly, Quotas and Limit Ranges can be used to control the amount of cluster resources each tenant can consume. Nevertheless, the cluster is the only construct that provides a strong security boundary. This is because an attacker that manages to gain access to a host within the cluster can retrieve all Secrets, ConfigMaps, and Volumes, mounted on that host. They could also impersonate the Kubelet which would allow them to manipulate the attributes of the node and/or move laterally within the cluster. The following sections will explain how to implement tenant isolation while mitigating the risks of using a single tenant orchestrator like Kubernetes.","title":"Tenant Isolation"},{"location":"security/docs/multitenancy/#soft-multi-tenancy","text":"With soft multi-tenancy, you use native Kubernetes constructs, e.g. namespaces, roles and role bindings, and network policies, to create logical separation between tenants. RBAC, for example, can prevent tenants from accessing or manipulate each other's resources. Quotas and limit ranges control the amount of cluster resources each tenant can consume while network policies can help prevent applications deployed into different namespaces from communicating with each other. None of these controls, however, prevent pods from different tenants from sharing a node. If stronger isolation is required, you can use a node selector, anti-affinity rules, and/or taints and tolerations to force pods from different tenants to be scheduled onto separate nodes; often referred to as sole tenant nodes . This could get rather complicated, and cost prohibitive, in an environment with many tenants. Attention Soft multi-tenancy implemented with Namespaces does not allow you to provide tenants with a filtered list of Namespaces because Namespaces are a globally scoped Type. If a tenant has the ability to view a particular Namespace, it can view all Namespaces within the cluster. Warning With soft-multi-tenancy, tenants retain the ability to query CoreDNS for all services that run within the cluster by default. An attacker could exploit this by running dig SRV . .svc.cluster.local from any pod in the cluster. If you need to restrict access to DNS records of services that run within your clusters, consider using the Firewall or Policy plugins for CoreDNS. For additional information, see https://github.com/coredns/policy#kubernetes-metadata-multi-tenancy-policy . Kiosk is an open source project that can aid in the implementation of soft multi-tenancy. It is implemented as a series of CRDs and controllers that provide the following capabilities: Accounts & Account Users to separate tenants in a shared Kubernetes cluster Self-Service Namespace Provisioning for account users Account Limits to ensure quality of service and fairness when sharing a cluster Namespace Templates for secure tenant isolation and self-service namespace initialization Loft is a commercial offering from the maintainers of Kiosk and DevSpace that adds the following capabilities: Multi-cluster access for granting access to spaces in different clusters Sleep mode scales down deployments in a space during periods of inactivity Single sign-on with OIDC authentication providers like GitHub There are three primary use cases that can be addressed by soft multi-tenancy.","title":"Soft multi-tenancy"},{"location":"security/docs/multitenancy/#enterprise-setting","text":"The first is in an Enterprise setting where the \"tenants\" are semi-trusted in that they are employees, contractors, or are otherwise authorized by the organization. Each tenant will typically align to an administrative division such as a department or team. In this type of setting, a cluster administrator will usually be responsible for creating namespaces and managing policies. They may also implement a delegated administration model where certain individuals are given oversight of a namespace, allowing them to perform CRUD operations for non-policy related objects like deployments, services, pods, jobs, etc. The isolation provided by a container runtime may be acceptable within this setting or it may need to be augmented with additional controls for pod security. It may also be necessary to restrict communication between services in different namespaces if stricter isolation is required.","title":"Enterprise Setting"},{"location":"security/docs/multitenancy/#kubernetes-as-a-service","text":"By contrast, soft multi-tenancy can be used in settings where you want to offer Kubernetes as a service (KaaS). With KaaS, your application is hosted in a shared cluster along with a collection of controllers and CRDs that provide a set of PaaS services. Tenants interact directly with the Kubernetes API server and are permitted to perform CRUD operations on non-policy objects. There is also an element of self-service in that tenants may be allowed to create and manage their own namespaces. In this type of environment, tenants are assumed to be running untrusted code. To isolate tenants in this type of environment, you will likely need to implement strict network policies as well as pod sandboxing . Sandboxing is where you run the containers of a pod inside a micro VM like Firecracker or in a user-space kernel. Today, you can create sandboxed pods with EKS Fargate.","title":"Kubernetes as a Service"},{"location":"security/docs/multitenancy/#software-as-a-service-saas","text":"The final use case for soft multi-tenancy is in a Software-as-a-Service (SaaS) setting. In this environment, each tenant is associated with a particular instance of an application that's running within the cluster. Each instance often has its own data and uses separate access controls that are usually independent of Kubernetes RBAC. Unlike the other use cases, the tenant in a SaaS setting does not directly interface with the Kubernetes API. Instead, the SaaS application is responsible for interfacing with the Kubernetes API to create the necessary objects to support each tenant.","title":"Software as a Service (SaaS)"},{"location":"security/docs/multitenancy/#kubernetes-constructs","text":"In each of these instances the following constructs are used to isolate tenants from each other:","title":"Kubernetes Constructs"},{"location":"security/docs/multitenancy/#namespaces","text":"Namespaces are fundamental to implementing soft multi-tenancy. They allow you to divide the cluster into logical partitions. Quotas, network policies, service accounts, and other objects needed to implement multi-tenancy are scoped to a namespace.","title":"Namespaces"},{"location":"security/docs/multitenancy/#network-policies","text":"By default, all pods in a Kubernetes cluster are allowed to communicate with each other. This behavior can be altered using network policies. Network policies restrict communication between pods using labels or IP address ranges. In a multi-tenant environment where strict network isolation between tenants is required, we recommend starting with a default rule that denies communication between pods, and another rule that allows all pods to query the DNS server for name resolution. With that in place, you can begin adding more permissive rules that allow for communication within a namespace. This can be further refined as required. Attention Network policies are necessary but not sufficient. The enforcement of network policies requires a policy engine such as Calico or Cilium.","title":"Network policies"},{"location":"security/docs/multitenancy/#role-based-access-control-rbac","text":"Roles and role bindings are the Kubernetes objects used to enforce role-based access control (RBAC) in Kubernetes. Roles contain lists of actions that can be performed against objects in your cluster. Role bindings specify the individuals or groups to whom the roles apply. In the enterprise and KaaS settings, RBAC can be used to permit administration of objects by selected groups or individuals.","title":"Role-based access control (RBAC)"},{"location":"security/docs/multitenancy/#quotas","text":"Quotas are used to define limits on workloads hosted in your cluster. With quotas, you can specify the maximum amount of CPU and memory that a pod can consume, or you can limit the number of resources that can be allocated in a cluster or namespace. Limit ranges allow you to declare minimum, maximum, and default values for each limit. Overcommitting resources in a shared cluster is often beneficial because it allows you maximize your resources. However, unbounded access to a cluster can cause resource starvation, which can lead to performance degradation and loss of application availability. If a pod's requests are set too low and the actual resource utilization exceeds the capacity of the node, the node will begin to experience CPU or memory pressure. When this happens, pods may be restarted and/or evicted from the node. To prevent this from happening, you should plan to impose quotas on namespaces in a multi-tenant environment to force tenants to specify requests and limits when scheduling their pods on the cluster. It will also mitigate a potential denial of service by constraining the amount of resources a pod can consume. You can also use quotas to apportion the cluster's resources to align with a tenant's spend. This is particularly useful in the KaaS scenario.","title":"Quotas"},{"location":"security/docs/multitenancy/#pod-priority-and-preemption","text":"Pod priority and preemption can be useful when you want to provide different qualities of services (QoS) for different customers. For example, with pod priority you can configure pods from customer A to run at a higher priority than customer B. When there's insufficient capacity available, the Kubelet will evict the lower-priority pods from customer B to accommodate the higher-priority pods from customer A. This can be especially handy in a SaaS environment where customers willing to pay a premium receive a higher quality of service.","title":"Pod priority and preemption"},{"location":"security/docs/multitenancy/#mitigating-controls","text":"Your chief concern as an administrator of a multi-tenant environment is preventing an attacker from gaining access to the underlying host. The following controls should be considered to mitigate this risk:","title":"Mitigating controls"},{"location":"security/docs/multitenancy/#sandboxed-execution-environments-for-containers","text":"Sandboxing is a technique by which each container is run in its own isolated virtual machine. Technologies that perform pod sandboxing include Firecracker and Weave's Firekube . If you are building your own self-managed Kubernetes cluster on AWS, you may be able to configure alternate container runtimes such as Kata Containers . For additional information about the effort to make Firecracker a supported runtime for EKS, see https://threadreaderapp.com/thread/1238496944684597248.html .","title":"Sandboxed execution environments for containers"},{"location":"security/docs/multitenancy/#open-policy-agent-opa-gatekeeper","text":"Gatekeeper is a Kubernetes admission controller that enforces policies created with OPA . With OPA you can create a policy that runs pods from tenants on separate instances or at a higher priority than other tenants. A collection of common OPA policies can be found in the GitHub repository for this project. There is also an experimental OPA plugin for CoreDNS that allows you to use OPA to filter/control the records returned by CoreDNS.","title":"Open Policy Agent (OPA) &amp; Gatekeeper"},{"location":"security/docs/multitenancy/#kyverno","text":"Kyverno is a Kubernetes native policy engine that can validate, mutate, and generate configurations with policies as Kubernetes resources. Kyverno uses Kustomize-style overlays for validation, supports JSON Patch and strategic merge patch for mutation, and can clone resources across namespaces based on flexible triggers. You can use Kyverno to isolate namespaces, enforce pod security and other best practices, and generate default configurations such as network policies. Several examples are included in the GitHub repository for this project. Many others are included in the policy library on the Kyverno website.","title":"Kyverno"},{"location":"security/docs/multitenancy/#isolating-tenant-workloads-to-specific-nodes","text":"Restricting tenant workloads to run on specific nodes can be used to increase isolation in the soft multi-tenancy model. With this approach, tenant-specific workloads are only run on nodes provisioned for the respective tenants. To achieve this isolation, native Kubernetes properties (node affinity, and taints and tolerations) are used to target specific nodes for pod scheduling, and prevent pods, from other tenants, from being scheduled on the tenant-specific nodes.","title":"Isolating tenant workloads to specific nodes"},{"location":"security/docs/multitenancy/#part-1-node-affinity","text":"Kubernetes node affinity is used to target nodes for scheduling, based on node labels . With node affinity rules, the pods are attracted to specific nodes that match the selector terms. In the below pod specification, the requiredDuringSchedulingIgnoredDuringExecution node affinity is applied to the respective pod. The result is that the pod will target nodes that are labeled with the following key/value: tenant: tenants-x . ... spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : tenant operator : In values : - tenants-x ... With this node affinity, the label is required during scheduling, but not during execution; if the underlying nodes' labels change, the pods will not be evicted due solely to that label change. However, future scheduling could be impacted. Info Instead of node affinity, we could have used the node selector . However, node affinity is more expressive and allows for more conditions to be considered during pod scheduling. For additional information about the differences and more advanced scheduling choices, please see this CNCF blog post on Advanced Kubernetes pod to node scheduling .","title":"Part 1 - Node affinity"},{"location":"security/docs/multitenancy/#part-2-taints-and-tolerations","text":"Attracting pods to nodes is just the first part of this three-part approach. For this approach to work, we must repel pods from scheduling onto nodes for which the pods are not authorized. To repel unwanted or unauthorized pods, Kubernetes uses node taints . Taints are used to place conditions on nodes that prevent pods from being scheduled. The below taint uses a key-value pair of tenant: tenants-x . ... taints : - key : tenant value : tenants-x effect : NoSchedule ... Given the above node taint , only pods that tolerate the taint will be allowed to be scheduled on the node. To allow authorized pods to be scheduled onto the node, the respective pod specifications must include a toleration to the taint, as seen below. ... tolerations : - effect : NoSchedule key : tenant operator : Equal value : tenants-x ... Pods with the above toleration will not be stopped from scheduling on the node, at least not because of that specific taint. Taints are also used by Kubernetes to temporarily stop pod scheduling during certain conditions, like node resource pressure. With node affinity, and taints and tolerations, we can effectively attract the desired pods to specific nodes and repel unwanted pods. Attention Certain Kubernetes pods are required to run on all nodes. Examples of these pods are those started by the Container Network Interface (CNI) and kube-proxy daemonsets . To that end, the specifications for these pods contain very permissive tolerations, to tolerate different taints. Care should be taken to not change these tolerations. Changing these tolerations could result in incorrect cluster operation. Additionally, policy-management tools, such as OPA/Gatekeeper and Kyverno can be used to write validating policies that prevent unauthorized pods from using these permissive tolerations.","title":"Part 2 - Taints and tolerations"},{"location":"security/docs/multitenancy/#part-3-policy-based-management-for-node-selection","text":"There are several tools that can be used to help manage the node affinity and tolerations of pod specifications, including enforcement of rules in CICD pipelines. However, enforcement of isolation should also be done at the Kubernetes cluster level. For this purpose, policy-management tools can be used to mutate inbound Kubernetes API server requests, based on request payloads, to apply the respective node affinity rules and tolerations mentioned above. For example, pods destined for the tenants-x namespace can be stamped with the correct node affinity and toleration to permit scheduling on the tenants-x nodes. Utilizing policy-management tools configured using the Kubernetes Mutating Admission Webhook , policies can be used to mutate the inbound pod specifications. The mutations add the needed elements to allow desired scheduling. An example OPA/Gatekeeper policy that adds a node affinity is seen below. apiVersion : mutations.gatekeeper.sh/v1alpha1 kind : Assign metadata : name : mutator-add-nodeaffinity-pod annotations : aws-eks-best-practices/description : >- Adds Node affinity - https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity spec : applyTo : - groups : [ \"\" ] kinds : [ \"Pod\" ] versions : [ \"v1\" ] match : namespaces : [ \"tenants-x\" ] location : \"spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms\" parameters : assign : value : - matchExpressions : - key : \"tenant\" operator : In values : - \"tenants-x\" The above policy is applied to a Kubernetes API server request, to apply a pod to the tenants-x namespace. The policy adds the requiredDuringSchedulingIgnoredDuringExecution node affinity rule, so that pods are attracted to nodes with the tenant: tenants-x label. A second policy, seen below, adds the toleration to the same pod specification, using the same matching criteria of target namespace and groups, kinds, and versions. apiVersion : mutations.gatekeeper.sh/v1alpha1 kind : Assign metadata : name : mutator-add-toleration-pod annotations : aws-eks-best-practices/description : >- Adds toleration - https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/ spec : applyTo : - groups : [ \"\" ] kinds : [ \"Pod\" ] versions : [ \"v1\" ] match : namespaces : [ \"tenants-x\" ] location : \"spec.tolerations\" parameters : assign : value : - key : \"tenant\" operator : \"Equal\" value : \"tenants-x\" effect : \"NoSchedule\" The above policies are specific to pods; this is due to the paths to the mutated elements in the policies' location elements. Additional policies could be written to handle resources that create pods, like Deployment and Job resources. The listed policies and other examples can been seen in the companion GitHub project for this guide. The result of these two mutations is that pods are attracted to the desired node, while at the same time, not repelled by the specific node taint. To verify this, we can see the snippets of output from two kubectl calls to get the nodes labeled with tenant=tenants-x , and get the pods in the tenants-x namespace. kubectl get nodes -l tenant = tenants-x NAME ip-10-0-11-255... ip-10-0-28-81... ip-10-0-43-107... kubectl -n tenants-x get pods -owide NAME READY STATUS RESTARTS AGE IP NODE tenant-test-deploy-58b895ff87-2q7xw 1 /1 Running 0 13s 10 .0.42.143 ip-10-0-43-107... tenant-test-deploy-58b895ff87-9b6hg 1 /1 Running 0 13s 10 .0.18.145 ip-10-0-28-81... tenant-test-deploy-58b895ff87-nxvw5 1 /1 Running 0 13s 10 .0.30.117 ip-10-0-28-81... tenant-test-deploy-58b895ff87-vw796 1 /1 Running 0 13s 10 .0.3.113 ip-10-0-11-255... tenant-test-pod 1 /1 Running 0 13s 10 .0.35.83 ip-10-0-43-107... As we can see from the above outputs, all the pods are scheduled on the nodes labeled with tenant=tenants-x . Simply put, the pods will only run on the desired nodes, and the other pods (without the required affinity and tolerations) will not. The tenant workloads are effectively isolated. An example mutated pod specification is seen below. apiVersion : v1 kind : Pod metadata : name : tenant-test-pod namespace : tenants-x spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : tenant operator : In values : - tenants-x ... tolerations : - effect : NoSchedule key : tenant operator : Equal value : tenants-x ... Attention Policy-management tools that are integrated to the Kubernetes API server request flow, using mutating and validating admission webhooks, are designed to respond to the API server's request within a specified timeframe. This is usually 3 seconds or less. If the webhook call fails to return a response within the configured time, the mutation and/or validation of the inbound API sever request may or may not occur. This behavior is based on whether the admission webhook configurations are set to Fail Open or Fail Close . In the above examples, we used policies written for OPA/Gatekeeper. However, there are other policy management tools that handle our node-selection use case as well. For example, this Kyverno policy could be used to handle the node affinity mutation. Tip If operating correctly, mutating policies will effect the desired changes to inbound API server request payloads. However, validating policies should also be included to verify that the desired changes occur, before changes are allowed to persist. This is especially important when using these policies for tenant-to-node isolation. It is also a good idea to include Audit policies to routinely check your cluster for unwanted configurations.","title":"Part 3 - Policy-based management for node selection"},{"location":"security/docs/multitenancy/#references","text":"k-rail Designed to help you secure a multi-tenant environment through the enforcement of certain policies. Security Practices for MultiTenant SaaS Applications using Amazon EKS","title":"References"},{"location":"security/docs/multitenancy/#hard-multi-tenancy","text":"Hard multi-tenancy can be implemented by provisioning separate clusters for each tenant. While this provides very strong isolation between tenants, it has several drawbacks. First, when you have many tenants, this approach can quickly become expensive. Not only will you have to pay for the control plane costs for each cluster, you will not be able to share compute resources between clusters. This will eventually cause fragmentation where a subset of your clusters are underutilized while others are overutilized. Second, you will likely need to buy or build special tooling to manage all of these clusters. In time, managing hundreds or thousands of clusters may simply become too unwieldy. Finally, creating a cluster per tenant will be slow relative to a creating a namespace. Nevertheless, a hard-tenancy approach may be necessary in highly-regulated industries or in SaaS environments where strong isolation is required.","title":"Hard multi-tenancy"},{"location":"security/docs/multitenancy/#future-directions","text":"The Kubernetes community has recognized the current shortcomings of soft multi-tenancy and the challenges with hard multi-tenancy. The Multi-Tenancy Special Interest Group (SIG) is attempting to address these shortcomings through several incubation projects, including Hierarchical Namespace Controller (HNC) and Virtual Cluster. The HNC proposal (KEP) describes a way to create parent-child relationships between namespaces with [policy] object inheritance along with an ability for tenant administrators to create sub-namespaces. The Virtual Cluster proposal describes a mechanism for creating separate instances of the control plane services, including the API server, the controller manager, and scheduler, for each tenant within the cluster (also known as \"Kubernetes on Kubernetes\"). The Multi-Tenancy Benchmarks proposal provides guidelines for sharing clusters using namespaces for isolation and segmentation, and a command line tool kubectl-mtb to validate conformance to the guidelines.","title":"Future directions"},{"location":"security/docs/multitenancy/#multi-cluster-management-resources","text":"Banzai Cloud Kommander Lens Nirmata Rafay Rancher Weave Flux","title":"Multi-cluster management resources"},{"location":"security/docs/network/","text":"Network security \u00b6 Network security has several facets. The first involves the application of rules which restrict the flow of network traffic between services. The second involves the encryption of traffic while it is in transit. The mechanisms to implement these security measures on EKS are varied but often include the following items: Traffic control \u00b6 Network Policies Security Groups Encryption in transit \u00b6 Service Mesh Container Network Interfaces (CNIs) Nitro Instances ACM Private CA with cert-manager Network policy \u00b6 Within a Kubernetes cluster, all Pod to Pod communication is allowed by default. While this flexibility may help promote experimentation, it is not considered secure. Kubernetes network policies give you a mechanism to restrict network traffic between Pods (often referred to as East/West traffic) and between Pods and external services. Kubernetes network policies operate at layers 3 and 4 of the OSI model. Network policies use pod selectors and labels to identify source and destination pods, but can also include IP addresses, port numbers, protocol number, or a combination of these. Calico , is an open source policy engine from Tigera that works well with EKS. In addition to implementing the full set of Kubernetes network policy features, Calico supports extended network polices with a richer set of features, including support for layer 7 rules, e.g. HTTP, when integrated with Istio. Isovalent, the maintainers of Cilium , have also extended the network policies to include partial support for layer 7 rules, e.g. HTTP. Cilium also has support for DNS hostnames which can be useful for restricting traffic between Kubernetes Services/Pods and resources that run within or outside of your VPC. By contrast, Calico Enterprise includes a feature that allows you to map a Kubernetes network policy to an AWS security group, as well as DNS hostnames. Attention When you first provision an EKS cluster, the Calico policy engine is not installed by default. The manifests for installing Calico can be found in the VPC CNI repository at https://github.com/aws/amazon-vpc-cni-k8s/tree/master/config . Calico policies can be scoped to Namespaces, Pods, service accounts, or globally. When policies are scoped to a service account, it associates a set of ingress/egress rules with that service account. With the proper RBAC rules in place, you can prevent teams from overriding these rules, allowing IT security professionals to safely delegate administration of namespaces. You can find a list of common Kubernetes network policies at https://github.com/ahmetb/kubernetes-network-policy-recipes . A similar set of rules for Calico are available at https://docs.projectcalico.org/security/calico-network-policy . Recommendations \u00b6 Create a default deny policy \u00b6 As with RBAC policies, network policies should adhere to the policy of least privileged access. Start by creating a deny all policy that restricts all inbound and outbound traffic from a namespace or create a global policy using Calico. Kubernetes network policy apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : default-deny namespace : default spec : podSelector : {} policyTypes : - Ingress - Egress Tip The image above was created by the network policy viewer from Tufin . Calico global network policy apiVersion : crd.projectcalico.org/v1 kind : GlobalNetworkPolicy metadata : name : default-deny spec : selector : all() types : - Ingress - Egress Create a rule to allow DNS queries \u00b6 Once you have the default deny all rule in place, you can begin layering on additional rules, such as a global rule that allows pods to query CoreDNS for name resolution. You begin by labeling the namespace: kubectl label namespace kube-system name=kube-system Then add the network policy: apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : allow-dns-access namespace : default spec : podSelector : matchLabels : {} policyTypes : - Egress egress : - to : - namespaceSelector : matchLabels : name : kube-system ports : - protocol : UDP port : 53 Calico global policy equivalent apiVersion : crd.projectcalico.org/v1 kind : GlobalNetworkPolicy metadata : name : allow-dns-egress spec : selector : all() types : - Egress egress : - action : Allow protocol : UDP destination : namespaceSelector : name == \"kube-system\" ports : - 53 The following is an example of how to associate a network policy with a service account while preventing users associated with the readonly-sa-group from editing the service account my-sa in the default namespace: apiVersion : v1 kind : ServiceAccount metadata : name : my-sa namespace : default labels : name : my-sa --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : namespace : default name : readonly-sa-role rules : # Allows the subject to read a service account called my-sa - apiGroups : [ \"\" ] resources : [ \"serviceaccounts\" ] resourceNames : [ \"my-sa\" ] verbs : [ \"get\" , \"watch\" , \"list\" ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : namespace : default name : readonly-sa-rolebinding # Binds the readonly-sa-role to the RBAC group called readonly-sa-group. subjects : - kind : Group name : readonly-sa-group apiGroup : rbac.authorization.k8s.io roleRef : kind : Role name : readonly-sa-role apiGroup : rbac.authorization.k8s.io --- apiVersion : crd.projectcalico.org/v1 kind : NetworkPolicy metadata : name : netpol-sa-demo namespace : default # Allows all ingress traffic to services in the default namespace that reference # the service account called my-sa spec : ingress : - action : Allow source : serviceAccounts : selector : 'name == \"my-sa\"' selector : all() Incrementally add rules to selectively allow the flow of traffic between namespaces/pods \u00b6 Start by allowing Pods within a Namespace to communicate with each other and then add custom rules that further restrict Pod to Pod communication within that Namespace. Log network traffic metadata \u00b6 AWS VPC Flow Logs captures metadata about the traffic flowing through a VPC, such as source and destination IP address and port along with accepted/dropped packets. This information could be analyzed to look for suspicious or unusual activity between resources within the VPC, including Pods. However, since the IP addresses of pods frequently change as they are replaced, Flow Logs may not be sufficient on its own. Calico Enterprise extends the Flow Logs with pod labels and other metadata, making it easier to decipher the traffic flows between pods. Use encryption with AWS load balancers \u00b6 The AWS Application Load Balancer (ALB) and Network Load Balancer (NLB) both have support for transport encryption (SSL and TLS). The alb.ingress.kubernetes.io/certificate-arn annotation for the ALB lets you to specify which certificates to add to the ALB. If you omit the annotation the controller will attempt to add certificates to listeners that require it by matching the available AWS Certificate Manager (ACM) certificates using the host field. Starting with EKS v1.15 you can use the service.beta.kubernetes.io/aws-load-balancer-ssl-cert annotation with the NLB as shown in the example below. apiVersion : v1 kind : Service metadata : name : demo-app namespace : default labels : app : demo-app annotations : service.beta.kubernetes.io/aws-load-balancer-type : \"nlb\" service.beta.kubernetes.io/aws-load-balancer-ssl-cert : \"<certificate ARN>\" service.beta.kubernetes.io/aws-load-balancer-ssl-ports : \"443\" service.beta.kubernetes.io/aws-load-balancer-backend-protocol : \"http\" spec : type : LoadBalancer ports : - port : 443 targetPort : 80 protocol : TCP selector : app : demo-app --- kind : Deployment apiVersion : apps/v1 metadata : name : nginx namespace : default labels : app : demo-app spec : replicas : 1 selector : matchLabels : app : demo-app template : metadata : labels : app : demo-app spec : containers : - name : nginx image : nginx ports : - containerPort : 443 protocol : TCP - containerPort : 80 protocol : TCP Additional Resources \u00b6 Kubernetes & Tigera: Network Policies, Security, and Audit Calico Enterprise Cilium NetworkPolicy Editor an interactive policy editor from Cilium Kinvolk's Network Policy Advisor Suggests network policies based on an analysis of network traffic Security groups \u00b6 EKS uses AWS VPC Security Groups (SGs) to control the traffic between the Kubernetes control plane and the cluster's worker nodes. Security groups are also used to control the traffic between worker nodes, and other VPC resources, and external IP addresses. When you provision an EKS cluster (with Kubernetes version 1.14-eks.3 or greater), a cluster security group is automatically created for you. This security group allows unfettered communication between the EKS control plane and the nodes from managed node groups. For simplicity, it is recommended that you add the cluster SG to all node groups, including unmanaged node groups. Prior to Kubernetes version 1.14 and EKS version eks.3, there were separate security groups configured for the EKS control plane and node groups. The minimum and suggested rules for the control plane and node group security groups can be found at https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html . The minimum rules for the control plane security group allows port 443 inbound from the worker node SG. This rule is what allows the kubelets to communicate with the Kubernetes API server. It also includes port 10250 for outbound traffic to the worker node SG; 10250 is the port that the kubelets listen on. Similarly, the minimum node group rules allow port 10250 inbound from the control plane SG and 443 outbound to the control plane SG. Finally there is a rule that allows unfettered communication between nodes within a node group. If you need to control communication between services that run within the cluster and service the run outside the cluster such as an RDS database, consider security groups for pods . With security groups for pods, you can assign an existing security group to a collection of pods. Warning If you reference a security group that does not exist prior to the creation of the pods, the pods will not get scheduled. You can control which pods are assigned to a security group by creating a SecurityGroupPolicy object and specifying a PodSelector or a ServiceAccountSelector . Setting the selectors to {} will assign the SGs referenced in the SecurityGroupPolicy to all pods in a namespace or all Service Accounts in a namespace. Be sure you've familiarized yourself with all the considerations before implementing security groups for pods. Important If you use SGs for pods you must create SGs that allow port 53 outbound to the cluster security group. Similarly, you must update the cluster security group to accept port 53 inbound traffic from the pod security group. Important The limits for security groups still apply when using security groups for pods so use them judiciously. Important You must create rules for inbound traffic from the cluster security group (kubelet) for all of the probes configured for pod. Warning There is a bug that currently prevents the kubelet from communicating with pods that are assigned to SGs. The current workaround involves running sudo sysctl net.ipv4.tcp_early_demux=0 on the affected worker nodes. This is fixed in CNI v1.7.3, https://github.com/aws/amazon-vpc-cni-k8s/releases/tag/v1.7.3 . Important Security groups for pods relies on a feature known as ENI trunking which was created to increase the ENI density of an EC2 instance. When a pod is assigned to an SG, a VPC controller associates a branch ENI from the node group with the pod. If there aren't enough branch ENIs available in a node group at the time the pod is scheduled, the pod will stay in pending state. The number of branch ENIs an instance can support varies by instance type/family. See https://docs.aws.amazon.com/eks/latest/userguide/security-groups-for-pods.html#supported-instance-types for further details. While security groups for pods offers an AWS-native way to control network traffic within and outside of your cluster without the overhead of a policy daemon, other options are available. For example, the Cilium policy engine allows you to reference a DNS name in a network policy. Calico Enterprise includes an option for mapping network policies to AWS security groups. If you've implemented a service mesh like Istio, you can use an egress gateway to restrict network egress to specific, fully qualified domains or IP addresses. For further information about this option, read the three part series on egress traffic control in Istio . Encryption in transit \u00b6 Applications that need to conform to PCI, HIPAA, or other regulations may need to encrypt data while it is in transit. Nowadays TLS is the de facto choice for encrypting traffic on the wire. TLS, like it's predecessor SSL, provides secure communications over a network using cryptographic protocols. TLS uses symmetric encryption where the keys to encrypt the data are generated based on a shared secret that is negotiated at the beginning of the session. The following are a few ways that you can encrypt data in a Kubernetes environment. Nitro Instances \u00b6 Traffic exchanged between the following Nitro instance types C5n, G4, I3en, M5dn, M5n, P3dn, R5dn, and R5n, is automatically encrypted by default. When there's an intermediate hop, like a transit gateway or a load balancer, the traffic is not encrypted. See Encryption in transit and the following What's new announcement for further details. Container Network Interfaces (CNIs) \u00b6 WeaveNet can be configured to automatically encrypt all traffic using NaCl encryption for sleeve traffic, and IPsec ESP for fast datapath traffic. Service Mesh \u00b6 Encryption in transit can also be implemented with a service mesh like App Mesh, Linkerd v2, and Istio. AppMesh supports mTLS with X.509 certificates or Envoy's Secret Discovery Service(SDS). Linkerd and Istio both have support for mTLS. The aws-app-mesh-examples GitHub repository provides walkthroughs for configuring mTLS using X.509 certificates and SPIRE as SDS provider with your Envoy container: Configuring mTLS using X.509 certificates Configuring TLS using SPIRE (SDS) App Mesh also supports TLS encryption with a private certificate issued by AWS Certificate Manager (ACM) or a certificate stored on the local file system of the virtual node. The aws-app-mesh-examples GitHub repository provides walkthroughs for configuring TLS using certificates issued by ACM and certificates that are packaged with your Envoy container: + Configuring TLS with File Provided TLS Certificates + Configuring TLS with AWS Certificate Manager Ingress Controllers and Load Balancers \u00b6 Ingress controllers are a way for you to intelligently route HTTP/S traffic that emanates from outside the cluster to services running inside the cluster. Oftentimes, these Ingresses are fronted by a layer 4 load balancer, like the Classic Load Balancer or the Network Load Balancer (NLB). Encrypted traffic can be terminated at different places within the network, e.g. at the load balancer, at the ingress resource, or the Pod. How and where you terminate your SSL connection will ultimately be dictated by your organization's network security policy. For instance, if you have a policy that requires end-to-end encryption, you will have to decrypt the traffic at the Pod. This will place additional burden on your Pod as it will have to spend cycles establishing the initial handshake. Overall SSL/TLS processing is very CPU intensive. Consequently, if you have the flexibility, try performing the SSL offload at the Ingress or the load balancer. An ingress controller can be configured to terminate SSL/TLS connections. An example for how to terminate SSL/TLS connections at the NLB appears above . Additional examples for SSL/TLS termination appear below. Securing EKS Ingress With Contour And Let\u2019s Encrypt The GitOps Way How do I terminate HTTPS traffic on Amazon EKS workloads with ACM? Attention Some Ingresses, like the ALB ingress controller, implement the SSL/TLS using Annotations instead of as part of the Ingress Spec. ACM Private CA with cert-manager \u00b6 You can enable TLS and mTLS to secure your EKS application workloads at the ingress, on the pod, and between pods using ACM Private Certificate Authority (CA) and cert-manager , a popular Kubernetes add-on to distribute, renew, and revoke certificates. ACM Private CA is a highly-available, secure, managed CA without the upfront and maintenance costs of managing your own CA. If you are using the default Kubernetes certificate authority, there is an opportunity to improve your security and meet compliance requirements with ACM Private CA. ACM Private CA secures private keys in FIPS 140-2 Level 3 hardware security modules (very secure), compared with the default CA storing keys encoded in memory (less secure). A centralized CA also gives you more control and improved auditability for private certificates both inside and outside of a Kubernetes environment. Learn more about ACM Private CA and its benefits here . Setup Instructions \u00b6 Start by creating a Private CA by following procedures provided in the ACM Private CA tech docs . Once you have a Private CA, install cert-manager using regular installation instructions . After installing cert-manager, install the Private CA Kubernetes cert-manager plugin by following the setup instructions in GitHub . The plugin lets cert-manager request private certificates from ACM Private CA. Now that you have a Private CA and an EKS cluster with cert-manager and the plugin installed, it\u2019s time to set permissions and create the issuer. Update IAM permissions of the EKS node role to allow access to ACM Private CA. Replace the <CA_ARN> with the value from your Private CA: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"awspcaissuer\", \"Action\": [ \"acm-pca:DescribeCertificateAuthority\", \"acm-pca:GetCertificate\", \"acm-pca:IssueCertificate\" ], \"Effect\": \"Allow\", \"Resource\": \"<CA_ARN>\" } ] } Service Roles for IAM Accounts, or IRSA can also be used. Please see the Additional Resources section below for complete examples. Create an Issuer in Amazon EKS by creating a Custom Resource Definition file named cluster-issuer.yaml with the following text in it, replacing <CA_ARN> and <Region> information with your Private CA. apiVersion : awspca . cert - manager . io / v1beta1 kind : AWSPCAClusterIssuer metadata : name : demo - test - root - ca spec : arn : < CA_ARN > region : < Region > Deploy the Issuer you created. kubectl apply -f cluster-issuer.yaml Your EKS cluster is configured to request certificates from Private CA. You can now use cert-manager's Certificate resource to issue certificates by changing the issuerRef field's values to the Private CA Issuer you created above. For more details on how to specify and request Certificate resources, please check cert-manager's Certificate Resources guide . See examples here . Additional Resources \u00b6 How to implement cert-manager and the ACM Private CA plugin to enable TLS in EKS . Setting up end-to-end TLS encryption on Amazon EKS with the new AWS Load Balancer Controller and ACM Private CA . Private CA Kubernetes cert-manager plugin on Github . Private CA Kubernetes cert-manager plugin user guide . Tooling \u00b6 Verifying Service Mesh TLS in Kubernetes, Using ksniff and Wireshark ksniff egress-operator An operator and DNS plugin to control egress traffic from your cluster without protocol inspection","title":"Network Security"},{"location":"security/docs/network/#network-security","text":"Network security has several facets. The first involves the application of rules which restrict the flow of network traffic between services. The second involves the encryption of traffic while it is in transit. The mechanisms to implement these security measures on EKS are varied but often include the following items:","title":"Network security"},{"location":"security/docs/network/#traffic-control","text":"Network Policies Security Groups","title":"Traffic control"},{"location":"security/docs/network/#encryption-in-transit","text":"Service Mesh Container Network Interfaces (CNIs) Nitro Instances ACM Private CA with cert-manager","title":"Encryption in transit"},{"location":"security/docs/network/#network-policy","text":"Within a Kubernetes cluster, all Pod to Pod communication is allowed by default. While this flexibility may help promote experimentation, it is not considered secure. Kubernetes network policies give you a mechanism to restrict network traffic between Pods (often referred to as East/West traffic) and between Pods and external services. Kubernetes network policies operate at layers 3 and 4 of the OSI model. Network policies use pod selectors and labels to identify source and destination pods, but can also include IP addresses, port numbers, protocol number, or a combination of these. Calico , is an open source policy engine from Tigera that works well with EKS. In addition to implementing the full set of Kubernetes network policy features, Calico supports extended network polices with a richer set of features, including support for layer 7 rules, e.g. HTTP, when integrated with Istio. Isovalent, the maintainers of Cilium , have also extended the network policies to include partial support for layer 7 rules, e.g. HTTP. Cilium also has support for DNS hostnames which can be useful for restricting traffic between Kubernetes Services/Pods and resources that run within or outside of your VPC. By contrast, Calico Enterprise includes a feature that allows you to map a Kubernetes network policy to an AWS security group, as well as DNS hostnames. Attention When you first provision an EKS cluster, the Calico policy engine is not installed by default. The manifests for installing Calico can be found in the VPC CNI repository at https://github.com/aws/amazon-vpc-cni-k8s/tree/master/config . Calico policies can be scoped to Namespaces, Pods, service accounts, or globally. When policies are scoped to a service account, it associates a set of ingress/egress rules with that service account. With the proper RBAC rules in place, you can prevent teams from overriding these rules, allowing IT security professionals to safely delegate administration of namespaces. You can find a list of common Kubernetes network policies at https://github.com/ahmetb/kubernetes-network-policy-recipes . A similar set of rules for Calico are available at https://docs.projectcalico.org/security/calico-network-policy .","title":"Network policy"},{"location":"security/docs/network/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/network/#create-a-default-deny-policy","text":"As with RBAC policies, network policies should adhere to the policy of least privileged access. Start by creating a deny all policy that restricts all inbound and outbound traffic from a namespace or create a global policy using Calico. Kubernetes network policy apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : default-deny namespace : default spec : podSelector : {} policyTypes : - Ingress - Egress Tip The image above was created by the network policy viewer from Tufin . Calico global network policy apiVersion : crd.projectcalico.org/v1 kind : GlobalNetworkPolicy metadata : name : default-deny spec : selector : all() types : - Ingress - Egress","title":"Create a default deny policy"},{"location":"security/docs/network/#create-a-rule-to-allow-dns-queries","text":"Once you have the default deny all rule in place, you can begin layering on additional rules, such as a global rule that allows pods to query CoreDNS for name resolution. You begin by labeling the namespace: kubectl label namespace kube-system name=kube-system Then add the network policy: apiVersion : networking.k8s.io/v1 kind : NetworkPolicy metadata : name : allow-dns-access namespace : default spec : podSelector : matchLabels : {} policyTypes : - Egress egress : - to : - namespaceSelector : matchLabels : name : kube-system ports : - protocol : UDP port : 53 Calico global policy equivalent apiVersion : crd.projectcalico.org/v1 kind : GlobalNetworkPolicy metadata : name : allow-dns-egress spec : selector : all() types : - Egress egress : - action : Allow protocol : UDP destination : namespaceSelector : name == \"kube-system\" ports : - 53 The following is an example of how to associate a network policy with a service account while preventing users associated with the readonly-sa-group from editing the service account my-sa in the default namespace: apiVersion : v1 kind : ServiceAccount metadata : name : my-sa namespace : default labels : name : my-sa --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : namespace : default name : readonly-sa-role rules : # Allows the subject to read a service account called my-sa - apiGroups : [ \"\" ] resources : [ \"serviceaccounts\" ] resourceNames : [ \"my-sa\" ] verbs : [ \"get\" , \"watch\" , \"list\" ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : namespace : default name : readonly-sa-rolebinding # Binds the readonly-sa-role to the RBAC group called readonly-sa-group. subjects : - kind : Group name : readonly-sa-group apiGroup : rbac.authorization.k8s.io roleRef : kind : Role name : readonly-sa-role apiGroup : rbac.authorization.k8s.io --- apiVersion : crd.projectcalico.org/v1 kind : NetworkPolicy metadata : name : netpol-sa-demo namespace : default # Allows all ingress traffic to services in the default namespace that reference # the service account called my-sa spec : ingress : - action : Allow source : serviceAccounts : selector : 'name == \"my-sa\"' selector : all()","title":"Create a rule to allow DNS queries"},{"location":"security/docs/network/#incrementally-add-rules-to-selectively-allow-the-flow-of-traffic-between-namespacespods","text":"Start by allowing Pods within a Namespace to communicate with each other and then add custom rules that further restrict Pod to Pod communication within that Namespace.","title":"Incrementally add rules to selectively allow the flow of traffic between namespaces/pods"},{"location":"security/docs/network/#log-network-traffic-metadata","text":"AWS VPC Flow Logs captures metadata about the traffic flowing through a VPC, such as source and destination IP address and port along with accepted/dropped packets. This information could be analyzed to look for suspicious or unusual activity between resources within the VPC, including Pods. However, since the IP addresses of pods frequently change as they are replaced, Flow Logs may not be sufficient on its own. Calico Enterprise extends the Flow Logs with pod labels and other metadata, making it easier to decipher the traffic flows between pods.","title":"Log network traffic metadata"},{"location":"security/docs/network/#use-encryption-with-aws-load-balancers","text":"The AWS Application Load Balancer (ALB) and Network Load Balancer (NLB) both have support for transport encryption (SSL and TLS). The alb.ingress.kubernetes.io/certificate-arn annotation for the ALB lets you to specify which certificates to add to the ALB. If you omit the annotation the controller will attempt to add certificates to listeners that require it by matching the available AWS Certificate Manager (ACM) certificates using the host field. Starting with EKS v1.15 you can use the service.beta.kubernetes.io/aws-load-balancer-ssl-cert annotation with the NLB as shown in the example below. apiVersion : v1 kind : Service metadata : name : demo-app namespace : default labels : app : demo-app annotations : service.beta.kubernetes.io/aws-load-balancer-type : \"nlb\" service.beta.kubernetes.io/aws-load-balancer-ssl-cert : \"<certificate ARN>\" service.beta.kubernetes.io/aws-load-balancer-ssl-ports : \"443\" service.beta.kubernetes.io/aws-load-balancer-backend-protocol : \"http\" spec : type : LoadBalancer ports : - port : 443 targetPort : 80 protocol : TCP selector : app : demo-app --- kind : Deployment apiVersion : apps/v1 metadata : name : nginx namespace : default labels : app : demo-app spec : replicas : 1 selector : matchLabels : app : demo-app template : metadata : labels : app : demo-app spec : containers : - name : nginx image : nginx ports : - containerPort : 443 protocol : TCP - containerPort : 80 protocol : TCP","title":"Use encryption with AWS load balancers"},{"location":"security/docs/network/#additional-resources","text":"Kubernetes & Tigera: Network Policies, Security, and Audit Calico Enterprise Cilium NetworkPolicy Editor an interactive policy editor from Cilium Kinvolk's Network Policy Advisor Suggests network policies based on an analysis of network traffic","title":"Additional Resources"},{"location":"security/docs/network/#security-groups","text":"EKS uses AWS VPC Security Groups (SGs) to control the traffic between the Kubernetes control plane and the cluster's worker nodes. Security groups are also used to control the traffic between worker nodes, and other VPC resources, and external IP addresses. When you provision an EKS cluster (with Kubernetes version 1.14-eks.3 or greater), a cluster security group is automatically created for you. This security group allows unfettered communication between the EKS control plane and the nodes from managed node groups. For simplicity, it is recommended that you add the cluster SG to all node groups, including unmanaged node groups. Prior to Kubernetes version 1.14 and EKS version eks.3, there were separate security groups configured for the EKS control plane and node groups. The minimum and suggested rules for the control plane and node group security groups can be found at https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html . The minimum rules for the control plane security group allows port 443 inbound from the worker node SG. This rule is what allows the kubelets to communicate with the Kubernetes API server. It also includes port 10250 for outbound traffic to the worker node SG; 10250 is the port that the kubelets listen on. Similarly, the minimum node group rules allow port 10250 inbound from the control plane SG and 443 outbound to the control plane SG. Finally there is a rule that allows unfettered communication between nodes within a node group. If you need to control communication between services that run within the cluster and service the run outside the cluster such as an RDS database, consider security groups for pods . With security groups for pods, you can assign an existing security group to a collection of pods. Warning If you reference a security group that does not exist prior to the creation of the pods, the pods will not get scheduled. You can control which pods are assigned to a security group by creating a SecurityGroupPolicy object and specifying a PodSelector or a ServiceAccountSelector . Setting the selectors to {} will assign the SGs referenced in the SecurityGroupPolicy to all pods in a namespace or all Service Accounts in a namespace. Be sure you've familiarized yourself with all the considerations before implementing security groups for pods. Important If you use SGs for pods you must create SGs that allow port 53 outbound to the cluster security group. Similarly, you must update the cluster security group to accept port 53 inbound traffic from the pod security group. Important The limits for security groups still apply when using security groups for pods so use them judiciously. Important You must create rules for inbound traffic from the cluster security group (kubelet) for all of the probes configured for pod. Warning There is a bug that currently prevents the kubelet from communicating with pods that are assigned to SGs. The current workaround involves running sudo sysctl net.ipv4.tcp_early_demux=0 on the affected worker nodes. This is fixed in CNI v1.7.3, https://github.com/aws/amazon-vpc-cni-k8s/releases/tag/v1.7.3 . Important Security groups for pods relies on a feature known as ENI trunking which was created to increase the ENI density of an EC2 instance. When a pod is assigned to an SG, a VPC controller associates a branch ENI from the node group with the pod. If there aren't enough branch ENIs available in a node group at the time the pod is scheduled, the pod will stay in pending state. The number of branch ENIs an instance can support varies by instance type/family. See https://docs.aws.amazon.com/eks/latest/userguide/security-groups-for-pods.html#supported-instance-types for further details. While security groups for pods offers an AWS-native way to control network traffic within and outside of your cluster without the overhead of a policy daemon, other options are available. For example, the Cilium policy engine allows you to reference a DNS name in a network policy. Calico Enterprise includes an option for mapping network policies to AWS security groups. If you've implemented a service mesh like Istio, you can use an egress gateway to restrict network egress to specific, fully qualified domains or IP addresses. For further information about this option, read the three part series on egress traffic control in Istio .","title":"Security groups"},{"location":"security/docs/network/#encryption-in-transit_1","text":"Applications that need to conform to PCI, HIPAA, or other regulations may need to encrypt data while it is in transit. Nowadays TLS is the de facto choice for encrypting traffic on the wire. TLS, like it's predecessor SSL, provides secure communications over a network using cryptographic protocols. TLS uses symmetric encryption where the keys to encrypt the data are generated based on a shared secret that is negotiated at the beginning of the session. The following are a few ways that you can encrypt data in a Kubernetes environment.","title":"Encryption in transit"},{"location":"security/docs/network/#nitro-instances","text":"Traffic exchanged between the following Nitro instance types C5n, G4, I3en, M5dn, M5n, P3dn, R5dn, and R5n, is automatically encrypted by default. When there's an intermediate hop, like a transit gateway or a load balancer, the traffic is not encrypted. See Encryption in transit and the following What's new announcement for further details.","title":"Nitro Instances"},{"location":"security/docs/network/#container-network-interfaces-cnis","text":"WeaveNet can be configured to automatically encrypt all traffic using NaCl encryption for sleeve traffic, and IPsec ESP for fast datapath traffic.","title":"Container Network Interfaces (CNIs)"},{"location":"security/docs/network/#service-mesh","text":"Encryption in transit can also be implemented with a service mesh like App Mesh, Linkerd v2, and Istio. AppMesh supports mTLS with X.509 certificates or Envoy's Secret Discovery Service(SDS). Linkerd and Istio both have support for mTLS. The aws-app-mesh-examples GitHub repository provides walkthroughs for configuring mTLS using X.509 certificates and SPIRE as SDS provider with your Envoy container: Configuring mTLS using X.509 certificates Configuring TLS using SPIRE (SDS) App Mesh also supports TLS encryption with a private certificate issued by AWS Certificate Manager (ACM) or a certificate stored on the local file system of the virtual node. The aws-app-mesh-examples GitHub repository provides walkthroughs for configuring TLS using certificates issued by ACM and certificates that are packaged with your Envoy container: + Configuring TLS with File Provided TLS Certificates + Configuring TLS with AWS Certificate Manager","title":"Service Mesh"},{"location":"security/docs/network/#ingress-controllers-and-load-balancers","text":"Ingress controllers are a way for you to intelligently route HTTP/S traffic that emanates from outside the cluster to services running inside the cluster. Oftentimes, these Ingresses are fronted by a layer 4 load balancer, like the Classic Load Balancer or the Network Load Balancer (NLB). Encrypted traffic can be terminated at different places within the network, e.g. at the load balancer, at the ingress resource, or the Pod. How and where you terminate your SSL connection will ultimately be dictated by your organization's network security policy. For instance, if you have a policy that requires end-to-end encryption, you will have to decrypt the traffic at the Pod. This will place additional burden on your Pod as it will have to spend cycles establishing the initial handshake. Overall SSL/TLS processing is very CPU intensive. Consequently, if you have the flexibility, try performing the SSL offload at the Ingress or the load balancer. An ingress controller can be configured to terminate SSL/TLS connections. An example for how to terminate SSL/TLS connections at the NLB appears above . Additional examples for SSL/TLS termination appear below. Securing EKS Ingress With Contour And Let\u2019s Encrypt The GitOps Way How do I terminate HTTPS traffic on Amazon EKS workloads with ACM? Attention Some Ingresses, like the ALB ingress controller, implement the SSL/TLS using Annotations instead of as part of the Ingress Spec.","title":"Ingress Controllers and Load Balancers"},{"location":"security/docs/network/#acm-private-ca-with-cert-manager","text":"You can enable TLS and mTLS to secure your EKS application workloads at the ingress, on the pod, and between pods using ACM Private Certificate Authority (CA) and cert-manager , a popular Kubernetes add-on to distribute, renew, and revoke certificates. ACM Private CA is a highly-available, secure, managed CA without the upfront and maintenance costs of managing your own CA. If you are using the default Kubernetes certificate authority, there is an opportunity to improve your security and meet compliance requirements with ACM Private CA. ACM Private CA secures private keys in FIPS 140-2 Level 3 hardware security modules (very secure), compared with the default CA storing keys encoded in memory (less secure). A centralized CA also gives you more control and improved auditability for private certificates both inside and outside of a Kubernetes environment. Learn more about ACM Private CA and its benefits here .","title":"ACM Private CA with cert-manager"},{"location":"security/docs/network/#setup-instructions","text":"Start by creating a Private CA by following procedures provided in the ACM Private CA tech docs . Once you have a Private CA, install cert-manager using regular installation instructions . After installing cert-manager, install the Private CA Kubernetes cert-manager plugin by following the setup instructions in GitHub . The plugin lets cert-manager request private certificates from ACM Private CA. Now that you have a Private CA and an EKS cluster with cert-manager and the plugin installed, it\u2019s time to set permissions and create the issuer. Update IAM permissions of the EKS node role to allow access to ACM Private CA. Replace the <CA_ARN> with the value from your Private CA: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"awspcaissuer\", \"Action\": [ \"acm-pca:DescribeCertificateAuthority\", \"acm-pca:GetCertificate\", \"acm-pca:IssueCertificate\" ], \"Effect\": \"Allow\", \"Resource\": \"<CA_ARN>\" } ] } Service Roles for IAM Accounts, or IRSA can also be used. Please see the Additional Resources section below for complete examples. Create an Issuer in Amazon EKS by creating a Custom Resource Definition file named cluster-issuer.yaml with the following text in it, replacing <CA_ARN> and <Region> information with your Private CA. apiVersion : awspca . cert - manager . io / v1beta1 kind : AWSPCAClusterIssuer metadata : name : demo - test - root - ca spec : arn : < CA_ARN > region : < Region > Deploy the Issuer you created. kubectl apply -f cluster-issuer.yaml Your EKS cluster is configured to request certificates from Private CA. You can now use cert-manager's Certificate resource to issue certificates by changing the issuerRef field's values to the Private CA Issuer you created above. For more details on how to specify and request Certificate resources, please check cert-manager's Certificate Resources guide . See examples here .","title":"Setup Instructions"},{"location":"security/docs/network/#additional-resources_1","text":"How to implement cert-manager and the ACM Private CA plugin to enable TLS in EKS . Setting up end-to-end TLS encryption on Amazon EKS with the new AWS Load Balancer Controller and ACM Private CA . Private CA Kubernetes cert-manager plugin on Github . Private CA Kubernetes cert-manager plugin user guide .","title":"Additional Resources"},{"location":"security/docs/network/#tooling","text":"Verifying Service Mesh TLS in Kubernetes, Using ksniff and Wireshark ksniff egress-operator An operator and DNS plugin to control egress traffic from your cluster without protocol inspection","title":"Tooling"},{"location":"security/docs/pods/","text":"Pod Security \u00b6 The pod specification includes a variety of different attributes that can strengthen or weaken your overall security posture. As a Kubernetes practitioner your chief concern should be preventing a process that\u2019s running in a container from escaping the isolation boundaries of the container runtime and gaining access to the underlying host. Linux Capabilities \u00b6 The processes that run within a container run under the context of the [Linux] root user by default. Although the actions of root within a container are partially constrained by the set of Linux capabilities that the container runtime assigns to the containers, these default privileges could allow an attacker to escalate their privileges and/or gain access to sensitive information bound to the host, including Secrets and ConfigMaps. Below is a list of the default capabilities assigned to containers. For additional information about each capability, see http://man7.org/linux/man-pages/man7/capabilities.7.html . CAP_AUDIT_WRITE, CAP_CHOWN, CAP_DAC_OVERRIDE, CAP_FOWNER, CAP_FSETID, CAP_KILL, CAP_MKNOD, CAP_NET_BIND_SERVICE, CAP_NET_RAW, CAP_SETGID, CAP_SETUID, CAP_SETFCAP, CAP_SETPCAP, CAP_SYS_CHROOT Info EC2 and Fargate pods are assigned the aforementioned capabilities by default. Additionally, Linux capabilities can only be dropped from Fargate pods. Pods that are run as privileged, inherit all of the Linux capabilities associated with root on the host. This should be avoided if possible. Node Authorization \u00b6 All Kubernetes worker nodes use an authorization mode called Node Authorization . Node Authorization authorizes all API requests that originate from the kubelet and allows nodes to perform the following actions: Read operations: services endpoints nodes pods secrets, configmaps, persistent volume claims and persistent volumes related to pods bound to the kubelet\u2019s node Write operations: nodes and node status (enable the NodeRestriction admission plugin to limit a kubelet to modify its own node) pods and pod status (enable the NodeRestriction admission plugin to limit a kubelet to modify pods bound to itself) events Auth-related operations: Read/write access to the CertificateSigningRequest (CSR) API for TLS bootstrapping the ability to create TokenReview and SubjectAccessReview for delegated authentication/authorization checks EKS uses the node restriction admission controller which only allows the node to modify a limited set of node attributes and pod objects that are bound to the node. Nevertheless, an attacker who manages to get access to the host will still be able to glean sensitive information about the environment from the Kubernetes API that could allow them to move laterally within the cluster. Pod Security Solutions \u00b6 Pod Security Policy (PSP) \u00b6 In the past, Pod Security Policy (PSP) resources were used to specify a set of requirements that pods had to meet before they could be created. As of Kubernetes version 1.21, PSP have been deprecated. They are scheduled for removal in Kubernetes version 1.25. Attention PSPs are deprecated in Kubernetes version 1.21. You will have until version 1.25 or roughly 2 years to transition to an alternative. This document explains the motivation for this deprecation. Migrating to a new pod security solution \u00b6 Since PSPs are scheduled to be removed and are no longer under active development, cluster administrators and operators must replace those security controls. Two solutions can fill this need: Policy-as-code (PAC) solutions from the Kubernetes ecosystem Kubernetes Pod Security Standards (PSS) Both the PAC and PSS solutions can coexist with PSP; they can be used in clusters before PSP is removed. This eases adoption when migrating from PSP. Please see this document when considering migrating from PSP to PSS. Policy-as-code (PAC) \u00b6 Policy-as-code (PAC) solutions provide guardrails to guide cluster users, and prevent unwanted behaviors, through prescribed and automated controls. PAC uses Kubernetes Dynamic Admission Controllers to intercept the Kubernetes API server request flow, via a webhook call, and mutate and validate request payloads, based on policies written and stored as code. Mutation and validation happens before the API server request results in a change to the cluster. PAC solutions use policies to match and act on API server request payloads, based on taxonomy and values. There are several open source PAC solutions available for Kubernetes. These solutions are not part of the Kubernetes project; they are sourced from the Kubernetes ecosystem. Some PAC solutions are listed below. OPA/Gatekeeper Open Policy Agent (OPA) Kyverno Kubewarden jsPolicy For further information about PAC solutions and how to help you select the appropriate solution for your needs, see the links below. Policy-based countermeasures for Kubernetes \u2013 Part 1 Policy-based countermeasures for Kubernetes \u2013 Part 2 Pod Security Standards (PSS) and Pod Security Admission (PSA) \u00b6 In response to the PSP deprecation and the ongoing need to control pod security out-of-the-box, with a built-in Kubernetes solution, the Kubernetes Auth Special Interest Group created the Pod Security Standards (PSS) and Pod Security Admission (PSA) . The PSA effort includes an admission controller webhook project that implements the controls defined in the PSS. This admission controller approach resembles that used in the PAC solutions. According to the Kubernetes documentation, the PSS \"define three different policies to broadly cover the security spectrum. These policies are cumulative and range from highly-permissive to highly-restrictive.\" These policies are defined as: Privileged: Unrestricted (unsecure) policy, providing the widest possible level of permissions. This policy allows for known privilege escalations. It is the absence of a policy. This is good for applications such as logging agents, CNIs, storage drivers, and other system wide applications that need privileged access. Baseline: Minimally restrictive policy which prevents known privilege escalations. Allows the default (minimally specified) Pod configuration. The baseline policy prohibits use of hostNetwork, hostPID, hostIPC, hostPath, hostPort, the inability to add Linux capabilities, along with several other restrictions. Restricted: Heavily restricted policy, following current Pod hardening best practices. This policy inherits from the baseline and adds further restrictions such as the inability to run as root or a root-group. Restricted policies may impact an application's ability to function. They are primarily targeted at running security critical applications. These policies define profiles for pod execution , arranged into three levels of privileged vs. restricted access. To implement the controls defined by the PSS, PSA operates in three modes: enforce: Policy violations will cause the pod to be rejected. audit: Policy violations will trigger the addition of an audit annotation to the event recorded in the audit log, but are otherwise allowed. warn: Policy violations will trigger a user-facing warning, but are otherwise allowed. These modes and the profile (restriction) levels are configured at the Kubernetes Namespace level, using labels, as seen in the below example. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/enforce : restricted When used independently, these operational modes have different responses that result in different user experiences. The enforce mode will prevent pods from being created if respective podSpecs violate the configured restriction level. However, in this mode, non-pod Kubernetes objects that create pods, such as Deployments, will not be prevented from being applied to the cluster, even if the podSpec therein violates the applied PSS. In this case the Deployment will be applied, while the pod(s) will be prevented from being applied. This is a difficult user experience, as there is no immediate indication that the successfully applied Deployment object belies failed pod creation. The offending podSpecs will not create pods. Inspecting the Deployment resource with kubectl get deploy <DEPLOYMENT_NAME> -oyaml will expose the message from the failed pod(s) .status.conditions element, as seen below. ... status : conditions : - lastTransitionTime : \"2022-01-20T01:02:08Z\" lastUpdateTime : \"2022-01-20T01:02:08Z\" message : 'pods \"test-688f68dc87-tw587\" is forbidden: violates PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"test\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"test\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"test\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"test\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")' reason : FailedCreate status : \"True\" type : ReplicaFailure ... In both the audit and warn modes, the pod restrictions do not prevent violating pods from being created and started. However, in these modes audit annotations on API server audit log events and warnings to API server clients, such as kubectl , are triggered, respectively, when pods, as well as objects that create pods, contain podSpecs with violations. A kubectl Warning message is seen below. Warning: would violate PodSecurity \"restricted:latest\" : allowPrivilegeEscalation ! = false ( container \"test\" must set securityContext.allowPrivilegeEscalation = false ) , unrestricted capabilities ( container \"test\" must set securityContext.capabilities.drop =[ \"ALL\" ]) , runAsNonRoot ! = true ( pod or container \"test\" must set securityContext.runAsNonRoot = true ) , seccompProfile ( pod or container \"test\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\" ) deployment.apps/test created The PSA audit and warn modes are useful when introducing the PSS without negatively impacting cluster operations. The PSA operational modes are not mutually exclusive, and can be used in a cumulative manner. As seen below, the multiple modes can be configured in a single namespace. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/audit : restricted pod-security.kubernetes.io/enforce : restricted pod-security.kubernetes.io/warn : restricted In the above example, the user-friendly warnings and audit annotations are provided when applying Deployments, while the enforce of violations are also provided at the pod level. In fact multiple PSA labels can use different profile levels, as seen below. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/enforce : baseline pod-security.kubernetes.io/warn : restricted In the above example, PSA is configured to allow the creation of all pods that satisfy the baseline profile level, and then warn on pods (and objects that create pods) that violate the restricted profile level. This is a useful approach to determine the possible impacts when changing from the baseline to restricted profiles. Existing Pods \u00b6 If a namespace with existing pods is modified to use a more restrictive PSS profile, the audit and warn modes will produce appropriate messages; however, enforce mode will not delete the pods. The warning messages are seen below. Warning: existing pods in namespace \"policy-test\" violate the new PodSecurity enforce level \"restricted:latest\" Warning: test-688f68dc87-htm8x: allowPrivilegeEscalation ! = false, unrestricted capabilities, runAsNonRoot ! = true, seccompProfile namespace/policy-test configured Exemptions \u00b6 PSA uses Exemptions to exclude enforcement of violations against pods that would have otherwise been applied. These exemptions are listed below. Usernames: requests from users with an exempt authenticated (or impersonated) username are ignored. RuntimeClassNames: pods and workload resources specifying an exempt runtime class name are ignored. Namespaces: pods and workload resources in an exempt namespace are ignored. These exemptions are applied statically in the PSA admission controller configuration as part of the API server configuration. In the Validating Webhook implementation the exemptions can be configured within a Kubernetes ConfigMap resource that gets mounted as a volume into the pod-security-webhook container. apiVersion : v1 kind : ConfigMap metadata : name : pod-security-webhook namespace : pod-security-webhook data : podsecurityconfiguration.yaml : | apiVersion: pod-security.admission.config.k8s.io/v1beta1 kind: PodSecurityConfiguration defaults: enforce: \"restricted\" enforce-version: \"latest\" audit: \"restricted\" audit-version: \"latest\" warn: \"restricted\" warn-version: \"latest\" exemptions: # Array of authenticated usernames to exempt. usernames: [] # Array of runtime class names to exempt. runtimeClasses: [] # Array of namespaces to exempt. namespaces: [\"kube-system\",\"policy-test1\"] As seen in the above ConfigMap YAML the cluster-wide default PSS level has been set to restricted for all PSA modes, audit , enforce , and warn . This affects all namespaces, except those exempted: namespaces: [\"kube-system\",\"policy-test1\"] . Additionally, in the ValidatingWebhookConfiguration resource, seen below, the pod-security-webhook namespace is also exempted from configured PSS. ... webhooks : # Audit annotations will be prefixed with this name - name : \"pod-security-webhook.kubernetes.io\" # Fail-closed admission webhooks can present operational challenges. # You may want to consider using a failure policy of Ignore, but should # consider the security tradeoffs. failurePolicy : Fail namespaceSelector : # Exempt the webhook itself to avoid a circular dependency. matchExpressions : - key : kubernetes.io/metadata.name operator : NotIn values : [ \"pod-security-webhook\" ] ... Attention As of Kubernetes versions 1.22 and 1.23 , the Pod Security Admission feature is alpha and beta status, respectively. At least until GA, the current admission controller can be used via a validating webhook, configured from these instructions . Choosing between policy-as-code and Pod Security Standards \u00b6 The Pod Security Standards (PSS) were developed to replace the Pod Security Policy (PSP), by providing a solution that was built-in to Kubernetes and did not require solutions from the Kubernetes ecosystem. That being said, policy-as-code (PAC) solutions are considerably more flexible. The following list of Pros and Cons is designed help you make a more informed decision about your pod security solution. Policy-as-code (as compared to Pod Security Standards) Pros: More flexible and more granular (down to attributes of resources if need be) Not just focused on pods, can be used against different resources and actions Not just applied at the namespace level More mature than the Pod Security Standards Decisions can be based on anything in the API server request payload, as well as existing cluster resources and external data (solution dependent) Supports mutating API server requests before validation (solution dependent) Can generate complementary policies and Kubernetes resources (solution dependent - From pod policies, Kyverno can auto-gen policies for higher-level controllers, such as Deployments. Kyverno can also generate additional Kubernetes resources \"when a new resource is created or when the source is updated\" by using Generate Rules .) Can be used to shift left, into CICD pipelines, before making calls to the Kubernetes API server (solution dependent) Can be used to implement behaviors that are not necessarily security related, such as best practices, organizational standards, etc. Can be used in non-Kubernetes use cases (solution dependent) Because of flexibility, the user experience can be tuned to users' needs Cons: Not built into Kubernetes More complex to learn, configure, and support Policy authoring may require new skills/languages/capabilities Pod Security Admission (as compared to policy-as-code) Pros: Built into Kubernetes Simpler to configure No new languages to use or policies to author If the cluster default admission level is configured to privileged , namespace labels can be used to opt namespaces into the pod security profiles. Cons: Not as flexible or granular as policy-as-code Only 3 levels of restrictions Primarily focused on pods Summary \u00b6 If you currently do not have a pod security solution, beyond PSP, and your required pod security posture fits the model defined in the Pod Security Standards (PSS), then an easier path may be to adopt the PSS, in lieu of a policy-as-code solution. However, if your pod security posture does not fit the PSS model, or you envision adding additional controls, beyond that defined by PSS, then a policy-as-code solution would seem a better fit. Recommendations \u00b6 Use multiple Pod Security Admission (PSA) modes for a better user experience \u00b6 As mentioned earlier, PSA enforce mode prevents pods with PSS violations from being applied, but does not stop higher-level controllers, such as Deployments. In fact, the Deployment will be applied successfully without any indication that the pods failed to be applied. While you can use kubectl to inspect the Deployment object, and discover the failed pods message from the PSA, the user experience could be better. To make the user experience better, multiple PSA modes (audit, enforce, warn) should be used. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/audit : restricted pod-security.kubernetes.io/enforce : restricted pod-security.kubernetes.io/warn : restricted In the above example, with enforce mode defined, when a Deployment manifest with PSS violations in the respective podSpec is attempted to be applied to the Kubernetes API server, the Deployment will be successfully applied, but the pods will not. And, since the audit and warn modes are also enabled, the API server client will receive a warning message and the API server audit log event will be annotated with a message as well. Restrict the containers that can run as privileged \u00b6 As mentioned, containers that run as privileged inherit all of the Linux capabilities assigned to root on the host. Seldom do containers need these types of privileges to function properly. There are multiple methods that can be used to restrict the permissions and capabilities of containers. Attention Fargate is a launch type that enables you to run \"serverless\" container(s) where the containers of a pod are run on infrastructure that AWS manages. With Fargate, you cannot run a privileged container or configure your pod to use hostNetwork or hostPort. Do not run processes in containers as root \u00b6 All containers run as root by default. This could be problematic if an attacker is able to exploit a vulnerability in the application and get shell access to the running container. You can mitigate this risk a variety of ways. First, by removing the shell from the container image. Second, adding the USER directive to your Dockerfile or running the containers in the pod as a non-root user. The Kubernetes podSpec includes a set of fields, under spec.securityContext , that let you specify the user and/or group under which to run your application. These fields are runAsUser and runAsGroup respectively. To enforce the use of the spec.securityContext , and its associated elements, within the Kubernetes podSpec, policy-as-code or Pod Security Standards can be added to clusters. These solutions allow you to write and/or use policies or profiles that can validate inbound Kubernetes API server request payloads, before they are persisted into etcd. Furthermore, policy-as-code solutions can mutate inbound requests, and in some cases, generate new requests. Never run Docker in Docker or mount the socket in the container \u00b6 While this conveniently lets you to build/run images in Docker containers, you're basically relinquishing complete control of the node to the process running in the container. If you need to build container images on Kubernetes use Kaniko , buildah , img , or a build service like CodeBuild instead. Tip Kubernetes clusters used for CICD processing, such as building container images, should be isolated from clusters running more generalized workloads. Restrict the use of hostPath or if hostPath is necessary restrict which prefixes can be used and configure the volume as read-only \u00b6 hostPath is a volume that mounts a directory from the host directly to the container. Rarely will pods need this type of access, but if they do, you need to be aware of the risks. By default pods that run as root will have write access to the file system exposed by hostPath. This could allow an attacker to modify the kubelet settings, create symbolic links to directories or files not directly exposed by the hostPath, e.g. /etc/shadow, install ssh keys, read secrets mounted to the host, and other malicious things. To mitigate the risks from hostPath, configure the spec.containers.volumeMounts as readOnly , for example: volumeMounts : - name : hostPath-volume readOnly : true mountPath : /host-path You should also use policy-as-code solutions to restrict the directories that can be used by hostPath volumes, or prevent hostPath usage altogether. You can use the Pod Security Standards Baseline or Restricted policies to prevent the use of hostPath . For further information about the dangers of privileged escalation, read Seth Art's blog Bad Pods: Kubernetes Pod Privilege Escalation . Set requests and limits for each container to avoid resource contention and DoS attacks \u00b6 A pod without requests or limits can theoretically consume all of the resources available on a host. As additional pods are scheduled onto a node, the node may experience CPU or memory pressure which can cause the Kubelet to terminate or evict pods from the node. While you can\u2019t prevent this from happening all together, setting requests and limits will help minimize resource contention and mitigate the risk from poorly written applications that consume an excessive amount of resources. The podSpec allows you to specify requests and limits for CPU and memory. CPU is considered a compressible resource because it can be oversubscribed. Memory is incompressible, i.e. it cannot be shared among multiple containers. When you specify requests for CPU or memory, you\u2019re essentially designating the amount of memory that containers are guaranteed to get. Kubernetes aggregates the requests of all the containers in a pod to determine which node to schedule the pod onto. If a container exceeds the requested amount of memory it may be subject to termination if there\u2019s memory pressure on the node. Limits are the maximum amount of CPU and memory resources that a container is allowed to consume and directly corresponds to the memory.limit_in_bytes value of the cgroup created for the container. A container that exceeds the memory limit will be OOM killed. If a container exceeds its CPU limit, it will be throttled. Tip When using container resources.limits it is strongly recommended that container resource usage (a.k.a. Resource Footprints) be data-driven and accurate, based on load testing. Absent an accurate and trusted resource footprint, container resources.limits can be padded. For example, resources.limits.memory could be padded 20-30% higher than observable maximums, to account for potential memory resource limit inaccuracies. Kubernetes uses three Quality of Service (QoS) classes to prioritize the workloads running on a node. These include: guaranteed burstable best-effort If limits and requests are not set, the pod is configured as best-effort (lowest priority). Best-effort pods are the first to get killed when there is insufficient memory. If limits are set on all containers within the pod, or if the requests and limits are set to the same values and not equal to 0, the pod is configured as guaranteed (highest priority). Guaranteed pods will not be killed unless they exceed their configured memory limits. If the limits and requests are configured with different values and not equal to 0, or one container within the pod sets limits and the others don\u2019t or have limits set for different resources, the pods are configured as burstable (medium priority). These pods have some resource guarantees, but can be killed once they exceed their requested memory. Attention Requests don't affect the memory_limit_in_bytes value of the container's cgroup; the cgroup limit is set to the amount of memory available on the host. Nevertheless, setting the requests value too low could cause the pod to be targeted for termination by the kubelet if the node undergoes memory pressure. Class Priority Condition Kill Condition Guaranteed highest limit = request != 0 Only exceed memory limits Burstable medium limit != request != 0 Can be killed if exceed request memory Best-Effort lowest limit & request Not Set First to get killed when there's insufficient memory For additional information about resource QoS, please refer to the Kubernetes documentation . You can force the use of requests and limits by setting a resource quota on a namespace or by creating a limit range . A resource quota allows you to specify the total amount of resources, e.g. CPU and RAM, allocated to a namespace. When it\u2019s applied to a namespace, it forces you to specify requests and limits for all containers deployed into that namespace. By contrast, limit ranges give you more granular control of the allocation of resources. With limit ranges you can min/max for CPU and memory resources per pod or per container within a namespace. You can also use them to set default request/limit values if none are provided. Policy-as-code solutions can be used enforce requests and limits. or to even create the resource quotas and limit ranges when namespaces are created. Do not allow privileged escalation \u00b6 Privileged escalation allows a process to change the security context under which its running. Sudo is a good example of this as are binaries with the SUID or SGID bit. Privileged escalation is basically a way for users to execute a file with the permissions of another user or group. You can prevent a container from using privileged escalation by implementing a policy-as-code mutating policy that sets allowPrivilegeEscalation to false or by setting securityContext.allowPrivilegeEscalation in the podSpec . Policy-as-code policies can also be used to prevent API server requests from succeeding if incorrect settings are detected. Pod Security Standards can also be used to prevent pods from using privilege escalation. Disable ServiceAccount token mounts \u00b6 For pods that do not need to access the Kubernetes API, you can disable the automatic mounting of a ServiceAccount token on a pod spec, or for all pods that use a particular ServiceAccount. Attention Disabling ServiceAccount mounting does not prevent a pod from having network access to the Kubernetes API. To prevent a pod from having any network access to the Kubernetes API, you will need to modify the EKS cluster endpoint access and use NetworkPolicy to block pod access apiVersion : v1 kind : Pod metadata : name : pod-no-automount spec : automountServiceAccountToken : false apiVersion : v1 kind : ServiceAccount metadata : name : sa-no-automount automountServiceAccountToken : false Disable service discovery \u00b6 For pods that do not need to lookup or call in-cluster services, you can reduce the amount of information given to a pod. You can set the Pod's DNS policy to not use CoreDNS, and not expose services in the pod's namespace as environment variables. See the Kubernetes docs on environment variables for more information on service links. The default value for a pod's DNS policy is \"ClusterFirst\" which uses in-cluster DNS, while the non-default value \"Default\" uses the underlying node's DNS resolution. See the Kubernetes docs on Pod DNS policy for more information. Attention Disabling service links and changing the pod's DNS policy does not prevent a pod from having network access to the in-cluster DNS service. An attacker can still enumerate services in a cluster by reaching the in-cluster DNS service. (ex: dig SRV *.*.svc.cluster.local @$CLUSTER_DNS_IP ) To prevent in-cluster service discovery, use NetworkPolicy to block pod access apiVersion : v1 kind : Pod metadata : name : pod-no-service-info spec : dnsPolicy : Default # \"Default\" is not the true default value enableServiceLinks : false Configure your images with read-only root file system \u00b6 Configuring your images with a read-only root file system prevents an attacker from overwriting a binary on the file system that your application uses. If your application has to write to the file system, consider writing to a temporary directory or attach and mount a volume. You can enforce this by setting the pod's SecurityContext as follows: ... securityContext : readOnlyRootFilesystem : true ... Policy-as-code and Pod Security Standards can be used to enforce this behavior. Info As per Windows containers in Kubernetes securityContext.readOnlyRootFilesystem cannot be set to true for a container running on Windows as write access is required for registry and system processes to run inside the container. Tools and Resources \u00b6 open-policy-agent/gatekeeper-library: The OPA Gatekeeper policy library a library of OPA/Gatekeeper policies that you can use as a substitute for PSPs. Kyverno Policy Library A collection of common OPA and Kyverno policies for EKS. Policy based countermeasures: part 1 Policy based countermeasures: part 2 Pod Security Policy Migrator a tool that converts PSPs to OPA/Gatekeeper, KubeWarden, or Kyverno policies","title":"Pod Security"},{"location":"security/docs/pods/#pod-security","text":"The pod specification includes a variety of different attributes that can strengthen or weaken your overall security posture. As a Kubernetes practitioner your chief concern should be preventing a process that\u2019s running in a container from escaping the isolation boundaries of the container runtime and gaining access to the underlying host.","title":"Pod Security"},{"location":"security/docs/pods/#linux-capabilities","text":"The processes that run within a container run under the context of the [Linux] root user by default. Although the actions of root within a container are partially constrained by the set of Linux capabilities that the container runtime assigns to the containers, these default privileges could allow an attacker to escalate their privileges and/or gain access to sensitive information bound to the host, including Secrets and ConfigMaps. Below is a list of the default capabilities assigned to containers. For additional information about each capability, see http://man7.org/linux/man-pages/man7/capabilities.7.html . CAP_AUDIT_WRITE, CAP_CHOWN, CAP_DAC_OVERRIDE, CAP_FOWNER, CAP_FSETID, CAP_KILL, CAP_MKNOD, CAP_NET_BIND_SERVICE, CAP_NET_RAW, CAP_SETGID, CAP_SETUID, CAP_SETFCAP, CAP_SETPCAP, CAP_SYS_CHROOT Info EC2 and Fargate pods are assigned the aforementioned capabilities by default. Additionally, Linux capabilities can only be dropped from Fargate pods. Pods that are run as privileged, inherit all of the Linux capabilities associated with root on the host. This should be avoided if possible.","title":"Linux Capabilities"},{"location":"security/docs/pods/#node-authorization","text":"All Kubernetes worker nodes use an authorization mode called Node Authorization . Node Authorization authorizes all API requests that originate from the kubelet and allows nodes to perform the following actions: Read operations: services endpoints nodes pods secrets, configmaps, persistent volume claims and persistent volumes related to pods bound to the kubelet\u2019s node Write operations: nodes and node status (enable the NodeRestriction admission plugin to limit a kubelet to modify its own node) pods and pod status (enable the NodeRestriction admission plugin to limit a kubelet to modify pods bound to itself) events Auth-related operations: Read/write access to the CertificateSigningRequest (CSR) API for TLS bootstrapping the ability to create TokenReview and SubjectAccessReview for delegated authentication/authorization checks EKS uses the node restriction admission controller which only allows the node to modify a limited set of node attributes and pod objects that are bound to the node. Nevertheless, an attacker who manages to get access to the host will still be able to glean sensitive information about the environment from the Kubernetes API that could allow them to move laterally within the cluster.","title":"Node Authorization"},{"location":"security/docs/pods/#pod-security-solutions","text":"","title":"Pod Security Solutions"},{"location":"security/docs/pods/#pod-security-policy-psp","text":"In the past, Pod Security Policy (PSP) resources were used to specify a set of requirements that pods had to meet before they could be created. As of Kubernetes version 1.21, PSP have been deprecated. They are scheduled for removal in Kubernetes version 1.25. Attention PSPs are deprecated in Kubernetes version 1.21. You will have until version 1.25 or roughly 2 years to transition to an alternative. This document explains the motivation for this deprecation.","title":"Pod Security Policy (PSP)"},{"location":"security/docs/pods/#migrating-to-a-new-pod-security-solution","text":"Since PSPs are scheduled to be removed and are no longer under active development, cluster administrators and operators must replace those security controls. Two solutions can fill this need: Policy-as-code (PAC) solutions from the Kubernetes ecosystem Kubernetes Pod Security Standards (PSS) Both the PAC and PSS solutions can coexist with PSP; they can be used in clusters before PSP is removed. This eases adoption when migrating from PSP. Please see this document when considering migrating from PSP to PSS.","title":"Migrating to a new pod security solution"},{"location":"security/docs/pods/#policy-as-code-pac","text":"Policy-as-code (PAC) solutions provide guardrails to guide cluster users, and prevent unwanted behaviors, through prescribed and automated controls. PAC uses Kubernetes Dynamic Admission Controllers to intercept the Kubernetes API server request flow, via a webhook call, and mutate and validate request payloads, based on policies written and stored as code. Mutation and validation happens before the API server request results in a change to the cluster. PAC solutions use policies to match and act on API server request payloads, based on taxonomy and values. There are several open source PAC solutions available for Kubernetes. These solutions are not part of the Kubernetes project; they are sourced from the Kubernetes ecosystem. Some PAC solutions are listed below. OPA/Gatekeeper Open Policy Agent (OPA) Kyverno Kubewarden jsPolicy For further information about PAC solutions and how to help you select the appropriate solution for your needs, see the links below. Policy-based countermeasures for Kubernetes \u2013 Part 1 Policy-based countermeasures for Kubernetes \u2013 Part 2","title":"Policy-as-code (PAC)"},{"location":"security/docs/pods/#pod-security-standards-pss-and-pod-security-admission-psa","text":"In response to the PSP deprecation and the ongoing need to control pod security out-of-the-box, with a built-in Kubernetes solution, the Kubernetes Auth Special Interest Group created the Pod Security Standards (PSS) and Pod Security Admission (PSA) . The PSA effort includes an admission controller webhook project that implements the controls defined in the PSS. This admission controller approach resembles that used in the PAC solutions. According to the Kubernetes documentation, the PSS \"define three different policies to broadly cover the security spectrum. These policies are cumulative and range from highly-permissive to highly-restrictive.\" These policies are defined as: Privileged: Unrestricted (unsecure) policy, providing the widest possible level of permissions. This policy allows for known privilege escalations. It is the absence of a policy. This is good for applications such as logging agents, CNIs, storage drivers, and other system wide applications that need privileged access. Baseline: Minimally restrictive policy which prevents known privilege escalations. Allows the default (minimally specified) Pod configuration. The baseline policy prohibits use of hostNetwork, hostPID, hostIPC, hostPath, hostPort, the inability to add Linux capabilities, along with several other restrictions. Restricted: Heavily restricted policy, following current Pod hardening best practices. This policy inherits from the baseline and adds further restrictions such as the inability to run as root or a root-group. Restricted policies may impact an application's ability to function. They are primarily targeted at running security critical applications. These policies define profiles for pod execution , arranged into three levels of privileged vs. restricted access. To implement the controls defined by the PSS, PSA operates in three modes: enforce: Policy violations will cause the pod to be rejected. audit: Policy violations will trigger the addition of an audit annotation to the event recorded in the audit log, but are otherwise allowed. warn: Policy violations will trigger a user-facing warning, but are otherwise allowed. These modes and the profile (restriction) levels are configured at the Kubernetes Namespace level, using labels, as seen in the below example. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/enforce : restricted When used independently, these operational modes have different responses that result in different user experiences. The enforce mode will prevent pods from being created if respective podSpecs violate the configured restriction level. However, in this mode, non-pod Kubernetes objects that create pods, such as Deployments, will not be prevented from being applied to the cluster, even if the podSpec therein violates the applied PSS. In this case the Deployment will be applied, while the pod(s) will be prevented from being applied. This is a difficult user experience, as there is no immediate indication that the successfully applied Deployment object belies failed pod creation. The offending podSpecs will not create pods. Inspecting the Deployment resource with kubectl get deploy <DEPLOYMENT_NAME> -oyaml will expose the message from the failed pod(s) .status.conditions element, as seen below. ... status : conditions : - lastTransitionTime : \"2022-01-20T01:02:08Z\" lastUpdateTime : \"2022-01-20T01:02:08Z\" message : 'pods \"test-688f68dc87-tw587\" is forbidden: violates PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"test\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"test\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"test\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"test\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")' reason : FailedCreate status : \"True\" type : ReplicaFailure ... In both the audit and warn modes, the pod restrictions do not prevent violating pods from being created and started. However, in these modes audit annotations on API server audit log events and warnings to API server clients, such as kubectl , are triggered, respectively, when pods, as well as objects that create pods, contain podSpecs with violations. A kubectl Warning message is seen below. Warning: would violate PodSecurity \"restricted:latest\" : allowPrivilegeEscalation ! = false ( container \"test\" must set securityContext.allowPrivilegeEscalation = false ) , unrestricted capabilities ( container \"test\" must set securityContext.capabilities.drop =[ \"ALL\" ]) , runAsNonRoot ! = true ( pod or container \"test\" must set securityContext.runAsNonRoot = true ) , seccompProfile ( pod or container \"test\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\" ) deployment.apps/test created The PSA audit and warn modes are useful when introducing the PSS without negatively impacting cluster operations. The PSA operational modes are not mutually exclusive, and can be used in a cumulative manner. As seen below, the multiple modes can be configured in a single namespace. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/audit : restricted pod-security.kubernetes.io/enforce : restricted pod-security.kubernetes.io/warn : restricted In the above example, the user-friendly warnings and audit annotations are provided when applying Deployments, while the enforce of violations are also provided at the pod level. In fact multiple PSA labels can use different profile levels, as seen below. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/enforce : baseline pod-security.kubernetes.io/warn : restricted In the above example, PSA is configured to allow the creation of all pods that satisfy the baseline profile level, and then warn on pods (and objects that create pods) that violate the restricted profile level. This is a useful approach to determine the possible impacts when changing from the baseline to restricted profiles.","title":"Pod Security Standards (PSS) and Pod Security Admission (PSA)"},{"location":"security/docs/pods/#existing-pods","text":"If a namespace with existing pods is modified to use a more restrictive PSS profile, the audit and warn modes will produce appropriate messages; however, enforce mode will not delete the pods. The warning messages are seen below. Warning: existing pods in namespace \"policy-test\" violate the new PodSecurity enforce level \"restricted:latest\" Warning: test-688f68dc87-htm8x: allowPrivilegeEscalation ! = false, unrestricted capabilities, runAsNonRoot ! = true, seccompProfile namespace/policy-test configured","title":"Existing Pods"},{"location":"security/docs/pods/#exemptions","text":"PSA uses Exemptions to exclude enforcement of violations against pods that would have otherwise been applied. These exemptions are listed below. Usernames: requests from users with an exempt authenticated (or impersonated) username are ignored. RuntimeClassNames: pods and workload resources specifying an exempt runtime class name are ignored. Namespaces: pods and workload resources in an exempt namespace are ignored. These exemptions are applied statically in the PSA admission controller configuration as part of the API server configuration. In the Validating Webhook implementation the exemptions can be configured within a Kubernetes ConfigMap resource that gets mounted as a volume into the pod-security-webhook container. apiVersion : v1 kind : ConfigMap metadata : name : pod-security-webhook namespace : pod-security-webhook data : podsecurityconfiguration.yaml : | apiVersion: pod-security.admission.config.k8s.io/v1beta1 kind: PodSecurityConfiguration defaults: enforce: \"restricted\" enforce-version: \"latest\" audit: \"restricted\" audit-version: \"latest\" warn: \"restricted\" warn-version: \"latest\" exemptions: # Array of authenticated usernames to exempt. usernames: [] # Array of runtime class names to exempt. runtimeClasses: [] # Array of namespaces to exempt. namespaces: [\"kube-system\",\"policy-test1\"] As seen in the above ConfigMap YAML the cluster-wide default PSS level has been set to restricted for all PSA modes, audit , enforce , and warn . This affects all namespaces, except those exempted: namespaces: [\"kube-system\",\"policy-test1\"] . Additionally, in the ValidatingWebhookConfiguration resource, seen below, the pod-security-webhook namespace is also exempted from configured PSS. ... webhooks : # Audit annotations will be prefixed with this name - name : \"pod-security-webhook.kubernetes.io\" # Fail-closed admission webhooks can present operational challenges. # You may want to consider using a failure policy of Ignore, but should # consider the security tradeoffs. failurePolicy : Fail namespaceSelector : # Exempt the webhook itself to avoid a circular dependency. matchExpressions : - key : kubernetes.io/metadata.name operator : NotIn values : [ \"pod-security-webhook\" ] ... Attention As of Kubernetes versions 1.22 and 1.23 , the Pod Security Admission feature is alpha and beta status, respectively. At least until GA, the current admission controller can be used via a validating webhook, configured from these instructions .","title":"Exemptions"},{"location":"security/docs/pods/#choosing-between-policy-as-code-and-pod-security-standards","text":"The Pod Security Standards (PSS) were developed to replace the Pod Security Policy (PSP), by providing a solution that was built-in to Kubernetes and did not require solutions from the Kubernetes ecosystem. That being said, policy-as-code (PAC) solutions are considerably more flexible. The following list of Pros and Cons is designed help you make a more informed decision about your pod security solution. Policy-as-code (as compared to Pod Security Standards) Pros: More flexible and more granular (down to attributes of resources if need be) Not just focused on pods, can be used against different resources and actions Not just applied at the namespace level More mature than the Pod Security Standards Decisions can be based on anything in the API server request payload, as well as existing cluster resources and external data (solution dependent) Supports mutating API server requests before validation (solution dependent) Can generate complementary policies and Kubernetes resources (solution dependent - From pod policies, Kyverno can auto-gen policies for higher-level controllers, such as Deployments. Kyverno can also generate additional Kubernetes resources \"when a new resource is created or when the source is updated\" by using Generate Rules .) Can be used to shift left, into CICD pipelines, before making calls to the Kubernetes API server (solution dependent) Can be used to implement behaviors that are not necessarily security related, such as best practices, organizational standards, etc. Can be used in non-Kubernetes use cases (solution dependent) Because of flexibility, the user experience can be tuned to users' needs Cons: Not built into Kubernetes More complex to learn, configure, and support Policy authoring may require new skills/languages/capabilities Pod Security Admission (as compared to policy-as-code) Pros: Built into Kubernetes Simpler to configure No new languages to use or policies to author If the cluster default admission level is configured to privileged , namespace labels can be used to opt namespaces into the pod security profiles. Cons: Not as flexible or granular as policy-as-code Only 3 levels of restrictions Primarily focused on pods","title":"Choosing between policy-as-code and Pod Security Standards"},{"location":"security/docs/pods/#summary","text":"If you currently do not have a pod security solution, beyond PSP, and your required pod security posture fits the model defined in the Pod Security Standards (PSS), then an easier path may be to adopt the PSS, in lieu of a policy-as-code solution. However, if your pod security posture does not fit the PSS model, or you envision adding additional controls, beyond that defined by PSS, then a policy-as-code solution would seem a better fit.","title":"Summary"},{"location":"security/docs/pods/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/pods/#use-multiple-pod-security-admission-psa-modes-for-a-better-user-experience","text":"As mentioned earlier, PSA enforce mode prevents pods with PSS violations from being applied, but does not stop higher-level controllers, such as Deployments. In fact, the Deployment will be applied successfully without any indication that the pods failed to be applied. While you can use kubectl to inspect the Deployment object, and discover the failed pods message from the PSA, the user experience could be better. To make the user experience better, multiple PSA modes (audit, enforce, warn) should be used. apiVersion : v1 kind : Namespace metadata : name : policy-test labels : pod-security.kubernetes.io/audit : restricted pod-security.kubernetes.io/enforce : restricted pod-security.kubernetes.io/warn : restricted In the above example, with enforce mode defined, when a Deployment manifest with PSS violations in the respective podSpec is attempted to be applied to the Kubernetes API server, the Deployment will be successfully applied, but the pods will not. And, since the audit and warn modes are also enabled, the API server client will receive a warning message and the API server audit log event will be annotated with a message as well.","title":"Use multiple Pod Security Admission (PSA) modes for a better user experience"},{"location":"security/docs/pods/#restrict-the-containers-that-can-run-as-privileged","text":"As mentioned, containers that run as privileged inherit all of the Linux capabilities assigned to root on the host. Seldom do containers need these types of privileges to function properly. There are multiple methods that can be used to restrict the permissions and capabilities of containers. Attention Fargate is a launch type that enables you to run \"serverless\" container(s) where the containers of a pod are run on infrastructure that AWS manages. With Fargate, you cannot run a privileged container or configure your pod to use hostNetwork or hostPort.","title":"Restrict the containers that can run as privileged"},{"location":"security/docs/pods/#do-not-run-processes-in-containers-as-root","text":"All containers run as root by default. This could be problematic if an attacker is able to exploit a vulnerability in the application and get shell access to the running container. You can mitigate this risk a variety of ways. First, by removing the shell from the container image. Second, adding the USER directive to your Dockerfile or running the containers in the pod as a non-root user. The Kubernetes podSpec includes a set of fields, under spec.securityContext , that let you specify the user and/or group under which to run your application. These fields are runAsUser and runAsGroup respectively. To enforce the use of the spec.securityContext , and its associated elements, within the Kubernetes podSpec, policy-as-code or Pod Security Standards can be added to clusters. These solutions allow you to write and/or use policies or profiles that can validate inbound Kubernetes API server request payloads, before they are persisted into etcd. Furthermore, policy-as-code solutions can mutate inbound requests, and in some cases, generate new requests.","title":"Do not run processes in containers as root"},{"location":"security/docs/pods/#never-run-docker-in-docker-or-mount-the-socket-in-the-container","text":"While this conveniently lets you to build/run images in Docker containers, you're basically relinquishing complete control of the node to the process running in the container. If you need to build container images on Kubernetes use Kaniko , buildah , img , or a build service like CodeBuild instead. Tip Kubernetes clusters used for CICD processing, such as building container images, should be isolated from clusters running more generalized workloads.","title":"Never run Docker in Docker or mount the socket in the container"},{"location":"security/docs/pods/#restrict-the-use-of-hostpath-or-if-hostpath-is-necessary-restrict-which-prefixes-can-be-used-and-configure-the-volume-as-read-only","text":"hostPath is a volume that mounts a directory from the host directly to the container. Rarely will pods need this type of access, but if they do, you need to be aware of the risks. By default pods that run as root will have write access to the file system exposed by hostPath. This could allow an attacker to modify the kubelet settings, create symbolic links to directories or files not directly exposed by the hostPath, e.g. /etc/shadow, install ssh keys, read secrets mounted to the host, and other malicious things. To mitigate the risks from hostPath, configure the spec.containers.volumeMounts as readOnly , for example: volumeMounts : - name : hostPath-volume readOnly : true mountPath : /host-path You should also use policy-as-code solutions to restrict the directories that can be used by hostPath volumes, or prevent hostPath usage altogether. You can use the Pod Security Standards Baseline or Restricted policies to prevent the use of hostPath . For further information about the dangers of privileged escalation, read Seth Art's blog Bad Pods: Kubernetes Pod Privilege Escalation .","title":"Restrict the use of hostPath or if hostPath is necessary restrict which prefixes can be used and configure the volume as read-only"},{"location":"security/docs/pods/#set-requests-and-limits-for-each-container-to-avoid-resource-contention-and-dos-attacks","text":"A pod without requests or limits can theoretically consume all of the resources available on a host. As additional pods are scheduled onto a node, the node may experience CPU or memory pressure which can cause the Kubelet to terminate or evict pods from the node. While you can\u2019t prevent this from happening all together, setting requests and limits will help minimize resource contention and mitigate the risk from poorly written applications that consume an excessive amount of resources. The podSpec allows you to specify requests and limits for CPU and memory. CPU is considered a compressible resource because it can be oversubscribed. Memory is incompressible, i.e. it cannot be shared among multiple containers. When you specify requests for CPU or memory, you\u2019re essentially designating the amount of memory that containers are guaranteed to get. Kubernetes aggregates the requests of all the containers in a pod to determine which node to schedule the pod onto. If a container exceeds the requested amount of memory it may be subject to termination if there\u2019s memory pressure on the node. Limits are the maximum amount of CPU and memory resources that a container is allowed to consume and directly corresponds to the memory.limit_in_bytes value of the cgroup created for the container. A container that exceeds the memory limit will be OOM killed. If a container exceeds its CPU limit, it will be throttled. Tip When using container resources.limits it is strongly recommended that container resource usage (a.k.a. Resource Footprints) be data-driven and accurate, based on load testing. Absent an accurate and trusted resource footprint, container resources.limits can be padded. For example, resources.limits.memory could be padded 20-30% higher than observable maximums, to account for potential memory resource limit inaccuracies. Kubernetes uses three Quality of Service (QoS) classes to prioritize the workloads running on a node. These include: guaranteed burstable best-effort If limits and requests are not set, the pod is configured as best-effort (lowest priority). Best-effort pods are the first to get killed when there is insufficient memory. If limits are set on all containers within the pod, or if the requests and limits are set to the same values and not equal to 0, the pod is configured as guaranteed (highest priority). Guaranteed pods will not be killed unless they exceed their configured memory limits. If the limits and requests are configured with different values and not equal to 0, or one container within the pod sets limits and the others don\u2019t or have limits set for different resources, the pods are configured as burstable (medium priority). These pods have some resource guarantees, but can be killed once they exceed their requested memory. Attention Requests don't affect the memory_limit_in_bytes value of the container's cgroup; the cgroup limit is set to the amount of memory available on the host. Nevertheless, setting the requests value too low could cause the pod to be targeted for termination by the kubelet if the node undergoes memory pressure. Class Priority Condition Kill Condition Guaranteed highest limit = request != 0 Only exceed memory limits Burstable medium limit != request != 0 Can be killed if exceed request memory Best-Effort lowest limit & request Not Set First to get killed when there's insufficient memory For additional information about resource QoS, please refer to the Kubernetes documentation . You can force the use of requests and limits by setting a resource quota on a namespace or by creating a limit range . A resource quota allows you to specify the total amount of resources, e.g. CPU and RAM, allocated to a namespace. When it\u2019s applied to a namespace, it forces you to specify requests and limits for all containers deployed into that namespace. By contrast, limit ranges give you more granular control of the allocation of resources. With limit ranges you can min/max for CPU and memory resources per pod or per container within a namespace. You can also use them to set default request/limit values if none are provided. Policy-as-code solutions can be used enforce requests and limits. or to even create the resource quotas and limit ranges when namespaces are created.","title":"Set requests and limits for each container to avoid resource contention and DoS attacks"},{"location":"security/docs/pods/#do-not-allow-privileged-escalation","text":"Privileged escalation allows a process to change the security context under which its running. Sudo is a good example of this as are binaries with the SUID or SGID bit. Privileged escalation is basically a way for users to execute a file with the permissions of another user or group. You can prevent a container from using privileged escalation by implementing a policy-as-code mutating policy that sets allowPrivilegeEscalation to false or by setting securityContext.allowPrivilegeEscalation in the podSpec . Policy-as-code policies can also be used to prevent API server requests from succeeding if incorrect settings are detected. Pod Security Standards can also be used to prevent pods from using privilege escalation.","title":"Do not allow privileged escalation"},{"location":"security/docs/pods/#disable-serviceaccount-token-mounts","text":"For pods that do not need to access the Kubernetes API, you can disable the automatic mounting of a ServiceAccount token on a pod spec, or for all pods that use a particular ServiceAccount. Attention Disabling ServiceAccount mounting does not prevent a pod from having network access to the Kubernetes API. To prevent a pod from having any network access to the Kubernetes API, you will need to modify the EKS cluster endpoint access and use NetworkPolicy to block pod access apiVersion : v1 kind : Pod metadata : name : pod-no-automount spec : automountServiceAccountToken : false apiVersion : v1 kind : ServiceAccount metadata : name : sa-no-automount automountServiceAccountToken : false","title":"Disable ServiceAccount token mounts"},{"location":"security/docs/pods/#disable-service-discovery","text":"For pods that do not need to lookup or call in-cluster services, you can reduce the amount of information given to a pod. You can set the Pod's DNS policy to not use CoreDNS, and not expose services in the pod's namespace as environment variables. See the Kubernetes docs on environment variables for more information on service links. The default value for a pod's DNS policy is \"ClusterFirst\" which uses in-cluster DNS, while the non-default value \"Default\" uses the underlying node's DNS resolution. See the Kubernetes docs on Pod DNS policy for more information. Attention Disabling service links and changing the pod's DNS policy does not prevent a pod from having network access to the in-cluster DNS service. An attacker can still enumerate services in a cluster by reaching the in-cluster DNS service. (ex: dig SRV *.*.svc.cluster.local @$CLUSTER_DNS_IP ) To prevent in-cluster service discovery, use NetworkPolicy to block pod access apiVersion : v1 kind : Pod metadata : name : pod-no-service-info spec : dnsPolicy : Default # \"Default\" is not the true default value enableServiceLinks : false","title":"Disable service discovery"},{"location":"security/docs/pods/#configure-your-images-with-read-only-root-file-system","text":"Configuring your images with a read-only root file system prevents an attacker from overwriting a binary on the file system that your application uses. If your application has to write to the file system, consider writing to a temporary directory or attach and mount a volume. You can enforce this by setting the pod's SecurityContext as follows: ... securityContext : readOnlyRootFilesystem : true ... Policy-as-code and Pod Security Standards can be used to enforce this behavior. Info As per Windows containers in Kubernetes securityContext.readOnlyRootFilesystem cannot be set to true for a container running on Windows as write access is required for registry and system processes to run inside the container.","title":"Configure your images with read-only root file system"},{"location":"security/docs/pods/#tools-and-resources","text":"open-policy-agent/gatekeeper-library: The OPA Gatekeeper policy library a library of OPA/Gatekeeper policies that you can use as a substitute for PSPs. Kyverno Policy Library A collection of common OPA and Kyverno policies for EKS. Policy based countermeasures: part 1 Policy based countermeasures: part 2 Pod Security Policy Migrator a tool that converts PSPs to OPA/Gatekeeper, KubeWarden, or Kyverno policies","title":"Tools and Resources"},{"location":"security/docs/runtime/","text":"Runtime security \u00b6 Runtime security provides active protection for your containers while they're running. The idea is to detect and/or prevent malicious activity from occurring inside the container. With secure computing (seccomp) you can prevent a containerized application from making certain syscalls to the underlying host operating system's kernel. While the Linux operating system has a few hundred system calls, the lion's share of them are not necessary for running containers. By restricting what syscalls can be made by a container, you can effectively decrease your application's attack surface. To get started with seccomp, use strace to generate a stack trace to see which system calls your application is making, then use a tool such as syscall2seccomp to create a seccomp profile from the data gathered from the trace. Unlike SELinux, seccomp was not designed to isolate containers from each other, however, it will protect the host kernel from unauthorized syscalls. It works by intercepting syscalls and only allowing those that have been allowlisted to pass through. Docker has a default seccomp profile which is suitable for a majority of general purpose workloads. You can configure your container or Pod to use this profile by adding the following annotation to your container's or Pod's spec (pre-1.19): annotations : seccomp . security . alpha . kubernetes . io /pod: \"runtime/ default \" 1.19 and later: securityContext : seccompProfile : type : RuntimeDefault It's also possible to create your own profiles for things that require additional privileges. Caution seccomp profiles are a Kubelet alpha feature. You'll need to add the --seccomp-profile-root flag to the Kubelet arguments to make use of this feature. AppArmor is similar to seccomp, only it restricts an container's capabilities including accessing parts of the file system. It can be run in either enforcement or complain mode. Since building Apparmor profiles can be challenging, it is recommended you use a tool like bane instead. Attention Apparmor is only available Ubuntu/Debian distributions of Linux. Attention Kubernetes does not currently provide any native mechanisms for loading AppArmor or seccomp profiles onto Nodes. They either have to be loaded manually or installed onto Nodes when they are bootstrapped. This has to be done prior to referencing them in your Pods because the scheduler is unaware of which nodes have profiles. Recommendations \u00b6 Use a 3rd party solution for runtime defense \u00b6 Creating and managing seccomp and Apparmor profiles can be difficult if you're not familiar with Linux security. If you don't have the time to become proficient, consider using a commercial solution. A lot of them have moved beyond static profiles like Apparmor and seccomp and have begun using machine learning to block or alert on suspicious activity. A handful of these solutions can be found below in the tools section. Additional options can be found on the AWS Marketplace for Containers . Consider add/dropping Linux capabilities before writing seccomp policies \u00b6 Capabilities involve various checks in kernel functions reachable by syscalls. If the check fails, the syscall typically returns an error. The check can be done either right at the beginning of a specific syscall, or deeper in the kernel in areas that might be reachable through multiple different syscalls (such as writing to a specific privileged file). Seccomp, on the other hand, is a syscall filter which is applied to all syscalls before they are run. A process can set up a filter which allows them to revoke their right to run certain syscalls, or specific arguments for certain syscalls. Before using seccomp, consider whether adding/removing Linux capabilities gives you the control you need. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-capabilities-for-a-container for further information. See whether you can accomplish your aims by using Pod Security Policies (PSPs) \u00b6 Pod Security Policies offer a lot of different ways to improve your security posture without introducing undue complexity. Explore the options available in PSPs before venturing into building seccomp and Apparmor profiles. Warning As of Kubernetes 1.25, PSPs have been removed and replaced with the Pod Security Admission controller. Third-party alternatives which exist include OPA/Gatekeeper and Kyverno. A collection of Gatekeeper constraints and constraint templates for implementing policies commonly found in PSPs can be pulled from the Gatekeeper library repository on GitHub. And many replacements for PSPs can be found in the Kyverno policy library including the full collection of Pod Security Standards . Additional Resources \u00b6 7 things you should know before you start AppArmor Loader Setting up nodes with profiles zaz A command-line tool to assist on assessing container security requirements and generating seccomp profiles seccomp-operator Is similar to the AppArmor Loader, only instead of AppArmor profiles, it creates a seccomp profiles on each host Tools \u00b6 Aqua Qualys Stackrox Sysdig Secure Prisma","title":"Runtime Security"},{"location":"security/docs/runtime/#runtime-security","text":"Runtime security provides active protection for your containers while they're running. The idea is to detect and/or prevent malicious activity from occurring inside the container. With secure computing (seccomp) you can prevent a containerized application from making certain syscalls to the underlying host operating system's kernel. While the Linux operating system has a few hundred system calls, the lion's share of them are not necessary for running containers. By restricting what syscalls can be made by a container, you can effectively decrease your application's attack surface. To get started with seccomp, use strace to generate a stack trace to see which system calls your application is making, then use a tool such as syscall2seccomp to create a seccomp profile from the data gathered from the trace. Unlike SELinux, seccomp was not designed to isolate containers from each other, however, it will protect the host kernel from unauthorized syscalls. It works by intercepting syscalls and only allowing those that have been allowlisted to pass through. Docker has a default seccomp profile which is suitable for a majority of general purpose workloads. You can configure your container or Pod to use this profile by adding the following annotation to your container's or Pod's spec (pre-1.19): annotations : seccomp . security . alpha . kubernetes . io /pod: \"runtime/ default \" 1.19 and later: securityContext : seccompProfile : type : RuntimeDefault It's also possible to create your own profiles for things that require additional privileges. Caution seccomp profiles are a Kubelet alpha feature. You'll need to add the --seccomp-profile-root flag to the Kubelet arguments to make use of this feature. AppArmor is similar to seccomp, only it restricts an container's capabilities including accessing parts of the file system. It can be run in either enforcement or complain mode. Since building Apparmor profiles can be challenging, it is recommended you use a tool like bane instead. Attention Apparmor is only available Ubuntu/Debian distributions of Linux. Attention Kubernetes does not currently provide any native mechanisms for loading AppArmor or seccomp profiles onto Nodes. They either have to be loaded manually or installed onto Nodes when they are bootstrapped. This has to be done prior to referencing them in your Pods because the scheduler is unaware of which nodes have profiles.","title":"Runtime security"},{"location":"security/docs/runtime/#recommendations","text":"","title":"Recommendations"},{"location":"security/docs/runtime/#use-a-3rd-party-solution-for-runtime-defense","text":"Creating and managing seccomp and Apparmor profiles can be difficult if you're not familiar with Linux security. If you don't have the time to become proficient, consider using a commercial solution. A lot of them have moved beyond static profiles like Apparmor and seccomp and have begun using machine learning to block or alert on suspicious activity. A handful of these solutions can be found below in the tools section. Additional options can be found on the AWS Marketplace for Containers .","title":"Use a 3rd party solution for runtime defense"},{"location":"security/docs/runtime/#consider-adddropping-linux-capabilities-before-writing-seccomp-policies","text":"Capabilities involve various checks in kernel functions reachable by syscalls. If the check fails, the syscall typically returns an error. The check can be done either right at the beginning of a specific syscall, or deeper in the kernel in areas that might be reachable through multiple different syscalls (such as writing to a specific privileged file). Seccomp, on the other hand, is a syscall filter which is applied to all syscalls before they are run. A process can set up a filter which allows them to revoke their right to run certain syscalls, or specific arguments for certain syscalls. Before using seccomp, consider whether adding/removing Linux capabilities gives you the control you need. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-capabilities-for-a-container for further information.","title":"Consider add/dropping Linux capabilities before writing seccomp policies"},{"location":"security/docs/runtime/#see-whether-you-can-accomplish-your-aims-by-using-pod-security-policies-psps","text":"Pod Security Policies offer a lot of different ways to improve your security posture without introducing undue complexity. Explore the options available in PSPs before venturing into building seccomp and Apparmor profiles. Warning As of Kubernetes 1.25, PSPs have been removed and replaced with the Pod Security Admission controller. Third-party alternatives which exist include OPA/Gatekeeper and Kyverno. A collection of Gatekeeper constraints and constraint templates for implementing policies commonly found in PSPs can be pulled from the Gatekeeper library repository on GitHub. And many replacements for PSPs can be found in the Kyverno policy library including the full collection of Pod Security Standards .","title":"See whether you can accomplish your aims by using Pod Security Policies (PSPs)"},{"location":"security/docs/runtime/#additional-resources","text":"7 things you should know before you start AppArmor Loader Setting up nodes with profiles zaz A command-line tool to assist on assessing container security requirements and generating seccomp profiles seccomp-operator Is similar to the AppArmor Loader, only instead of AppArmor profiles, it creates a seccomp profiles on each host","title":"Additional Resources"},{"location":"security/docs/runtime/#tools","text":"Aqua Qualys Stackrox Sysdig Secure Prisma","title":"Tools"},{"location":"windows/docs/ami/","text":"Amazon EKS optimized Windows AMI management \u00b6 The Amazon EKS optimized AMI is built on top of Windows Server 2019, and is configured to serve as the base image for Amazon EKS Windows nodes. The AMI is configured to work with Amazon EKS out of the box, and it includes Docker, the kubelet, and the AWS IAM Authenticator. You can programmatically retrieve the Amazon Machine Image (AMI) ID for Amazon EKS optimized AMIs by querying the AWS Systems Manager Parameter Store API. This parameter eliminates the need for you to manually look up Amazon EKS optimized AMI IDs. For more information about the Systems Manager Parameter Store API, see GetParameter . Your user account must have the ssm:GetParameter IAM permission to retrieve the Amazon EKS optimized AMI metadata. The following example retrieves the AMI ID for the latest Amazon EKS optimized AMI for Windows Server 2019 LTSC Core. The version number listed in the AMI name relates to the corresponding Kubernetes build it is prepared for. aws ssm get-parameter --name /aws/service/ami-windows-latest/Windows_Server-2019-English-Core-EKS_Optimized-1.21/image_id --region us-east-1 --query \"Parameter.Value\" --output text Example output: ami-09770b3eec4552d4e Managing your own Amazon EKS optimized Windows AMI \u00b6 An essential step towards production environments is maintaining the same Amazon EKS optimized Windows AMI and kubelet version across the Amazon EKS cluster. Using the same version across the Amazon EKS cluster reduces the time during troubleshooting and increases cluster consistency. Amazon EC2 Image Builder helps create and maintain custom Amazon EKS optimized Windows AMIs to be used across an Amazon EKS cluster. Use Amazon EC2 Image Builder to select between Windows Server versions, AWS Windows Server AMI release dates, and/or OS build version. The build components step, allows you to select between existing EKS Optimized Windows Artifacts as well as the kubelet versions. For more information: https://docs.aws.amazon.com/eks/latest/userguide/eks-custom-ami-windows.html NOTE: Prior to selecting a base image, consult the Windows Server Version and License section for important details pertaining to release channel updates. Configuring faster launching for custom EKS optimized AMIs \u00b6 When using a custom EKS Optimized AMI, Windows worker nodes can be launched up to 65% faster by enabling the Fast Launch feature. This feature maintains a set of pre-provisioned snapshots which have the Sysprep specialize , Windows Out of Box Experience (OOBE) steps and required reboots already completed. These snapshots are then used on subsequent launches, reducing the time to scale-out or replace nodes. Fast Launch can be only enabled for AMIs you own through the EC2 console or in the AWS CLI and the number of snapshots maintained is configurable. Warning Fast Launch is not compatible with the default Amazon-provided EKS optimized AMI, create a custom AMI as above before attempting to enable it. For more information: AWS Windows AMIs - Configure your AMI for faster launching Caching Windows base layers on custom AMIs \u00b6 Windows container images are larger than their Linux counterparts. A base image of Windows Server 2019 LTSC Core is 5.74GB on disk. If you are running the full suite of .NET Framework 4.8 on the same base image, the size grows to 8.24GB. It is essential to implement a Windows base layer caching strategy while using Auto-Scaling through Cluster Autoscaler in order to avoid delays during a pod launch on a new Windows node. Pulling the image from the repository isn't an expensive operation for the OS; however, the extraction operation may take minutes depending on the size and number of layers an image contains. As mentioned in the Patching Windows Server and Container topic, there is an option to build a custom AMI with EKS. During the AMI preparation, you can add an additional EC2 Image builder component to pull all the necessary Windows container images locally and then generate the AMI. This strategy will drastically reduce the time a pod reaches the status Running . On Amazon EC2 Image Builder, create a component to download the necessary images and attach it to the Image recipe. The following example pulls a specific image from a ECR repository. name : DockerPull description : This component pulls the necessary containers images for a cache strategy . schemaVersion : 1.0 phases : - name : build steps : - name : Dockerpull action : ExecutePowerShell inputs : commands : - Set - ExecutionPolicy Unrestricted - Force - ( Get - ECRLoginCommand ). Password | docker login -- username AWS -- password - stdin 111000111000 . dkr . ecr . us - east - 1 . amazonaws . com - docker pull 111000111000 . dkr . ecr . us - east - 1 . amazonaws . com / fluentd - windows - servercore - ltsc2019 To make sure the following component works as expected, check if the IAM role used by EC2 Image builder (EC2InstanceProfileForImageBuilder) has the attached policies:","title":"AMI Management"},{"location":"windows/docs/ami/#amazon-eks-optimized-windows-ami-management","text":"The Amazon EKS optimized AMI is built on top of Windows Server 2019, and is configured to serve as the base image for Amazon EKS Windows nodes. The AMI is configured to work with Amazon EKS out of the box, and it includes Docker, the kubelet, and the AWS IAM Authenticator. You can programmatically retrieve the Amazon Machine Image (AMI) ID for Amazon EKS optimized AMIs by querying the AWS Systems Manager Parameter Store API. This parameter eliminates the need for you to manually look up Amazon EKS optimized AMI IDs. For more information about the Systems Manager Parameter Store API, see GetParameter . Your user account must have the ssm:GetParameter IAM permission to retrieve the Amazon EKS optimized AMI metadata. The following example retrieves the AMI ID for the latest Amazon EKS optimized AMI for Windows Server 2019 LTSC Core. The version number listed in the AMI name relates to the corresponding Kubernetes build it is prepared for. aws ssm get-parameter --name /aws/service/ami-windows-latest/Windows_Server-2019-English-Core-EKS_Optimized-1.21/image_id --region us-east-1 --query \"Parameter.Value\" --output text Example output: ami-09770b3eec4552d4e","title":"Amazon EKS optimized Windows AMI management"},{"location":"windows/docs/ami/#managing-your-own-amazon-eks-optimized-windows-ami","text":"An essential step towards production environments is maintaining the same Amazon EKS optimized Windows AMI and kubelet version across the Amazon EKS cluster. Using the same version across the Amazon EKS cluster reduces the time during troubleshooting and increases cluster consistency. Amazon EC2 Image Builder helps create and maintain custom Amazon EKS optimized Windows AMIs to be used across an Amazon EKS cluster. Use Amazon EC2 Image Builder to select between Windows Server versions, AWS Windows Server AMI release dates, and/or OS build version. The build components step, allows you to select between existing EKS Optimized Windows Artifacts as well as the kubelet versions. For more information: https://docs.aws.amazon.com/eks/latest/userguide/eks-custom-ami-windows.html NOTE: Prior to selecting a base image, consult the Windows Server Version and License section for important details pertaining to release channel updates.","title":"Managing your own Amazon EKS optimized Windows AMI"},{"location":"windows/docs/ami/#configuring-faster-launching-for-custom-eks-optimized-amis","text":"When using a custom EKS Optimized AMI, Windows worker nodes can be launched up to 65% faster by enabling the Fast Launch feature. This feature maintains a set of pre-provisioned snapshots which have the Sysprep specialize , Windows Out of Box Experience (OOBE) steps and required reboots already completed. These snapshots are then used on subsequent launches, reducing the time to scale-out or replace nodes. Fast Launch can be only enabled for AMIs you own through the EC2 console or in the AWS CLI and the number of snapshots maintained is configurable. Warning Fast Launch is not compatible with the default Amazon-provided EKS optimized AMI, create a custom AMI as above before attempting to enable it. For more information: AWS Windows AMIs - Configure your AMI for faster launching","title":"Configuring faster launching for custom EKS optimized AMIs"},{"location":"windows/docs/ami/#caching-windows-base-layers-on-custom-amis","text":"Windows container images are larger than their Linux counterparts. A base image of Windows Server 2019 LTSC Core is 5.74GB on disk. If you are running the full suite of .NET Framework 4.8 on the same base image, the size grows to 8.24GB. It is essential to implement a Windows base layer caching strategy while using Auto-Scaling through Cluster Autoscaler in order to avoid delays during a pod launch on a new Windows node. Pulling the image from the repository isn't an expensive operation for the OS; however, the extraction operation may take minutes depending on the size and number of layers an image contains. As mentioned in the Patching Windows Server and Container topic, there is an option to build a custom AMI with EKS. During the AMI preparation, you can add an additional EC2 Image builder component to pull all the necessary Windows container images locally and then generate the AMI. This strategy will drastically reduce the time a pod reaches the status Running . On Amazon EC2 Image Builder, create a component to download the necessary images and attach it to the Image recipe. The following example pulls a specific image from a ECR repository. name : DockerPull description : This component pulls the necessary containers images for a cache strategy . schemaVersion : 1.0 phases : - name : build steps : - name : Dockerpull action : ExecutePowerShell inputs : commands : - Set - ExecutionPolicy Unrestricted - Force - ( Get - ECRLoginCommand ). Password | docker login -- username AWS -- password - stdin 111000111000 . dkr . ecr . us - east - 1 . amazonaws . com - docker pull 111000111000 . dkr . ecr . us - east - 1 . amazonaws . com / fluentd - windows - servercore - ltsc2019 To make sure the following component works as expected, check if the IAM role used by EC2 Image builder (EC2InstanceProfileForImageBuilder) has the attached policies:","title":"Caching Windows base layers on custom AMIs"},{"location":"windows/docs/gmsa/","text":"Configure gMSA for Windows Pods and containers \u00b6 What is a gMSA account \u00b6 Windows-based applications such as .NET applications often use Active Directory as an identity provider, providing authorization/authentication using NTLM or Kerberos protocol. An application server to exchange Kerberos tickets with Active Directory requires to be domain-joined. Windows containers don\u2019t support domain joins and would not make much sense as containers are ephemeral resources, creating a burden on the Active Directory RID pool. However, administrators can leverage gMSA Active Directory accounts to negotiate a Windows authentication for resources such as Windows containers, NLB, and server farms. Windows container and gMSA use case \u00b6 ASP.NET applications that leverage on Windows authentication, and run as Windows containers, benefit from gMSA because the Windows Node is used to exchange the Kerberos ticket on behalf of the container. However, the dockerfile used to build the Windows container image needs configure IIS and enable Windows authentication. The following steps will set up IIS for Windows Authentication: Install the Windows-Auth feature on IIS as it isn't installed by default on a Windows image Setup the IIS Application pool to run under a Network Account Disable anonymousAuthentication which is enabled by default Enable Windows Authentication RUN Install-WindowsFeature -Name Web-Windows-Auth -IncludeAllSubFeature RUN Import-Module WebAdministration ; Set-ItemProperty 'IIS:\\AppPools\\SiteName' -name processModel.identityType -value 2 RUN Import-Module WebAdministration ; Set-WebConfigurationProperty -Filter '/system.webServer/security/authentication/anonymousAuthentication' -Name Enabled -Value False -PSPath 'IIS:\\' -Location 'SiteName' RUN Import-Module WebAdministration ; Set-WebConfigurationProperty -Filter '/system.webServer/security/authentication/windowsAuthentication' -Name Enabled -Value True -PSPath 'IIS:\\' -Location 'SiteName' Enabling gMSA on Amazon EKS cluster \u00b6 In November 2020, AWS published a step-by-step on how to set up an Amazon EKS cluster to use gMSA. This guide can be used for any scenario that requires Active Directory authentication, including the use cases mentioned above. The blog post walks-through: Creating an EKS cluster with self-managed Windows worker nodes Joining the Windows worker node to an Active Directory Domain Creating and configure gMSA accounts on Active Directory Domain Installing the gMSA CredentialSpec CRD Installing the Windows gMSA Webhook Admission controller Creating gMSA credential spec resources Creating a Kubernetes ClusterRole to be defined for each gMSA credential spec Assigning the Kubernetes ClusterRole to a service accounts to use specific gMSA credential specs Configuring DNS forwarder with CoreDNS Configuring the gMSA credential spec in the Windows pod spec Testing the Windows Authentication from inside the Windows pod Blog link: https://aws.amazon.com/blogs/containers/windows-authentication-on-amazon-eks-windows-pods/","title":"gMSA for Windows Containers"},{"location":"windows/docs/gmsa/#configure-gmsa-for-windows-pods-and-containers","text":"","title":"Configure gMSA for Windows Pods and containers"},{"location":"windows/docs/gmsa/#what-is-a-gmsa-account","text":"Windows-based applications such as .NET applications often use Active Directory as an identity provider, providing authorization/authentication using NTLM or Kerberos protocol. An application server to exchange Kerberos tickets with Active Directory requires to be domain-joined. Windows containers don\u2019t support domain joins and would not make much sense as containers are ephemeral resources, creating a burden on the Active Directory RID pool. However, administrators can leverage gMSA Active Directory accounts to negotiate a Windows authentication for resources such as Windows containers, NLB, and server farms.","title":"What is a gMSA account"},{"location":"windows/docs/gmsa/#windows-container-and-gmsa-use-case","text":"ASP.NET applications that leverage on Windows authentication, and run as Windows containers, benefit from gMSA because the Windows Node is used to exchange the Kerberos ticket on behalf of the container. However, the dockerfile used to build the Windows container image needs configure IIS and enable Windows authentication. The following steps will set up IIS for Windows Authentication: Install the Windows-Auth feature on IIS as it isn't installed by default on a Windows image Setup the IIS Application pool to run under a Network Account Disable anonymousAuthentication which is enabled by default Enable Windows Authentication RUN Install-WindowsFeature -Name Web-Windows-Auth -IncludeAllSubFeature RUN Import-Module WebAdministration ; Set-ItemProperty 'IIS:\\AppPools\\SiteName' -name processModel.identityType -value 2 RUN Import-Module WebAdministration ; Set-WebConfigurationProperty -Filter '/system.webServer/security/authentication/anonymousAuthentication' -Name Enabled -Value False -PSPath 'IIS:\\' -Location 'SiteName' RUN Import-Module WebAdministration ; Set-WebConfigurationProperty -Filter '/system.webServer/security/authentication/windowsAuthentication' -Name Enabled -Value True -PSPath 'IIS:\\' -Location 'SiteName'","title":"Windows container and gMSA use case"},{"location":"windows/docs/gmsa/#enabling-gmsa-on-amazon-eks-cluster","text":"In November 2020, AWS published a step-by-step on how to set up an Amazon EKS cluster to use gMSA. This guide can be used for any scenario that requires Active Directory authentication, including the use cases mentioned above. The blog post walks-through: Creating an EKS cluster with self-managed Windows worker nodes Joining the Windows worker node to an Active Directory Domain Creating and configure gMSA accounts on Active Directory Domain Installing the gMSA CredentialSpec CRD Installing the Windows gMSA Webhook Admission controller Creating gMSA credential spec resources Creating a Kubernetes ClusterRole to be defined for each gMSA credential spec Assigning the Kubernetes ClusterRole to a service accounts to use specific gMSA credential specs Configuring DNS forwarder with CoreDNS Configuring the gMSA credential spec in the Windows pod spec Testing the Windows Authentication from inside the Windows pod Blog link: https://aws.amazon.com/blogs/containers/windows-authentication-on-amazon-eks-windows-pods/","title":"Enabling gMSA on Amazon EKS cluster"},{"location":"windows/docs/hardening/","text":"Hardening the Windows worker node \u00b6 Windows Server hardening involves identifying and remediating security vulnerabilities before they are exploited. Microsoft offers a range of tools like Microsoft Security Compliance Toolkit and Security Baselines that should be applied to an operational system. This guide focus specifically on Windows nodes running on Amazon Elastic Kubernetes Service (EKS). Reducing attack surface with Windows Server Core \u00b6 Windows Server Core is a minimal installation option that is available as part of the EKS Optimized Windows AMI . Deploying Windows Server Core has a couple benefits. First, it has a relatively small disk footprint being 6GB on Server Core against 10GB on Windows Server with Desktop experience. Second, it has smaller attack surface because of its smaller code base. You can specify the Server Core EKS Optimized AMI for Windows when you deploy your nodes through eksctl or Cloudformation. The example below is an eksctl manifest for a Windows node group based on Windows Server Core 2004: nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false The amiFamily name conventions can be found on the eksctl official documentation. Avoiding RDP connections \u00b6 Remote Desktop Protocol (RDP) is a connection protocol developed by Microsoft to provide users with a graphical interface to connect to another Windows computer over a network. As a best practice, you should treat your Windows worker nodes as if they were immutable. That means no management connections, no updates, and no troubleshooting. Any modification and update should be implemented as a new custom AMI and replaced by updating an Auto Scaling group. See Patching Windows Servers and Containers and Amazon EKS optimized Windows AMI management . Disable RDP connections on Windows nodes during the deployment by passing the value false on the ssh property, as the example below: nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false If access to the Windows node is needed, use AWS System Manager Session Manager to establish a secure PowerShell session through the AWS Console and SSM agent. To see how to implement the solution watch Securely Access Windows Instances Using AWS Systems Manager Session Manager In order to use System Manager Session Manager an additional IAM policy must be applied to the Windows nodes. Below is an example where the AmazonSSMManagedInstanceCore is specified in the eksctl cluster manifest: nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false iam : attachPolicyARNs : - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore Amazon Inspector \u00b6 Amazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS. Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices. After performing an assessment, Amazon Inspector produces a detailed list of security findings prioritized by level of severity. These findings can be reviewed directly or as part of detailed assessment reports which are available via the Amazon Inspector console or API. Amazon Inspector can be used to run CIS Benchmark assessment on the Windows worker node and it can be installed on a Windows Server Core by performing the following tasks: Download the following .exe file: https://inspector-agent.amazonaws.com/windows/installer/latest/AWSAgentInstall.exe Transfer the agent to the Windows worker node. Run the following command on PowerShell to install the Amazon Inspector Agent: .\\AWSAgentInstall.exe /install Below is the ouput after the first run. As you can see, it generated findings based on the CVE database. You can use this to harden your Worker nodes or create an AMI based on the hardened configurations. For more information on Amazon Inspector, including how to install Amazon Inspector agents, set up the CIS Benchmark assessment, and generate reports, watch the Improving the security and compliance of Windows Workloads with Amazon Inspector video. Amazon GuardDuty \u00b6 Amazon GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect your AWS accounts, workloads, and data stored in Amazon S3. With the cloud, the collection and aggregation of account and network activities is simplified, but it can be time consuming for security teams to continuously analyze event log data for potential threats. By using Amazon GuardDuty you have visilitiby on malicious actitivy against Windows worker nodes, like RDP brute force and Port Probe attacks. Watch the Threat Detection for Windows Workloads using Amazon GuardDuty video to learn how to implement and run CIS Benchmarks on Optimized EKS Windows AMI Security in Amazon EC2 for Windows \u00b6 Read up on the Security best practices for Amazon EC2 Windows instances to implement security controls at every layer.","title":"Windows Server Hardening"},{"location":"windows/docs/hardening/#hardening-the-windows-worker-node","text":"Windows Server hardening involves identifying and remediating security vulnerabilities before they are exploited. Microsoft offers a range of tools like Microsoft Security Compliance Toolkit and Security Baselines that should be applied to an operational system. This guide focus specifically on Windows nodes running on Amazon Elastic Kubernetes Service (EKS).","title":"Hardening the Windows worker node"},{"location":"windows/docs/hardening/#reducing-attack-surface-with-windows-server-core","text":"Windows Server Core is a minimal installation option that is available as part of the EKS Optimized Windows AMI . Deploying Windows Server Core has a couple benefits. First, it has a relatively small disk footprint being 6GB on Server Core against 10GB on Windows Server with Desktop experience. Second, it has smaller attack surface because of its smaller code base. You can specify the Server Core EKS Optimized AMI for Windows when you deploy your nodes through eksctl or Cloudformation. The example below is an eksctl manifest for a Windows node group based on Windows Server Core 2004: nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false The amiFamily name conventions can be found on the eksctl official documentation.","title":"Reducing attack surface with Windows Server Core"},{"location":"windows/docs/hardening/#avoiding-rdp-connections","text":"Remote Desktop Protocol (RDP) is a connection protocol developed by Microsoft to provide users with a graphical interface to connect to another Windows computer over a network. As a best practice, you should treat your Windows worker nodes as if they were immutable. That means no management connections, no updates, and no troubleshooting. Any modification and update should be implemented as a new custom AMI and replaced by updating an Auto Scaling group. See Patching Windows Servers and Containers and Amazon EKS optimized Windows AMI management . Disable RDP connections on Windows nodes during the deployment by passing the value false on the ssh property, as the example below: nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false If access to the Windows node is needed, use AWS System Manager Session Manager to establish a secure PowerShell session through the AWS Console and SSM agent. To see how to implement the solution watch Securely Access Windows Instances Using AWS Systems Manager Session Manager In order to use System Manager Session Manager an additional IAM policy must be applied to the Windows nodes. Below is an example where the AmazonSSMManagedInstanceCore is specified in the eksctl cluster manifest: nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false iam : attachPolicyARNs : - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore","title":"Avoiding RDP connections"},{"location":"windows/docs/hardening/#amazon-inspector","text":"Amazon Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS. Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices. After performing an assessment, Amazon Inspector produces a detailed list of security findings prioritized by level of severity. These findings can be reviewed directly or as part of detailed assessment reports which are available via the Amazon Inspector console or API. Amazon Inspector can be used to run CIS Benchmark assessment on the Windows worker node and it can be installed on a Windows Server Core by performing the following tasks: Download the following .exe file: https://inspector-agent.amazonaws.com/windows/installer/latest/AWSAgentInstall.exe Transfer the agent to the Windows worker node. Run the following command on PowerShell to install the Amazon Inspector Agent: .\\AWSAgentInstall.exe /install Below is the ouput after the first run. As you can see, it generated findings based on the CVE database. You can use this to harden your Worker nodes or create an AMI based on the hardened configurations. For more information on Amazon Inspector, including how to install Amazon Inspector agents, set up the CIS Benchmark assessment, and generate reports, watch the Improving the security and compliance of Windows Workloads with Amazon Inspector video.","title":"Amazon Inspector"},{"location":"windows/docs/hardening/#amazon-guardduty","text":"Amazon GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect your AWS accounts, workloads, and data stored in Amazon S3. With the cloud, the collection and aggregation of account and network activities is simplified, but it can be time consuming for security teams to continuously analyze event log data for potential threats. By using Amazon GuardDuty you have visilitiby on malicious actitivy against Windows worker nodes, like RDP brute force and Port Probe attacks. Watch the Threat Detection for Windows Workloads using Amazon GuardDuty video to learn how to implement and run CIS Benchmarks on Optimized EKS Windows AMI","title":"Amazon GuardDuty"},{"location":"windows/docs/hardening/#security-in-amazon-ec2-for-windows","text":"Read up on the Security best practices for Amazon EC2 Windows instances to implement security controls at every layer.","title":"Security in Amazon EC2 for Windows"},{"location":"windows/docs/heterogeneous/","text":"Running Heterogeneous workloads \u00b6 Kubernetes has support for heterogeneous clusters where you a have mixture of Linux and Windows nodes in the same cluster. Within that cluster, you can have mixture of Pods that run on Linux and Pods that run on Windows. You can even run multiple versions of Windows in the same cluster. However, there are several factors that will need to be accounted for when making this decision. This guide specifically covers running Windows workloads on EKS but can be applied generally. Placement \u00b6 It\u2019s a good practice to keep the Windows workloads in a separate nodegroup within the EKS cluster. If you are running multiple versions of Windows, deploy each version into a separate nodegroup. If your operations model involves running multiple clusters, creating a separate cluster for running Windows workloads is not a bad idea. While the multi-cluster model comes with some advantages, there a lot of other factors, such as inter-cluster communication, single pane observability, a unified trust domain and the like, that should be considered beforehand. Scheduling \u00b6 There is a bit of a burden when it comes to scheduling workloads on Windows nodes. It is no different than scheduling workloads to run on specific instances in homogeneous (Linux only) clusters. You need to use taints and node selectors - in combination with tolerations - in order to keep Linux and Windows workloads on their respective OS-specific nodes. You can add node groups using different Windows Server image types (LTSC or SAC) to your cluster. In a cluster with mixed Windows Server types, you need to ensure that your Windows Server containers are not scheduled onto an incompatible version of Windows Server. This is achieved using node labels. You can run windows Server node groups with multiple different LTSC or SAC versions as well. Windows Server containers have important version compatibility requirements: Windows Server containers built for LTSC do not run on SAC nodes, and vice-versa. Windows Server containers built for a specific LTSC or SAC version do not run on other LTSC or SAC versions without being rebuilt to target the other version. Building your Windows Server container images as multi-arch images that can target multiple Windows Server versions can help you manage this versioning (https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-windows-ami.html) complexity. If you are using EKS, eksctl offers ways to apply taints through clusterConfig nodeGroups : - name : windows-ng amiFamily : WindowsServer2019FullContainer ... labels : nodeclass : windows2019 taints : os : \"windows:NoSchedule\" And then use the following in your deployment manifest, to target the Windows specific deployments to specific Windows nodes. nodeSelector : kubernetes.io/os : windows nodeclass : windows2019 tolerations : - key : \"os\" operator : \"Equal\" value : \"windows\" effect : \"NoSchedule\" The best practice is to use RuntimeClasses instead. You can create a Runtime class per nodegroup apiVersion : node.k8s.io/v1 kind : RuntimeClass .... scheduling : nodeSelector : kubernetes.io/os : 'windows' nodeclass : windows2019 tolerations : - effect : NoSchedule key : os operator : Equal value : \"windows\" And leverage them in the deployment Spec, like so, using runtimeClassName apiVersion : apps/v1 kind : Deployment ... spec : replicas : 1 template : ... spec : runtimeClassName : windows2019 Handling multiple Windows versions in the same cluster is no different. Kubenetes versions 1.17+ the node controller applies some default labels based on Windows OS, architecture, and version. These labels can be used for scheduling workloads onto specific instances. Network considerations \u00b6 Windows doesn't support hostNetwork. Consequently, at least one Linux node (2 for production grade cluster) in the cluster is required to run the VPC resource controller and CoreDNS. When working with mixed clusters you need to understand that Windows hosts have only one ENI and that having 1 ENI can impact your pod density. Take this into consideration: IP's available = (# of IP\u2019s on the interface -1).","title":"Running Mixed Workloads"},{"location":"windows/docs/heterogeneous/#running-heterogeneous-workloads","text":"Kubernetes has support for heterogeneous clusters where you a have mixture of Linux and Windows nodes in the same cluster. Within that cluster, you can have mixture of Pods that run on Linux and Pods that run on Windows. You can even run multiple versions of Windows in the same cluster. However, there are several factors that will need to be accounted for when making this decision. This guide specifically covers running Windows workloads on EKS but can be applied generally.","title":"Running Heterogeneous workloads"},{"location":"windows/docs/heterogeneous/#placement","text":"It\u2019s a good practice to keep the Windows workloads in a separate nodegroup within the EKS cluster. If you are running multiple versions of Windows, deploy each version into a separate nodegroup. If your operations model involves running multiple clusters, creating a separate cluster for running Windows workloads is not a bad idea. While the multi-cluster model comes with some advantages, there a lot of other factors, such as inter-cluster communication, single pane observability, a unified trust domain and the like, that should be considered beforehand.","title":"Placement"},{"location":"windows/docs/heterogeneous/#scheduling","text":"There is a bit of a burden when it comes to scheduling workloads on Windows nodes. It is no different than scheduling workloads to run on specific instances in homogeneous (Linux only) clusters. You need to use taints and node selectors - in combination with tolerations - in order to keep Linux and Windows workloads on their respective OS-specific nodes. You can add node groups using different Windows Server image types (LTSC or SAC) to your cluster. In a cluster with mixed Windows Server types, you need to ensure that your Windows Server containers are not scheduled onto an incompatible version of Windows Server. This is achieved using node labels. You can run windows Server node groups with multiple different LTSC or SAC versions as well. Windows Server containers have important version compatibility requirements: Windows Server containers built for LTSC do not run on SAC nodes, and vice-versa. Windows Server containers built for a specific LTSC or SAC version do not run on other LTSC or SAC versions without being rebuilt to target the other version. Building your Windows Server container images as multi-arch images that can target multiple Windows Server versions can help you manage this versioning (https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-windows-ami.html) complexity. If you are using EKS, eksctl offers ways to apply taints through clusterConfig nodeGroups : - name : windows-ng amiFamily : WindowsServer2019FullContainer ... labels : nodeclass : windows2019 taints : os : \"windows:NoSchedule\" And then use the following in your deployment manifest, to target the Windows specific deployments to specific Windows nodes. nodeSelector : kubernetes.io/os : windows nodeclass : windows2019 tolerations : - key : \"os\" operator : \"Equal\" value : \"windows\" effect : \"NoSchedule\" The best practice is to use RuntimeClasses instead. You can create a Runtime class per nodegroup apiVersion : node.k8s.io/v1 kind : RuntimeClass .... scheduling : nodeSelector : kubernetes.io/os : 'windows' nodeclass : windows2019 tolerations : - effect : NoSchedule key : os operator : Equal value : \"windows\" And leverage them in the deployment Spec, like so, using runtimeClassName apiVersion : apps/v1 kind : Deployment ... spec : replicas : 1 template : ... spec : runtimeClassName : windows2019 Handling multiple Windows versions in the same cluster is no different. Kubenetes versions 1.17+ the node controller applies some default labels based on Windows OS, architecture, and version. These labels can be used for scheduling workloads onto specific instances.","title":"Scheduling"},{"location":"windows/docs/heterogeneous/#network-considerations","text":"Windows doesn't support hostNetwork. Consequently, at least one Linux node (2 for production grade cluster) in the cluster is required to run the VPC resource controller and CoreDNS. When working with mixed clusters you need to understand that Windows hosts have only one ENI and that having 1 ENI can impact your pod density. Take this into consideration: IP's available = (# of IP\u2019s on the interface -1).","title":"Network considerations"},{"location":"windows/docs/images/","text":"Container image scanning \u00b6 Image Scanning is an automated vulnerability assessment feature that helps improve the security of your application\u2019s container images by scanning them for a broad range of operating system vulnerabilities. Currently, the Amazon Elastic Container Registry (ECR) is only able to scan Linux container image for vulnerabilities. However; there are third-party tools which can be integrated with an existing CI/CD pipeline for Windows container image scanning. Anchore PaloAlto Prisma Cloud Trend Micro - Deep Security Smart Check To learn more about how to integrate these solutions with Amazon Elastic Container Repository (ECR), check: Anchore, scanning images on Amazon Elastic Container Registry (ECR) PaloAlto, scanning images on Amazon Elastic Container Registry (ECR) TrendMicro, scanning images on Amazon Elastic Container Registry (ECR)","title":"Scanning Windows Images"},{"location":"windows/docs/images/#container-image-scanning","text":"Image Scanning is an automated vulnerability assessment feature that helps improve the security of your application\u2019s container images by scanning them for a broad range of operating system vulnerabilities. Currently, the Amazon Elastic Container Registry (ECR) is only able to scan Linux container image for vulnerabilities. However; there are third-party tools which can be integrated with an existing CI/CD pipeline for Windows container image scanning. Anchore PaloAlto Prisma Cloud Trend Micro - Deep Security Smart Check To learn more about how to integrate these solutions with Amazon Elastic Container Repository (ECR), check: Anchore, scanning images on Amazon Elastic Container Registry (ECR) PaloAlto, scanning images on Amazon Elastic Container Registry (ECR) TrendMicro, scanning images on Amazon Elastic Container Registry (ECR)","title":"Container image scanning"},{"location":"windows/docs/licensing/","text":"Choosing a Windows Server Version and License \u00b6 There are two primary release channels available to Windows Server customers, the Long-Term Servicing Channel and the Semi-Annual Channel. You can keep servers on the Long-Term Servicing Channel (LTSC), move them to the Semi-Annual Channel (SAC), or have some servers on either track, depending on what works best for your needs. Long-Term Servicing Channel (LTSC) \u00b6 Formerly called the \u201cLong-Term Servicing Branch\u201d, this is the release model you are already familiar with where a new major version of Windows Server is released every 2-3 years. Users are entitled to 5 years of mainstream support and 5 years of extended support. This channel is appropriate for systems that require a longer servicing option and functional stability. Deployments of Windows Server 2019 and earlier versions of Windows Server will not be affected by the new Semi-Annual Channel releases. The Long-Term Servicing Channel will continue to receive security and non-security updates, only receiving select new features and functionality. Semi-Annual Channel (SAC) \u00b6 Windows Server products in the Semi-Annual Channel have new releases available twice a year, in spring and fall. Each release in this channel is supported for 18 months from the initial release. Most of the features introduced in the Semi-Annual Channel will be rolled up into the next Long-Term Servicing Channel release of Windows Server. The editions, functionality, and supporting content might vary from release to release depending on customer feedback. In this model, Windows Server releases are identified by the year and month or half of release: for example, in 2020, the release in the 4th month (April) is identified as version 2004. This naming changed with the last SAC release which is identified as 20H2. Which channel should I use? \u00b6 Microsoft is moving to the LTSC as the primary release channel. The two current SAC builds will be supported until the end of their 18-month lifecycles ending 2021-12-14 for version 2004 and 2022-05-10 for version 20H2. Important features optimized for Container workloads which originated in the SAC have been incorporated into the LTSC build: Direct Server Return (DSR) support. (available in the LTSC August 2020 Cumulative Update ) What is Direct Server Return? DSR is an implementation of asymmetric network load distribution in load balanced systems, meaning that the request and response traffic use a different network path. Licensing \u00b6 At Amazon Web Services (AWS), the EKS Optimized AMIs for Windows are based on the Datacenter version, which doesn't have a limitation on the numbers of containers running on a worker node. For more information: https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/faq","title":"Windows Versions and Licensing"},{"location":"windows/docs/licensing/#choosing-a-windows-server-version-and-license","text":"There are two primary release channels available to Windows Server customers, the Long-Term Servicing Channel and the Semi-Annual Channel. You can keep servers on the Long-Term Servicing Channel (LTSC), move them to the Semi-Annual Channel (SAC), or have some servers on either track, depending on what works best for your needs.","title":"Choosing a Windows Server Version and License"},{"location":"windows/docs/licensing/#long-term-servicing-channel-ltsc","text":"Formerly called the \u201cLong-Term Servicing Branch\u201d, this is the release model you are already familiar with where a new major version of Windows Server is released every 2-3 years. Users are entitled to 5 years of mainstream support and 5 years of extended support. This channel is appropriate for systems that require a longer servicing option and functional stability. Deployments of Windows Server 2019 and earlier versions of Windows Server will not be affected by the new Semi-Annual Channel releases. The Long-Term Servicing Channel will continue to receive security and non-security updates, only receiving select new features and functionality.","title":"Long-Term Servicing Channel (LTSC)"},{"location":"windows/docs/licensing/#semi-annual-channel-sac","text":"Windows Server products in the Semi-Annual Channel have new releases available twice a year, in spring and fall. Each release in this channel is supported for 18 months from the initial release. Most of the features introduced in the Semi-Annual Channel will be rolled up into the next Long-Term Servicing Channel release of Windows Server. The editions, functionality, and supporting content might vary from release to release depending on customer feedback. In this model, Windows Server releases are identified by the year and month or half of release: for example, in 2020, the release in the 4th month (April) is identified as version 2004. This naming changed with the last SAC release which is identified as 20H2.","title":"Semi-Annual Channel (SAC)"},{"location":"windows/docs/licensing/#which-channel-should-i-use","text":"Microsoft is moving to the LTSC as the primary release channel. The two current SAC builds will be supported until the end of their 18-month lifecycles ending 2021-12-14 for version 2004 and 2022-05-10 for version 20H2. Important features optimized for Container workloads which originated in the SAC have been incorporated into the LTSC build: Direct Server Return (DSR) support. (available in the LTSC August 2020 Cumulative Update ) What is Direct Server Return? DSR is an implementation of asymmetric network load distribution in load balanced systems, meaning that the request and response traffic use a different network path.","title":"Which channel should I use?"},{"location":"windows/docs/licensing/#licensing","text":"At Amazon Web Services (AWS), the EKS Optimized AMIs for Windows are based on the Datacenter version, which doesn't have a limitation on the numbers of containers running on a worker node. For more information: https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/faq","title":"Licensing"},{"location":"windows/docs/logging/","text":"Logging \u00b6 Containerized applications typically direct application logs to STDOUT. The container runtime traps these logs and does something with them - typically writes to a file. Where these files are stored depends on the container runtime and configuration. One fundamental difference with Windows pods is they do not generate STDOUT. You can run LogMonitor to retrieve the ETW (Event Tracing for Windows), Windows Event Logs and other application specific logs from running Windows containers and pipes formatted log output to STDOUT. These logs can then be streamed using fluent-bit or fluentd to your desired destination such as Amazon CloudWatch. The Log collection mechanism retrieves STDOUT/STDERR logs from Kubernetes pods. A DaemonSet is a common way to collect logs from containers. It gives you the ability to manage log routing/filtering/enrichment independently of the application. A fluentd DaemonSet can be used to stream these logs and any other application generated logs to a desired log aggregator. More detailed information about log streaming from Windows workloads to CloudWatch is explained here Logging Recomendations \u00b6 The general logging best practices are no different when operating Windows workloads in Kubernetes. Always log structured log entries (JSON/SYSLOG) which makes handling log entries easier as there are many pre-written parsers for such structured formats. Centralize logs - dedicated logging containers can be used specifically to gather and forward log messages from all containers to a destination Keep log verbosity down except when debugging. Verbosity places a lot of stress on the logging infrastructure and significant events can be lost in the noise. Always log the application information along with transaction/request id for traceability. Kubernetes objects do-not carry the application name, so for example a pod name windows-twryrqyw may not carry any meaning when debugging logs. This helps with traceability and troubleshooting applications with your aggregated logs. How you generate these transaction/correlation id's depends on the programming construct. But a very common pattern is to use a logging Aspect/Interceptor, which can use MDC (Mapped diagnostic context) to inject a unique transaction/correlation id to every incoming request, like so: import org.slf4j.MDC ; import java.util.UUID ; Class LoggingAspect { //interceptor @Before ( value = \"execution(* *.*(..))\" ) func before (...) { transactionId = generateTransactionId (); MDC . put ( CORRELATION_ID , transactionId ); } func generateTransactionId () { return UUID . randomUUID (). toString (); } }","title":"Logging"},{"location":"windows/docs/logging/#logging","text":"Containerized applications typically direct application logs to STDOUT. The container runtime traps these logs and does something with them - typically writes to a file. Where these files are stored depends on the container runtime and configuration. One fundamental difference with Windows pods is they do not generate STDOUT. You can run LogMonitor to retrieve the ETW (Event Tracing for Windows), Windows Event Logs and other application specific logs from running Windows containers and pipes formatted log output to STDOUT. These logs can then be streamed using fluent-bit or fluentd to your desired destination such as Amazon CloudWatch. The Log collection mechanism retrieves STDOUT/STDERR logs from Kubernetes pods. A DaemonSet is a common way to collect logs from containers. It gives you the ability to manage log routing/filtering/enrichment independently of the application. A fluentd DaemonSet can be used to stream these logs and any other application generated logs to a desired log aggregator. More detailed information about log streaming from Windows workloads to CloudWatch is explained here","title":"Logging"},{"location":"windows/docs/logging/#logging-recomendations","text":"The general logging best practices are no different when operating Windows workloads in Kubernetes. Always log structured log entries (JSON/SYSLOG) which makes handling log entries easier as there are many pre-written parsers for such structured formats. Centralize logs - dedicated logging containers can be used specifically to gather and forward log messages from all containers to a destination Keep log verbosity down except when debugging. Verbosity places a lot of stress on the logging infrastructure and significant events can be lost in the noise. Always log the application information along with transaction/request id for traceability. Kubernetes objects do-not carry the application name, so for example a pod name windows-twryrqyw may not carry any meaning when debugging logs. This helps with traceability and troubleshooting applications with your aggregated logs. How you generate these transaction/correlation id's depends on the programming construct. But a very common pattern is to use a logging Aspect/Interceptor, which can use MDC (Mapped diagnostic context) to inject a unique transaction/correlation id to every incoming request, like so: import org.slf4j.MDC ; import java.util.UUID ; Class LoggingAspect { //interceptor @Before ( value = \"execution(* *.*(..))\" ) func before (...) { transactionId = generateTransactionId (); MDC . put ( CORRELATION_ID , transactionId ); } func generateTransactionId () { return UUID . randomUUID (). toString (); } }","title":"Logging Recomendations"},{"location":"windows/docs/monitoring/","text":"Monitoring \u00b6 Prometheus, a graduated CNCF project is by far the most popular monitoring system with native integration into Kubernetes. Prometheus collects metrics around containers, pods, nodes, and clusters. Additionally, Prometheus leverages AlertsManager which lets you program alerts to warn you if something in your cluster is going wrong. Prometheus stores the metric data as a time series data identified by metric name and key/value pairs. Prometheus includes away to query using a language called PromQL, which is short for Prometheus Query Language. The high level architecture of Prometheus metrics collection is shown below: Prometheus uses a pull mechanism and scrapes metrics from targets using exporters and from the Kubernetes API using the kube state metrics . This means applications and services must expose a HTTP(S) endpoint containing Prometheus formatted metrics. Prometheus will then, as per its configuration, periodically pull metrics from these HTTP(S) endpoints. An exporter lets you consume third party metrics as Prometheus formatted metrics. A Prometheus exporter is typically deployed on each node. For a complete list of exporters please refer to the Prometheus exporters . While node exporter is suited for exporting host hardware and OS metrics for linux nodes, it wont work for Windows nodes. In a mixed node EKS cluster with Windows nodes when you use the stable Prometheus helm chart , you will see failed pods on the Windows nodes, as this exporter is not intended for Windows. You will need to treat the Windows worker pool separate and instead install the Windows exporter on the Windows worker node group. In order to setup Prometheus monitoring for Windows nodes, you need to download and install the WMI exporter on the Windows server itself and then setup the targets inside the scrape configuration of the Prometheus configuration file. The releases page provides all available .msi installers, with respective feature sets and bug fixes. The installer will setup the windows_exporter as a Windows service, as well as create an exception in the Windows firewall. If the installer is run without any parameters, the exporter will run with default settings for enabled collectors, ports, etc. You can check out the scheduling best practices section of this guide which suggests the use of taints/tolerations or RuntimeClass to selectively deploy node exporter only to linux nodes, while the Windows exporter is installed on Windows nodes as you bootstrap the node or using a configuration management tool of your choice (example chef, Ansible, SSM etc). Note that, unlike the linux nodes where the node exporter is installed as a daemonset , on Windows nodes the WMI exporter is installed on the host itself. The exporter will export metrics such as the CPU usage, the memory and the disk I/O usage and can also be used to monitor IIS sites and applications, the network interfaces and services. The windows_exporter will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors. However, for advanced use the windows_exporter can be passed an optional list of collectors to filter metrics. The collect[] parameter, in the Prometheus configuration lets you do that. The default install steps for Windows include downloading and starting the exporter as a service during the bootstrapping process with arguments, such as the collectors you want to filter. > Powershell Invoke-WebRequest https :// github . com / prometheus-community / windows_exporter / releases / download / v0 . 13 . 0 / windows_exporter - 0 . 13 . 0-amd64 . msi -OutFile < DOWNLOADPATH > > msiexec / i < DOWNLOADPATH > ENABLED_COLLECTORS = \"cpu,cs,logical_disk,net,os,system,container,memory\" By default, the metrics can be scraped at the /metrics endpoint on port 9182. At this point, Prometheus can consume the metrics by adding the following scrape_config to the Prometheus configuration scrape_configs : - job_name : \"prometheus\" static_configs : - targets : [ 'localhost:9090' ] ... - job_name : \"wmi_exporter\" scrape_interval : 10s static_configs : - targets : [ '<windows-node1-ip>:9182' , '<windows-node2-ip>:9182' , ... ] Prometheus configuration is reloaded using > ps aux | grep prometheus > kill HUP <PID> A better and recommended way to add targets is to use a Custom Resource Definition called ServiceMonitor, which comes as part of the Prometheus operator ] that provides the definition for a ServiceMonitor Object and a controller that will activate the ServiceMonitors we define and automatically build the required Prometheus configuration. The ServiceMonitor, which declaratively specifies how groups of Kubernetes services should be monitored, is used to define an application you wish to scrape metrics from within Kubernetes. Within the ServiceMonitor we specify the Kubernetes labels that the operator can use to identify the Kubernetes Service which in turn identifies the Pods, that we wish to monitor. In order to leverage the ServiceMonitor, create an Endpoint object pointing to specific Windows targets, a headless service and a ServiceMontor for the Windows nodes. apiVersion : v1 kind : Endpoints metadata : labels : k8s-app : wmiexporter name : wmiexporter namespace : kube-system subsets : - addresses : - ip : NODE-ONE-IP targetRef : kind : Node name : NODE-ONE-NAME - ip : NODE-TWO-IP targetRef : kind : Node name : NODE-TWO-NAME - ip : NODE-THREE-IP targetRef : kind : Node name : NODE-THREE-NAME ports : - name : http-metrics port : 9182 protocol : TCP --- apiVersion : v1 kind : Service ##Headless Service metadata : labels : k8s-app : wmiexporter name : wmiexporter namespace : kube-system spec : clusterIP : None ports : - name : http-metrics port : 9182 protocol : TCP targetPort : 9182 sessionAffinity : None type : ClusterIP --- apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor ##Custom ServiceMonitor Object metadata : labels : k8s-app : wmiexporter name : wmiexporter namespace : monitoring spec : endpoints : - interval : 30s port : http-metrics jobLabel : k8s-app namespaceSelector : matchNames : - kube-system selector : matchLabels : k8s-app : wmiexporter For more details on the operator and the usage of ServiceMonitor, checkout the official operator documentation. Note that Prometheus does support dynamic target discovery using many service discovery options.","title":"Monitoring Windows Containers"},{"location":"windows/docs/monitoring/#monitoring","text":"Prometheus, a graduated CNCF project is by far the most popular monitoring system with native integration into Kubernetes. Prometheus collects metrics around containers, pods, nodes, and clusters. Additionally, Prometheus leverages AlertsManager which lets you program alerts to warn you if something in your cluster is going wrong. Prometheus stores the metric data as a time series data identified by metric name and key/value pairs. Prometheus includes away to query using a language called PromQL, which is short for Prometheus Query Language. The high level architecture of Prometheus metrics collection is shown below: Prometheus uses a pull mechanism and scrapes metrics from targets using exporters and from the Kubernetes API using the kube state metrics . This means applications and services must expose a HTTP(S) endpoint containing Prometheus formatted metrics. Prometheus will then, as per its configuration, periodically pull metrics from these HTTP(S) endpoints. An exporter lets you consume third party metrics as Prometheus formatted metrics. A Prometheus exporter is typically deployed on each node. For a complete list of exporters please refer to the Prometheus exporters . While node exporter is suited for exporting host hardware and OS metrics for linux nodes, it wont work for Windows nodes. In a mixed node EKS cluster with Windows nodes when you use the stable Prometheus helm chart , you will see failed pods on the Windows nodes, as this exporter is not intended for Windows. You will need to treat the Windows worker pool separate and instead install the Windows exporter on the Windows worker node group. In order to setup Prometheus monitoring for Windows nodes, you need to download and install the WMI exporter on the Windows server itself and then setup the targets inside the scrape configuration of the Prometheus configuration file. The releases page provides all available .msi installers, with respective feature sets and bug fixes. The installer will setup the windows_exporter as a Windows service, as well as create an exception in the Windows firewall. If the installer is run without any parameters, the exporter will run with default settings for enabled collectors, ports, etc. You can check out the scheduling best practices section of this guide which suggests the use of taints/tolerations or RuntimeClass to selectively deploy node exporter only to linux nodes, while the Windows exporter is installed on Windows nodes as you bootstrap the node or using a configuration management tool of your choice (example chef, Ansible, SSM etc). Note that, unlike the linux nodes where the node exporter is installed as a daemonset , on Windows nodes the WMI exporter is installed on the host itself. The exporter will export metrics such as the CPU usage, the memory and the disk I/O usage and can also be used to monitor IIS sites and applications, the network interfaces and services. The windows_exporter will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors. However, for advanced use the windows_exporter can be passed an optional list of collectors to filter metrics. The collect[] parameter, in the Prometheus configuration lets you do that. The default install steps for Windows include downloading and starting the exporter as a service during the bootstrapping process with arguments, such as the collectors you want to filter. > Powershell Invoke-WebRequest https :// github . com / prometheus-community / windows_exporter / releases / download / v0 . 13 . 0 / windows_exporter - 0 . 13 . 0-amd64 . msi -OutFile < DOWNLOADPATH > > msiexec / i < DOWNLOADPATH > ENABLED_COLLECTORS = \"cpu,cs,logical_disk,net,os,system,container,memory\" By default, the metrics can be scraped at the /metrics endpoint on port 9182. At this point, Prometheus can consume the metrics by adding the following scrape_config to the Prometheus configuration scrape_configs : - job_name : \"prometheus\" static_configs : - targets : [ 'localhost:9090' ] ... - job_name : \"wmi_exporter\" scrape_interval : 10s static_configs : - targets : [ '<windows-node1-ip>:9182' , '<windows-node2-ip>:9182' , ... ] Prometheus configuration is reloaded using > ps aux | grep prometheus > kill HUP <PID> A better and recommended way to add targets is to use a Custom Resource Definition called ServiceMonitor, which comes as part of the Prometheus operator ] that provides the definition for a ServiceMonitor Object and a controller that will activate the ServiceMonitors we define and automatically build the required Prometheus configuration. The ServiceMonitor, which declaratively specifies how groups of Kubernetes services should be monitored, is used to define an application you wish to scrape metrics from within Kubernetes. Within the ServiceMonitor we specify the Kubernetes labels that the operator can use to identify the Kubernetes Service which in turn identifies the Pods, that we wish to monitor. In order to leverage the ServiceMonitor, create an Endpoint object pointing to specific Windows targets, a headless service and a ServiceMontor for the Windows nodes. apiVersion : v1 kind : Endpoints metadata : labels : k8s-app : wmiexporter name : wmiexporter namespace : kube-system subsets : - addresses : - ip : NODE-ONE-IP targetRef : kind : Node name : NODE-ONE-NAME - ip : NODE-TWO-IP targetRef : kind : Node name : NODE-TWO-NAME - ip : NODE-THREE-IP targetRef : kind : Node name : NODE-THREE-NAME ports : - name : http-metrics port : 9182 protocol : TCP --- apiVersion : v1 kind : Service ##Headless Service metadata : labels : k8s-app : wmiexporter name : wmiexporter namespace : kube-system spec : clusterIP : None ports : - name : http-metrics port : 9182 protocol : TCP targetPort : 9182 sessionAffinity : None type : ClusterIP --- apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor ##Custom ServiceMonitor Object metadata : labels : k8s-app : wmiexporter name : wmiexporter namespace : monitoring spec : endpoints : - interval : 30s port : http-metrics jobLabel : k8s-app namespaceSelector : matchNames : - kube-system selector : matchLabels : k8s-app : wmiexporter For more details on the operator and the usage of ServiceMonitor, checkout the official operator documentation. Note that Prometheus does support dynamic target discovery using many service discovery options.","title":"Monitoring"},{"location":"windows/docs/networking/","text":"Windows Networking \u00b6 Windows Container Networking Overview \u00b6 Windows containers are fundamentally different than Linux containers. Linux containers use Linux constructs like namespaces, the union file system, and cgroups. On Windows, those constructs are abstracted from Docker by the Host Compute Service (HCS) . HCS acts as an API layer that sits above the container implementation on Windows. Windows containers also leverage the Host Network Service (HNS) that defines the network topology on a node. From a networking perspective, HCS and HNS make Windows containers function like virtual machines. For example, each container has a virtual network adapter (vNIC) that is connected to a Hyper-V virtual switch (vSwitch) as shown in the diagram above. IP Management \u00b6 Windows Server uses an Elastic Network Interface (ENI) to connect to an AWS VPC network. The EKS Container Network Interface (CNI) for Windows currently supports only one ENI per worker node. The number of pods that a Windows worker node can support is dictated by the size and type of the instance. You can calculate max pods using the following formula: (number of primary ENIs * IP Addresses per Interface) - 3 = Total IP addresses available for Pods We subtract 3 IP addresses from the total because the worker node requires one IP for itself, one for the VPC CNI, and one more for kube-proxy. Using the formula above, we can calculate max pods for an m5.large instance. (1 primary ENI * 10 secondary IPs per ENI) - 3 = 7 Note: The reason it only support 7 is because the VPC CNI for Windows only allows us to use the worker node's primary ENI. Also each ENI on an m5.large supports 10 secondary IP addresses, so we subtract 3 from 10 to get our total of 7 IP addresses. For more information on how many IP addresses an instance type can support, see IP addresses per network interface per instance type . Another key consideration is the flow of network traffic. With Windows there is a risk of port exhaustion on nodes with more than 100 services. When this condition arises, the nodes will start throwing errors with the following message: \"Policy creation failed: hcnCreateLoadBalancer failed in Win32: The specified port already exists.\" To address this issue, we leverage Direct Server Return (DSR). DSR is an implementation of asymmetric network load distribution. In other words, the request and response traffic use different network paths. This feature speeds up communication between pods and reduces the risk of port exhaustion. We therefore recommend enabling DSR on Windows nodes. DSR is enabled by default in Windows Server SAC EKS Optimized AMIs. For Windows Server 2019 LTSC EKS Optimized AMIs, you will need to enable it during instance provisioning using the script below and by using Windows Server 2019 Full or Core as the amiFamily in the eksctl nodeGroup. See eksctl custom AMI for additional information. nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false In order to utilize DSR in Windows Server 2019 and above, you will need to specify the following kube-proxy flags during instance startup. You can do this by adjusting the userdata script associated with the self-managed node groups Launch Template . < powershell > [string] $EKSBinDir = \"$env:ProgramFiles\\Amazon\\EKS\" [string] $EKSBootstrapScriptName = 'Start-EKSBootstrap.ps1' [string] $EKSBootstrapScriptFile = \"$EKSBinDir\\$EKSBootstrapScriptName\" ( Get-Content $EKSBootstrapScriptFile ). replace ( '\"--proxy-mode=kernelspace\",' , '\"--proxy-mode=kernelspace\", \"--feature-gates WinDSR=true\", \"--enable-dsr\",' ) | Set-Content $EKSBootstrapScriptFile & $EKSBootstrapScriptFile -EKSClusterName \"eks-windows\" -APIServerEndpoint \"https://<REPLACE-EKS-CLUSTER-CONFIG-API-SERVER>\" -Base64ClusterCA \"<REPLACE-EKSCLUSTER-CONFIG-DETAILS-CA>\" -DNSClusterIP \"172.20.0.10\" -KubeletExtraArgs \"--node-labels=alpha.eksctl.io/cluster-name=eks-windows,alpha.eksctl.io/nodegroup-name=windows-ng-ltsc2019 --register-with-taints=\" 3 >& 1 4 >& 1 5 >& 1 6 >& 1 </ powershell > DSR enablement can be verified following the instructions in the Microsoft Networking blog and the Windows Containers on AWS Lab . Using an older versions of Windows will increase the risk of port exhaustion as those versions do not support DSR. Container Network Interface (CNI) options \u00b6 The AWSVPC CNI is the de facto CNI plugin for Windows and Linux worker nodes. While the AWSVPC CNI satisfies the needs of many customers, still there may be times when you need to consider alternatives like an overlay network to avoid IP exhaustion. In these cases, the Calico CNI can be used in place of the AWSVPC CNI. Project Calico is open source software that was developed by Tigera . That software includes a CNI that works with EKS. Instructions for installing Calico CNI in EKS can be found on the Project Calico EKS installation page. Network Polices \u00b6 It is considered a best practice to change from the default mode of open communication between pods on your Kubernetes cluster to limiting access based on network polices. The open source Project Calico has strong support for network polices that work with both Linux and Windows nodes. This feature is separate and not dependent on using the Calico CNI. We therefore recommend installing Calico and using it for network policy management. Instructions for installing Calico in EKS can be found on the Installing Calico on Amazon EKS page. In addition, the advice provided in the Amazon EKS Best Practices Guide for Security - Network Section applies equally to EKS clusters with Windows worker nodes, however, some features like \"Security Groups for Pods\" are not supported by Windows at this time.","title":"Windows Networking"},{"location":"windows/docs/networking/#windows-networking","text":"","title":"Windows Networking"},{"location":"windows/docs/networking/#windows-container-networking-overview","text":"Windows containers are fundamentally different than Linux containers. Linux containers use Linux constructs like namespaces, the union file system, and cgroups. On Windows, those constructs are abstracted from Docker by the Host Compute Service (HCS) . HCS acts as an API layer that sits above the container implementation on Windows. Windows containers also leverage the Host Network Service (HNS) that defines the network topology on a node. From a networking perspective, HCS and HNS make Windows containers function like virtual machines. For example, each container has a virtual network adapter (vNIC) that is connected to a Hyper-V virtual switch (vSwitch) as shown in the diagram above.","title":"Windows Container Networking Overview"},{"location":"windows/docs/networking/#ip-management","text":"Windows Server uses an Elastic Network Interface (ENI) to connect to an AWS VPC network. The EKS Container Network Interface (CNI) for Windows currently supports only one ENI per worker node. The number of pods that a Windows worker node can support is dictated by the size and type of the instance. You can calculate max pods using the following formula: (number of primary ENIs * IP Addresses per Interface) - 3 = Total IP addresses available for Pods We subtract 3 IP addresses from the total because the worker node requires one IP for itself, one for the VPC CNI, and one more for kube-proxy. Using the formula above, we can calculate max pods for an m5.large instance. (1 primary ENI * 10 secondary IPs per ENI) - 3 = 7 Note: The reason it only support 7 is because the VPC CNI for Windows only allows us to use the worker node's primary ENI. Also each ENI on an m5.large supports 10 secondary IP addresses, so we subtract 3 from 10 to get our total of 7 IP addresses. For more information on how many IP addresses an instance type can support, see IP addresses per network interface per instance type . Another key consideration is the flow of network traffic. With Windows there is a risk of port exhaustion on nodes with more than 100 services. When this condition arises, the nodes will start throwing errors with the following message: \"Policy creation failed: hcnCreateLoadBalancer failed in Win32: The specified port already exists.\" To address this issue, we leverage Direct Server Return (DSR). DSR is an implementation of asymmetric network load distribution. In other words, the request and response traffic use different network paths. This feature speeds up communication between pods and reduces the risk of port exhaustion. We therefore recommend enabling DSR on Windows nodes. DSR is enabled by default in Windows Server SAC EKS Optimized AMIs. For Windows Server 2019 LTSC EKS Optimized AMIs, you will need to enable it during instance provisioning using the script below and by using Windows Server 2019 Full or Core as the amiFamily in the eksctl nodeGroup. See eksctl custom AMI for additional information. nodeGroups : - name : windows-ng instanceType : c5.xlarge minSize : 1 volumeSize : 50 amiFamily : WindowsServer2019CoreContainer ssh : allow : false In order to utilize DSR in Windows Server 2019 and above, you will need to specify the following kube-proxy flags during instance startup. You can do this by adjusting the userdata script associated with the self-managed node groups Launch Template . < powershell > [string] $EKSBinDir = \"$env:ProgramFiles\\Amazon\\EKS\" [string] $EKSBootstrapScriptName = 'Start-EKSBootstrap.ps1' [string] $EKSBootstrapScriptFile = \"$EKSBinDir\\$EKSBootstrapScriptName\" ( Get-Content $EKSBootstrapScriptFile ). replace ( '\"--proxy-mode=kernelspace\",' , '\"--proxy-mode=kernelspace\", \"--feature-gates WinDSR=true\", \"--enable-dsr\",' ) | Set-Content $EKSBootstrapScriptFile & $EKSBootstrapScriptFile -EKSClusterName \"eks-windows\" -APIServerEndpoint \"https://<REPLACE-EKS-CLUSTER-CONFIG-API-SERVER>\" -Base64ClusterCA \"<REPLACE-EKSCLUSTER-CONFIG-DETAILS-CA>\" -DNSClusterIP \"172.20.0.10\" -KubeletExtraArgs \"--node-labels=alpha.eksctl.io/cluster-name=eks-windows,alpha.eksctl.io/nodegroup-name=windows-ng-ltsc2019 --register-with-taints=\" 3 >& 1 4 >& 1 5 >& 1 6 >& 1 </ powershell > DSR enablement can be verified following the instructions in the Microsoft Networking blog and the Windows Containers on AWS Lab . Using an older versions of Windows will increase the risk of port exhaustion as those versions do not support DSR.","title":"IP Management"},{"location":"windows/docs/networking/#container-network-interface-cni-options","text":"The AWSVPC CNI is the de facto CNI plugin for Windows and Linux worker nodes. While the AWSVPC CNI satisfies the needs of many customers, still there may be times when you need to consider alternatives like an overlay network to avoid IP exhaustion. In these cases, the Calico CNI can be used in place of the AWSVPC CNI. Project Calico is open source software that was developed by Tigera . That software includes a CNI that works with EKS. Instructions for installing Calico CNI in EKS can be found on the Project Calico EKS installation page.","title":"Container Network Interface (CNI) options"},{"location":"windows/docs/networking/#network-polices","text":"It is considered a best practice to change from the default mode of open communication between pods on your Kubernetes cluster to limiting access based on network polices. The open source Project Calico has strong support for network polices that work with both Linux and Windows nodes. This feature is separate and not dependent on using the Calico CNI. We therefore recommend installing Calico and using it for network policy management. Instructions for installing Calico in EKS can be found on the Installing Calico on Amazon EKS page. In addition, the advice provided in the Amazon EKS Best Practices Guide for Security - Network Section applies equally to EKS clusters with Windows worker nodes, however, some features like \"Security Groups for Pods\" are not supported by Windows at this time.","title":"Network Polices"},{"location":"windows/docs/oom/","text":"Avoiding OOM errors \u00b6 Windows does not have an out-of-memory process killer as Linux does. Windows always treats all user-mode memory allocations as virtual, and pagefiles are mandatory. The net effect is that Windows won't reach out of memory conditions the same way Linux does. Processes will page to disk instead of being subject to out of memory (OOM) termination. If memory is over-provisioned and all physical memory is exhausted, then paging can slow down performance. Reserving system and kubelet memory \u00b6 Different from Linux where --kubelet-reserve capture resource reservation for kubernetes system daemons like kubelet, container runtime, etc; and --system-reserve capture resource reservation for OS system daemons like sshd, udev and etc. On Windows these flags do not capture and set memory limits on kubelet or processes running on the node. However, you can combine these flags to manage NodeAllocatable to reduce Capacity on the node with Pod manifest memory resource limit to control memory allocation per pod. Using this strategy you have a better control of memory allocation as well as a mechanism to minimize out-of-memory (OOM) on Windows nodes. On Windows nodes, a best practice is to reserve at least 2GB of memory for the OS and process. Use --kubelet-reserve and/or --system-reserve to reduce NodeAllocatable. Following the Amazon EKS Self-managed Windows nodes documentation, use the CloudFormation template to launch a new Windows node group with customizations to kubelet configuration. The CloudFormation has an element called BootstrapArguments which is the same as KubeletExtraArgs . Use with the following flags and values: --kube-reserved memory = 0 .5Gi,ephemeral-storage = 1Gi --system-reserved memory = 1 .5Gi,ephemeral-storage = 1Gi --eviction-hard memory.available<200Mi,nodefs.available< 10 % \" If eksctl is the deployment tool, check the following documentation to customize the kubelet configuration https://eksctl.io/usage/customizing-the-kubelet/ Windows container memory requirements \u00b6 As per Microsoft documentation , a Windows Server base image for NANO requires at least 30MB, whereas Server Core requires 45MB. These numbers grow as you add Windows components such as the .NET Framework, Web Services as IIS and applications. It is essential for you to know the minimum amount of memory required by your Windows container image, i.e. the base image plus its application layers, and set it as the container's resources/requests in the pod specification. You should also set a limit to avoid pods to consume all the available node memory in case of an application issue. In the example below, when the Kubernetes scheduler tries to place a pod on a node, the pod's requests are used to determine which node has sufficient resources available for scheduling. spec : - name : iis image : mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2019 resources : limits : cpu : 1 memory : 800Mi requests : cpu : .1 memory : 128Mi Conclusion \u00b6 Using this approach minimizes the risks of memory exhaustion but does not prevent it happen. Using Amazon CloudWatch Metrics, you can set up alerts and remediations in case of memory exhaustion occurs.","title":"Memory and Systems Management"},{"location":"windows/docs/oom/#avoiding-oom-errors","text":"Windows does not have an out-of-memory process killer as Linux does. Windows always treats all user-mode memory allocations as virtual, and pagefiles are mandatory. The net effect is that Windows won't reach out of memory conditions the same way Linux does. Processes will page to disk instead of being subject to out of memory (OOM) termination. If memory is over-provisioned and all physical memory is exhausted, then paging can slow down performance.","title":"Avoiding OOM errors"},{"location":"windows/docs/oom/#reserving-system-and-kubelet-memory","text":"Different from Linux where --kubelet-reserve capture resource reservation for kubernetes system daemons like kubelet, container runtime, etc; and --system-reserve capture resource reservation for OS system daemons like sshd, udev and etc. On Windows these flags do not capture and set memory limits on kubelet or processes running on the node. However, you can combine these flags to manage NodeAllocatable to reduce Capacity on the node with Pod manifest memory resource limit to control memory allocation per pod. Using this strategy you have a better control of memory allocation as well as a mechanism to minimize out-of-memory (OOM) on Windows nodes. On Windows nodes, a best practice is to reserve at least 2GB of memory for the OS and process. Use --kubelet-reserve and/or --system-reserve to reduce NodeAllocatable. Following the Amazon EKS Self-managed Windows nodes documentation, use the CloudFormation template to launch a new Windows node group with customizations to kubelet configuration. The CloudFormation has an element called BootstrapArguments which is the same as KubeletExtraArgs . Use with the following flags and values: --kube-reserved memory = 0 .5Gi,ephemeral-storage = 1Gi --system-reserved memory = 1 .5Gi,ephemeral-storage = 1Gi --eviction-hard memory.available<200Mi,nodefs.available< 10 % \" If eksctl is the deployment tool, check the following documentation to customize the kubelet configuration https://eksctl.io/usage/customizing-the-kubelet/","title":"Reserving system and kubelet memory"},{"location":"windows/docs/oom/#windows-container-memory-requirements","text":"As per Microsoft documentation , a Windows Server base image for NANO requires at least 30MB, whereas Server Core requires 45MB. These numbers grow as you add Windows components such as the .NET Framework, Web Services as IIS and applications. It is essential for you to know the minimum amount of memory required by your Windows container image, i.e. the base image plus its application layers, and set it as the container's resources/requests in the pod specification. You should also set a limit to avoid pods to consume all the available node memory in case of an application issue. In the example below, when the Kubernetes scheduler tries to place a pod on a node, the pod's requests are used to determine which node has sufficient resources available for scheduling. spec : - name : iis image : mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2019 resources : limits : cpu : 1 memory : 800Mi requests : cpu : .1 memory : 128Mi","title":"Windows container memory requirements"},{"location":"windows/docs/oom/#conclusion","text":"Using this approach minimizes the risks of memory exhaustion but does not prevent it happen. Using Amazon CloudWatch Metrics, you can set up alerts and remediations in case of memory exhaustion occurs.","title":"Conclusion"},{"location":"windows/docs/patching/","text":"Patching Windows Servers and Containers \u00b6 Patching Windows Server is a standard management task for Windows Administrators. This can be accomplished using different tools like Amazon System Manager - Patch Manager, WSUS, System Center Configuration Manager, and many others. However, Windows nodes in an Amazon EKS cluster should not be treated as an ordinary Windows servers. They should be treated as an immutable server. Simply put, avoid updating an existing node, just launch a new one based on an new updated AMI. Using EC2 Image Builder you can automate AMIs build, by creating recipes and adding components. The following example shows components , which can be pre-existing ones built by AWS (Amazon-managed) as well as the components you create (Owned by me). Pay close attention to the Amazon-managed component called update-windows , this updates Windows Server before generating the AMI through the EC2 Image Builder pipeline. EC2 Image Builder allows you to build AMI's based off Amazon Managed Public AMIs and customize them to meet your business requirements. You can then associate those AMIs with Launch Templates which allows you to link a new AMI to the Auto Scaling Group created by the EKS Nodegroup. After that is complete, you can begin terminating the existing Windows Nodes and new ones will be launched based on the new updated AMI. Pushing and pulling Windows images \u00b6 Amazon publishes EKS optimized AMIs that include two cached Windows container images. mcr.microsoft.com/windows/servercore mcr.microsoft.com/windows/nanoserver Cached images are updated following the updates on the main OS. When Microsoft releases a new Windows update that directly affects the Windows container base image, the update will be launched as an ordinary Windows Update on the main OS. Keeping the environment up-to-date offers a more secure environment at the Node and Container level. The size of a Windows container image influences push/pull operations which can lead to slow container startup times. Caching Windows container images allows the expensive I/O operations (file extraction) to occur on the AMI build creation instead of the container launch. As a result, all the necessary image layers will be extracted on the AMI and will be ready to be used, speeding up the time a Windows container launches and can start accepting traffic. During a push operation, only the layers that compose your image are uploaded to the repository. The following example shows that on the Amazon ECR the fluentd-windows-sac2004 images have only 390.18MB . This is the amount of upload that happened during the push operation. The following example shows a fluentd Windows ltsc image pushed to an Amazon ECR repository. The size of the layer stored in ECR is 533.05MB . The output below from docker image ls , the size of the fluentd v1.14-windows-ltsc2019-1 is 6.96GB on disk, but that doesn't mean it downloaded and extracted that amount of data. In practice, during the pull operation only the compressed 533.05MB will be downloaded and extracted. REPOSITORY TAG IMAGE ID CREATED SIZE 111122223333 .dkr.ecr.us-east-1.amazonaws.com/fluentd-windows-coreltsc latest 721afca2c725 7 weeks ago 6 .96GB fluent/fluentd v1.14-windows-ltsc2019-1 721afca2c725 7 weeks ago 6 .96GB amazonaws.com/eks/pause-windows latest 6392f69ae6e7 10 months ago 255MB The size column shows the overall size of image, 6.96GB. Breaking it down: Windows Server Core 2019 LTSC Base image = 5.74GB Fluentd Uncompressed Base Image = 6.96GB Difference on disk = 1.2GB Fluentd compressed final image ECR = 533.05MB The base image already exists on the local disk, resulting in the total amount on disk being 1.2GB additional. The next time you see the amount of GBs in the size column, don't worry too much, likely more than 70% is already on disk as a cached container image. Reference \u00b6 Speeding up Windows container launch times with EC2 Image builder and image cache strategy","title":"Infrastructure Management"},{"location":"windows/docs/patching/#patching-windows-servers-and-containers","text":"Patching Windows Server is a standard management task for Windows Administrators. This can be accomplished using different tools like Amazon System Manager - Patch Manager, WSUS, System Center Configuration Manager, and many others. However, Windows nodes in an Amazon EKS cluster should not be treated as an ordinary Windows servers. They should be treated as an immutable server. Simply put, avoid updating an existing node, just launch a new one based on an new updated AMI. Using EC2 Image Builder you can automate AMIs build, by creating recipes and adding components. The following example shows components , which can be pre-existing ones built by AWS (Amazon-managed) as well as the components you create (Owned by me). Pay close attention to the Amazon-managed component called update-windows , this updates Windows Server before generating the AMI through the EC2 Image Builder pipeline. EC2 Image Builder allows you to build AMI's based off Amazon Managed Public AMIs and customize them to meet your business requirements. You can then associate those AMIs with Launch Templates which allows you to link a new AMI to the Auto Scaling Group created by the EKS Nodegroup. After that is complete, you can begin terminating the existing Windows Nodes and new ones will be launched based on the new updated AMI.","title":"Patching Windows Servers and Containers"},{"location":"windows/docs/patching/#pushing-and-pulling-windows-images","text":"Amazon publishes EKS optimized AMIs that include two cached Windows container images. mcr.microsoft.com/windows/servercore mcr.microsoft.com/windows/nanoserver Cached images are updated following the updates on the main OS. When Microsoft releases a new Windows update that directly affects the Windows container base image, the update will be launched as an ordinary Windows Update on the main OS. Keeping the environment up-to-date offers a more secure environment at the Node and Container level. The size of a Windows container image influences push/pull operations which can lead to slow container startup times. Caching Windows container images allows the expensive I/O operations (file extraction) to occur on the AMI build creation instead of the container launch. As a result, all the necessary image layers will be extracted on the AMI and will be ready to be used, speeding up the time a Windows container launches and can start accepting traffic. During a push operation, only the layers that compose your image are uploaded to the repository. The following example shows that on the Amazon ECR the fluentd-windows-sac2004 images have only 390.18MB . This is the amount of upload that happened during the push operation. The following example shows a fluentd Windows ltsc image pushed to an Amazon ECR repository. The size of the layer stored in ECR is 533.05MB . The output below from docker image ls , the size of the fluentd v1.14-windows-ltsc2019-1 is 6.96GB on disk, but that doesn't mean it downloaded and extracted that amount of data. In practice, during the pull operation only the compressed 533.05MB will be downloaded and extracted. REPOSITORY TAG IMAGE ID CREATED SIZE 111122223333 .dkr.ecr.us-east-1.amazonaws.com/fluentd-windows-coreltsc latest 721afca2c725 7 weeks ago 6 .96GB fluent/fluentd v1.14-windows-ltsc2019-1 721afca2c725 7 weeks ago 6 .96GB amazonaws.com/eks/pause-windows latest 6392f69ae6e7 10 months ago 255MB The size column shows the overall size of image, 6.96GB. Breaking it down: Windows Server Core 2019 LTSC Base image = 5.74GB Fluentd Uncompressed Base Image = 6.96GB Difference on disk = 1.2GB Fluentd compressed final image ECR = 533.05MB The base image already exists on the local disk, resulting in the total amount on disk being 1.2GB additional. The next time you see the amount of GBs in the size column, don't worry too much, likely more than 70% is already on disk as a cached container image.","title":"Pushing and pulling Windows images"},{"location":"windows/docs/patching/#reference","text":"Speeding up Windows container launch times with EC2 Image builder and image cache strategy","title":"Reference"},{"location":"windows/docs/scheduling/","text":"Assigning PODs to Nodes Best practices \u00b6 In order to keep Linux and Windows workloads on their respective OS-specific nodes, you need to use some combination of node selectors and taints/tolerations. The main goal of scheduling workloads in a heterogeneous environment is to avoid breaking compatibility for existing Linux workloads. Ensuring OS-specific workloads land on the appropriate container host \u00b6 Users can ensure Windows containers can be scheduled on the appropriate host using nodeSelectors. All Kubernetes nodes today have the following default labels: kubernetes.io/os = [windows|linux] kubernetes.io/arch = [amd64|arm64|...] If a Pod specification does not include a nodeSelector like \"kubernetes.io/os\": windows , the Pod may be scheduled on any host, Windows or Linux. This can be problematic since a Windows container can only run on Windows and a Linux container can only run on Linux. In Enterprise environments, it's not uncommon to have a large number of pre-existing deployments for Linux containers, as well as an ecosystem of off-the-shelf configurations, like Helm charts. In these situations, you may be hesitant to make changes to a deployment's nodeSelectors. The alternative is to use Taints . For example: --register-with-taints='os=windows:NoSchedule' If you are using EKS, eksctl offers ways to apply taints through clusterConfig: NodeGroups : - name : windows-ng amiFamily : WindowsServer2019FullContainer ... labels : nodeclass : windows2019 taints : os : \"windows:NoSchedule\" Adding a taint to all Windows nodes, the scheduler will not schedule pods on those nodes unless they tolerate the taint. Pod manifest example: nodeSelector : kubernetes.io/os : windows tolerations : - key : \"os\" operator : \"Equal\" value : \"windows\" effect : \"NoSchedule\" Handling multiple Windows build in the same cluster \u00b6 The Windows container base image used by each pod must match the same kernel build version as the node. If you want to use multiple Windows Server builds in the same cluster, then you should set additional node labels, nodeSelectors or leverage a label called windows-build . Kubernetes 1.17 automatically adds a new label node.kubernetes.io/windows-build to simplify the management of multiple Windows build in the same cluster. If you're running an older version, then it's recommended to add this label manually to Windows nodes. This label reflects the Windows major, minor, and build number that need to match for compatibility. Below are values used today for each Windows Server version. Product Name Build Number(s) Server core 2019 LTSC 10.0.17763 Server core 2004 SAC 10.0.19041 Server core 20H2 SAC 10.0.19042 It is possible to check the OS build version through the following command: kubectl get pods -o wide The KERNEL-VERSION output matches the Windows OS build version. NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-172-31-20-44.ec2.internal Ready <none> 42d v1.18.9-eks-d1db3c 172 .31.20.44 3 .237.46.98 Windows Server 2019 Datacenter 10 .0.17763.1697 docker://19.3.13 ip-172-31-44-38.ec2.internal Ready <none> 42d v1.18.9-eks-d1db3c 172 .31.44.38 54 .91.221.109 Amazon Linux 2 4 .14.209-160.339.amzn2.x86_64 docker://19.3.6 ip-172-31-5-245.ec2.internal Ready <none> 31d v1.18.9-eks-d1db3c 172 .31.5.245 3 .236.151.236 Windows Server Datacenter 10 .0.19041.685 docker://19.3.14 The example below applies an additional nodeSelector to the pod manifest in order to match the correct Windows-build version when running different Windows node groups OS versions. nodeSelector : kubernetes.io/os : windows node.kubernetes.io/windows-build : '10.0.17763' tolerations : - key : \"os\" operator : \"Equal\" value : \"windows\" effect : \"NoSchedule\" Simplifying NodeSelector and Toleration in Pod manifests using RuntimeClass \u00b6 You can also make use of RuntimeClass to simplify the process of using taints and tolerations. This can be accomplished by creating a RuntimeClass object which is used to encapsulate these taints and tolerations. Create a RuntimeClass by running the following manifest: apiVersion : node.k8s.io/v1beta1 kind : RuntimeClass metadata : name : windows-2019 handler : 'docker' scheduling : nodeSelector : kubernetes.io/os : 'windows' kubernetes.io/arch : 'amd64' node.kubernetes.io/windows-build : '10.0.17763' tolerations : - effect : NoSchedule key : os operator : Equal value : \"windows\" Once the Runtimeclass is created, assign it using as a Spec on the Pod manifest: apiVersion : apps/v1 kind : Deployment metadata : name : iis-2019 labels : app : iis-2019 spec : replicas : 1 template : metadata : name : iis-2019 labels : app : iis-2019 spec : runtimeClassName : windows-2019 containers : - name : iis Additional documentations \u00b6 AWS Official Documentation: https://docs.aws.amazon.com/eks/latest/userguide/windows-support.html To better understand how Pod Networking (CNI) works, check the following link: https://docs.aws.amazon.com/eks/latest/userguide/pod-networking.html","title":"Scheduling"},{"location":"windows/docs/scheduling/#assigning-pods-to-nodes-best-practices","text":"In order to keep Linux and Windows workloads on their respective OS-specific nodes, you need to use some combination of node selectors and taints/tolerations. The main goal of scheduling workloads in a heterogeneous environment is to avoid breaking compatibility for existing Linux workloads.","title":"Assigning PODs to Nodes Best practices"},{"location":"windows/docs/scheduling/#ensuring-os-specific-workloads-land-on-the-appropriate-container-host","text":"Users can ensure Windows containers can be scheduled on the appropriate host using nodeSelectors. All Kubernetes nodes today have the following default labels: kubernetes.io/os = [windows|linux] kubernetes.io/arch = [amd64|arm64|...] If a Pod specification does not include a nodeSelector like \"kubernetes.io/os\": windows , the Pod may be scheduled on any host, Windows or Linux. This can be problematic since a Windows container can only run on Windows and a Linux container can only run on Linux. In Enterprise environments, it's not uncommon to have a large number of pre-existing deployments for Linux containers, as well as an ecosystem of off-the-shelf configurations, like Helm charts. In these situations, you may be hesitant to make changes to a deployment's nodeSelectors. The alternative is to use Taints . For example: --register-with-taints='os=windows:NoSchedule' If you are using EKS, eksctl offers ways to apply taints through clusterConfig: NodeGroups : - name : windows-ng amiFamily : WindowsServer2019FullContainer ... labels : nodeclass : windows2019 taints : os : \"windows:NoSchedule\" Adding a taint to all Windows nodes, the scheduler will not schedule pods on those nodes unless they tolerate the taint. Pod manifest example: nodeSelector : kubernetes.io/os : windows tolerations : - key : \"os\" operator : \"Equal\" value : \"windows\" effect : \"NoSchedule\"","title":"Ensuring OS-specific workloads land on the appropriate container host"},{"location":"windows/docs/scheduling/#handling-multiple-windows-build-in-the-same-cluster","text":"The Windows container base image used by each pod must match the same kernel build version as the node. If you want to use multiple Windows Server builds in the same cluster, then you should set additional node labels, nodeSelectors or leverage a label called windows-build . Kubernetes 1.17 automatically adds a new label node.kubernetes.io/windows-build to simplify the management of multiple Windows build in the same cluster. If you're running an older version, then it's recommended to add this label manually to Windows nodes. This label reflects the Windows major, minor, and build number that need to match for compatibility. Below are values used today for each Windows Server version. Product Name Build Number(s) Server core 2019 LTSC 10.0.17763 Server core 2004 SAC 10.0.19041 Server core 20H2 SAC 10.0.19042 It is possible to check the OS build version through the following command: kubectl get pods -o wide The KERNEL-VERSION output matches the Windows OS build version. NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-172-31-20-44.ec2.internal Ready <none> 42d v1.18.9-eks-d1db3c 172 .31.20.44 3 .237.46.98 Windows Server 2019 Datacenter 10 .0.17763.1697 docker://19.3.13 ip-172-31-44-38.ec2.internal Ready <none> 42d v1.18.9-eks-d1db3c 172 .31.44.38 54 .91.221.109 Amazon Linux 2 4 .14.209-160.339.amzn2.x86_64 docker://19.3.6 ip-172-31-5-245.ec2.internal Ready <none> 31d v1.18.9-eks-d1db3c 172 .31.5.245 3 .236.151.236 Windows Server Datacenter 10 .0.19041.685 docker://19.3.14 The example below applies an additional nodeSelector to the pod manifest in order to match the correct Windows-build version when running different Windows node groups OS versions. nodeSelector : kubernetes.io/os : windows node.kubernetes.io/windows-build : '10.0.17763' tolerations : - key : \"os\" operator : \"Equal\" value : \"windows\" effect : \"NoSchedule\"","title":"Handling multiple Windows build in the same cluster"},{"location":"windows/docs/scheduling/#simplifying-nodeselector-and-toleration-in-pod-manifests-using-runtimeclass","text":"You can also make use of RuntimeClass to simplify the process of using taints and tolerations. This can be accomplished by creating a RuntimeClass object which is used to encapsulate these taints and tolerations. Create a RuntimeClass by running the following manifest: apiVersion : node.k8s.io/v1beta1 kind : RuntimeClass metadata : name : windows-2019 handler : 'docker' scheduling : nodeSelector : kubernetes.io/os : 'windows' kubernetes.io/arch : 'amd64' node.kubernetes.io/windows-build : '10.0.17763' tolerations : - effect : NoSchedule key : os operator : Equal value : \"windows\" Once the Runtimeclass is created, assign it using as a Spec on the Pod manifest: apiVersion : apps/v1 kind : Deployment metadata : name : iis-2019 labels : app : iis-2019 spec : replicas : 1 template : metadata : name : iis-2019 labels : app : iis-2019 spec : runtimeClassName : windows-2019 containers : - name : iis","title":"Simplifying NodeSelector and Toleration in Pod manifests using RuntimeClass"},{"location":"windows/docs/scheduling/#additional-documentations","text":"AWS Official Documentation: https://docs.aws.amazon.com/eks/latest/userguide/windows-support.html To better understand how Pod Networking (CNI) works, check the following link: https://docs.aws.amazon.com/eks/latest/userguide/pod-networking.html","title":"Additional documentations"},{"location":"windows/docs/security/","text":"Pod Security Contexts \u00b6 Pod Security Policies (PSP) and Pod Security Standards (PSS) are two main ways of enforcing security in Kubernetes. Note that PodSecurityPolicy is deprecated as of Kubernetes v1.21, and will be removed in v1.25 and Pod Security Standard (PSS) is the Kubernetes recommended approach for enforcing security going forward. A Pod Security Policy (PSP) is a native solution in Kubernetes to implement security policies. PSP is a cluster-level resource that controls security-sensitive aspects of the Pod specification. Using Pod Security Policy you can define a set of conditions that Pods must meet to be accepted by the cluster. The PSP feature has been available from the early days of Kubernetes and is designed to block misconfigured pods from being created on a given cluster. For more information on Pod Security Policies please reference the Kubernetes documentation . According to the Kubernetes deprecation policy , older versions will stop getting support nine months after the deprecation of the feature. On the other hand, Pod Security Standards (PSS) which is the recommended security approach and typically implemented using Security Contexts are defined as part of the Pod and container specifications in the Pod manifest. PSS is the official standard that the Kubernetes project team has defined to address the security-related best practices for Pods. It defines policies such as baseline (minimally restrictive, default), privileged (unrestrictive) and restricted (most restrictive). We recommend starting with the baseline profile. PSS baseline profile provides a solid balance between security and potential friction, requiring a minimal list of exceptions, it serves as a good starting point for workload security. If you are currently using PSPs we recommend switching to PSS. More details on the PSS policies can be found in the Kubernetes documentation . These policies can be enforced with several tools including those from OPA and Kyverno . For example, Kyverno provides the full collection of PSS policies here . Security context settings allow one to give privileges to select processes, use program profiles to restrict capabilities to individual programs, allow privilege escalation, filter system calls, among other things. Windows pods in Kubernetes have some limitations and differentiators from standard Linux-based workloads when it comes to security contexts. Windows uses a Job object per container with a system namespace filter to contain all processes in a container and provide logical isolation from the host. There is no way to run a Windows container without the namespace filtering in place. This means that system privileges cannot be asserted in the context of the host, and thus privileged containers are not available on Windows. The following windowsOptions are the only documented Windows Security Context options while the rest are general Security Context options For a list of security context attributes that are supported in Windows vs linux, please refer to the official documentation here . The Pod specific settings are applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. For example, runAsUserName setting for Pods and containers which is a Windows option is a rough equivalent of the Linux-specific runAsUser setting and in the following manifest, the pod specific security context is applied to all containers apiVersion : v1 kind : Pod metadata : name : run-as-username-pod-demo spec : securityContext : windowsOptions : runAsUserName : \"ContainerUser\" containers : - name : run-as-username-demo ... nodeSelector : kubernetes.io/os : windows Whereas in the following, the container level security context overrides the pod level security context. apiVersion : v1 kind : Pod metadata : name : run-as-username-container-demo spec : securityContext : windowsOptions : runAsUserName : \"ContainerUser\" containers : - name : run-as-username-demo .. securityContext : windowsOptions : runAsUserName : \"ContainerAdministrator\" nodeSelector : kubernetes.io/os : windows Examples of acceptable values for the runAsUserName field: ContainerAdministrator, ContainerUser, NT AUTHORITY\\NETWORK SERVICE, NT AUTHORITY\\LOCAL SERVICE It is generally a good idea to run your containers with ContainerUser for Windows pods. The users are not shared between the container and host but the ContainerAdministrator does have additional privileges with in the container. Note that, there are username limitations to be aware of. A good example of when to use ContainerAdministrator is to set PATH. You can use the USER directive to do that, like so: USER ContainerAdministrator RUN setx /M PATH \"%PATH%;C:/your/path\" USER ContainerUser Also note that, secrets are written in clear text on the node's volume (as compared to tmpfs/in-memory on linux). This means you have to do two things Use file ACLs to secure the secrets file location Use volume-level encryption using BitLocker","title":"Pod Security for Windows Containers"},{"location":"windows/docs/security/#pod-security-contexts","text":"Pod Security Policies (PSP) and Pod Security Standards (PSS) are two main ways of enforcing security in Kubernetes. Note that PodSecurityPolicy is deprecated as of Kubernetes v1.21, and will be removed in v1.25 and Pod Security Standard (PSS) is the Kubernetes recommended approach for enforcing security going forward. A Pod Security Policy (PSP) is a native solution in Kubernetes to implement security policies. PSP is a cluster-level resource that controls security-sensitive aspects of the Pod specification. Using Pod Security Policy you can define a set of conditions that Pods must meet to be accepted by the cluster. The PSP feature has been available from the early days of Kubernetes and is designed to block misconfigured pods from being created on a given cluster. For more information on Pod Security Policies please reference the Kubernetes documentation . According to the Kubernetes deprecation policy , older versions will stop getting support nine months after the deprecation of the feature. On the other hand, Pod Security Standards (PSS) which is the recommended security approach and typically implemented using Security Contexts are defined as part of the Pod and container specifications in the Pod manifest. PSS is the official standard that the Kubernetes project team has defined to address the security-related best practices for Pods. It defines policies such as baseline (minimally restrictive, default), privileged (unrestrictive) and restricted (most restrictive). We recommend starting with the baseline profile. PSS baseline profile provides a solid balance between security and potential friction, requiring a minimal list of exceptions, it serves as a good starting point for workload security. If you are currently using PSPs we recommend switching to PSS. More details on the PSS policies can be found in the Kubernetes documentation . These policies can be enforced with several tools including those from OPA and Kyverno . For example, Kyverno provides the full collection of PSS policies here . Security context settings allow one to give privileges to select processes, use program profiles to restrict capabilities to individual programs, allow privilege escalation, filter system calls, among other things. Windows pods in Kubernetes have some limitations and differentiators from standard Linux-based workloads when it comes to security contexts. Windows uses a Job object per container with a system namespace filter to contain all processes in a container and provide logical isolation from the host. There is no way to run a Windows container without the namespace filtering in place. This means that system privileges cannot be asserted in the context of the host, and thus privileged containers are not available on Windows. The following windowsOptions are the only documented Windows Security Context options while the rest are general Security Context options For a list of security context attributes that are supported in Windows vs linux, please refer to the official documentation here . The Pod specific settings are applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. For example, runAsUserName setting for Pods and containers which is a Windows option is a rough equivalent of the Linux-specific runAsUser setting and in the following manifest, the pod specific security context is applied to all containers apiVersion : v1 kind : Pod metadata : name : run-as-username-pod-demo spec : securityContext : windowsOptions : runAsUserName : \"ContainerUser\" containers : - name : run-as-username-demo ... nodeSelector : kubernetes.io/os : windows Whereas in the following, the container level security context overrides the pod level security context. apiVersion : v1 kind : Pod metadata : name : run-as-username-container-demo spec : securityContext : windowsOptions : runAsUserName : \"ContainerUser\" containers : - name : run-as-username-demo .. securityContext : windowsOptions : runAsUserName : \"ContainerAdministrator\" nodeSelector : kubernetes.io/os : windows Examples of acceptable values for the runAsUserName field: ContainerAdministrator, ContainerUser, NT AUTHORITY\\NETWORK SERVICE, NT AUTHORITY\\LOCAL SERVICE It is generally a good idea to run your containers with ContainerUser for Windows pods. The users are not shared between the container and host but the ContainerAdministrator does have additional privileges with in the container. Note that, there are username limitations to be aware of. A good example of when to use ContainerAdministrator is to set PATH. You can use the USER directive to do that, like so: USER ContainerAdministrator RUN setx /M PATH \"%PATH%;C:/your/path\" USER ContainerUser Also note that, secrets are written in clear text on the node's volume (as compared to tmpfs/in-memory on linux). This means you have to do two things Use file ACLs to secure the secrets file location Use volume-level encryption using BitLocker","title":"Pod Security Contexts"},{"location":"windows/docs/storage/","text":"Persistent storage options \u00b6 What is an in-tree vs. out-of-tree volume plugin? \u00b6 Before the introduction of the Container Storage Interface (CSI), all volume plugins were in-tree meaning they were built, linked, compiled, and shipped with the core Kubernetes binaries and extend the core Kubernetes API. This meant that adding a new storage system to Kubernetes (a volume plugin) required checking code into the core Kubernetes code repository. Out-of-tree volume plugins are developed independently of the Kubernetes code base, and are deployed (installed) on Kubernetes clusters as extensions. This gives vendors the ability to update drivers out-of-band, i.e. separately from the Kubernetes release cycle. This is largely possible because Kubernetes has created a storage interface or CSI that provides vendors a standard way of interfacing with k8s. You can check more about Amazon Elastic Kubernetes Services (EKS) storage classes and CSI Drivers on https://docs.aws.amazon.com/eks/latest/userguide/storage.html In-tree Volume Plugin for Windows \u00b6 Kubernetes volumes enable applications, with data persistence requirements, to be deployed on Kubernetes. The management of persistent volumes consists of provisioning/de-provisioning/resizing of volumes, attaching/detaching a volume to/from a Kubernetes node, and mounting/dismounting a volume to/from individual containers in a pod. The code for implementing these volume management actions for a specific storage back-end or protocol is shipped in the form of a Kubernetes volume plugin (In-tree Volume Plugins) . On Amazon Elastic Kubernetes Services (EKS) the following class of Kubernetes volume plugins are supported on Windows: In-tree Volume Plugin: awsElasticBlockStore In order to use In-tree volume plugin on Windows nodes, it is necessary to create an additional StorageClass to use NTFS as the fsType. On EKS, the default StorageClass uses ext4 as the default fsType. A StorageClass provides a way for administrators to describe the \"classes\" of storage they offer. Different classes might map to quality-of-service levels, backup policies, or arbitrary policies determined by the cluster administrators. Kubernetes is unopinionated about what classes represent. This concept is sometimes called \"profiles\" in other storage systems. You can check it by running the following command: kubectl describe storageclass gp2 Output: Name: gp2 IsDefaultClass: Yes Annotations: kubectl.kubernetes.io/last-applied-configuration ={ \"apiVersion\" : \"storage.k8s.io/v1\" , \"kind\" : \"StorageClas \" , \"metadata\" : { \"annotations\" : { \"storageclass.kubernetes.io/is-default-class\" : \"true\" } , \"name\" : \"gp2\" } , \"parameters\" : { \"fsType\" \"ext4\" , \"type\" : \"gp2\" } , \"provisioner\" : \"kubernetes.io/aws-ebs\" , \"volumeBindingMode\" : \"WaitForFirstConsumer\" } ,storageclass.kubernetes.io/is-default-class = true Provisioner: kubernetes.io/aws-ebs Parameters: fsType = ext4,type = gp2 AllowVolumeExpansion: <unset> MountOptions: <none> ReclaimPolicy: Delete VolumeBindingMode: WaitForFirstConsumer Events: <none> To create the new StorageClass to support NTFS , use the following manifest: kind : StorageClass apiVersion : storage.k8s.io/v1 metadata : name : gp2-windows provisioner : kubernetes.io/aws-ebs parameters : type : gp2 fsType : ntfs volumeBindingMode : WaitForFirstConsumer Create the StorageClass by running the following command: kubectl apply -f NTFSStorageClass.yaml The next step is to create a Persistent Volume Claim (PVC). A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using PVC. It is a resource in the cluster just like a node is a cluster resource. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system. A PersistentVolumeClaim (PVC) is a request for storage by a user. Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany). Users need PersistentVolumes with different attributes, such as performance, for different use cases. Cluster administrators need to be able to offer a variety of PersistentVolumes that differ in more ways than just size and access modes, without exposing users to the details of how those volumes are implemented. For these needs, there is the StorageClass resource. In the example below, the PVC has been created within the namespace windows. apiVersion : v1 kind : PersistentVolumeClaim metadata : name : ebs-windows-pv-claim namespace : windows spec : accessModes : - ReadWriteOnce storageClassName : gp2-windows resources : requests : storage : 1Gi Create the PVC by running the following command: kubectl apply -f persistent-volume-claim.yaml The following manifest creates a Windows Pod, setup the VolumeMount as C:\\Data and uses the PVC as the attached storage on C:\\Data . apiVersion : apps/v1 kind : Deployment metadata : name : windows-server-ltsc2019 namespace : windows spec : selector : matchLabels : app : windows-server-ltsc2019 tier : backend track : stable replicas : 1 template : metadata : labels : app : windows-server-ltsc2019 tier : backend track : stable spec : containers : - name : windows-server-ltsc2019 image : mcr.microsoft.com/windows/servercore:ltsc2019 ports : - name : http containerPort : 80 imagePullPolicy : IfNotPresent volumeMounts : - mountPath : \"C:\\\\data\" name : test-volume volumes : - name : test-volume persistentVolumeClaim : claimName : ebs-windows-pv-claim nodeSelector : kubernetes.io/os : windows node.kubernetes.io/windows-build : '10.0.17763' Test the results by accessing the Windows pod via PowerShell: kubectl exec -it podname powershell -n windows Inside the Windows Pod, run: ls Output: PS C: \\> ls Directory: C: \\ Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 3 /8/2021 1 :54 PM data d----- 3 /8/2021 3 :37 PM inetpub d-r--- 1 /9/2021 7 :26 AM Program Files d----- 1 /9/2021 7 :18 AM Program Files ( x86 ) d-r--- 1 /9/2021 7 :28 AM Users d----- 3 /8/2021 3 :36 PM var d----- 3 /8/2021 3 :36 PM Windows -a---- 12 /7/2019 4 :20 AM 5510 License.txt The data directory is provided by the EBS volume. Out-of-tree for Windows \u00b6 Code associated with CSI plugins ship as out-of-tree scripts and binaries that are typically distributed as container images and deployed using standard Kubernetes constructs like DaemonSets and StatefulSets. CSI plugins handle a wide range of volume management actions in Kubernetes. CSI plugins typically consist of node plugins (that run on each node as a DaemonSet) and controller plugins. CSI node plugins (especially those associated with persistent volumes exposed as either block devices or over a shared file-system) need to perform various privileged operations like scanning of disk devices, mounting of file systems, etc. These operations differ for each host operating system. For Linux worker nodes, containerized CSI node plugins are typically deployed as privileged containers. For Windows worker nodes, privileged operations for containerized CSI node plugins is supported using csi-proxy , a community-managed, stand-alone binary that needs to be pre-installed on each Windows node. The Amazon EKS Optimized Windows AMI does not contain the CSI-Proxy executable by default. Amazon FSx for Windows File Server \u00b6 An option is to use Amazon FSx for Windows File Server through an SMB feature called SMB Global Mapping which makes it possible to mount a SMB share on the host, then pass directories on that share into a container. The container doesn't need to be configured with a specific server, share, username or password - that's all handled on the host instead. The container will work the same as if it had local storage. The SMB Global Mapping is transparent to the orchestrator, and it is mounted through HostPath which can imply in secure concerns . In the example below, the path G:\\Directory\\app-state is an SMB share on the Windows Node. apiVersion : v1 kind : Pod metadata : name : test-fsx spec : containers : - name : test-fsx image : mcr.microsoft.com/windows/servercore:ltsc2019 command : - powershell.exe - -command - \"Add-WindowsFeature Web-Server; Invoke-WebRequest -UseBasicParsing -Uri 'https://dotnetbinaries.blob.core.windows.net/servicemonitor/2.0.1.6/ServiceMonitor.exe' -OutFile 'C:\\\\ServiceMonitor.exe'; echo '<html><body><br/><br/><marquee><H1>Hello EKS!!!<H1><marquee></body><html>' > C:\\\\inetpub\\\\wwwroot\\\\default.html; C:\\\\ServiceMonitor.exe 'w3svc'; \" volumeMounts : - mountPath : C:\\dotnetapp\\app-state name : test-mount volumes : - name : test-mount hostPath : path : G:\\Directory\\app-state type : Directory nodeSelector : beta.kubernetes.io/os : windows beta.kubernetes.io/arch : amd64 The following blog has implementation details on how to setup Amazon FSx for Windows File Server as a persistent storage for Windows Pods.","title":"Storage Options"},{"location":"windows/docs/storage/#persistent-storage-options","text":"","title":"Persistent storage options"},{"location":"windows/docs/storage/#what-is-an-in-tree-vs-out-of-tree-volume-plugin","text":"Before the introduction of the Container Storage Interface (CSI), all volume plugins were in-tree meaning they were built, linked, compiled, and shipped with the core Kubernetes binaries and extend the core Kubernetes API. This meant that adding a new storage system to Kubernetes (a volume plugin) required checking code into the core Kubernetes code repository. Out-of-tree volume plugins are developed independently of the Kubernetes code base, and are deployed (installed) on Kubernetes clusters as extensions. This gives vendors the ability to update drivers out-of-band, i.e. separately from the Kubernetes release cycle. This is largely possible because Kubernetes has created a storage interface or CSI that provides vendors a standard way of interfacing with k8s. You can check more about Amazon Elastic Kubernetes Services (EKS) storage classes and CSI Drivers on https://docs.aws.amazon.com/eks/latest/userguide/storage.html","title":"What is an in-tree vs. out-of-tree volume plugin?"},{"location":"windows/docs/storage/#in-tree-volume-plugin-for-windows","text":"Kubernetes volumes enable applications, with data persistence requirements, to be deployed on Kubernetes. The management of persistent volumes consists of provisioning/de-provisioning/resizing of volumes, attaching/detaching a volume to/from a Kubernetes node, and mounting/dismounting a volume to/from individual containers in a pod. The code for implementing these volume management actions for a specific storage back-end or protocol is shipped in the form of a Kubernetes volume plugin (In-tree Volume Plugins) . On Amazon Elastic Kubernetes Services (EKS) the following class of Kubernetes volume plugins are supported on Windows: In-tree Volume Plugin: awsElasticBlockStore In order to use In-tree volume plugin on Windows nodes, it is necessary to create an additional StorageClass to use NTFS as the fsType. On EKS, the default StorageClass uses ext4 as the default fsType. A StorageClass provides a way for administrators to describe the \"classes\" of storage they offer. Different classes might map to quality-of-service levels, backup policies, or arbitrary policies determined by the cluster administrators. Kubernetes is unopinionated about what classes represent. This concept is sometimes called \"profiles\" in other storage systems. You can check it by running the following command: kubectl describe storageclass gp2 Output: Name: gp2 IsDefaultClass: Yes Annotations: kubectl.kubernetes.io/last-applied-configuration ={ \"apiVersion\" : \"storage.k8s.io/v1\" , \"kind\" : \"StorageClas \" , \"metadata\" : { \"annotations\" : { \"storageclass.kubernetes.io/is-default-class\" : \"true\" } , \"name\" : \"gp2\" } , \"parameters\" : { \"fsType\" \"ext4\" , \"type\" : \"gp2\" } , \"provisioner\" : \"kubernetes.io/aws-ebs\" , \"volumeBindingMode\" : \"WaitForFirstConsumer\" } ,storageclass.kubernetes.io/is-default-class = true Provisioner: kubernetes.io/aws-ebs Parameters: fsType = ext4,type = gp2 AllowVolumeExpansion: <unset> MountOptions: <none> ReclaimPolicy: Delete VolumeBindingMode: WaitForFirstConsumer Events: <none> To create the new StorageClass to support NTFS , use the following manifest: kind : StorageClass apiVersion : storage.k8s.io/v1 metadata : name : gp2-windows provisioner : kubernetes.io/aws-ebs parameters : type : gp2 fsType : ntfs volumeBindingMode : WaitForFirstConsumer Create the StorageClass by running the following command: kubectl apply -f NTFSStorageClass.yaml The next step is to create a Persistent Volume Claim (PVC). A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using PVC. It is a resource in the cluster just like a node is a cluster resource. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system. A PersistentVolumeClaim (PVC) is a request for storage by a user. Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany). Users need PersistentVolumes with different attributes, such as performance, for different use cases. Cluster administrators need to be able to offer a variety of PersistentVolumes that differ in more ways than just size and access modes, without exposing users to the details of how those volumes are implemented. For these needs, there is the StorageClass resource. In the example below, the PVC has been created within the namespace windows. apiVersion : v1 kind : PersistentVolumeClaim metadata : name : ebs-windows-pv-claim namespace : windows spec : accessModes : - ReadWriteOnce storageClassName : gp2-windows resources : requests : storage : 1Gi Create the PVC by running the following command: kubectl apply -f persistent-volume-claim.yaml The following manifest creates a Windows Pod, setup the VolumeMount as C:\\Data and uses the PVC as the attached storage on C:\\Data . apiVersion : apps/v1 kind : Deployment metadata : name : windows-server-ltsc2019 namespace : windows spec : selector : matchLabels : app : windows-server-ltsc2019 tier : backend track : stable replicas : 1 template : metadata : labels : app : windows-server-ltsc2019 tier : backend track : stable spec : containers : - name : windows-server-ltsc2019 image : mcr.microsoft.com/windows/servercore:ltsc2019 ports : - name : http containerPort : 80 imagePullPolicy : IfNotPresent volumeMounts : - mountPath : \"C:\\\\data\" name : test-volume volumes : - name : test-volume persistentVolumeClaim : claimName : ebs-windows-pv-claim nodeSelector : kubernetes.io/os : windows node.kubernetes.io/windows-build : '10.0.17763' Test the results by accessing the Windows pod via PowerShell: kubectl exec -it podname powershell -n windows Inside the Windows Pod, run: ls Output: PS C: \\> ls Directory: C: \\ Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 3 /8/2021 1 :54 PM data d----- 3 /8/2021 3 :37 PM inetpub d-r--- 1 /9/2021 7 :26 AM Program Files d----- 1 /9/2021 7 :18 AM Program Files ( x86 ) d-r--- 1 /9/2021 7 :28 AM Users d----- 3 /8/2021 3 :36 PM var d----- 3 /8/2021 3 :36 PM Windows -a---- 12 /7/2019 4 :20 AM 5510 License.txt The data directory is provided by the EBS volume.","title":"In-tree Volume Plugin for Windows"},{"location":"windows/docs/storage/#out-of-tree-for-windows","text":"Code associated with CSI plugins ship as out-of-tree scripts and binaries that are typically distributed as container images and deployed using standard Kubernetes constructs like DaemonSets and StatefulSets. CSI plugins handle a wide range of volume management actions in Kubernetes. CSI plugins typically consist of node plugins (that run on each node as a DaemonSet) and controller plugins. CSI node plugins (especially those associated with persistent volumes exposed as either block devices or over a shared file-system) need to perform various privileged operations like scanning of disk devices, mounting of file systems, etc. These operations differ for each host operating system. For Linux worker nodes, containerized CSI node plugins are typically deployed as privileged containers. For Windows worker nodes, privileged operations for containerized CSI node plugins is supported using csi-proxy , a community-managed, stand-alone binary that needs to be pre-installed on each Windows node. The Amazon EKS Optimized Windows AMI does not contain the CSI-Proxy executable by default.","title":"Out-of-tree for Windows"},{"location":"windows/docs/storage/#amazon-fsx-for-windows-file-server","text":"An option is to use Amazon FSx for Windows File Server through an SMB feature called SMB Global Mapping which makes it possible to mount a SMB share on the host, then pass directories on that share into a container. The container doesn't need to be configured with a specific server, share, username or password - that's all handled on the host instead. The container will work the same as if it had local storage. The SMB Global Mapping is transparent to the orchestrator, and it is mounted through HostPath which can imply in secure concerns . In the example below, the path G:\\Directory\\app-state is an SMB share on the Windows Node. apiVersion : v1 kind : Pod metadata : name : test-fsx spec : containers : - name : test-fsx image : mcr.microsoft.com/windows/servercore:ltsc2019 command : - powershell.exe - -command - \"Add-WindowsFeature Web-Server; Invoke-WebRequest -UseBasicParsing -Uri 'https://dotnetbinaries.blob.core.windows.net/servicemonitor/2.0.1.6/ServiceMonitor.exe' -OutFile 'C:\\\\ServiceMonitor.exe'; echo '<html><body><br/><br/><marquee><H1>Hello EKS!!!<H1><marquee></body><html>' > C:\\\\inetpub\\\\wwwroot\\\\default.html; C:\\\\ServiceMonitor.exe 'w3svc'; \" volumeMounts : - mountPath : C:\\dotnetapp\\app-state name : test-mount volumes : - name : test-mount hostPath : path : G:\\Directory\\app-state type : Directory nodeSelector : beta.kubernetes.io/os : windows beta.kubernetes.io/arch : amd64 The following blog has implementation details on how to setup Amazon FSx for Windows File Server as a persistent storage for Windows Pods.","title":"Amazon FSx for Windows File Server"}]}